---
title: "FFmpeg文档" # Title of the blog post.
date: 2021-05-12T20:37:14+08:00 # Date of post creation.
description: "Article description." # Description used for search engine.
featured: true # Sets if post is a featured post, making it appear on the sidebar. A featured post won't be listed on the sidebar if it's the current page
draft: false # Sets whether to render this page. Draft of true will not be rendered.
toc: false # Controls if a table of contents should be generated for first-level links automatically.
# menu: main
#featureImage: "/images/path/file.jpg" # Sets featured image on blog post.
#thumbnail: "/images/path/thumbnail.png" # Sets thumbnail image appearing inside card on homepage.
shareImage: "/images/path/share.png" # Designate a separate image for social media sharing.
codeMaxLines: 10 # Override global value for how many lines within a code block before auto-collapsing.
codeLineNumbers: false # Override global value for showing of line numbers within code block.
figurePositionShow: true # Override global value for showing the figure label.
categories:
  - ffmpeg
tags:
  - ffmpeg
  - video
  - audio
---

<!--more-->
**目录**

[第一章 多媒体概念介绍	6](#_Toc32313)

[1.1视频格式	6](#_Toc17137)

[1.1.1常见格式	6](#_Toc12689)

[1.2音频格式	9](#_Toc2251)

[1.2.1常见格式	9](#_Toc19841)

[1.2.2比较	15](#_Toc17696)

[1.3字幕格式	15](#_Toc24108)

[1.3.1外挂字幕与内嵌字幕的阐述	15](#_Toc24511)

[1.3.2外挂字幕视频与内嵌字幕视频的画面比较	15](#_Toc20370)

[1.3.3外挂字幕的三种格式	15](#_Toc21096)

[1.4采集录制和播放渲染	16](#_Toc811)

[1.4.1视频采集	16](#_Toc29826)

[1.4.2视频录制	17](#_Toc18251)

[1.4.3视频渲染	17](#_Toc1398)

[1.5编解码器	18](#_Toc26258)

[1.6容器和协议	19](#_Toc29396)

[1.6.1容器格式和编码格式	19](#_Toc30715)

[1.6.2协议	26](#_Toc175)

[1.6.2.1 视频协议	26](#_Toc7240)

[1.6.2.2 音频协议.	26](#_Toc28117)

[1.6.2.3 上层通讯协议	27](#_Toc31701)

[1.7常用概念介绍	27](#_Toc15054)

[1.7.1硬解	27](#_Toc12325)

[1.7.2 IBP帧	28](#_Toc12743)

[1.7.3 DTS和PTS	31](#_Toc24222)

[1.7.4 分辨率	31](#_Toc32463)

[1.7.5 码率	32](#_Toc13900)

[1.7.6 帧率	32](#_Toc25366)

[1.7.7 RGB和YUV	32](#_Toc20649)

[1.7.8 实时和非实时	32](#_Toc8973)

[1.7.9 复合视频和s-video	32](#_Toc13755)

[1.7.10 硬件加速	32](#_Toc3733)

[1.7.11 FFmpeg Device	32](#_Toc1541)

[第二章 FFmpeg框架	34](#_Toc15271)

[2.1 FFmpeg概述	34](#_Toc8480)

[2.1.1简介	34](#_Toc3851)

[2.1.2功能	34](#_Toc5621)

[2.1.3模块组成	35](#_Toc19495)

[2.1.4命令集	35](#_Toc20974)

[2.2 媒体播放器三大底层框架	37](#_Toc27630)

[第三章 编译及简单应用	41](#_Toc28320)

[3.1 FFmpeg库编译和入门介绍 41	41](#_Toc15462)

[3.2 流媒体数据流程讲解	49](#_Toc14769)

[3.3 简单应用	51](#_Toc5486)

[3.4 SDL（ Simple Direct Layer）	55](#_Toc12554)

[3.4.1 SDL显示视频	55](#_Toc5290)

[3.4.2 SDL显示音频	55](#_Toc15775)

[3.5 ffmpeg程序的使用（ffmpeg.exe，ffplay.exe，ffprobe.exe）	56](#_Toc8630)

[3.5.1 ffmpeg.exe	56](#_Toc2371)

[3.5.2 ffplay.exe	56](#_Toc17682)

[3.5.3 ffprobe.exe	56](#_Toc28783)

[第四章 数据结构	57](#_Toc28526)

[4.1  AVCodec结构体	59](#_Toc22239)

[4.2  AVCodecContext结构体	59](#_Toc31796)

[4.3  AVInputFormat结构体	60](#_Toc7790)

[4.4  AVFormatContext结构体	61](#_Toc20868)

[4.5  MovContext结构体	62](#_Toc14757)

[4.6  URLProtocol结构体	62](#_Toc20740)

[4.7  URLContext结构体	63](#_Toc24527)

[4.8  AVIOContext结构体(老版本为：ByteIOContext)	63](#_Toc10284)

[4.9  AVStream结构体	64](#_Toc22156)

[4.10  MOVStreamContext 结构体	65](#_Toc17400)

[4.11  AVPacket 结构体	66](#_Toc9538)

[4.12  AVPacketList 结构体	67](#_Toc2853)

[4.13 AVFrame结构体	67](#_Toc26851)

[第五章 重要模块	76](#_Toc23401)

[5.1 libavutil公共模块	76](#_Toc29385)

[1 文件列表	76](#_Toc26942)

[2 common.h 文件	76](#_Toc29647)

[3 bswap.h 文件	78](#_Toc24381)

[4 rational.h 文件	79](#_Toc15559)

[5 mathematics.h 文件	80](#_Toc16666)

[6 avutil.h 文件	80](#_Toc10234)

[5.2 libavcodec编解码模块	82](#_Toc30659)

[1 文件列表	82](#_Toc7002)

[2 avcodec.h 文件	82](#_Toc22320)

[3 allcodec.c 文件	87](#_Toc20874)

[4 dsputil.h 文件	87](#_Toc13278)

[5 dsputil.c 文件	88](#_Toc18411)

[6 utils_codec.c 文件	88](#_Toc3349)

[7 imgconvert_template.h 文件	99](#_Toc25168)

[8 imgconvert.c 文件	121](#_Toc14950)

[9 msrle.c 文件	164](#_Toc6404)

[10 turespeech_data.h 文件	171](#_Toc15870)

[11 turespeech.c 文件	174](#_Toc27714)

[5.3 libavformat容器模块	184](#_Toc10955)

[1 文件列表	184](#_Toc28769)

[2 avformat.h 文件	184](#_Toc17537)

[3 allformat.c 文件	190](#_Toc8236)

[4 cutils.c 文件	190](#_Toc28923)

[5 file.c 文件	192](#_Toc20297)

[6 avio.h 文件	194](#_Toc3483)

[7 avio.c 文件	196](#_Toc9378)

[8 aviobuf.c 文件	200](#_Toc4230)

[9 utils_format.c 文件	209](#_Toc1311)

[10 avidec.c 文件	220](#_Toc23799)

[5.4 libswscale视频色彩空间转换	243](#_Toc22841)

[5.5 libswresample音频重采样	243](#_Toc11008)

[5.6 libavfilter音视频滤器	243](#_Toc11316)

[5.7 libavdevice设备输入和输出容器	243](#_Toc9837)

[5.8 libpostproc视频后期处理	243](#_Toc23031)

[第六章 播放器	243](#_Toc17832)

[6.1 视频播放器	243](#_Toc26847)

[6.1.1 ffmpeg库的配置	243](#_Toc8394)

[6.1.2 一个简单的视频播放器	244](#_Toc22279)

[6.2 音频播放器	247](#_Toc4678)

[6.3 一个完整的播放器--ffplay	253](#_Toc7888)

[6.3.1 ffplay流程图	253](#_Toc30159)

[6.3.2 ffplay源码剖析	254](#_Toc5297)

[第七章 应用开发	275](#_Toc16218)

[7.1 ffmpeg库的使用：编码	275](#_Toc4257)

[第八章 关键函数介绍	280](#_Toc13180)

[8.1 avformat_open_input	280](#_Toc10122)

[8.2 avcodec_register_all()	281](#_Toc4978)

[8.3 av_read_frame()	283](#_Toc7598)

[8.4 avcodec_decode_video2()	283](#_Toc25230)

[8.5 transcode_init()	283](#_Toc16616)

[8.6 transcode()	294](#_Toc22492)

[第九章 ffmpeg相关工程	301](#_Toc4647)

[9.1 ffdshow	301](#_Toc26182)

[ffdshow 源代码分析1 ： 整体结构	302](#_Toc8089)

[ffdshow 源代码分析 2： 位图覆盖滤镜（对话框部分Dialog）	304](#_Toc22141)

[ffdshow 源代码分析 3： 位图覆盖滤镜（设置部分Settings）	312](#_Toc15715)

[ffdshow 源代码分析 4： 位图覆盖滤镜（滤镜部分Filter）	317](#_Toc2412)

[ffdshow 源代码分析 5： 位图覆盖滤镜（总结）	322](#_Toc30933)

[ffdshow 源代码分析 6： 对解码器的dll的封装（libavcodec）	322](#_Toc28417)

[ffdshow 源代码分析 8： 视频解码器类（TvideoCodecDec）	344](#_Toc17015)

[ffdshow 源代码分析 9： 编解码器有关类的总结	352](#_Toc23700)

[9.2 LAV filters	357](#_Toc28016)

[LAV Filter 源代码分析 1： 总体结构	357](#_Toc1845)

[LAV Filter 源代码分析 2： LAV Splitter	358](#_Toc22280)

[LAV Filter 源代码分析 3： LAV Video （1）	382](#_Toc18848)

[LAV Filter 源代码分析 4： LAV Video （2）	400](#_Toc24404)

[9.3 MPlayer	427](#_Toc23216)

[9.3.1 Mplayer支持的格式	427](#_Toc25693)

[9.3.2 Mplayer 中头文件的功能分析	427](#_Toc134)

[9.3.3 MPlayer.main 主流程简要说明	428](#_Toc15151)

[9.3.4 Mplayer源码分析	429](#_Toc28089)

[第十章 开发实例	436](#_Toc16056)

[第十一章 mp4文件封装协议分析	436](#_Toc8531)

[11.1  概述	436](#_Toc2665)

[11.2  mp4的物理结构	436](#_Toc10085)

[11.3  数据的组织结构	437](#_Toc26343)

[11.4  mp4的时间结构	437](#_Toc18288)

[11.5  文件结构分析	438](#_Toc24921)

[11.5.1  File Type Box（ftyp）	438](#_Toc22272)

[11.5.2  Movie Box（moov）	438](#_Toc2582)

[第十二章 flv 文件格式分析	457](#_Toc23076)

[12.1  概述	457](#_Toc32184)

[12.2  文件总体结构	457](#_Toc10414)

[12.3  文件结构分析	458](#_Toc13287)

[12.3.1  flv文件头的结构	458](#_Toc18011)

[12.3.2  body主体结构	459](#_Toc10582)

[附录A：常见问题	465](#_Toc19794)

[1 ffmpeg 从内存中读取数据	465](#_Toc26309)

[2 MFC中使用SDL播放音频没有声音的解决方法	465](#_Toc1446)

[附录B：经典代码示例	466](#_Toc13579)

[附录c：ffmpeg参数中文详细解释	477](#_Toc22959)

[附录D：ffplay的快捷键以及选项	479](#_Toc3701)

[附录E： ffmpeg处理rtmp流媒体	481](#_Toc5762)




# **第一章 多媒体概念介绍**
## **1.1视频格式**
视频格式可以分为适合本地播放的本地影像视频和适合在网络中播放的网络流媒体影像视频两大类。尽管后者在播放的稳定性和播放画面质量上可能没有前者优秀，但网络流媒体影像视频的广泛传播性使之正被广泛应用于视频点播、网络演示、远程教育、网络视频广告等等互联网信息服务领域。

注：原始的视频数据可以理解为通过摄像头等驱动获取的没有经过编码的数据，市面上usb摄像头输出格式常见的有：RGB24、YUV2、YV2（这些都是没有编码的原始数据），MJPEG（经过编码的数据）。摄像头捕捉的数据也是可以设置的，比如windows下用cap来设置。
### **1.1.1常见格式**
[**MPEG](http://baike.baidu.com/view/7689.htm)**/[MPG](http://baike.baidu.com/view/7711.htm)/[DAT**](http://baike.baidu.com/view/387002.htm)**

[MPEG](http://baike.baidu.com/view/7689.htm)（运动图像专家组）是Motion Picture Experts Group 的缩写。这类格式包括了[MPEG-1](http://baike.baidu.com/view/7739.htm),[MPEG-2](http://baike.baidu.com/view/7747.htm)和[MPEG-4](http://baike.baidu.com/view/7754.htm)在内的多种视频格式。MPEG-1相信是大家接触得最多的了，因为其正在被广泛地应用在VCD 的制作和一些视频片段下载的网络应用上面，大部分的[VCD](http://baike.baidu.com/view/7313.htm)都是用MPEG1 格式压缩的( 刻录软件自动将MPEG1转换为DAT格式 ) ，使用MPEG-1 的压缩算法，可以把一部120 分钟长的电影压缩到1.2 GB 左右大小。MPEG-2 则是应用在DVD 的制作，同时在一些[HDTV](http://baike.baidu.com/view/8295.htm)（高清晰电视广播）和一些高要求[视频编辑](http://baike.baidu.com/view/2795688.htm)、处理上面也有相当多的应用。使用MPEG-2 的压缩算法压缩一部120 分钟长的电影可以压缩到5-8 GB 的大小（MPEG2的图像质量是MPEG-1 无法比拟的）。MPEG系列标准已成为国际上影响最大的[多媒体](http://baike.baidu.com/view/3323.htm)[技术标准](http://baike.baidu.com/view/9164.htm)，其中MPEG-1和MPEG-2是采用相同原理为基础的[预测编码](http://baike.baidu.com/view/1051749.htm)、变换编码、[熵编码](http://baike.baidu.com/view/182718.htm)及运动补偿等第一代数据压缩编码技术；MPEG-4（ISO/IEC 14496）则是基于第二代压缩编码技术制定的国际标准，它以视听媒体对象为[基本单元](http://baike.baidu.com/view/693012.htm)，采用基于内容的压缩编码，以实现数字视音频、图形合成应用及交互式多媒体的集成。MPEG系列标准对VCD、DVD等视听消费电子及数字电视和[高清晰度电视](http://baike.baidu.com/view/70858.htm)（DTV&&HDTV）、[多媒体](http://baike.baidu.com/view/3323.htm)通信等信息产业的发展产生了巨大而深远的影响。

![视频格式](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.001.jpeg "cc11728b4710b912cd01005cc3fdfc039345224b")

[**AVI**](http://baike.baidu.com/view/7697.htm)

[AVI](http://baike.baidu.com/view/7697.htm)，音频视频交错(Audio Video Interleaved)的英文缩写。AVI这个由[微软公司](http://baike.baidu.com/view/39784.htm)发表的视频格式，在视频领域可以说是最悠久的格式之一。AVI格式调用方便、图像质量好，压缩标准可任意选择，是应用最广泛、也是应用时间最长的格式之一。

[MOV](http://baike.baidu.com/view/7723.htm)

使用过[Mac](http://baike.baidu.com/view/32702.htm)机的朋友应该多少接触过[QuickTime](http://baike.baidu.com/view/196819.htm)。QuickTime原本是[Apple](http://baike.baidu.com/view/14874.htm)公司用于Mac[计算机](http://baike.baidu.com/view/3314.htm)上的一种图像[视频处理](http://baike.baidu.com/view/2792642.htm)软件。Quick-Time提供了两种标准图像和[数字视频](http://baike.baidu.com/view/257435.htm)格式, 即可以支持静态的\*.PIC和\*.JPG图像格式，动态的基于Indeo压缩法的\*.MOV和基于MPEG压缩法的\*.MPG视频格式。

[**ASF**](http://baike.baidu.com/view/7704.htm)

[ASF](http://baike.baidu.com/view/7704.htm)(Advanced Streaming format高级流格式)。ASF 是MICROSOFT 为了和的Real player 竞争而发展出来的一种可以直接在网上观看视频节目的文件[压缩格式](http://baike.baidu.com/view/2954654.htm)。ASF使用了MPEG4 的压缩算法，压缩率和图像的质量都很不错。因为ASF 是以一个可以在网上即时观赏的视频“流”格式存在的，所以它的图像质量比VCD 差一点点并不出奇，但比同是视频“流”格式的RAM 格式要好。

[**WMV**](http://baike.baidu.com/view/66019.htm)

一种独立于编码方式的在Internet上实时传播[多媒体](http://baike.baidu.com/view/3323.htm)的[技术标准](http://baike.baidu.com/view/9164.htm)，[Microsoft](http://baike.baidu.com/view/2422.htm)公司希望用其取代[QuickTime](http://baike.baidu.com/view/196819.htm)之类的技术标准以及WAV、AVI之类的文件扩展名。[WMV](http://baike.baidu.com/view/66019.htm)的主要优点在于：可扩充的媒体类型、本地或网络回放、可伸缩的媒体类型、流的优先级化、多语言支持、扩展性等。

[**NAVI**](http://baike.baidu.com/view/45888.htm)

如果发现原来的播放软件突然打不开此类格式的AVI文件，那你就要考虑是不是碰到了n AVI。n AVI是New AVI 的缩写，是一个名为Shadow Realm 的地下组织发展起来的一种新视频格式。它是由Microsoft ASF 压缩算法的修改而来的（并不是想象中的AVI），视频格式追求的无非是压缩率和图像质量，所以 NAVI 为了追求这个目标，改善了原始的ASF 格式的一些不足，让NAVI 可以拥有更高的帧率。可以这样说，NAVI 是一种去掉视频流特性的改良型ASF 格式。

[**3GP**](http://baike.baidu.com/view/7077.htm)

[3GP](http://baike.baidu.com/view/7077.htm)是一种3G流媒体的[视频编码](http://baike.baidu.com/view/746807.htm)格式，主要是为了配合3G网络的高传输速度而开发的，也是目前手机中最为常见的一种视频格式。

简单的说，该格式是“第三代合作伙伴项目”(3GPP)制定的一种[多媒体](http://baike.baidu.com/view/3323.htm)标准，使用户能使用手机享受高质量的视频、音频等多媒体内容。其核心由包括高级[音频编码](http://baike.baidu.com/view/1531030.htm)(AAC)、自适应多速率 (AMR) 和MPEG-4 和H.263[视频编码](http://baike.baidu.com/view/746807.htm)[解码器](http://baike.baidu.com/view/1079.htm)等组成，目前大部分支持视频拍摄的手机都支持3GPP格式的视频播放。其特点是网速占用较少，但画质较差。

[**REAL VIDEO**](http://baike.baidu.com/view/18083.htm)

[REAL VIDEO](http://baike.baidu.com/view/18083.htm)（[RA](http://baike.baidu.com/view/288774.htm)、[RAM](http://baike.baidu.com/view/3558.htm)）格式由一开始就是定位在[视频流](http://baike.baidu.com/view/2722588.htm)应用方面的，也可以说是视频流技术的始创者。它可以在用56K MODEM 拨号上网的条件实现不间断的视频播放，当然，其图像质量和[MPEG2](http://baike.baidu.com/view/89020.htm)、[DIVX](http://baike.baidu.com/view/7716.htm)等比是不敢恭维的啦。毕竟要实现在网上传输不间断的视频是需要很大的[频宽](http://baike.baidu.com/view/632842.htm)的，这方面是[ASF](http://baike.baidu.com/view/7704.htm)的有力竞争者。

[**MKV**](http://baike.baidu.com/view/91917.htm)

一种后缀为[MKV](http://baike.baidu.com/view/91917.htm)的视频文件频频出现在网络上，它可在一个文件中集成多条不同类型的音轨和字幕轨，而且其[视频编码](http://baike.baidu.com/view/746807.htm)的自由度也非常大，可以是常见的[DivX](http://baike.baidu.com/view/7716.htm)、[XviD](http://baike.baidu.com/view/30246.htm)、3IVX，甚至可以是RealVideo、QuickTime、WMV 这类流式视频。实际上，它是一种全称为Matroska的新型[多媒体](http://baike.baidu.com/view/3323.htm)[封装格式](http://baike.baidu.com/view/1942911.htm)，这种先进的、开放的封装格式已经给我们展示出非常好的应用前景。

[**FLV**](http://baike.baidu.com/view/364757.htm)

[FLV](http://baike.baidu.com/view/364757.htm)是FLASH VIDEO的简称，FLV[流媒体](http://baike.baidu.com/view/794.htm)格式是一种新的视频格式。由于它形成的文件极小、加载速度极快，使得网络观看视频文件成为可能，它的出现有效地解决了视频文件导入[Flash](http://baike.baidu.com/view/7641.htm)后，使导出的SWF文件体积庞大，不能在网络上很好的使用等缺点。

[**F4V**](http://baike.baidu.com/view/2302577.htm)

作为一种更小更清晰，更利于在网络传播的格式，[F4V](http://baike.baidu.com/view/2302577.htm)已经逐渐取代了传统[FLV](http://baike.baidu.com/view/364757.htm)，也已经被大多数主流播放器兼容播放，而不需要通过转换等复杂的方式。F4V是[Adobe](http://baike.baidu.com/view/7578.htm)公司为了迎接[高清](http://baike.baidu.com/view/752328.htm)时代而推出继FLV格式后的支持H.264的F4V[流媒体](http://baike.baidu.com/view/794.htm)格式。它和FLV主要的区别在于，FLV格式采用的是H263编码，而F4V则支持H.264编码的高清晰视频，码率最高可达50Mbps。也就是说F4V和FLV在同等体积的前提下，能够实现更高的分辨率，并支持更高比特率，就是我们所说的更清晰更流畅。另外，很多主流媒体网站上下载的F4V文件后缀却为FLV，这是F4V格式的另一个特点，属正常现象，观看时可明显感觉到这种实为F4V的FLV有明显更高的清晰度和流畅度。

[**RMVB**](http://baike.baidu.com/view/8680.htm)

RMVB的前身为RM格式，它们是[Real Networks](http://baike.baidu.com/view/1617391.htm)公司所制定的音频视频压缩规范，根据不同的[网络传输速率](http://baike.baidu.com/view/2381438.htm)，而制定出不同的压缩比率，从而实现在低速率的网络上进行影像数据实时传送和播放，具有体积小，画质也还不错的优点。

早期的RM格式为了能够实现在有限带宽的情况下，进行视频在线播放而被研发出来，并一度红遍整个互联网。而为了实现更优化的体积与画面质量，Real Networks公司不久又在RM的基础上，推出了[可变比特率](http://baike.baidu.com/view/656405.htm)编码的RMVB格式。RMVB的诞生，打破了原先RM格式那种平均压缩采样的方式，在保证平均压缩比的基础上，采用浮动比特率编码的方式，将较高的比特率用于复杂的动态画面（如歌舞、飞车、战争等），而在静态画面中则灵活地转为较低的采样率，从而合理地利用了比特率资源，使RMVB最大限度地压缩了影片的大小，最终拥有了近乎完美的接近于DVD品质的视听效果。我们可以做个简单对比，一般而言一部120分钟的dvd体积为4GB，而rmvb格式来压缩，仅400MB左右，而且清晰度流畅度并不比原DVD差太远。

人们为了缩短视频文件在网络进行传播的下载时间，为了节约用户[电脑硬盘](http://baike.baidu.com/view/2074271.htm)宝贵的空间容量，已越来越多的视频被压制成了RMVB格式，并广为流传。到如今，可能每一位电脑使用者（或许就包括正在阅读这篇文章的您）电脑中的视频文件，超过80%都会是RMVB格式。

RMVB由于本身的优势，成为目前PC中最广泛存在的视频格式，但在[MP4播放器](http://baike.baidu.com/view/42387.htm)中，RMVB格式却长期得不到重视。MP4发展的整整七个年头里，虽然早就可以做到完美支持[AVI格式](http://baike.baidu.com/view/725802.htm)，但却久久未有能够完全兼容RMVB格式的机型诞生。对于MP4，尤其是容量小价格便宜的[闪存](http://baike.baidu.com/view/1371.htm)MP4而言，怎样的视频格式才将会是其未来的主流呢？我们不妨来探讨一番。

[**WebM**](http://baike.baidu.com/view/3655243.htm)

由Google提出，是一个开放、免费的媒体[文件格式](http://baike.baidu.com/view/1066926.htm)。WebM 影片格式其实是以 Matroska（即 MKV）容器格式为基础开发的新容器格式，里面包括了 VP8 影片轨和 Ogg Vorbis 音轨，其中Google将其拥有的VP8[视频编码](http://baike.baidu.com/view/746807.htm)技术以类似BSD授权开源，Ogg Vorbis 本来就是开放格式。 WebM标准的[网络视频](http://baike.baidu.com/view/94301.htm)更加偏向于开源并且是基于HTML5标准的，WebM 项目旨在为对每个人都开放的网络开发高质量、开放的视频格式，其重点是解决视频服务这一核心的网络用户体验。Google 说 WebM 的格式相当有效率，应该可以在 netbook、tablet、手持式装置等上面顺畅地使用。

Ogg Vorbis 本来就是开放格式，大家应该都知道，至于 VP8 则是 Google 当年买下一间叫 On2 的公司的时候，取得的 Video Codec， Google 也把这个 Codec 以类似 BSD 授权放出来，因此 WebM 应该是不会有 H.264 的那些潜在的专利问题。

Youtube 也会支持 WebM 的播放。来自产业界的有 Adobe -- Flash Player 将会支持 WebM 格式的播放 -- AMD、ARM、Broadcom、Freescale、NVIDIA、Qualcomm、TI 等。谁不在上头？Intel。在 Browser 方面，Chrome 不要说，Firefox、Opera 都已经表态将会支持这个新格式。微软IE9 的支持就没这么直接，出厂时仅会支持 H.264 影片的播放，但如果你另外下载并安装了 VP8，那当然你也可以播放 HTML / VP8 的影片。 　要推动一个新格式进入主流，甚至成为龙头老大，是非常不容易的。但 WebM 和 VP8 的推动者是 Google，而且是在 H.264 正因为其非开放性而备受质疑的时候，或许 WebM 真有机会迅速地站稳脚跟，一举成为新一代的影片通用格式呢！
## **1.2音频格式**
音频格式是指要在计算机内播放或是处理音频文件，也就是要对声音文件进行数、模转换，这个过程同样由采样和量化构成，人耳所能听到的声音，最低的频率是从20Hz起一直到最高频率20KHZ，20KHz以上人耳是听不到的，因此音频文件格式的最大带宽是20KHZ，故而采样速率需要介于40~50KHZ之间，而且对每个样本需要更多的量化比特数。音频数字化的标准是每个样本16位-96dB的信噪比，采用线性脉冲编码调制PCM，每一量化步长都具有相等的长度。在音频文件的制作中，正是采用这一标准。
### **1.2.1常见格式**
常见的音频格式有：CD格式、WAVE（\*.WAV）、AIFF、AU、MP3、MIDI、WMA、RealAudio、VQF、OggVorbis、AAC、APE。

**CD**

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.002.png)

CD格式的音质是比较高的音频格式。因此要讲音频格式，CD自然是打头阵的先锋。在大多数播放软件的“打开文件类型”中，都可以看到\*.cda格式，这就是CD音轨了。标准CD格式也就是44.1K的采样频率，速率88K/秒，16位量化位数，因为CD音轨可以说是近似无损的，因此它的声音基本上是忠于原声的，因此如果你是一个音响发烧友的话，CD是你的首选。它会让你感受到天籁之音。CD光盘可以在CD唱机中播放，也能用电脑里的各种播放软件来重放。一个CD音频文件是一个\*.cda文件，这只是一个索引信息，并不是真正的包含声音信息，所以不论CD音乐的长短，在电脑上看到的“\*.cda文件”都是44字节长。注意：不能直接的复制CD格式的\*.cda文件到硬盘上播放，需要使用象EAC这样的抓音轨软件把CD格式的文件转换成WAV，这个转换过程如果光盘驱动器质量过关而且EAC的参数设置得当的话，可以说是基本上无损抓音频。推荐大家使用这种方法。

**WAVE**

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.003.png)

WAVE（\*.WAV）是微软公司开发的一种声音文件格式，它符合PIFFResource Interchange File Format 文件规范，用于保存WINDOWS平台的音频信息资源，被WINDOWS平台及其应用程序所支持。“\*.WAV”格式支持MSADPCM、CCITT A LAW等多种压缩算法，支持多种音频位数、采样频率和声道，标准格式的WAV文件和CD格式一样，也是44.1K的采样频率，速率88K/秒，16位量化位数，看到了吧，WAV格式的声音文件质量和CD相差无几，也是目前PC机上广为流行的声音文件格式，几乎所有的音频编辑软件都“认识”WAV格式。

**AIFF**

AIFF（Audio Interchange File Format）格式和AU格式，它们都和WAV非常相像，在大多数的音频编辑软件中也都支持它们这几种常见的音乐格式。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.004.png)

AIFF是音频交换文件格式的英文缩写。是APPLE公司开发的一种音频文件格式，被MACINTOSH平台及其应用程序所支持，NETSCAPE浏览器中LIVEAUDIO也支持AIFF格式。所以大家都不常见。AIFF是Apple苹果电脑上面的标准音频格式，属于QuickTime技术的一部分。这一格式的特点就是格式本身与数据的意义无关，因此受到了Microsoft的青睐，并据此搞出来WAV格式。AIFF虽然是一种很优秀的文件格式，但由于它是苹果电脑上的格式，因此在PC平台上并没有得到很大的流行。不过由于Apple电脑多用于多媒体制作出版行业，因此几乎所有的音频编辑软件和播放软件都或多或少地支持AIFF格式。只要苹果电脑还在，AIFF就始终还占有一席之地。由于AIFF的包容特性，所以它支持许多压缩技术。

**AU**

AUDIO文件是SUN公司推出的一种数字音频格式。AU文件原先是UNIX操作系统下的数字声音文件。由于早期INTERNET上的WEB服务器主要是基于UNIX的，所以，AU格式的文件在如今的INTERNET中也是常用的声音文件格式。

MPEG

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.005.png)

MPEG是动态图象专家组的英文缩写。这个专家组始建于1988年，专门负责为CD建立视频和音频压缩标准。MPEG音频文件指的是MPEG标准中的声音部分即MPEG音频层。目前INTERNET上的音乐格式以MP3最为常见。虽然它是一种有损压缩，但是它的最大优势是以极小的声音失真换来了较高的压缩比。MPEG含有格式包括：MPEG-1、MPEG-2、MPEG-Layer3、MPEG-4

**MP3**

MP3格式诞生于八十年代的德国，所谓的MP3也就是指的是MPEG标准中的音频部分，也就是MPEG音频层。根据压缩质量和编码处理的不同分为3层，分别对应“\*.mp1"/“\*.mp2”/“\*.mp3”这3种声音文件。需要提醒大家注意的地方是：MPEG音频文件的压缩是一种有损压缩，MPEG3音频编码具有10：1~12：1的高压缩率，同时基本保持低音频部分不失真，但是牺牲了声音文件中12KHz到16KHz高音频这部分的质量来换取文件的尺寸，相同长度的音乐文件，用\*.mp3格式来储存，一般只有\*.wav文件的1/10，而音质要次于CD格式或WAV格式的声音文件。由于其文件尺寸小，音质好；所以在它问世之初还没有什么别的音频格式可以与之匹敌，因而为\*.mp3格式的发展提供了良好的条件。直到现在，这种格式还是风靡一时，作为主流音频格式的地位难以被撼动。但是树大招风，MP3音乐的版权问题也一直是找不到办法解决，因为MP3没有版权保护技术，说白了也就是谁都可以用。

MP3格式压缩音乐的采样频率有很多种，可以用64Kbps或更低的采样频率节省空间，也可以用320Kbps的标准达到极高的音质。用装有Fraunhofer IIS Mpeg Lyaer3的 MP3编码器（现在效果最好的编码器）MusicMatch Jukebox 6.0在128Kbps的频率下编码一首3分钟的歌曲，得到2.82MB的MP3文件。采用缺省的CBR（固定采样频率）技术可以以固定的频率采样一首歌曲，而VBR（可变采样频率）则可以在音乐“忙”的时候加大采样的频率获取更高的音质，不过产生的MP3文件可能在某些播放器上无法播放。把VBR的级别设定成为与前面的CBR文件的音质基本一样，生成的VBR MP3文件为2.9MB。

MP3是到2008年止使用用户最多的有损压缩数字音频格式了。它的全称是MPEG(MPEG：MovingPictureExpertsGroup)AudioLayer-3，刚出现时它的编码技术并不完善，它更像一个编码标准框架，留待人们去完善。早期的MP3编码采用的的是固定编码率的方式（CBR），看到的128KBPS，就是代表它是以128KBPS固定数据速率编码——你可以提高这个编码率，最高可以到320KBPS，音质会更好，自然，文件的体积会相应增大。

因为MP3的编码方式是开放的，可以在这个标准框架的基础上自己选择不同的声学原理进行压缩处理，所以，很快由Xing公司推出可变编码率的压缩方式（VBR）。它的原理就是利用将一首歌的复杂部分用高bitrate编码，简单部分用低bitrate编码，通过这种方式，进一步取得质量和体积的统一。当然，早期的Xing编码器的VBR算法很差，音质与CBR（固定码率）相去甚远。但是，这种算法指明了一种方向，其他开发者纷纷推出自己的VBR算法，使得效果一直在改进。目前公认比较好的首推LAME，它完美地实现了VBR算法，而且它是是完全免费的软件，并且由爱好者组成的开发团队一直在不断的发展完善。

而在VBR的基础上，LAME更加发展出ABR算法。ABR（AverageBitrate）平均比特率，是VBR的一种插值参数。LAME针对CBR不佳的文件体积比和VBR生成文件大小不定的特点独创了这种编码模式。ABR在指定的文件大小内，以每50帧（30帧约1秒）为一段，低频和不敏感频率使用相对低的流量，高频和大动态表现时使用高流量，可以做为VBR和CBR的一种折衷选择。

MP3问世不久，就凭这较高的压缩比12:1和较好的音质创造了一个全新的音乐领域，然而MP3的开放性却最终不可避免的导致了版权之争，在这样的背景之下，文件更小，音质更佳，同时还能有效保护版权的MP4就应运而生了。MP3和MP4之间其实并没有必然的联系，首先MP3是一种音频压缩的国际技术标准，而MP4却是一个商标的名称。

**MPEG-4**

MPEG-4标准是由国际运动图像专家组于2000年10月公布的一种面向多媒体应用的视频压缩标准。它采用了基于对象的压缩编码技术，在编码前首先对视频序列进行分析，从原始图像中分割出各个视频对象，然后再分别对每个视频对象的形状信息、运动信息、纹理信息单独编码，并通过比MPEG-2更优的运动预测和运动补偿来去除连续帧之间的时间冗余。其核心是基于内容的尺度可变性(Content-basedscalability)，可以对图像中各个对象分配优先级，对比较重要的对象用高的空间和时间分辨率表示，对不甚重要的对象(如监控系统的背景)以较低的分辨率表示，甚至不显示。因此它具有自适应调配资源能力，可以实现高质量低速率的图像通信和视频传输。 MPEG-4以其高质量、低传输速率等优点已经被广泛应用到网络多媒体、视频会议和多媒体监控等图像传输系统中。中国内外大部分成熟的MPEG-4应用均为基于PC层面的客户端和服务器模式，应用在嵌入式系统上的并不多，且多数嵌入式MPEG-4解码系统大多使用商业的嵌入式操作系统，如WindowsCE、VxWorks等，成本高、灵活性差。如以嵌入式Linux作为操作系统不仅开发方便，且可以节约成本，并可以根据实际情况进行裁减，占用资源少、灵活性强，网络性能好，适用范围更广。

**MIDI**

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.006.png)

MIDI（Musical Instrument Digital Interface）格式被经常玩音乐的人使用，MIDI允许数字合成器和其他设备交换数据。MID文件格式由MIDI继承而来。MID文件并不是一段录制好的声音，而是记录声音的信息，然后在告诉声卡如何再现音乐的一组指令。这样一个MIDI文件每存1分钟的音乐只用大约5～10KB。MID文件主要用于原始乐器作品，流行歌曲的业余表演，游戏音轨以及电子贺卡等。\*.mid文件重放的效果完全依赖声卡的档次。\*.mid格式的最大用处是在电脑作曲领域。\*.mid文件可以用作曲软件写出，也可以通过声卡的MIDI口把外接音序器演奏的乐曲输入电脑里，制成\*.mid文件。

**WMA**

WMA (Windows Media Audio) 格式是来自于微软的重量级选手，后台强硬，音质要强于MP3格式，更远胜于RA格式，它和日本YAMAHA公司开发的VQF格式一样，是以减少数据流量但保持音质的方法来达到比MP3压缩率更高的目的，WMA的压缩率一般都可以达到1：18左右，WMA的另一个优点是内容提供商可以通过DRM（Digital Rights Management）方案如Windows Media Rights Manager 7加入防拷贝保护。这种内置了版权保护技术可以限制播放时间和播放次数甚至于播放的机器等等，这对被盗版搅得焦头乱额的音乐公司来说可是一个福音，另外WMA还支持音频流(Stream)技术，适合在网络上在线播放，作为微软抢占网络音乐的开路先锋可以说是技术领先、风头强劲，更方便的是不用象MP3那样需要安装额外的播放器，而Windows操作系统和Windows Media Player的无缝捆绑让你只要安装了windows操作系统就可以直接播放WMA音乐，新版本的Windows Media Player7.0更是增加了直接把CD光盘转换为WMA声音格式的功能，在新出品的操作系统Windows XP中，WMA是默认的编码格式，大家知道Netscape的遭遇，现在“狼”又来了。WMA这种格式在录制时可以对音质进行调节。同一格式，音质好的可与CD媲美，压缩率较高的可用于网络广播。虽然现在网络上还不是很流行，但是在微软的大规模推广下已经是得到了越来越多站点的承认和大力支持，在网络音乐领域中直逼\*.mp3，在网络广播方面，也正在瓜分Real打下的天下。因此，几乎所有的音频格式都感受到了WMA格式的压力。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.007.png)

微软官方宣布的资料中称WMA格式的可保护性极强，甚至可以限定播放机器、播放时间及播放次数，具有相当的版权保护能力。应该说，WMA的推出，就是针对MP3没有版权限制的缺点而来——普通用户可能很欢迎这种格式，但作为版权拥有者的唱片公司来说，它们更喜欢难以复制拷贝的音乐压缩技术，而微软的WMA则照顾到了这些唱片公司的需求。

除了版权保护外，WMA还在压缩比上进行了深化，它的目标是在相同音质条件下文件体积可以变的更小（当然，只在MP3低于192KBPS码率的情况下有效，实际上当采用LAME算法压缩MP3格式时，高于192KBPS时普遍的反映是MP3的音质要好于WMA）。

**RealAudio**

RealAudio主要适用于在网络上的在线音乐欣赏，现在大多数的用户仍然在使用56Kbps或更低速率的Modem，所以典型的回放并非最好的音质。有的下载站点会提示你根据你的Modem速率选择最佳的Real文件。real的的文件格式主要有这么几种：有RA（RealAudio）、RM（RealMedia，RealAudio G2）、RMX（RealAudio Secured），还有更多。这些格式的特点是可以随网络带宽的不同而改变声音的质量，在保证大多数人听到流畅声音的前提下，令带宽较富裕的听众获得较好的音质。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.008.png)

近来随着网络带宽的普遍改善，Real公司正推出用于网络广播的、达到CD音质的格式。如果你的RealPlayer软件不能处理这种格式，它就会提醒你下载一个免费的升级包。许多音乐网站 提供了歌曲的Real格式的试听版本。现在最新的版本是RealPlayer 9.0，第39期《电脑报》也对RealPlayer 9.0作了详细的介绍，这里不再赘述。

**VQF**

雅马哈公司另一种格式是\*.vqf，它的核心是减少数据流量但保持音质的方法来达到更高的压缩比，VQF的音频压缩率比标准的MPEG音频压缩率高出近一倍，可以达到18:1左右甚至更高。也就是说把一首4分钟的歌曲（WAV文件）压成MP3，大约需要4MB左右的硬盘空间，而同一首歌曲，如果使用VQF音频压缩技术的话，那只需要2MB左右的硬盘空间。因此，在音频压缩率方面，MP3和RA都不是VQF的对手。相同情况下压缩后VQF的文件体积比MP3小30%～50%，更便利于网上传播，同时音质极佳，接近CD音质(16位44.1kHz立体声)。可以说技术上也是很先进的，但是由于宣传不力，这种格式难有用武之地。\*.vqf可以用雅马哈的播放器播放。同时雅马哈也提供从\*.wav文件转换到\*.vqf文件的软件。 此文件缺少特点外加缺乏宣传。

当VQF以44KHz、80kbit/s的音频采样率压缩音乐时，它的音质优于44KHz、128kbit/s的MP3，当VQF以44KHz、96kbit/s的频率压缩时，它的音质几乎等于44KHz、256kbit/s的MP3。经SoundVQ压缩后的音频文件在进行回放效果试听时，几乎没有人能听出它与原音频文件的差异。

VQF音频文件个格式

播放VQF对计算机的配置要求仅为奔腾75或更高，当然如果您用奔腾100或以上的机器，VQF能够运行得更加出色。实际上，播放VQF对CPU的要求仅比Mp3高5～10%左右。

VQF即TwinVQ技术虽然是由NTT和YAMAHA开发的，但它们的应用软件都是免费的。只是NTT和YAMAHA并没有公布VQF的源代码。

**OggVorbis**

OggVorbis是一种新的音频压缩格式，类似于MP3等现有的音乐格式。但有一点不同的是，它是完全免费、开放和没有专利限制的。Vorbis是这种音频压缩机制的名字，而Ogg则是一个计划的名字，该计划意图设计一个完全开放性的多媒体系统。目前该计划只实现了OggVorbis这一部分。

OggVorbis文件的扩展名是\*.OGG。这种文件的设计格式是非常先进的。这种文件格式可以不断地进行大小和音质的改良，而不影响旧有的编码器或播放器。

VORBIS采用有损压缩，但通过使用更加先进的声学模型去减少损失，因此，同样位速率(BitRate)编码的OGG与MP3相比听起来更好一些。另外，还有一个原因，MP3格式是受专利保护的。如果你想使用MP3格式发布自己的作品，则需要付给Fraunhofer（发明MP3的公司）专利使用费。而VORBIS就完全没有这个问题。

对于乐迷来说，使用OGG文件的显著好处是可以用更小的文件获得优越的声音质量。而且，由于OGG是完全开放和免费的，制作OGG文件将不受任何专利限制，可望可以获得大量的编码器和播放器。这也是为何现在MP3编码器如此少而且大多是商业软件的原因，因为Fraunhofer要收取专利使用费。Vorbis使用了与MP3相比完全不同的数学原理，因此在压缩音乐时受到的挑战也不同。同样位速率编码的Vorbis和MP3文件具有同等的声音质量。Vorbis具有一个设计良好、灵活的注释，避免了象MP3文件的ID3标记那样烦琐的操作；Vorbis还具有位速率缩放：可以不用重新编码便可调节文件的位速率。Vorbis文件可以被分成小块并以样本粒度进行编辑；Vorbis支持多通道；Vorbis文件可以以逻辑方式相连接等。

**AMR**

AMR全称Adaptive Multi-Rate，自适应多速率编码，主要用于移动设备的音频，压缩比比较大，但相对其他的压缩格式质量比较差，由于多用于人声，通话，效果还是很不错的。

分类

1. AMR: 又称为AMR-NB，相对于下面的WB而言，语音带宽范围：300－3400Hz，8KHz抽样

2. AMR-WB:AMR WideBand，

语音带宽范围： 50－7000Hz 16KHz抽样

“AMR-WB”全称为“Adaptive Multi-rate - Wideband”，即“自适应多速率宽带编码”，采样频率为16kHz，是一种同时被国际标准化组织ITU-T和3GPP采用的宽带语音编码标准，也称为G722.2标准。AMR-WB提供语音带宽范围达到50～7000Hz，用户可主观感受到话音比以前更加自然、舒适和易于分辨。

与之作比较，现在GSM用的EFR(Enhenced Full Rate，增强型全速率编码)采样频率为8kHz，语音带宽为200～3400Hz。

AMR-WB应用于窄带GSM(全速信道16k，GMSK)的优势在于其可采用从6.6kb/s, 8.85kb/s和12.65kb/s三种编码，当网络繁忙时C/I恶化，编码器可以自动调整编码模式，从而增强QoS。在这种应用中，AMR-WB抗扰度优于AMR-NB。

AMR-WB应用于EDGE、3G可充分体现其优势。足够的传输带宽保证AMR-WB可采用从 6.6kb/s到23.85kb/s共九种编码，语音质量超越PSTN固定电话。
### **1.2.2比较**
作为数字音乐文件格式的标准，WAV格式容量过大，因而使用起来很不方便。因此，一般情况下我们把它压缩为MP3或WMA格式。压缩方法有无损压缩，有损压缩，以及混成压缩。MPEG,JPEG就属于混成压缩，如果把压缩的数据还原回去，数据其实是不一样的。当然，人耳是无法分辨的。因此，如果把MP3，OGG格式从压缩的状态还原回去的话，就会产生损失。然而，APE格式即使还原，也能毫无损失地保留原有音质。所以，APE可以无损失高音质地压缩和还原。在完全保持音质的前提下，APE的压缩容量有了适当的减小。拿一个最为常见的38MBWAV文件为例，压缩为APE格式后为25MB左右，比开始足足少了13MB。而且MP3容量越来越大的今天，25M的歌曲已经算不上什么庞然大物了。以1GB的mp3来说可以放入4张CD，那就是40多首歌曲，已经足够了！

MP3支持格式有MP3和WMA。MP3由于是有损压缩，因此讲求采样率，一般是44.1KHZ。另外，还有比特率，即数据流，一般为8---320KBPS。在MP3编码时，还看看它是否支持可变比特率（VBR），现在出的MP3机大部分都支持，这样可以减小有效文件的体积。WMA则是微软力推的一种音频格式，相对来说要比MP3体积更小。
## **1.3字幕格式**
### **1.3.1外挂字幕与内嵌字幕的阐述**
外挂字幕：是视频文件和字幕文件分离，在播放的时候要导入字幕文件。比如DVD就会自动导入字幕。外挂字幕的好处是：可以导入自己国家的语言。

内嵌字幕：视频文件和字幕文件已经集成到了一起，没有办法改变和去掉了。
### **1.3.2外挂字幕视频与内嵌字幕视频的画面比较**
外挂字幕相对于内嵌字幕来说对视频的质量损害就会小很多，外挂的意思就是在视频之外单独运行的一种字幕文件，对视频本身的分辨率损害很小甚至为零。而内嵌的字面意思就是将视频连带外挂字幕用专有的录制软件重新将视频录制一遍，成为一个新的视频；这种方法虽然解决了视频体积过大和播放器不兼容等问题，但是在重新录制视频过程当中会无意识的损害原视频本身的码率，使重新录制出来的视频分辨率大大不如原视频，所以在选择外挂与内嵌字幕时需结合自身情况考虑视频需要进行选择。
### **1.3.3外挂字幕的三种格式**
1、srt格式：这是最好的，体积小，用[记事本](http://baike.baidu.com/view/152865.htm)可以打开编辑。

2、sub+idx：这种是图形字幕，只能用字幕转换[软件](http://baike.baidu.com/view/37.htm)；体积较大。

3、ass字幕：网上比较少，比srt多一些特效。

外挂字幕的一些基本注意事项：

使用外挂字幕的时候，要保证字幕文件和视频文件放置在同一个文件夹下，并且保证两者的文件名相同，但是不要修改后缀和标识（常见的标识有chs、GB，cht，Big5，eng五种；其中chs和GB表示简体中文，cht和Big5表示繁体中文，eng表示英文）：

例如：

视频的文件名为：越狱（13）.avi

外挂字幕的文件名就应为：越狱（13）.chs.srt

当然，能在视频中显示字幕的前提是你的电脑里安装有字幕插件。否则建议安装能够[完美解码](http://baike.baidu.com/view/1395585.htm)的万能播放器。
## **1.4采集录制和播放渲染**
### **1.4.1视频采集**
视频采集（Video Capture）把模拟视频转换成数字视频，并按数字视频文件的格式保存下来。所谓视频采集就是将模拟摄像机、录像机、LD视盘机、电视机输出的视频信号，通过专用的模拟、数字转换设备，转换为二进制数字信息的过程。在视频采集工作中，视频采集卡是主要设备，它分为专业和家用两个级别。专业级视频采集卡不仅可以进行视频采集，并且还可以实现硬件级的视频压缩和视频编辑。家用级的视频采集卡只能做到视频采集和初步的硬件级压缩，而更为“低端”的电视卡，虽可进行视频的采集，但它通常都省却了硬件级的视频压缩功能。

**视频保存格式**

影片拍好了，可以直接放在DV带上保存，以后就用DV机回放，也可以采集到计算机里，编辑后回录到DV带上，还可以采集到计算机里，直接把DVAVI文件刻到CDR上去保存，也可以压缩成MPG，刻成VCD或者SVCD，DVD和CD保存。MPG是有损压缩，不管是压缩成什么格式，对画质都有损失，但是刻MPG盘保存还是最常用的方式。

![视频采集设备](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.009.jpeg "728da9773912b31ba22d0fb38618367adbb4e1e3")

DV影片的回放在电视机上的表现远强于在CRT上的表现，尽管CRT的分辨率要高得多，主要是因为电视的设计就是为了显示动态画面，所以在亮度、色彩鲜艳上都比显示静态为主的CRT要好，而普通电视的显示分辨率只有320线，那么DV的高达720×576的分辨率根本用不着，不管是VCD的352×288还是SVCD的480×576都够了，所以尽管压缩成MPG画质有损失，但是在电视上基本是看不出来的。在电脑上看，SVCD的分辨率也足够清晰了。

**保存格式的优劣性**

DV带的保存是个问题，毕竟是磁带，DV带还用得时间不长，但是以前的录音机磁带时间长了粘连和发霉大家估计都见过的。而CDR光盘蓝盘、绿盘在一般情况下不磨损光盘一般是保存30~50年，金盘号称能保存100年，虽然光盘也有发霉的可能，但是毕竟好得多。

播放的方便性上，也是光盘强，DV带就得把DV机搬出来，还只能在电视上看，对磁头也是个磨损，倒带也很麻烦，而VCD，SVCD光盘方便。
### **1.4.2视频录制**
### **1.4.3视频渲染**
渲染，英文为Render,也有的把它称为着色，但我更习惯把Shade称为着色，把Render称为渲染。因为Render和Shade这两个词在三维软件中是截然不同的两个概念，虽然它们的功能很相似，但却有不同。Shade是一种显示方案，一般出现在三维软件的主要窗口中，和三维模型的线框图一样起到辅助观察模型的作用。很明显，着色模式比线框模式更容易让我们理解模型的结构，但它只是简单的显示而已，数字图像中把它称为明暗着色法。在像Maya这样的高级三维软件中，还可以用Shade显示出简单的灯光效果、阴影效果和表面纹理效果，当然，高质量的着色效果是需要专业三维图形显示卡来支持的，它可以加速和优化三维图形的显示。但无论怎样优化，它都无法把显示出来的三维图形变成高质量的图像，这是因为Shade采用的是一种实时显示技术，硬件的速度限制它无法实时地反馈出场景中的反射、折射等光线追踪效果。而现实工作中我们往往要把模型或者场景输出成图像文件、视频信号或者电影胶片，这就必须经过Render程序。

Shade窗口，提供了非常直观、实时的表面基本着色效果，根据硬件的能力，还能显示出纹理贴图、光源影响甚至阴影效果，但这一切都是粗糙的，特别是在没有硬件支持的情况下，它的显示甚至会是无理无序的。Render效果就不同了，它是基于一套完整的程序计算出来的，硬件对它的影响只是一个速度问题，而不会改变渲染的结果，影响结果的是看它是基于什么程序渲染的，比如是光影追踪还是光能传递。

**渲染过程**

首先，必须定位三维场景中的摄像机，这和真实的摄影是一样的。一般来说，三维软件已经提供了四个默认的摄像机，那就是软件中四个主要的窗口，分为顶视图、正视图、侧视图和[透视图](http://baike.baidu.com/view/1142999.htm)。我们大多数时候渲染的是透视图而不是其它视图，透视图的摄像机基本遵循真实摄像机的原理，所以我们看到的结果才会和真实的三维世界一样，具备立体感。接下来，为了体现空间感，渲染程序要做一些“特殊”的工作，就是决定哪些物体在前面、哪些物体在后面和哪些物体被遮挡等。空间感仅通过物体的遮挡关系是不能完美再现的，很多初学三维的人只注意立体感的塑造而忽略了空间感。要知道空间感和光源的衰减、环境雾、景深效果都是有着密切联系的。

渲染程序通过摄像机获取了需要渲染的范围之后，就要计算光源对物体的影响，这和真实世界的情况又是一样的。许多三维软件都有默认的光源，否则，我们是看不到透视图中的着色效果的，更不要说渲染了。因此，渲染程序就是要计算我们在场景中添加的每一个光源对物体的影响。和真实世界中光源不同的是，渲染程序往往要计算大量的辅助光源。在场景中，有的光源会照射所有的物体，而有的光源只照射某个物体，这样使得原本简单的事情又变得复杂起来。在这之后，还要是使用深度贴图阴影还是使用光线追踪阴影？这往往取决于在场景中是否使用了透明材质的物体计算光源投射出来的阴影。另外，使用了面积光源之后，渲染程序还要计算一种特殊的阴影－－软阴影（只能使用光线追踪），场景中的光源如果使用了光源特效，渲染程序还将花费更多的[系统资源](http://baike.baidu.com/view/53557.htm)来计算特效的结果，特别是体积光，也称为灯光雾，它会占用大量的系统资源，使用的时候一定要注意。

在这之后，渲染程序还要根据物体的材质来计算物体表面的颜色，材质的类型不同，属性不同，纹理不同都会产生各种不同的效果。而且，这个结果不是独立存在的，它必须和前面所说的光源结合起来。如果场景中有[粒子系统](http://baike.baidu.com/view/85873.htm)，比如火焰、烟雾等，渲染程序都要加以“考虑”。

**数字影片的后期处理**

对录制完成的数字影片进行了剪接、加效果、加字幕、音乐等后期制作，当生成影片时需要将后加入的素材融合到影片中并压缩成为影片最终格式。这个一般都是这样，只是因环境的不同而不同。

**渲染滤镜**

“**渲染**”滤镜在图像中创建云彩图案、折射图案和模拟的光反射。也可在 3D 空间中操纵对象，并从灰度文件创建纹理填充以产生类似 3D 的光照效果。

1、分层云彩

使用随机生成的介于前景色与背景色之间的值，生成云彩图案。此滤镜将云彩数据和现有的像素混合，其方式与“差值”模式混合颜色的方式相同。第一次选取此滤镜时，图像的某些部分被反相为云彩图案。应用此滤镜几次之后，会创建出与大理石的纹理相似的凸缘与叶脉图案。

2、光照效果

使您可以通过改变 17 种光照样式、3 种光照类型和 4 套光照属性，在 RGB 图像上产生无数种光照效果。还可以使用灰度文件的纹理（称为凹凸图）产生类似 3D 的效果，并存储您自己的样式以在其它图像中使用。

3、镜头光晕

模拟亮光照射到像机镜头所产生的折射。通过点按图像缩览图的任一位置或拖移其十字线，指定光晕中心的位置。

4、纹理填充

用灰度文件或其中的一部分填充选区。若要将纹理添加到文档或选区，请打开要用作纹理填充的灰度文档。并将它装入要进行纹理填充的图像的某一通道中（新建），执行完效果后，可以看到灰度图浮凸在该图像中的效果。

5、云彩

使用介于前景色与背景色之间的随机值，生成柔和的云彩图案。若要生成色彩较为分明的云彩图案，请按住 Alt 键并选取“滤镜/渲染/云彩”命令。

【Proe中的渲染】

Pro / E 提供了制作高质量图像的渲染工具，能使零件或装配的显现近乎于照片。使用Pro/E的渲染功能，给予各零件色彩及相应的透明度，可是所设计的产品立体分明，更具视觉效果。而不必通过产生样机或[实物模型](http://baike.baidu.com/view/2226052.htm)来比较外观。特别是值入了 CDRS2001 里的高级渲染功能 Photolux，增加渲染的特殊效果而设的指令，可以做出雾效和透镜闪光等效果。可以将产品模型置于特定的环境，比如室内，你可以在此设置地板、四壁和天花板的背景，可对背景进行预览、尺寸和位置的调整；可以在特征或某个表面上设置材质，定义表面颜色、透明度、粗糙度和纹理等；另外，运用贴图功能在产品和包装上生成和附加常规的标记和图案，指定每个图案的大小、位置和透明度；指定光线类型颜色和强度，方便地选择和控制阴影的形式。
## **1.5编解码器**
编解码器（codec）指的是一个能够对一个信号或者一个数据流进行变换的设备或者程序。这里指的变换既包括将信号或者数据流进行编码（通常是为了传输、存储或者加密）或者提取得到一个编码流的操作，也包括为了观察或者处理从这个编码流中恢复适合观察或操作的形式的操作。编解码器经常用在视频会议和流媒体等应用中，通常主要还是用在广电行业，作前端应用。

经过编码的音频或者视频原始码流经常被叫做“Essence”（有译作“本体”，“精”），以区别于之后加入码流的元信息和其它用以帮助访问码流和增强码流鲁棒性的数据。

大多数编解码器是有损的，目的是为了得到更大的压缩比和更小的文件大小。当然也有无损的编解码器，但是通常没有必要为了一些几乎注意不到的的质量损失而大大增加编码后文件的大小。除非该编码的结果还将在以后进行下一步的处理，此时连续的有损编码通常会带来较大的质量损失。

很多多媒体数据流需要同时包含音频数据和视频数据，这时通常会加入一些用于音频和视频数据同步的元数据。这三种数据流可能会被不同的程序，进程或者硬件处理，但是当它们传输或者存储的时候，这三种数据通常是被封装在一起的。通常这种封装是通过视频文件格式来实现的，例如常见的\*.mpg, \*.avi, \*.mov, \*.mp4, \*.rm, \*.ogg or \*.tta. 这些格式中有些只能使用某些编解码器，而更多可以以容器的方式使用各种编解码器。

编解码器对应的英文“codec”（coder和decoder简化而成的合成词语）和decode通常指软件，当特指硬件的时候，通常使用“endec”这个单词。

硬件编解码器有标清编解码器和高清编解码器。所谓标清，英文为“Standard Definition”，是物理分辨率在720p以下的一种视频格式。720p是指视频的垂直分辨率为720线逐行扫描。具体的说，是指分辨率在400线左右的VCD、DVD、电视节目等“标清”视频格式，即标准清晰度。而物理分辨率达到720p以上则称作为高清,（英文表述High Definition）简称HD。关于高清的标准，国际上公认的有两条：视频垂直分辨率超过720p或1080i；视频宽纵比为16：9。
## **1.6容器和协议**
### **1.6.1容器格式和编码格式**
#### **1.6.1.1 简介**
音频视频编码及文件格式（容器）是一个很庞大的知识领域，完整的说清楚，那就需要些写成一本教材了。这里先就几个简单的概念问题作以介绍： 

`    `首先要分清楚媒体文件和编码的区别：

l 文件是既包括视频又包括音频、甚至还带有脚本的一个集合，也可以叫容器；

l 文件当中的视频和音频的压缩算法才是具体的编码。

`    `也就是说一个.avi文件，当中的视频可能是编码a，也可能是编码b，音频可能是编码5，也可能是编码6，具体的用那种编码的解码器，则由播放器按照avi文件格式读取信息去调用了。

音频视频编码方案有很多，用百家争鸣形容不算过分，目前常见的音频视频编码有以下几类：

- MPEG系列：（由ISO[国际标准组织机构]下属的MPEG[运动图象专家组]开发 ）

`    `视频编码方面主要是Mpeg1（vcd用的就是它）、Mpeg2（DVD使用）、Mpeg4（现在的DVDRIP使用的都是它的变种，如：divx，xvid等）、Mpeg4 AVC（现在正热门）；

`    `音频编码方面主要是MPEG Audio Layer 1/2、MPEG Audio Layer 3（大名鼎鼎的mp3）、MPEG-2 AAC 、MPEG-4 AAC等等。 注意：DVD音频没有采用Mpeg的

- H.26X系列：（由ITU[国际电传视讯联盟]主导，侧重网络传输，注意：只是视频编码）

`      `包括H261、H262、H263、H263+、H263++、H264（就是MPEG4 AVC-合作的结晶）

- 微软windows media系列：（公司牛，能自己定标准啊...）

`    `视频编码有Mpeg-4 v1/v2/v3（基于MPEG4，DIVX3的来源，呵呵）、Windows Media Video 7/8/9/10

`      `音频编码有Windows Media audeo v1/v2/7/8/9

- Real Media系列：（注意，这里说的Real的编码，可不是rm、rmvb文件，呵呵）

`      `视频编码有RealVideo G2（早期）、RealVideo 8/9/10

`      `音频编码有RealAudio cook/sipro（早期）、RealAudio AAC/AACPlus等

- QuickTime系列：（是一个平台，有很多编码器）

`      `视频编码有Sorenson Video 3（用于QT5，成标准了）、Apple MPEG-4、Apple H.264 

`      `音频编码有QDesign Music 2、Apple MPEG-4 AAC （这个不错） 

其它，如：Ogg、On2-vpx、flash vidio：不详述啦。

特殊说明的，是DVD这种媒介的音频编码，采用了相对独立的几种，就列2个常见的吧：AC3（杜比公司开发）、DTS文件格式（容器）：

- AVI 

`     `音视频交互存储，最常见的音频视频容器。支持的视频音频编码也是最多的。 

- MPG 
- MPEG编码采用的音频视频容器，具有流的特性。里面又分为 PS，TS 等，PS 主要用于 DVD 存储，TS 主要用于 HDTV。 
- VOB 

DVD采用的音频视频容器格式（即视频MPEG-2，音频用AC3或者DTS），支持多视频多音轨多字幕章节等。 

- MP4 

MPEG-4编码采用的音频视频容器，基于QuickTime MOV开发，具有许多先进特性。 

- 3GP 

`    `3GPP视频采用的格式，主要用于流媒体传送。 

- ASF 

`     `Windows Media 采用的音频视频容器，能够用于流传送，还能包容脚本等。 

- RM 

`     `RealMedia 采用的音频视频容器，用于流传送。 

`  `注意：RMVB，是视频编码部分采用可变码率压缩的文件格式（容器）

- MOV 

QuickTime 的音频视频容器，恐怕也是现今最强大的容器，甚至支持虚拟现实技术，Java 等，它的变种 MP4,3GP都没有这么厉害。 

- MKV 

MKV 它能把 Windows Media Video，RealVideo，MPEG-4 等视频音频融为一个文件，而且支持多音轨，支持章节字幕等。 

- WAV 

一种音频容器（注意：只是音频），大家常说的 WAV 就是没有压缩的 PCM 编码，其实 WAV 里面还可以包括 MP3 等其他 ACM 压缩编码。 

- MP3

如前所述，不用多说了吧？就是MPEG Audio Layer 3（Mpeg 1 的音频编码的一种）

文件转换（实际上也是编码转换）
#### **1.6.1.2 多媒体容器文件格式**
多媒体容器文件格式一般都包括文件头部分、索引部分和多媒体数据部分（如图1所示）。                 

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.010.png)

`   `文件头部分

`    `索引部分

多媒体数据部分文件头部分说明了多媒体数据符合的压缩标准及规范信息，多媒体数据符合的规范信息可以包括视频的分辨率、帧率，音频的采样率等。

索引部分:由于多媒体数据通常会被分成若干块，各块数据之间也可能是不连续存储的，因此需要再索引部分建立多媒体数据的存储位置索引（如图2所示），其详细显示了视频数据存储位置索引，用来记录相应数据块的存储位置的偏移量，由于各数据块的大小可能不同，因此也可能需要在索引部分建立各种多媒体数据块的尺寸大小索引，用来记录相应数据块的尺寸大小。此外在索引部分还建立了其他索引，比如音视频同步索引等等。PC上播放这些多媒体容器文件时，一般是将索引一次性的全部放到内存中，然后在播放中根据操作（快进、快退等）来通过数据索引得到所需的数据。这个貌似和项目里面的视频信息文件的作用类似~~~

多媒体数据部分就是经过压缩的多媒体数据，包括视频数据、音频数据、文本数据及其他多媒体数据。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.011.png)
#### **1.6.1.3 音频编解码格式** 
1) 音频编解码格式

`    `\*MPEG Audio Layer 1/2 

`　　`\*MPEG Audio Layer 3(MP3) 

`　　`\*MPEG2 AAC 

`　　`\*MPEG4 AAC 

`　　`\*Windows Media audeo v1/v2/7/8/9 

`　　`\*RealAudio cook/sipro(real media array) 

`　　`\*RealAudio AAC/AACPlus(real media series) 

`　　`\*QDesign Music 2(apple series) 

`　　`是QDesign 公司开发的用于高保真高压缩率的编码方式，类似于MP3，不过比MP3要先进。支持流式播放. 

`　　`\*Apple MPEG-4 AAC(apple series) 

`　　`\*ogg(ogg vorbis音频) 

`　　`\*AC3(DVD 专用音频编码) 

`　　`\*DTS(DVD 专用音频编码) 

`　　`\*APE(monkey’s 音频) 

`　　`\*AU(sun 格式) 

`　　`\*FLAC(fress lossless 音频) 

`　　`\*M4A(mpeg-4音频)（苹果改用的名字，可以改成.mp4） 

`　　`\*MP2(mpeg audio layer2音频) 

`　　`\*WMA 

1) 视频编解码格式 

`　　`\*MPEG1(VCD) 

`　　`\*MPEG2(DVD) 

`　　`\*MPEG4(divx,xvid) 

`　　`\*MPEG4 AVC/h.264 

`　　`\*h.261 

`　　`\*h.262 

`　　`\*h.263 

`　　`\*h.263+ 

`　　`\*h.263++ 

`　　`\*MPEG-4 v1/v2/v3(微软windows media系列) 

`　　`\*Windows Media Video 7/8/9/10 

`　　`\*Sorenson Video 3（用于QT5，成标准了）(apple series) 

`　　`\*RealVideo G2(real media series) 

`　　`\*RealVideo 8/9/10(real media series) 

`　　`\*Apple MPEG-4(apple series) 

`　　`\*Apple H.264(apple series) 

`　　`\*flash video 

1) 音视频文件格式 

`　　 `首先要分清楚媒体文件和编码的区别：文件是既包括视频又包括音频、甚至还带有脚本的一个集合，也可以叫容器；文件当中的视频和音频的压缩算法才是具体的编码。 

`　　`\*AVI 

`　　`音视频交互存储，最常见的音频视频容器。支持的视频音频编码也是最多的 

`　　`\*MPG 

`　　`MPEG编码采用的音频视频容器，具有流的特性。里面又分为 PS，TS 等，PS 主要用于 DVD 存储，TS 主要用于 HDTV。 

`　　`\*VOB 

`　　`DVD采用的音频视频容器格式（即视频MPEG-2，音频用AC3或者DTS），支持多视频多音轨多字幕章节等。 

`　　`\*MP4 

`　　`MPEG-4编码采用的音频视频容器，基于 QuickTime MOV 开发，具有许多先进特性。 

`　　`\*3GP 

`　　`3GPP视频采用的格式，主要用于流媒体传送。 

`　　`\*ASF 

`　　`Windows Media 采用的音频视频容器，能够用于流传送，还能包容脚本等。 

`　　`\*RM 

`　　`RealMedia 采用的音频视频容器，用于流传送。 

`　　`\*MOV 

`　　`QuickTime 的音频视频容器，恐怕也是现今最强大的容器，甚至支持虚拟现实技术，Java 等，它的变种 MP4,3GP都没有这么厉害。 

`　　`\*MKV 

`　　`MKV 它能把 Windows Media Video，RealVideo，MPEG-4 等视频音频融为一个文件，而且支持多音轨，支持章节字幕等。 

`　　`\*WAV 

`　　`一种音频容器（注意：只是音频），大家常说的 WAV 就是没有压缩的 PCM 编码，其实 WAV 里面还可以包括 MP3 等其他 ACM 压缩编码。 

1) 音视频技术 

`　　`VCD 

`　　`DVD 

`　　`DVD目录是如何工作的 

`　　`Audio CD 

`　　`\*标准CD格式也就是44.1K的采样频率，速率88K/秒，16位量化位数 

`　　`\*＊.cda格式，这就是CD音轨了，一个CD音频文件是一个＊.cda文件，这只是一个索引信息，并不是真正的包含声音信息，所以不论CD音乐的长短，在电脑上看到的“＊.cda文件”都是44字节长 

`　　`MP3 

`　　`\*MPEG音频文件的压缩是一种有损压缩，MPEG3音频编码具有10：1~12：1的高压缩率，同时基本保持低音频部分不失真，但是牺牲了声音文件中12KHz到16KHz高音频这部分的质量来换取文件的尺寸，相同长度的音乐文件，用＊.mp3格式来储存，一般只有＊.wav文件的1/10，而音质要次于CD格式或WAV格式的声音文件 

`　　`\*MP3格式压缩音乐的采样频率有很多种，可以用64Kbps或更低的采样频率节省空间，也可以用320Kbps的标准达到极高的音质 

`　　`\*每分钟音乐的MP3格式只有1MB左右大小 

`　　`MIDI： 

`　　`经常玩音乐的人应该常听到MIDI（Musical Instrument Digital Interface）这个词，MIDI允许数字合成器和其他设备交换数据。MID文件格式由MIDI继承而来。MID文件并不是一段录制好的声音，而是记录声音的信息，然后在告诉声卡如何再现音乐的一组指令。这样一个MIDI文件每存1分钟的音乐只用大约5～10KB。今天，MID文件主要用于原始乐器作品，流行歌曲的业余表演，游戏音轨以及电子贺卡等。＊.mid文件重放的效果完全依赖声卡的档次。＊.mid格式的最大用处是在电脑作曲领域。＊.mid文件可以用作曲软件写出，也可以通过声卡的MIDI口把外接音序器演奏的乐曲输入电脑里，制成＊.mid文件。 

`　　`WMA: 

`　　`\*WMA的压缩率一般都可以达到1：18左右，WMA的另一个优点是内容提供商可以通过DRM（Digital Rights Management）方案如Windows Media Rights Manager 7加入防拷贝保护。这种内置了版权保护技术可以限制播放时间和播放次数甚至于播放的机器等等，这对被盗版搅得焦头乱额的音乐公司来说可是一个福音，另外WMA还支持音频流(Stream)技术，适合在网络上在线播放 

`　　`\* WMA这种格式在录制时可以对音质进行调节。同一格式，音质好的可与CD媲美，压缩率较高的可用于网络广播 

1) 以文件名标识识别音频编码格式 

`　　`\*.aac 

`　　`音频编码：aac 

`　　`\*.ac3 

`　　`音频编码：ac3 

`　　`\*.ape 

`　　`\*.au 

`　　`音频编码：pcm\_s16be 

`　　`\*.m4a 

`　　`音频编码：mpeg4 aac 

`　　`\*.mp2 

`　　`\*.mp3 

`　　`\*.ogg 

`　　`音频编码：vorbis 

`　　`\*.wav 

`　　`音频编码：pcm\_s16le 

`　　`\*.flav 

`　　`\*.wma 

`　　`音频编码：wma7x 

`　　`以文件名标识识别音视频编码格式 

`　　`1．\*.MP4 (MP4 MPEG-4视频) 

`　　`视频编码：mpeg4 

`　　`音频编码：mpeg4 aac 

`　　`２．\*.3gp (3GPP 第三代合作项目) 

`　　`视频编码：mpeg4 

`　　`音频编码：amr\_nb((mono, 8000 Hz, Sample Depth 16 morsel, bitrate 12 kbps) 

`　　`３．\*.3g2 (3GPP 第三代合作项目2) 

`　　`视频编码：mpeg4 

`　　`音频编码：mpeg4 aac 

`　　`4．\*.asf (ASF 高级流格式) 

`　　`视频编码：msmpeg4 

`　　`音频编码：mp3 

`　　`5．\*.avi （AVI 音视频交错格式） 

`　　`视频编码：mpeg4 

`　　`音频编码：pcm\_s161e 

`　　`6．\*.avi （divx 影片） 

`　　`视频编码：mpeg4 

`　　`音频编码：mp3 

`　　`7．\*.avi（xvid 视频） 

`　　`视频编码：Xvid 

`　　`音频编码：mp3 

`　　`8．\*.vob （DVD） 

`　　`视频编码：mpeg2 video 

`　　`音频编码：ac3 

`　　`9．\*.flv (flash 视频格式) 

`　　`视频编码： 

`　　`音频编码：mp3 

`　　`10．\*.mp4 (iPod 320\*240 MPEG-4 视频格式) 

`　　`视频编码：mpeg4 

`　　`音频编码：mpeg4 aac 

`　　`11．\*.mp4(iPod video2 640\*480 MPEG-4 视频格式) 

`　　`视频编码：mpeg4 

`　　`音频编码：mpeg4 aac 

`　　`12．\*.mov (MOV 苹果quicktime 格式) 

`　　`视频编码：mpeg4\_qt 

`　　`音频编码：mpeg4 aac\_qt 

`　　`13．\*.mpg （mpeg1影片） 

`　　`视频编码：mpeg1 video 

`　　`音频编码：mp2 

`　　`14．\*.mpg （mpeg2 影片） 

`　　`视频编码：mpeg2 video 

`　　`音频编码：mp2 

`　　`15．\*.mp4 （mpeg4 avc 视频格式） 

`　　`视频编码：h.264 

`　　`音频编码：mpeg4 aac 

`　　`16．\*.mp4 （PSP mpeg4 影片） 

`　　`视频编码：Xvid 

`　　`音频编码：mpeg4 aac 

`　　`17．\*.mp4 （PSP AVC 视频格式） 

`　　`视频编码：h.264 

`　　`音频编码：mpeg4 aac 

`　　`18．\*.rm （RM realvideo） 

`　　`视频编码：rv10 

`　　`音频编码：ac3 

`　　`19．\*.mpg (超级VCD) 

`　　`视频编码：mpeg2 video 

`　　`音频编码：mp2 

`　　`20．\*.swf (SWF 格式) 

`　　`视频编码： 

`　　`音频编码：mp3 

`　　`21．\*.mpg （video CD 格式） 

`　　`视频编码：mpeg1 video 

`　　`音频编码：mp2 

`　　`22．\*.vob （mpeg2 ps格式） 

`　　`视频编码：mpeg2 video 

`　　`音频编码：ac3 

`　　`23．\*.wmv（windows 视频格式） 

`　　`视频编码：wmv3x 

音频编码：wma7x
### **1.6.2协议**
两大标准制定组织 

这里的标准，主要指的是音视频压缩标准。两大组织分别是国际标准化组织（iso）和国际电信联盟（itu），相信it行业的从业者没听说过这两个行业的人很少。 

在音视频压缩标准方面，mpeg系列的协议是iso制定的标准，而h系列的协议则是itu制定的标准。
### **1.6.2.1 视频协议**
目前主要的视频压缩协议有：h.261、h.263、h.264和mpeg-1、mpeg-2和mpeg-4。第一个视频压缩标准是h.261，它的算法 现 在来看，非常简单，但是，它的很多视频压缩的思想，一直影响到现在最新的压缩标准h.264。h.264单看名字，感觉是itu组织制定的，其实它还有一 个名字叫mpeg-4   part   10，翻译过来叫mpeg-4   第十部分，这是因为h.264是iso和itu组织共同制定的，版权共享。其实，一直以来，h系列的标准制定者和mpeg系列的标准制定者基本上就是同一 群人，而且，这两个系列的算法思想基本上都差不多，唯一有一点不同的协议是mpeg-4，它在它的高级profile中提出了小波变换等算法来实现视频压 缩，从实际发展看，个人感觉不是很成功，采用小波变换的商用codec很少，这可能和这些算法的达不到实时性有关系。 

从应用的角度看，mpeg 系列在消费类应用更广些，大家也更熟悉些，我们熟悉的vcd格式视频主要是mpeg-1，dvd的视频则是mpeg-2，早期大家看的电影在电脑上存盘文 件格式都是\*.mpg，基本上也都是mpeg做的压缩了。在行业上，国内的监控行业，也是从mpeg-1到mpeg-2，到前两三年的mpeg-4，再到 最近的h.264。而h系列的标准，用得最多的是视频会议，从h.261到h.263，再到h.263+、h.263++等，再到现在的h.264。 

从技术角度说，h系列的协议对网络的支持更好些，这点mpeg系列要差一些，但是，mpeg它每一代都比h系列同一代的协议要出得晚些，算法也相对更先进 些，因此，它用来做存储协议是很合适的，这也就是为什么普通消费类产品用户很少了解到h系列协议的原因。 

h.264是两大组织最新的算法成果，它在算法层面应该说是非常先进了，有人评价，h.264是视频压缩技术的一个里程碑，在可预见的5到10年内，出现新的视频压缩协议可能性很小，除非压缩理论有重大突破。 

中国也有自己的视频压缩协议，叫做avs，搞了好多年了，不过搞得不是很好。从市场分析，消费类电子、视频会议和流媒体行业，现在要再想进去可能很困难 了。不过最近听说avs又有点火起来了，有消息称，iptv指定要支持avs，这可能是它的最后机会了吧。 

除了上面说的协议，还有很多公司也有自己的压缩算法，不过基本上都是不公开的了，他们这些算法也都非常好，不过和开发人员关系倒不是很大了，典型的是微软 的wmv、realplay公司的rm和rmvb等，他们的使用者也很多，而且他们都偏向流媒体应用。 
### **1.6.2.2 音频协议.**
音频协议也分两大类，itu组织的主要是用于视频会议的g系列协议，包括g.711、g.722、g.723、g.726、g.728、g.729等。这些 协议主要有两大特点，第一是比较关注语音压缩，毕竟开会主要是要听人讲话；对音乐的压缩效果可能就不是太好了；第二是压缩率都比较大，码率都比较低，典型 的g.723支持5.9k/s这样的码率，而且语音音质还很不错。iso的音频可能更为人熟知一些，最流行的就是mp3，它的全称是mpeg-1 audio layer 3，意思是mpeg-1的音频第三层；另外，最新的音频算法被称为aac（也称为mp4），它定义在mpeg-2或mpeg-4的音频部分。他们的特点是 音质好，支持多声道，高采样精度和采样频率，尤其对音乐的压缩效果比g系列要好太多。当然，这也是因为它们的应用领域侧重点不同造成的。 

同样的，很多大公司也有自己的语音压缩标准，效果也非常好。不过都是他们自己的知识产权和算法，通用市场用的还是少。
### **1.6.2.3 上层通讯协议**
在视频会议系统中，目前最流行的有h.323和sip协议，在流媒体应用中，isma   rtsp应用得比较多，它属于开源项目，而很多流媒体产商有自己的流媒体传输协议，比如微软的mms等。 

h.323 主要用于视频会议，被称为协议簇，我们前面提到的h系列视频压缩协议和g系列音频压缩协议都属于它的子协议。除了音视频编解码器外；它还定义了各种数据应 用，包括t.120、t.84、t.434等；另外还包括h.245控制信道、h.225.0呼叫信令信道以及ras信道。详细的h.323的知识，这里 就不深入介绍了。 

sip是由ietf提出来的一个应用控制（信令）协议。正如名字所隐含的--用于发起会话。它可用来创建、修改以及终结多个参与者参加的多媒体会话进程。参与会话的成员可以通过组播方式、单播连网或者两者结合的形式进行通信。 

h.323 和sip分别是通信领域与因特网两大阵营推出的建议。h.323企图把ip电话当作是众所周知的传统电话，只是传输方式发生了改变，由电路交换变成了分组交换。而sip协议侧重于将ip电话作为因特网上的一 个应用，较其实应用（如ftp，e-mail等）增加了信令和qos的要求，它们支持的业务基本相同，也都利用rtp作为媒体传输的协议。但h.323是 一个相对复杂的协议。 

rtsp主要用于流媒体传输，它的英文全称是real time streaming protocol。典型的应用就是网络电视的应用，由客户向服务器进行点播，如果在监控行业应用的话，建议当用户进行远程回放录像时，可采用rtsp协议。
## **1.7常用概念介绍**
### **1.7.1硬解**
硬件解码：

视频解码分为软解和硬解。

所谓“软解”就是通过软件让CPU进行视频解码处理；而“硬解”是指不依赖于CPU，通过专用的设备（子卡）单独完成视频解码，比如曾经的VCD/DVD解压卡、视频压缩卡都被冠以“硬解”的称号。现在实现高清硬解不需要额外的子卡，也不需要额外的投入，因为硬解码模块被整合在了GPU内部，而目前主流的显卡（包括整合显卡）都能支持硬解码。

“硬解”其实更需要软件的支持，只是基本不需要CPU参与运算，从而为系统节约了很多资源开销。通过降低CPU占用率，可以给用户带来很多实惠：

● GPU硬解码高清视频的优势：

\1. 不需要太好的CPU，单核足矣，CPU方面节约不少资金；

\2. 硬解码基本相当于免费附送，不到500元的整合主板都能完美支持；

\3. 硬解码让CPU占用率超低，系统有能力在看HDTV的同时进行多任务操作；

\4. CPU需要倾尽全力才能解码HDTV，而GPU只需动用0.1亿晶体管的解码模块就能完成任务，功耗控制更好；

● GPU硬解码高清视频的劣势：

\1. 起步较晚，软件支持度无法与软解相提并论；

\2. 面对杂乱无章的视频编码、封装格式，硬解码无法做到全面兼容；

\3. 软解拥有大量画面输出补偿及画质增强技术，而硬解这方面做得还远远不够；

\4. 硬解码软件设置较为复杂，很多朋友根本不知道该如何正确使用GPU硬件解码。

虽然硬解码拥有种种缺点，但依然倍受广大用户追捧，因为低成本和节能环保这两大致命诱惑让人难以抗拒。随着时间的推移，现在硬解码的缺点基本被改进，只是很多人还不懂得如何用好硬解码，本文就通过大量应用案例来释放出硬解码真正的威力！

**解码芯片**(又叫[解压缩](http://baike.baidu.com/view/845020.htm)芯片). 手机播放视频要依赖于解码芯片把画面和声音还原成可以播放的信号， 交由显示屏和喇叭(耳机)输出。 解码芯片的性能是有局限的, 类似于汽车的发动机功率是有极限的. 它能够流畅解码的数据，主要受限于以下几个参数和条件。
### **1.7.2 IBP帧**
帧——就是影像动画中最小单位的单幅影像画面，相当于电影胶片上的每一格镜头。而在实际压缩时，会采取各种算法减少数据的容量，其中IPB就是最常见的。

1、基本概念

I frame ：帧内编码帧 又称intra picture，I 帧通常是每个 GOP（MPEG 所使用的一种视频压缩技术）的第一个帧，经过适度地压缩，做为随机访问的参考点，可以当成图象。I帧可以看成是一个图像经过压缩后的产物。P frame: 前向预测编码帧 又称predictive-frame，通过充分将低于图像序列中前面已编码帧的时间冗余信息来压缩传输数据量的编码图像，也叫预测帧；

B frame: 双向预测内插编码帧 又称bi-directional interpolated prediction frame，既考虑与源图像序列前面已编码帧，也顾及源图像序列后面已编码帧之间的时间冗余信息来压缩传输数据量的编码图像，也叫双向预测帧；

PTS：Presentation Time Stamp。PTS主要用于度量解码后的视频帧什么时候被显示出来

DTS：Decode Time Stamp。DTS主要是标识读入内存中的ｂｉｔ流在什么时候开始送入解码器中进行解码。

ps:在没有B帧存在的情况下DTS的顺序和PTS的顺序应该是一样的。

2、I、B、P的特点

I帧特点: 

1.它是一个全帧压缩编码帧。它将全帧图像信息进行JPEG压缩编码及传输; 

2.解码时仅用I帧的数据就可重构完整图像; 

3.I帧描述了图像背景和运动主体的详情; 

4.I帧不需要参考其他画面而生成; 

5.I帧是P帧和B帧的参考帧(其质量直接影响到同组中以后各帧的质量); 

6.I帧是帧组GOP的基础帧(第一帧),在一组中只有一个I帧; 

7.I帧不需要考虑运动矢量; 

8.I帧所占数据的信息量比较大。

P帧:前向预测编码帧。

P帧的预测与重构:P 帧是以I帧为参考帧,在I帧中找出P帧“某点”的预测值和运动矢量,

取预测差值和运动矢量一起传送。在接收端根据运动矢量从I帧中找出P帧“某点”的预测

值并与差值相加以得到P帧“某点”样值,从而可得到完整的P帧。

P帧特点: 

1.P帧是I帧后面相隔1~2帧的编码帧; 

2.P帧采用运动补偿的方法传送它与前面的I或P帧的差值及运动矢量(预测误差); 

3.解码时必须将I帧中的预测值与预测误差求和后才能重构完整的P帧图像; 

4.P帧属于前向预测的帧间编码。它只参考前面最靠近它的I帧或P帧; 

5.P帧可以是其后面P帧的参考帧,也可以是其前后的B帧的参考帧; 

6.由于P帧是参考帧,它可能造成解码错误的扩散; 

7.由于是差值传送,P帧的压缩比较高。

B帧:双向预测内插编码帧。

B帧的预测与重构

B帧以前面的I或P帧和后面的P帧为参考帧,“找出”B帧“某点”的预测值和两个运动矢

量,并取预测差值和运动矢量传送。接收端根据运动矢量在两个参考帧中“找出(算出)”预测

值并与差值求和,得到B帧“某点”样值,从而可得到完整的B帧。

B帧特点

1.B帧是由前面的I或P帧和后面的P帧来进行预测的; 

2.B帧传送的是它与前面的I或P帧和后面的P帧之间的预测误差及运动矢量; 

3.B帧是双向预测编码帧; 

4.B帧压缩比最高,因为它只反映丙参考帧间运动主体的变化情况,预测比较准确; 

5.B帧不是参考帧,不会造成解码错误的扩散。

注:I、B、P各帧是根据压缩算法的需要,是人为定义的,它们都是实实在在的物理帧,至于图像

中的哪一帧是I帧,是随机的,一但确定了I帧,以后的各帧就严格按规定顺序排列

`    `从上面的解释看，我们知道I和P的解码算法比较简单，资源占用也比较少，I只要自己完成就行了，P呢，也只需要解码器把前一个画面缓存一下，遇到P时就使用之前缓存的画面就好了，如果视频流只有I和P，解码器可以不管后面的数据，边读边解码，线性前进，大家很舒服。

`    `但网络上的电影很多都采用了B帧，因为B帧记录的是前后帧的差别，比P帧能节约更多的空间，但这样一来，文件小了，解码器就麻烦了，因为在解码时，不仅要用之前缓存的画面，还要知道下一个I或者P的画面（也就是说要预读预解码），而且，B帧不能简单地丢掉，因为B帧其实也包含了画面信息，如果简单丢掉，并用之前的画面简单重复，就会造成画面卡（其实就是丢帧了），并且由于网络上的电影为了节约空间，往往使用相当多的B帧，B帧用的多，对不支持B帧的播放器就造成更大的困扰，画面也就越卡。

`    `一般平均来说，I的压缩率是7（跟JPG差不多），P是20，B可以达到50，可见使用B帧能节省大量空间，节省出来的空间可以用来保存多一些I帧，这样在相同码率下，可以提供更好的画质。

3、GOP

GOP：Group of Pictures 画面组 

`  `GOP（Group of Pictures）策略影响编码质量：所谓GOP，意思是画面组，一个GOP就是一组连续的画面。MPEG编码将画面（即帧）分为I、P、B三种，I是内部编码帧，P是前向预测帧，B是双向内插帧。简单地讲，I帧是一个完整的画面，而P帧和B帧记录的是相对于I帧的变化。没有I帧，P帧和B帧就无法解码，这就是MPEG格式难以精确剪辑的原因，也是我们之所以要微调头和尾的原因。   MPEG-2 帧结构 

`  `MPEG-2压缩的帧结构有两个参数，一个是GOP（Group Of Picture）图像组的长度，一般可按编码方式从1－15；另一个是I帧和P帧之间B帧的数量，一般是1－2个。前者在理论上记录为N，即多少帧里面出现一次I帧；后者描述为多少帧里出现一次P帧，记录为M。

下面举例说明：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.012.jpeg)

在如上图中，GOP (Group of Pictures)长度为13，S0~S7 表示 8个视点，T0~T12 为 GOP的 13个时刻。每个 GOP包含帧数为视点数 GOP 长度的乘积。在该图中一个 GOP 中，包含94 个 B帧。B 帧占一个 GOP 总帧数的 90.38%。GOP 越长，B 帧所占比例更高，编码的率失真性能越高。下图测试序列 Race1 在不同 GOP 下的率失真性能对比。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.013.jpeg)

4、mpeg4视频中IBP的判定

`    `mpeg4的每一帧开头是固定的：00 00 01 b6，那么我们如何判断当前帧属于什么帧呢？在接下来的2bit，将会告诉我们答案。注意：是2bit，不是byte，下面是各类型帧与2bit的对应关系：

`　　`00: I Frame

`　　`01: P Frame

`　　`10: B Frame　

为了更好地说明，我们举几个例子，以下是16进制显示的视频编码：

`　　`00 00 01 b6 10 34 78 97 09 87 06 57 87 ……                             I帧

`　　`00 00 01 b6 50 78 34 20 cc 66 b3 89 ……                                  P帧

`　　`00 00 01 b6 96 88 99 06 54 34 78 90 98 ……                              B帧

下面我们来分析一下为什么他们分别是I、P、B帧

`　　`0x10 = 0001 0000

`　　`0x50 = 0101 0000

`　　`0x96 = 1001 0100　

大家看红色的2bit，再对照开头说的帧与2bit的对应关系，是不是符合了呢？

下面给出一段c++代码供大家参考：

**[cpp]** [view plain](http://blog.csdn.net/ameyume/article/details/6722450#)[copy](http://blog.csdn.net/ameyume/article/details/6722450#)

```cpp

switch(buf[i] & (BYTE)0xc0)   
{ 
	case 0x00:
		//I Frame  
		break;  
	case 0x40:  
		//P Frame  
		break;  
	case 0x80:  
		//B Frame  
		break;  
	default:  
		break; 
} 
```

### **1.7.3 DTS和PTS**
### **1.7.4 分辨率**
这里有2个概念， 分别是：

a. 物理分辨率, 即手机屏幕能显示的像素数， 用W x H个像素表示。常见的手机屏幕分辨率为320x240(QVGA), 随着大屏幕手机的普及， 更高的分辨率也开始出现. 例如: 480x320(iphone),640x360(nHD, 诺基亚触屏系列常见),640x480(VGA, 多普达系列常见), 甚至高达852x480(夏普高端手机常见).

b. 视频文件的分辨率， 这个是指视频画面的实际分辨率, 如， 320x240, 480x272, 640x480等等。

一般来说， 大部分手机的解码芯片不支持超过其屏幕物理分辨率的视频, 部分可以支持超过其屏幕物理分辨率的视频， 例如, 虽然iphone的屏幕物理分辨率为480x320, 但它支持640x480的视频， 此时播放的画面实际是把原视频缩小的.
### **1.7.5 码率**
一般用多少kbps(千比特/秒)或者[mbps](http://baike.baidu.com/view/496716.htm)([兆比特](http://baike.baidu.com/view/1094167.htm)/秒)来表示。 手机解码芯片所支持的码率一般都在1Mbps以下.
### **1.7.6 帧率**
(FPS, 帧/秒), 就是视频画面刷新的速度， 作为参考, 国内电视机一般是25FPS, 电影标准为24FPS. 手机芯片， 最高支持30FPS, 早期型号最大只能15fps。
### **1.7.7 RGB和YUV**
RGB指的是红绿蓝，应用还是很广泛的，比如显示器显示，bmp文件格式中的像素值等；而yuv主要指亮度和两个色差信号，被称为luminance和 chrominance他们的转化关系可以自己去查一下，我们视频里面基本上都是用yuv格式。 

YUV文件格式又分很多种，如果算上存储格式，就更多了，比如yuv444、yuv422、yuv411、yuv420等等，视频压缩用到的是420格式，这是 因为人眼对亮度更敏感些，对色度相对要差些。另外要注意几个英文单词的意思，比如：packet、planar、interlace、 progressive等。 
### **1.7.8 实时和非实时**
实时与非实时 主要用来形容编码器，它含有两个意思，一个是要保证帧率，也就是每秒25帧，另一个是“live”的意思，意味着直播，所谓的“实况转播”的“实”。
### **1.7.9 复合视频和s-video**
ntsc 和pal彩色视频信号是这样构成的--首先有一个基本的黑白视频信号，然后在每个水平同步脉冲之后，加入一个颜色脉冲和一个亮度信号。因为彩色信号是由多 种数据“叠加”起来的，故称之为“复合视频”。s-video则是一种信号质量更高的视频接口，它取消了信号叠加的方法，可有效避免一些无谓的质量损失。 它的   功能是将rgb三原色和亮度进行分离处理。
### **1.7.10 硬件加速**
VDA/vaspi/DX等等。
### **1.7.11 FFmpeg Device**
硬件方式：CDIO / DC1394 （输入设备）

非扩展硬件：DSHOW（输入设备）、SDL（输出设备）、X11（输入）、VFWCAP（输入）、DV1394（输入）等等。

第二章 FFmpeg框架
## **2.1 FFmpeg概述**
### **2.1.1简介**
Open-source multimedia library， 遵从GPL/LGPL协议，ffmpeg只是一个商标，它的所有权属于ffmpeg org。

由Fabrice Bellard（法国著名程序员Born in 1972）于2000年发起创建的开源项目，同时也是TinyCC(1996)、发现最快速计算圆周率算法(1997)、 TinyGL(1998)、QEMU(2003)、 Jslinux(2011)等等的发起人或作者。

FFmpeg在Linux平台下开发，但它同样也可以在其它操作系统环境中编译运行，包括Windows、Mac OS X等。

这个项目最早由Fabrice Bellard发起，现在由Michael Niedermayer维护。许多FFmpeg的开发人员都来自MPlayer项目，而且当前FFmpeg也是放在MPlayer项目组的服务器上。项目的名称来自MPEG视频编码标准，前面的"FF"代表"Fast Forward"。

FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。它包括了目前领先的音/视频编码库libavcodec。 FFmpeg是在Linux下开发出来的，但它可以在包括Windows在内的大多数操作系统中编译。这个项目是由Fabrice Bellard发起的，现在由Michael Niedermayer主持。可以轻易地实现多种视频格式之间的相互转换，例如可以将摄录下的视频avi等转成现在视频网站所采用的flv格式。
### **2.1.2功能**
多媒体视频处理工具FFmpeg有非常强大的功能[2]包括视频采集功能、视频格式转换、视频抓图、给视频加水印等。

视频采集功能

FFmpeg是在Linux下开发出来的，但它可以在包括Windows在内的大多数操作系统中编译。这个项目是由Fabrice Bellard发起的，现在由Michael Niedermayer主持。

ffmpeg视频采集功能非常强大，不仅可以采集视频采集卡或USB摄像头的图像，还可以进行屏幕录制，同时还支持以RTP方式将视频流传送给支持RTSP的流媒体服务器，支持直播应用。

ffmpeg在Linux下的视频采集

在Linux平台上，ffmpeg对V4L2的视频设备提高了很好的支持，如：

./ffmpeg -t 10 -f video4linux2 -s 176\*144 -r 8 -i /dev/video0 -vcodec h263 -f rtp rtp://192.168.1.105:5060 > /tmp/ffmpeg.sdp

以上命令表示：采集10秒钟视频，对video4linux2视频设备进行采集，采集QCIF(176\*144)的视频，每秒8帧，视频设备为/dev/video0，视频编码为h263，输出格式为RTP，后面定义了IP地址及端口，将该码流所对应的SDP文件重定向到/tmp/ffmpeg.sdp中，将此SDP文件上传到流媒体服务器就可以实现直播了。

ffmpeg在windows下的视频采集

在windows下关于ffmpeg视频采集的资料非常少，但是ffmpeg还是支持windows下视频采集的。ffmpeg支持windows下video for windows(VFW)设备的视频采集，不过VFW设备已经过时，正在被WDM的视频设备所取代，但是ffmpeg还没有支持WDM的计划，不过好像有将WDM转为VFW的工具，因此ffmpeg还是可以在windows下进行视频采集的。

视频格式转换功能

ffmpeg视频转换功能。视频格式转换，比如可以将多种视频格式转换为flv格式，可不是视频信号转换 。

ffmpeg可以轻易地实现多种视频格式之间的相互转换(wma,rm,avi,mod等)，例如可以将摄录下的视频avi等转成现在视频网站所采用的flv格式。

视频截图功能

对于选定的视频，截取指定时间的缩略图。视频抓图，获取静态图和动态图，不提倡抓gif文件;因为抓出的gif文件大而播放不流畅

给视频加水印功能

使用ffmpeg 视频添加水印(logo)。
### **2.1.3模块组成**
FFmpeg是一套可以用来记录、转换数字音频、视频，并能将其转化为流的开源计算机程序。它包括了领先的音/视频编码库libavcodec等。

libavformat：用于各种音视频封装格式的生成和解析，包括获取解码所需信息以生成解码上下文结构和读取音视频帧等功能；音视频的格式解析协议，为libavcodec分析码流提供独立的音频或视频码流源。

libavcodec：用于各种类型声音/图像编解码；该库是音视频编解码核心，实现了市面上可见的绝大部分解码器的功能，libavcodec库被其他各大解码器ffdshow，Mplayer等所包含或应用。

libavdevice：硬件采集、加速、显示。操作计算机中常用的音视频捕获或输出设备：ALSA,AUDIO\_BEOS,JACK,OSS,1394，VFW。

libavfilter:filter（FileIO、FPS、DrawText）音视频滤波器的开发，如宽高比 裁剪 格式化 非格式化 伸缩。

libavutil：包含一些公共的工具函数的使用库，包括算数运算 字符操作；

libavresample：音视频封转编解码格式预设等。

libswscale：（原始视频格式转换）用于视频场景比例缩放、色彩映射转换；图像颜色空间或格式转换，如rgb565 rgb888等与yuv420等之间转换。

libswresample：原始音频格式转码

libpostproc：（同步、时间计算的简单算法）用于后期效果处理；音视频应用的后处理，如图像的去块效应。

ffmpeg：该项目提供的一个工具，可用于格式转换、解码或电视卡即时编码等；

ffsever：一个 HTTP 多媒体即时广播串流服务器；

ffplay：是一个简单的播放器，使用ffmpeg 库解析和解码，通过SDL显示；
### **2.1.4命令集**
ffmpeg 命令集举例

1.获取视频的信息
```
ffmpeg -i video.avi
```

2.将图片序列合成视频
```
ffmpeg -f image2 -i image%d.jpg video.mpg
```
上面的命令会把当前目录下的图片（名字如：image1.jpg. image2.jpg. 等...）合并成video.mpg

3.将视频分解成图片序列
```
ffmpeg -i video.mpg image%d.jpg
```
上面的命令会生成image1.jpg. image2.jpg. ...

支持的图片格式有：PGM. PPM. PAM. PGMYUV. JPEG. GIF. PNG. TIFF. SGI

4.为视频重新编码以适合在iPod/iPhone上播放
```
ffmpeg -i source\_video.avi input -acodec aac -ab 128kb -vcodec mpeg4 -b 1200kb -mbd 2 -flags +4mv+trell -aic 2 -cmp 2 -subcmp 2 -s 320x180 -title X final\_video.mp4
```
说明：

\* 源视频：source\_video.avi

\* 音频编码：aac

\* 音频位率：128kb/s

\* 视频编码：mpeg4

\* 视频位率：1200kb/s

\* 视频尺寸：320 X 180

\* 生成的视频：final\_video.mp4

5.为视频重新编码以适合在PSP上播放
```
ffmpeg -i source\_video.avi -b 300 -s 320x240 -vcodec xvid -ab 32 -ar 24000 -acodec aac final\_video.mp4
```

说明：

\* 源视频：source\_video.avi

\* 音频编码：aac

\* 音频位率：32kb/s

\* 视频编码：xvid

\* 视频位率：1200kb/s

\* 视频尺寸：320 X 180

\* 生成的视频：final\_video.mp4

6.从视频抽出声音.并存为Mp3
```
ffmpeg -i source\_video.avi -vn -ar 44100 -ac 2 -ab 192 -f mp3 sound.mp3
```

说明：

\* 源视频：source\_video.avi

\* 音频位率：192kb/s

\* 输出格式：mp3

\* 生成的声音：sound.mp3

7.将wav文件转成Mp3
```
ffmpeg -i son\_origine.avi -vn -ar 44100 -ac 2 -ab 192 -f mp3 son\_final.mp3
```

8.将.avi视频转成.mpg
```
ffmpeg -i video\_origine.avi video\_finale.mpg
```

9.将.mpg转成.avi
```
ffmpeg -i video\_origine.mpg video\_finale.avi
```

10.将.avi转成gif动画（未压缩）
```
ffmpeg -i video\_origine.avi gif\_anime.gif
```

11.合成视频和音频
```
ffmpeg -i son.wav -i video\_origine.avi video\_finale.mpg
```

12.将.avi转成.flv
```
ffmpeg -i video\_origine.avi -ab 56 -ar 44100 -b 200 -r 15 -s 320x240 -f flv video\_finale.flv
```

13.将.avi转成dv
```
ffmpeg -i video\_origine.avi -s pal -r pal -aspect 4:3 -ar 48000 -ac 2 video\_finale.dv
```

或者：

```
ffmpeg -i video\_origine.avi -target pal-dv video\_finale.dv
```

14.将.avi压缩成divx

```
ffmpeg -i video\_origine.avi -s 320x240 -vcodec msmpeg4v2 video\_finale.avi
```

15.将Ogg Theora压缩成Mpeg dvd

```
ffmpeg -i film\_sortie\_cinelerra.ogm -s 720x576 -vcodec mpeg2video -acodec mp3 film\_terminate.mpg
```

16.将.avi压缩成SVCD mpeg2

NTSC格式：

```
ffmpeg -i video\_origine.avi -target ntsc-svcd video\_finale.mpg
```

PAL格式：

```
ffmpeg -i video\_origine.avi -target pal-svcd video\_finale.mpg
```

17.将.avi压缩成VCD mpeg2

NTSC格式：

```
ffmpeg -i video\_origine.avi -target ntsc-vcd video\_finale.mpg
```

PAL格式：

```
ffmpeg -i video\_origine.avi -target pal-vcd video\_finale.mpg
```

18.多通道编码

```
ffmpeg -i fichierentree -pass 2 -passlogfile ffmpeg2pass fichiersortie-2
```

19.从flv提取mp3
```
ffmpeg -i source.flv -ab 128k dest.mp3
```

## **2.2 媒体播放器三大底层框架**
媒体播放工具，这里主要指视频播放，因为要面临庞大的兼容性和纷繁复杂的算法，从架构上看，能脱颖而出的体系屈指可数。大体来说业界主要有3大架构：MPC、MPlayer和VLC。这3大架构及其衍生品占领了90%的市场，凡是用户能看到的免费媒体播放软件，无一不是源自这3大架构。

**MPC/HC架构**

`	`MPC（Media Player Classic）和它的后续者MPC-HC应该并列而说。MPC基于DirectShow架构，是Windows系统下元祖级别的播放器。包括KMP之流最早也就是抄来MPC的代码再换个界面。MPCHC则在MPC的原作者Gabest渐渐退出开发后的继承者，MPCHC有很多创新特性，包括开始融入ffmpeg和支持更多DirectX特性和DXVA等等。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.014.png)

优点：更直接的支持DXVA，对一些稀奇古怪的Windows平台上的格式可以通过调用第三方的Filter组件等，拥有更好的兼容性

缺点：有人说DirectShow是Windows中最难掌握的SDK，开发复杂；DirectShow允许第三方封装的特点也让兼容性和稳定性问题复杂化；第三方Filter出现异常时非常难以分析处理，更难以复用；

射手播放器的架构主要来自MPC-HC，但更多的融合了FFmpeg的优势，对DirectShow Filter进行了多处改写，大大加强了对ffmpeg的利用，提高了解码稳定性，同时扩展了解码能力和兼容性。

**mplayer架构**

如果说MPC是Windows上的元祖，那么mplayer就是linux上媒体播放的元祖了。mplayer使用ffmpeg作为解码核心，也是与ffmpeg结合最紧密的项目，ffmpeg的代码就是由mplayer来host，开发者群也有非常大的交集。借助linux开发/使用者的强大实力，mplayer建立了要比DirectShow稳定的多的工作流程。超越ffmpeg本身的功能外，后来又通过反向工程使之可以调用Windows上的DirectShow Filter DLL，让mplayer架构越来越吸引人，成为兼具稳定性和性能的优秀作品。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.015.png)

优点：稳定，兼容性也可以说相当不错

缺点：代码结构不清晰；纯C语言开发，难于阅读；显卡硬件加速还需要越过更多障碍

**VLC架构**

VLC是个后起之秀，开发速度的进展可以说是一只奇葩。虽然同样基于ffmpeg，但可能是相对于“左三年右三年缝缝补补又三年”的mplayer架构来说，VLC的架构在设计之初就很好的考虑到模块化开发，所以使它更吸引年轻的开发人员。成为近年发展非常快的架构。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.016.png)

优点：稳定，兼容性也可以说相当不错

缺点：纯C语言开发，难于阅读；硬件加速略有障碍

很多人都会发现，3大架构中都可以看到ffmpeg的名字。说起ffmpeg，那真是”One Ring to rule them all，One Ring to find them, One Ring to bring them all“。在#ffmpeg有人和我说过，想不用ffmpeg去写媒体播放器，就像是造汽车而不用车轮。但是ffmpeg本身仅作为命令行工具或类库（常见的如libavcodec）出现。终端用户很少能直接接触到ffmpeg，所以知名度也较小。
# **第三章 编译及简单应用**
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.017.png)
## **3.1 FFmpeg库编译和入门介绍 41**
FFmpeg的编译主要有linux和windows下面两种，linux下面简单，此处着重讲解windows下面的交叉编译：

0. 官网直接获取exe

ffmpeg的官方网站是：http://ffmpeg.org/

编译好的windows可用版本的下载地址（官网中可以连接到这个网站，和官方网站保持同步）： http://ffmpeg.zeranoe.com/builds/

该网站中的FFMPEG分为3个版本：Static，Shared，Dev。

前两个版本可以直接在命令行中使用，他们的区别在于：Static里面只有3个应用程序：ffmpeg.exe，ffplay.exe，ffprobe.exe，每个exe的体积都很大，相关的Dll已经被编译到exe里面去了。Shared里面除了3个应用程序：ffmpeg.exe，ffplay.exe，ffprobe.exe之外，还有一些Dll，比如说avcodec-54.dll之类的。Shared里面的exe体积很小，他们在运行的时候，到相应的Dll中调用功能。

Dev版本是用于开发的，里面包含了库文件xxx.lib以及头文件xxx.h，这个版本不包含exe文件。

打开系统命令行接面，切换到ffmpeg所在的目录，就可以使用这3个应用程序了。

ps ：建议大家跳过第0步，学会自己从源码开始编译调试

1、获取ffmpeg源码

下载网址：svn://svn.mplayerhq.hu/ffmpeg/trunk

首先需要安装svn客户端，我用的是TortoiseSVN，应该是可以很方便地从网上下载，下载之后安装。

安装之后，在你要保存ffmpeg源代码的位置上点右键，然后选择check out，输入以上的网址，包括前面的“svn:”，然后点OK按钮，它会把整个源代码下到本地，根据网速，可能几秒钟到几十分钟不等。

#tar -xvf ffmpeg-0.10.x.tar.bz2

#cd 

#./configure 

#make

#make install

2、搭建windows下的编译环境   

2.1 mingw和msys     

下载地址http://sourceforge.net/projects/mingw/

执行下载文件：mingw-get-setup.exe，选择下一步----安装路径：C:\MinGW（我直接采用默认路径，未做修改）

`   `（提示：msys此处就不用下载了，mingw-get-setup.exe中已经包含了msys1.0,后面安装的时候就可以看到该选项。 ）

`   `安装后会启用MinGW Installer，在Installation Package Settings中选择：

`   `√ Basic Setup 

`   `√ All Packages

`        `√ MinGW 

`                `MinGW Base System

`                `MinGW Libraries

`                `MinGW Contributed

`                `MinGW Autotools

`        `√ MSYS

`               `MSYS Base System

`               `MinGW Developer ToolKit

`               `MSYS System Builder

等待安装完成（去倒杯水，或者听两首歌吧）！我的选择是把看上去有点熟悉的、会用到的package都装上！

也可以通过Installation Package Settings随时添加/删除需要的库文件，所以无需太过担心。

安装完成后，在C:\MinGW目录下可以看到 msys 文件夹，msys也已经安装。

ps：windows下MinGW-w64安装，这个我没有试过，有兴趣的朋友可以去试下   链接地址：http://blog.csdn.net/ayw\_hehe/article/details/11761755

2.2 下载 yasm(汇编编译器)，也可以直接下载源码包进行编译安装

ffmpeg编译的时候里面的汇编代码需要yasm.exe

去官网：http://yasm.tortall.net/Download.html 下载

在Latest Release栏，直接下载：Win32 .exe (for general use on 32-bit Windows) 

文件名类似为：yasm-1.2.0-win32.exe

2.3准备一个线程库（不准备编译x264的可以跳过）

下载 pthreadGC2.dll

pthreadgc2.dll是功能强大的处理数字化影视作品编辑软件premiere6运行所需的一个DLL文件。这是一个无威胁文件。属于Open Source Software community project的文件。

`    `直接去baidu或google搜索下载就可以了。

3、配置 msys.bat 批处理文件

此处为了方便VS2010调用ffmpeg的动态库，可以通过配置让ffmpeg编译时产生windows下调用dll对应的lib，当然，如果你没有这个需要，那么就可以省略以下处理，直接进入步骤4。

`    `进入：C:\MinGW\msys\1.0\文件夹，使用UltraEdit打开msys.bat文件，在文件的最最前面加入如下一行：

`    `call "D:\Program Files\Microsoft Visual Studio 10.0\VC\bin\vcvars32.bat"

`    `添加后效果如下：

`      `call "D:\Program Files\Microsoft Visual Studio 10.0\VC\bin\vcvars32.bat"

`         `@echo off

`         `rem Copyright (C):  2001, 2002, 2003, 2004, 2005  Earnie Boyd

`         `rem   mailto:earnie@users.sf.net

`         `rem This file is part of Minimal SYStem

`         `rem   http://www.mingw.org/msys.shtml

`         `rem

`         `rem File:     msys.bat

`         `rem Revision:     2.4

`         `rem Revision Date:  December 8th, 2005

`         `rem ember to set the "Start in:" field of the shortcut.

`         `rem A value similar to C:\msys\1.0\bin is what the "Start in:" field needs

`         `rem to represent.

`    `其中“D:\Program Files\Microsoft Visual Studio 10.0”为你机器上安装VS200X或VS2010的目录，我的电脑安装的是VS2010，并且安装在了D盘。文件修改后保存即可。）

`  `ps:不要告诉我 / 和 \ 的区别你不知道？！

4、系统整合

将fstab.sample改为fstab，用文本编辑器（需要使用一个支持Unix换行风格的编辑器，比如Notepad++，强烈推荐UltraEdit），把下面这行：

c:/MinGW/msys/1.0/mingw/mingw

改为：

c:/MinGW  /mingw

完成以上步骤，MSys+MinGW系统就配置完成了。 

\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*

此处可以通过gcc -v进行判断，如果修改成功gcc将从版本3.4.4变为4.8.1，如果使用gcc3（低版本），编译安装的时候会报错的！！

ps:如果gcc版本过低，编译SDL的时候报错很头疼，虽然我通过在网上查找修改源代码通过了，但是坑太大！！

5、基本库

视情况而定，初次测试编译安装的时候，安装一个SDL就差不多了（有多少人不想要ffplay的？O(∩\_∩)O~），其他的库可以后期再弄！

编译 mp3lame(可选项)

`    `为了让编译出来的ffmpeg支持对mp3格式的编解码，您需要先下载lame。

`    `到：http://sourceforge.net/projects/lame/files/ 下载 

`    `文件名类似为：lame-3.99.2.tar.gz 的包。

`    `$ tar -zxvf lame-3.99.2.tar.gz

`    `$ cd lame-3.99.2

`    `再执行以下命令：

`    `$./configure --disable-shared (首选)

或: $./configure --disable-static --enable-shared

`    `$ make

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下



编译 x264(可选项)

`    `为了让编译出来的ffmpeg支持对x264格式的编解码，您需要先下载x264。

`    `到：http://www.videolan.org/developers/x264.html下载 

`    `文件名类似为：last\_x264.tar.bz2 的包。

`    `$ tar -xvf last\_x264.tar.bz2

`    `$ cd x264-20111124-2245

`    `再执行以下命令：

`    `$./configure --enable-shared --disable-asm

`    `$ make

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下

编译 Xvid(可选项)

`    `为了让编译出来的ffmpeg支持对Xvid格式的编解码，您需要先下载Xvid。

`    `到：http://www.xvid.org/ 下载 

`    `文件名类似为：xvidcore-1.3.2.tar.gz 的包。

`    `$ tar -zxvf xvidcore-1.3.2.tar.gz

`    `$ cd xvidcore/build/generic

`    `再执行以下命令：

`    `$./configure --prefix=C:/MinGW/msys/1.0/local

`    `$ make

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下。

`    `需要注意的就是：此处编译加上了路径

`    `如果make时出现：cc1.exe: error: unrecognized command line option '-mno-cygwin' 错误，请在./configure后make之前修改xvidcore\build\generic里的 platform.inc文件，直接删除里面的“-mno-cygwin”。 

`    `具体可以参考：http://ffmpeg.zeranoe.com/forum/viewtopic.php?f=5&t=111里2楼的回答，如果按他说的：I recommend re running ./bootstrap.sh after you do this.，我发现不太行，一运行bootstrap.sh后，platform.inc文件会被还原，并且./configure时也会还原该文件，所以我选择在./configure后make前修改，可以编译通过，目前没检验Xvid是否可用。

编译 faad2(可选项)

`    `到：http://www.audiocoding.com/downloads.html 下载：Version 2.7 bootstrapped TAR.GZ Package

`    `文件名类似为：faad2-2.7.tar.gz 的包。

`    `$ tar -zxvf faad2-2.7.tar.gz

`    `$ cd faad2-2.7

`    `再执行以下命令：

`    `$./bootstrap

`    `$./configure --disable-static --enable-shared

`    `$ make

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下

编译faac(可选项)

`    `到：http://www.audiocoding.com/downloads.html 下载：Version 1.28 bootstrapped TAR.GZ Package

`    `文件名类似为：faac-1.28.tar.gz 的包。

`    `$ tar -zxvf faac-1.28.tar.gz

`    `$ cd faac-1.28

`    `再执行以下命令：

`    `$./bootstrap

`    `$./configure --disable-static --enable-shared

`    `$ make

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下

编译vo-aacenc (可选项)

`     `到：http://sourceforge.net/projects/opencore-amr/files/ 下载：vo-aacenc

`    `文件名类似为：vo-aacenc-0.1.1.tar.gz 的包。

`    `$ tar -zxvf vo-aacenc-0.1.1.tar.gz

`    `$ cd vo-aacenc-0.1.1

`    `再执行以下命令：

`    `$./configure --disable-shared

`    `$ make

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下

编译amr-nb和amr-wb (早期ffmpeg版本，可选项)

`    `在编译amrnb和amrwb之前还需要做点其它的准备工作：

`    `A 先到网上搜索下载wget工具，解压后放到C:\MinGW\bin目录下，此工具是个网络下载工具，用来在编译时自动下载3gpp源码。 

`    `B 再先到http://downloads.sourceforge.net/gnuwin32/unzip-5.51-1-bin.zip 下载unzip-5.51-1-bin.zip后进行解压，并把unzip-5.51-1-bin\bin中的unzip.exe拷贝到C:\MinGW\bin目录下，此工具用来在编译时自动解压3gpp源码。

`    `到：http://www.penguin.cz/%7Eutx/amr 下载：amrnb-7.0.0.2.tar.bz2与amrwb-7.0.0.4.tar.bz2

`    `$ tar -xvf amrnb-7.0.0.2.tar.bz2

`    `$ cd amrnb-7.0.0.2

`    `再执行以下命令：

`    `$./configure --disable-static --enable-shared

`    `$ make

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下

`    `$ tar -xvf amrwb-7.0.0.4.tar.bz2

`    `$ cd amrwb-7.0.0.4

`    `再执行以下命令：

`    `$./configure --disable-static --enable-shared

`    `$ make

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下

编译opencore-amr 和vo-amrwbenc (可选项)

`    `到：http://sourceforge.net/projects/opencore-amr/files/ 下载：opencore-amr 与 vo-amrwbenc

`    `文件名类似为：opencore-amr-0.1.2.tar.gz 与vo-amrwbenc-0.1.1.tar.gz 的包。   

`    `如果是opencore-amr-0.1.1.tar.gz请注释掉以下Makefile中的几行

`    `文件: ./opencore-amr/amrnb/Makefile

`    `install: libopencore-amrnb.a $(SHLIB)

`    `install -d $(DESTDIR)$(PREFIX)/lib

`    `install -m 644 libopencore-amrnb.a $(DESTDIR)$(PREFIX)/lib

`    `# install $(SHLIB) $(DESTDIR)$(PREFIX)/lib

`    `ifneq ($(shell uname), Darwin)

`    `# ln -sf $(SHLIB) $(DESTDIR)$(PREFIX)/lib/$(SONAME)

`    `# ln -sf $(SONAME) $(DESTDIR)$(PREFIX)/lib/libopencore-amrnb.so

`    `endif

`    `文件: ./opencore-amr/amrwb/Makefile

`    `install: libopencore-amrwb.a $(SHLIB)

`    `install -d $(DESTDIR)$(PREFIX)/lib

`    `install -m 644 libopencore-amrwb.a $(DESTDIR)$(PREFIX)/lib

`    `# install $(SHLIB) $(DESTDIR)$(PREFIX)/lib

`    `ifneq ($(shell uname), Darwin)

`    `# ln -sf $(SHLIB) $(DESTDIR)$(PREFIX)/lib/$(SONAME)

`    `# ln -sf $(SONAME) $(DESTDIR)$(PREFIX)/lib/libopencore-amrwb.so

`    `endif

`    `$ tar -zxvf opencore-amr-0.1.2.tar.gz

`    `$ cd opencore-amr-0.1.2

`    `再执行以下命令：

`    `$./configure --disable-shared

`    `$ make CC=gcc

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下

`    `$ tar -zxvf vo-amrwbenc-0.1.1.tar.gz

`    `$ cd vo-amrwbenc-0.1.1

`    `再执行以下命令：

`    `$./configure --disable-shared

`    `$ make CC=gcc

`    `$ make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下

编译SDL(可选项)

`   `SDL下载可以到：http://www.libsdl.org/download-1.2.php

`    `在Source Code栏选择类似：SDL-1.2.14.tar.gz - GPG signed 进行下载，

`    `文件名类似为：SDL-1.2.14.tar.tar，此文件需要编译才能生成lib库。

`    `也可以直接下载 SDL-devel-1.2.14-mingw32.tar.gz (Mingw32)，文件名类似为：SDL-devel-1.2.14-mingw32.tar.tar，此文件带有编译好的lib，在编译ffmpeg时可以直接使用。

`    `$ tar -zxvf SDL-1.2.14.tar.gz

`    `$ cd SDL-1.2.14

`    `再执行以下命令：

`    `./configure

`    `make

`    `make install

`    `编译结果在：C:\MinGW\msys\1.0\local 目录下 

`    `注意：如果是使用编译好的SDL-devel-1.2.14-mingw32.tar.tar，那么就可以省掉上面的编译工作，直接解压SDL-devel-1.2.14-mingw32.tar.tar文件即可。自己编译或直接使用编译好的都需要做下面的修改和拷贝工作。

`    `使用UltraEdit打开C:\MinGW\msys\1.0\local\bin下的 sdl-config文件

`    `把 prefix=/usr 该成： prefix=c:/mingw

`    `其中：c:/mingw 为 mingw的安装路径，请根据你的安装进行修改。为了编译时msys能识别sdl并开启 SDL support yes 进行编译，请把C:\MinGW\msys\1.0\local编译结果bin、include和lib中有关sdl的拷贝一份到C:\MinGW\的对应目录中。

6、编译安装ffmpeg

lib 动态链接库位置

include 编程要用到头文件

bin 执行文件所在的目录

(为了以后方便编程，我们把lib中的三个链接库libavcodec.so libavformat.so libavutil.so复制到/usr/lib下。把include目录下的ffmpeg目录复制到/usr/include下)

\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*

` `但是我编译完没有ffserver.exe,网上说是因为MinGW里面少了关于ffserver用的网络的相关的包。

参考http://bbs.chinavideo.org/viewthread.php?tid=95。

单独使用ffplay，需要将c:/msys/1.0/mingw/bin/SDL.dll和ffplay.exe放到相同的目录下。

6.1 编译静态库

`  `配置

在shell提示符下输入：

./configure --enable-static --enable-memalign-hack --prefix=c:/msys/1.0 --extra-cflags="-fno-common"

这个过程要花费较长的时间，开始会有较长的时间没有反应。其中的prefix是msys的安装路径

` `编译

make

安装

make install

安装只是把要开发使用的库文件拷贝到c:/msys/1.0/lib/目录中，头文件拷贝到c:/msys/1.0/include/目录中。

产生的库文件为.a文件

6.2 编译动态库

动态库和静态库只在配置上的差别，配置如下：

./configure --enable-shared --disable-static --enable-memalign-hack --prefix=c:/msys/1.0 --extra-cflags="-fno-common"

后面的步骤一样：

make

make install

在开始编译之前，可以把原来编译的目标 文件清除掉：

make clean

动态编译应该是会产生lib文件，但是我编译之后一直没有产生

编译之后的dll文件被放到了ffmpeg目录下，可以搜索查看它们

7、开发

如果写了一个test.c文件，要包含ffmpeg的头文件，可以这样写：

#include 

编译：gcc -o test test.c -lavformat -lavcodec -lavtuil (前提是有第6步的操作)

如果没有第6步的操作，则编译的时候如下：

gcc -o test test.c -I/usr/local/ffmpeg/include -L/usr/local/ffmpeg/lib -lavformat -lavcodec -lavtuil

编译成功之后，执行的时候还是需要动态库的支持，还是要把那三个动态库文件复制到/usr/lib或者/lib中，不然执行的时候会说找不到动态库链接。

还有一个方法可以解决这个问题，就是把/usr/local/ffmpeg/lib这个目录加入到/etc/ld.so.config中，然后执行ldconfig，或者重启电脑，这样执行

的时候系统就可以从/usr/local/ffmpeg/lib这个目录下去找这三个动态库文件了。

以上的方式是采用动态库编译ffmpeg的，如果在configure的时候不加上--enable-shared的，则采用静态链接的方式，不会生成那三个动态库。同时

生成的ffplay、ffmpeg的执行文件也比较的大，因为他们不需要动态库的支持，就可以执行。但是不利于再次开发，所以我采用动态链接的方式。

configure中还有很多的选项，可以通过./configure --help查看，也可以直接查看configure文件。这在配置的时候很重要。
## **3.2 流媒体数据流程讲解**
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.018.png)

FFMpeg 的 output\_example.c 例子分析

该例子讲了如何输出一个 libavformat 库所支持格式的媒体文件。

（1）av\_regis ter\_all()，初始化 libavcodec 库，并注册所有的编解码器和格式。

（2）guess\_form at()，根据文件名来获取输出文件格式，默认为 mpeg。

（3）av\_alloc\_form at\_context()分配输出媒体内容。

ov->oform at = fm t;

s nprintf( oc->filename, sizeof(oc->filename), “%s ”, filenam e );

（4）add\_video\_s tream ()使用默认格式的编解码器来增加一个视频流，并初始化编解码器。

（4.1）av\_new\_s tream ()增加一个新的流到一个媒体文件。

（4.2）初始化编解码器：

c = s t->codec;

c->codec\_id = codec\_id;

c->codec\_type = CODEC\_TYPE\_ VIDEO;

c->bit\_rate = 400000;

c->width = 352;

c->height = 288;

c->tim e\_base.den = STREAM\_FR AME\_RATE ; //每秒 25 副图像

c->tim e\_base.num  = 1;

c->gop\_size = 12;

c->pix\_fm t = STREAM\_PIX\_FMT; //默认格式为 P IX\_FMT\_ YUV420P

…… ……

（5）av\_s et\_parameters ()设置输出参数，即使没有参数，该函数也必须被调用。

（6）dum p\_form at()输出格式信息，用于调试。

（7）open\_video()打开视频编解码器并分配必要的编码缓存。

（7.1）avcodec\_find\_encoder()寻找 c->codec\_id 指定的视频编码器。

（7.2）avcodec\_open()打开编码器。

（7.3）分配视频输出缓存：

video\_outbuf\_s ize = 200000;

video\_outbuf = av\_m alloc( video\_outbuf\_s ize );

（7.4）picture = alloc\_picture()分配原始图像。

（7.4.1）avcodec\_alloc\_frame()分配一个 AVFram e 并设置默认值。

（7.4.2）s ize = avpicture\_get\_s ize()计算对于给定的图片格式以及宽和高，所需占用多少 内存。

（7.4.3）picture\_buf = av\_malloc( s ize )分配所需内存。

（7.4.4）avpicture\_fill()填充 AVPicture 的域。

（7.5）可选。如果输出格式不是 YUV420P，那么临时的 YU V420P 格式的图像也是需要的，由 此再转换为我们所需的格式，因此需要为临时的 YU V420P 图像分配缓存：

tm p\_picture = alloc\_picture()

说明：tm p\_picture，picture，video\_outbuf。如果输出格式为 YUV420P，则直接通过 avcodec\_

encode\_video()函数将 picture 缓存中的原始图像编码保存到 video\_outbuf 缓存中；如果输出格式不 是 YU V420P，则需要先通过 sws \_s cale()函数，将 YUV420P 格式转换为目标格式，此时 tm p\_picture 缓 存存放的是 YU V420P 格式的图像，而 picture 缓存为转换为目标格式后保存的图像，进而再将 picture 缓

存中的图像编码保存到 video\_outbuf 缓存中。

（8）url\_fopen()打开输出文件，如果需要的话。

（9）av\_write\_header()写流动头部。

（10）LOOP 循环{

计算当前视频时间 video\_pts 是否超时退出循环？ write\_video\_fram e()视频编码

}

（10.1）write\_video\_frame()

如果图片不是 YU V420P，则需要用 sws \_s cale()函数先进行格式转换。 若需要原始图像：

av\_init\_packet()初始化一个包的选项域。

av\_write\_fram e()向输出媒体文件写一个包，该包会包含一个视频帧。 若需要编码图像：

avcodec\_encode\_video()编码一视频帧。

av\_init\_packet()

av\_write\_fram e()

（11）close\_video()关闭每个编解码器。

（12）av\_write\_trailer()写流的尾部。

（13）释放资源

av\_freep()释放 AVForm atContext 下的 AVS tream ->AVCodecContext 和 AVStream ：

for( i = 0; i < oc->nb\_s treams ; i++ ){

av\_freep( &oc->s treams [i]->codec );

av\_freep( &oc->s treams [i] );

}

url\_fclose()关闭输出文件。

av\_free()释放 AVForm atContext。
## **3.3 简单应用**
PS:此处举tutorial的例子是为了更好的引出一个循序渐进的例程。条件适当的话添加output\_example.c实例并进行说明。

FFmpeg tutorial对初级的掌握以及使用ffmpeg有重要指导作用，但是里面的一些函数没有实时更新了，tutorial01~08是一个播放器开发的由浅入深的过程，下面介绍tutorial01（tutorial 02~08详见附录）使用源码：

/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/

`	`/\* tutorial1 制作屏幕录像

`	`执行后，将视频文件按照一定的格式保存为.ppm文件 \*/

/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/

#include "libavcodec/avcodec.h"

#include "libavformat/avformat.h"

#include "libswscale/swscale.h"

#include <windows.h>

#include <stdio.h>

void SaveFrame(AVFrame \*pFrame, int width, int height, int iFrame) {

`	`FILE \*pFile;

`	`char szFilename[32];

`	`int  y;

`	`// Open file

`	`sprintf(szFilename, "frame%d.ppm", iFrame);

`	`pFile=fopen(szFilename, "wb");

`	`if(pFile==NULL)

`		`return;

`	`// Write header

`	`fprintf(pFile, "P6\n%d %d\n255\n", width, height);

`	`// Write pixel data

`	`for(y=0; y<height; y++)

`		`fwrite(pFrame->data[0]+y\*pFrame->linesize[0], 1, width\*3, pFile);

`	`// Close file

`	`fclose(pFile);

}

int main(int argc, char \*argv[])

{

`	`AVFormatContext \*pFormatCtx;

`	`int i,videoStream;

`	`AVCodecContext \*pCodecCtx;

`	`AVCodec \*pCodec;

`	`AVFrame \*pFrame;

`	`AVFrame \*pFrameRGB;

`	`AVPacket packet;

`	`int frameFinished;

`	`int numBytes;

`	`uint8\_t \*buffer;



`	`if (argc < 2)

`	`{

`	`printf("please provide a movie file\n");

`	`return -1;

`	`}

`	`//register all formats and codes

`	`av\_register\_all();

`	`//support network stream input

`	`avformat\_network\_init();

`	`pFormatCtx = avformat\_alloc\_context();





`	`//Open the media file and read the header

`	`if(avformat\_open\_input(&pFormatCtx,argv[1],NULL,NULL) != 0)

`	`{

`		`printf("couldn't open file \n");

`		`return -1;

`	`}

`	`//retrieve stream information

`	`if (av\_find\_stream\_info(pFormatCtx) < 0 )

`		`return -1;

`	`//dump information about file into standard error

`	`av\_dump\_format(pFormatCtx,-1,argv[1],0);

`	`// Find the first video stream

`	`videoStream = -1;

`	`for (int i = 0 ;i < pFormatCtx->nb\_streams; i++ )

`		`if (pFormatCtx->streams[i]->codec->codec\_type == AVMEDIA\_TYPE\_VIDEO)

`		`{

`			`videoStream = i ;

`			`break;

`		`}



`	`if (videoStream == -1)

`		`return -1;

`	`//get a pointer to the codec context for the video stream

`	`pCodecCtx = pFormatCtx ->streams[videoStream]->codec;

`	`pCodec = avcodec\_find\_decoder(pCodecCtx->codec\_id);

`	`if (pCodec == NULL)

`	`{

`		`fprintf(stderr,"unsupported codec \n");

`		`return -1;

`	`}

`	`//open codec 

`	`if(avcodec\_open2(pCodecCtx,pCodec,NULL) < 0 )

`		`return -1;

`	`//allocate video frame

`	`pFrame = avcodec\_alloc\_frame();

`	`if(NULL == pFrame )

`		`return -1;

`	`//allocate an avframe structure

`	`pFrameRGB = avcodec\_alloc\_frame();

`	`if (pFrameRGB == NULL)

`		`return -1;

`	`//determine required buffer size and allocate buffer

`	`numBytes = avpicture\_get\_size(PIX\_FMT\_RGB24,pCodecCtx->width,pCodecCtx->height);

`	`//buffer = (uint8\_t \*)av\_malloc\_attrib(numBytes \* sizeof(uint8\_t));

`	`buffer = (uint8\_t \*)av\_malloc(numBytes \* sizeof(uint8\_t));

`	`avpicture\_fill((AVPicture \*)pFrameRGB,buffer,PIX\_FMT\_RGB24,pCodecCtx->width,pCodecCtx->height);



`	`i = 0;

`	`while (av\_read\_frame(pFormatCtx,&packet)>=0)

`	`{

`		`if (packet.stream\_index == videoStream)

`		`{

`			`avcodec\_decode\_video2(pCodecCtx,pFrame,&frameFinished,&packet);

`			`if( frameFinished ) 

`			`{

`				`struct SwsContext \*img\_convert\_ctx = NULL;

`				`img\_convert\_ctx =sws\_getCachedContext(img\_convert\_ctx, pCodecCtx->width,pCodecCtx->height, \

`					`pCodecCtx->pix\_fmt,pCodecCtx->width, pCodecCtx->height,PIX\_FMT\_RGB24, SWS\_BICUBIC,NULL, NULL, NULL);



`				`if( !img\_convert\_ctx ) 

`				`{

`					`fprintf(stderr, "Cannot initialize sws conversion context\n");

`					`exit(1);

`				`}



`				`/\*

`				`int sws\_scale(struct SwsContext \*c, const uint8\_t \*const srcSlice[],

`				`const int srcStride[], int srcSliceY, int srcSliceH,

`				`uint8\_t \*const dst[], const int dstStride[]);

`				`\*/

`				`sws\_scale(img\_convert\_ctx, pFrame->data,\

`						`pFrame->linesize, 0, pCodecCtx->height, pFrameRGB->data,pFrameRGB->linesize);

`				`if( i++ < 50 )

`					`SaveFrame(pFrameRGB, pCodecCtx->width, pCodecCtx->height, i);

`			`}

`		`}

`		`av\_free\_packet(&packet);

`	`}

`	`//free the RGB image

`	`av\_free(buffer);

`	`av\_free(pFrameRGB);

`	`av\_free(pFrame);

`	`avcodec\_close(pCodecCtx);

`	`av\_close\_input\_file(pFormatCtx);

}
## **3.4 SDL（ Simple Direct Layer）**
它是一个出色的多媒体库，适用于 PC 平台，并且已经应用在许多工 程中，它是如此的优秀，甚至已移植到某些手机平台上。它的官方网站是 [http://www.libsdl.org/，在这个网](http://www.libsdl.org/)站上可以下载 SDL 库的源代码自己编译库，也可以直接下载预编译库。
### **3.4.1 SDL显示视频**
SDL 显示视频图像函数调用序列如下，忽略掉错误处理：

1):初始化 SDL 库，

SDL\_Init(SDL\_INIT\_VIDEO | SDL\_INIT\_AUDIO | SDL\_INIT\_TIMER)

2):创建显示表面，

SDL\_Surface \*screen = SDL\_SetVideoMode(width, height, 0, 0)

3):创建Overlay表面，

SDL\_Overlay \*bmp = SDL\_CreateYUVOverlay(width, height, SDL\_YV12\_OVERLAY, screen)

4):取得独占权和 Overlay 表面首地址， SDL\_LockYUVOverlay(bmp);

5):填充视频数据，纹理数据

6):释放独占权， SDL\_UnlockYUVOverlay(bmp);

7):刷新视频， SDL\_DisplayYUVOverlay(bmp, &rect);
### **3.4.2 SDL显示音频**
SDL 播放音频采用回调函数的方式来保证音频的连续性，在设置音频输出参数，向系统注册回调函数后，每 次写入的音频数据播放完，系统自动调用注册的回调函数，通常在此回调函数中继续往系统写入音频数据。

SDL 播放音频函数调用序列，忽略掉错误处理：

1):初始化 SDL\_AudioSpec 结构，此结构包括音频参数和回调函数，比如 SDL\_AudioSpec wanted\_spec；

wanted\_spec.userdata = is; wanted\_spec.channels = 2; wanted\_spec.callback = sdl\_audio\_callback;

2) ......
2) :打开音频设备 SDL\_OpenAudio(&wanted\_spec, &spec)；

3)激活 音频设备开始工作 SDL\_PauseAudio(0);

4)在音频回调函数中写入音频数据，示意代码如下

void sdl\_audio\_callback(void \*opaque, Uint8 \*stream, int len)

{

memcpy(stream, (uint8\_t\*)audio\_buf, len);

}

5) : 播放完后关闭音频 SDL\_CloseAudio();
## **3.5 ffmpeg程序的使用（ffmpeg.exe，ffplay.exe，ffprobe.exe）**
### **3.5.1 ffmpeg.exe**
ffmpeg是用于转码的应用程序。

一个简单的转码命令可以这样写：

将input.avi转码成output.ts，并设置视频的码率为640kbps

#ffmpeg -i input.avi -b:v 640k output.ts  

具体的使用方法可以参考： ffmpeg参数中文详细解释

详细的使用说明（英文）：<http://ffmpeg.org/ffmpeg.html>
### **3.5.2 ffplay.exe**
ffplay是用于播放的应用程序。

一个简单的播放命令可以这样写：

播放test.avi

#ffplay test.avi  

具体的使用方法可以参考：ffplay的快捷键以及选项

详细的使用说明（英文）：<http://ffmpeg.org/ffplay.html>
### **3.5.3 ffprobe.exe**
ffprobe是用于查看文件格式的应用程序。

这个就不多介绍了。

详细的使用说明（英文）：<http://ffmpeg.org/ffprobe.html>
# **第四章 数据结构**
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.019.png)

注：ByteIOContext→AVIOContext

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)ffmpeg定义的数据结构很有特色:

有一些是动态与静态的关系，比如， URLProtocol 和 URLContex t ，AVInputFormat 和 AVFormatContext ， AVCodec 和 AVCodecContext。从前面播放器的一般原理我们可知，播放器内部要实现的几大功能是，读文件， 识别格式，音视频解码，音视频渲染。其中音视频渲染由 SDL 实现，我们不讨论。ffplay 把其他的每个大功能抽 象成一个相当于 C++ 中 COM 接口的数据结构，着重于功能函数，同时这些功能函数指针在编译的时候就能静态 确定。每一个大功能都要支持多种类型的广义数据，ffplay 把这多种类型的广义数据的共同的部分抽象成对应的 Context 结构，这些对应的 context 结构着重于动态性，其核心成员只能在程序运行时动态确定其值。并且 COM 接口类的数据结构在程序运行时有很多很多实例，而相应的 Context 类只有一个实例，这里同时体现了数据结构 的划分原则，如果有一对多的关系就要分开定义。

有一些是指针表述的排他性包含关系(因为程序运行时同一类型的多种数据只支持一种，所以就有排他性 )。 比如，AVCodecContex t 用 priv\_dat a 包含 MsrleContex t 或 TSContext，AVFormatContext 用 priv\_dat a 包含 AVIContext 或其他类 Context，AVStream 用 priv\_dat a 包含 AVIStream 或其他类 Stream。由前面数据结构的动态与静态关系 可知，ffplay 把多种类型的广义数据的共同部分抽象成 context 结构，那么广义数据的各个特征不同部分就抽象成 各种具体类型的 context，然后用 priv\_dat a 字段表述的指针排他性的关联起来。由于瘦身后的 ffplay 只支持有限 类型，所以 AVFormatContext 只能关联包含 AVIContext，AVStream 只能关联包含 AVIStream。

有一些是扩展包含关系，比如，ByteIOCon text  包含 URLContext ，就是在应用层把没有缓存的 URLContext

扩展有缓冲区的广义文件 ByteIOCon text ，改善程序 IO 性能。

有一些是直接包含关系，比如，AVFrame 包含 AVPicture，这两个结构共有的字段，其定义类型、大小、顺 序都一模一样，除了更准确的描述各自的意义便于阅读理解维护代码外，还可以方便的把 AVFrame 大结构强制 转换 AVPicture 小结构。

我们先来重点分析 AVCodec/AVCodecContext/MsrleContex t 这几个数据结构，这几个数据结构定义了编解码 器的核心架构，相当于 Directshow 中的各种音视频解码器 decoder。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.021.jpeg)

解协议（http,rtsp,rtmp,mms）→解封装（flv,avi,rmvb,mp4）→解码h264,mpeg2,aac,mp3）→存数据
## **4.1  AVCodec结构体**
typedef struct AVCodec

{

// 标示Codec 的名字, 比如，"h264" "h263" 等。

const char \*name; 

// 标示Codec 的类型，有video ，audio等类型。

enum CodecType type;

// 标示Codec 的ID，有CODEC\_ID\_H264等。

enum CodecID id; 

// 标示具体的Codec 对应的Context 的size,如：H264Context。

int priv\_data\_size; 

// 以下标示Codec 对外提供的操作,每一种解码器都会实现这些操作。

int(\*init)(AVCodecContext\*);

int(\*encode)(AVCodecContext 	\*, uint8\_t \*buf, int buf\_size, void 	\*data);

int(\*close)(AVCodecContext\*);

int(\*decode)(AVCodecContext \*, void \*outdata, int 	\*outdata\_size, 	uint8\_t \*buf, int buf\_size);

struct AVCodec \*next; 

}AVCodec;

H264的主要结构的初始化如下：

AVCodec ff\_h264\_decoder = {

`    `"h264",

`    `AVMEDIA\_TYPE\_VIDEO,

`    `CODEC\_ID\_H264,

`    `sizeof(H264Context),

`    `ff\_h264\_decode\_init,

`    `NULL,

`    `ff\_h264\_decode\_end,

`    `decode\_frame

}

说明：

AVCodec 是类似 COM 接口的数据结构，表示音视频编解码器，着重于功能函数，一种媒体类型对应一个 AVCodec 结构，在程序运行时有多个实例。next 变量用于把所有支持的编解码器连接成链表，便于遍历查找；id 确定了 唯 一编 解 码器 ； priv\_data\_size 表示具 体 的 Codec 对应的 Context 结构大 小 ，比 如 MsrleContext  或 TSContext，这些具体的结够定义散落于各个.c 文件中，为避免太多的 if else  类语句判断类型再计算大小，这里 就直接指明大小，因为这是一个编译时静态确定的字段，所以放在 AVCodec 而不是 AVCodecContex t 中。
## **4.2  AVCodecContext结构体**
typedef struct AVCodecContext

{

int bit\_rate;

int frame\_number;

//扩展数据，如mov格式中audio trak中aac格式中esds的附加解码信息。

unsigned char \*extradata; 

//扩展数据的size

int extradata\_size; 

//视频的原始的宽度与高度

int width, height; // 此逻辑段仅针对视频

//视频一帧图像的格式，如YUV420

enum PixelFormat pix\_fmt;

//音频的采样率

int sample\_rate;

//音频的声道的数目 

int channels;

int bits\_per\_sample;

int block\_align;

// 指向相应的解码器，如：ff\_h264\_decoder

struct AVCodec \*codec; 

//指向具体相应的解码器的context，如H264Context

void \*priv\_data; 

//公共操作函数

int(\*get\_buffer)(struct AVCodecContext \*c, AVFrame \*pic);

void(\*release\_buffer)(struct AVCodecContext \*c, AVFrame \*pic);

int(\*reget\_buffer)(struct AVCodecContext \*c, AVFrame \*pic);

}AVCodecContext;

说明：

AVCodecContext 结构表示程序运行的当前Codec 使用的上下文，着重于所有Codec 共有的属性(并且是在程序运行时才能确定其值)和关联其他结构的字段。extradata 和extradata\_size 两个字段表述了相应Codec 使用的私有数据；codec 字段关联相应的编解码器；priv\_data 字段关联各个具体编解码器独有的属性context，和AVCodec 结构中的priv\_data\_size 配对使用。
## **4.3  AVInputFormat结构体**
typedef struct AVInputFormat

{

// 标示format的名字, 比如，“mov” “mp4” 等。

const char \*name;

// 标示具体的format对应的Context 的size,如：MovContext。

int priv\_data\_size; 

//具体的操作函数

int(\*read\_probe)(AVProbeData\*);

int(\*read\_header)(struct AVFormatContext \*,AVFormatParameters \*ap);

int(\*read\_packet)(struct AVFormatContext \*, AVPacket \*pkt);

int(\*read\_close)(struct AVFormatContext\*);

struct AVInputFormat \*next;

} AVInputFormat;

Mov或mp4的主要结构的初始化如下：

AVInputFormat ff\_mov\_demuxer = {

`       `"mov,mp4,m4a,3gp,3g2,mj2",

`   	 	`NULL\_IF\_CONFIG\_SMALL("QuickTime/MPEG-4/Motion JPEG 2000 			format"),

`    	`sizeof(MOVContext),

`    	`mov\_probe,

`    	`mov\_read\_header,

`    	`mov\_read\_packet,

`    	`mov\_read\_close,

`    	`mov\_read\_seek,

}

说明：

AVInputFormat 是类似COM 接口的数据结构，表示输入文件容器	格式，着重于功能函数，一种文件容器格式对应一个AVInputFormat 结构，在程序运行时有多个实例。next变量用于把所有支持的输入文件容器格式连接成链表，便于遍历查找。priv\_data\_size 标示具体的文件容器格式对应的Context的大小，在本例中是MovContext，这些具体的结够定义散落于各个.c 文件中。
## **4.4  AVFormatContext结构体**
typedef struct AVFormatContext 

{

//指向AVInputFormat，如对于mp4或mov为ff\_mov\_demuxer

struct AVInputFormat \*iformat;

// 指向具体的格式对应的Context，如：MovContext。

void \*priv\_data; 

//指向数据读取统一接口context

ByteIOContext pb;  

//流的数目

int nb\_streams;

//至少2个指针元素分别指向video stream和audio stream

AVStream \*streams[MAX\_STREAMS];

} AVFormatContext;

说明：

AVFormatContext 结构表示程序运行的当前文件容器格式使用的上下文，着重于所有文件容器共有的属性(并且是在程序运行时才能确定其值)和关联其他结构的字段。iformat字段关联相应的文件容器格式；pb 关联广义的输入文件；streams 关联音视频流；priv\_data 字段关联各个具体文件容器独有的属性上下文，和priv\_data\_size 配对使用。
## **4.5  MovContext结构体**
typedef struct MovContext

{

`   `//临时持有AVFormatContext 的指针

`    `AVFormatContext \*fc;



`   `//时间缩放因子

int time\_scale;

//视频的时长

int64\_t duration;     

//拆包时是否发现”moov“头

int found\_moov;       

//拆包时是否发现"mdat"头

int found\_mdat;     



int isom;              

MOVFragment fragment;  

MOVTrackExt \*trex\_data;

`    `unsigned trex\_count;

`    `int itunes\_metadata;  ///< metadata are itunes style

int chapter\_track;

} MOVContext;

说明：

MOVContext定义了mp4 中流的一些属性。
## **4.6  URLProtocol结构体**
typedef struct URLProtocol

{

const char \*name; 

//用的统一的模板函数

int(\*url\_open)(URLContext \*h, const char \*filename, int flags);

int(\*url\_read)(URLContext \*h, unsigned char \*buf, int size);

int(\*url\_write)(URLContext \*h, unsigned char \*buf, int size);

offset\_t(\*url\_seek)(URLContext \*h, offset\_t pos, int whence);

int(\*url\_close)(URLContext \*h);

struct URLProtocol \*next;

} URLProtocol;ffurl\_connect

file的主要结构的初始化如下：

URLProtocol ff\_file\_protocol = {

`    `.name                = "file",

`    `.url\_open            = file\_open,

`    `.url\_read            = file\_read,

`    `.url\_write           = file\_write,

`    `.url\_seek            = file\_seek,

`    `.url\_close           = file\_close,

`    `.url\_get\_file\_handle = file\_get\_handle,

`    `.url\_check           = file\_check,

}

说明：

URLProtocol 是类似COM 接口的数据结构，表示广义的输入文件，着重于功能函数，一种广义的输入文件对应一个URLProtocol 结构，比如file，pipe，tcp 等等，定义了对file tcp等方式的通用模板函数。next 变量用于把所有支持的广义的输入文件连接成链表，便于遍历查找。
## **4.7  URLContext结构体**
typedef struct URLContext

{

`   `//指向相应的协议(协议为从初始化链表中注册的),如ff\_file\_protocol

struct URLProtocol \*prot;

int flags;

int max\_packet\_size; 

//相应通信方式的句柄，对于文件为fd句柄，对于网络为socket句柄等

void \*priv\_data; 

//文件的名字，不区分本地和网络

char \*filename;

} URLContext

说明：

URLContext 结构表示程序运行的当前广义输入文件使用的context，着重于所有广义输入文件共有的属性(并且是在程序运行时才能确定其值)和关联其他结构的字段。prot 字段关联相应的广义输入文件；priv\_data 字段关联各个具体广义输入文件的句柄。
## **4.8  AVIOContext结构体(老版本为：ByteIOContext)**
typedef struct ByteIOContext

{

//数据缓冲区

unsigned char \*buffer;



//数据缓冲size

int buffer\_size;

//数据读取标记指针

unsigned char \*buf\_ptr, \*buf\_end;

//该指针指向相应的URLContext，关联URLContext

void \*opaque; 

int (\*read\_packet)(void \*opaque, uint8\_t \*buf, int buf\_size);

int (\*write\_packet)(void \*opaque, uint8\_t \*buf, int buf\_size);

offset\_t(\*seek)(void \*opaque, offset\_t offset, int whence);

//当前buffer在文件中的位置

offset\_t pos;  

//表示要进行seek，冲刷数据

int must\_flush;  

//是否到达了文件末尾

int eof\_reached; // true if eof reached

int write\_flag; 

int max\_packet\_size;

int error; // contains the error code or 0 if no error happened

} ByteIOContext;

说明：

ByteIOContext 结构扩展URLProtocol 结构成内部有缓冲机制的广泛意义上的文件，改善广义输入文件的IO性能。由其数据结构定义的字段可知，主要是缓冲区相关字段，标记字段，和一个关联字段opaque 来完成广义文件读写操作。opaque 关联字段用于关联URLContext 结构，间接关联并扩展URLProtocol 结构。
## **4.9  AVStream结构体**
typedef struct AVStream 

{

//指向解码器context，用于关联解码器

AVCodecContext \*actx; 

//codec解析器，每一种编码器在进行压缩时都会对实际负载数据进行封装，加//入头信息，如h264，需要解析nal单元，关联通过avav\_find\_stream\_info()

` `struct AVCodecParserContext \*parser;

//指向解复用的流的context，比如mp4的MovStreamcontext

void \*priv\_data;  

AVRational time\_base; 

//用于seek时使用，用于快速索引关键帧，如flv的keyframes索引表和mp4的I 

//帧的索引表都存于此，很重要

AVIndexEntry \*index\_entries; 

//index\_entries的元素的个数

int nb\_index\_entries;

int index\_entries\_allocated\_size;

double frame\_last\_delay;

} AVStream;

说明：

AVStream 结构表示当前媒体流的上下文，着重于所有媒体流共有的属性(并且是在程序运行时才能确定其值)和关联其他结构的字段。actx 字段关联当前音视频媒体使用的编解码器的context；priv\_data 字段关联解析各个具体媒体流解复用拆包用的context；还有关键帧的索引表也存于此。
## **4.10  MOVStreamContext 结构体**
typedef struct MOVStreamContext {

`    `//流的索引,0或者1

int ffindex;    

//临时变量，保存下一个chunk块的编号      

int next\_chunk;

//chunk的个数(在mp4的文件格式中,从stco中取值肯定为chunk的总数)

unsigned int chunk\_count;    

//chunk在文件中的偏移量数组(每个chunk中的sample在文件中的物理存储	//是连续	的),用于保存scto表

int64\_t \*chunk\_offsets;

//stts的元素的个数

unsigned int stts\_count;   

//stts时间数据表

MOVStts \*stts\_data; 

//ctts(用于在有B帧混合时进行纠正时间戳)的元素的个数

unsigned int ctts\_count;

`   `//ctts数据表

MOVStts \*ctts\_data;

//stsc(空间分布表)的元素的个数

unsigned int stsc\_count;

//stsc数据表

MOVStsc \*stsc\_data;



`    `//临时变量，记录当前使用的ctts表的索引

int ctts\_index;

//记录当前的ctts元素作用的sample的索引

`    `int ctts\_sample;



`    `//stsz表中可能smaple的size相同，如果相同使用该值

unsigned int sample\_size;

//stsz中元素的个数

unsigned int sample\_count;//sample的个数

//stsz数据表，记录每个sample的size，如果sample\_size=0，该表才不会	//空

int \*sample\_sizes;

//stss(关键帧索引表)中元素的个数

unsigned int keyframe\_count;

//关键帧数据表

int \*keyframes;



//dref的元素的个数，一般为1

unsigned drefs\_count;

//dref数据表

MOVDref \*drefs;

`    `//tkhd宽度

int width;      



//tkhd高度

int height;           

} MOVStreamContext;

说明：

MOVStreamContext结构用于保存从mov或mp4中进行拆包解复用从头部得到的信息。
## **4.11  AVPacket 结构体**
typedef struct AVPacket

{

//显示时间戳

int64\_t pts; 

//解码时间戳

int64\_t dts; 

//记录在文件或网络中的流中的字节的位置

int64\_t pos; 

//实际数据指针

uint8\_t \*data;

//实际的数据的大小

int size;

//该packet所属的流的索引，一般为0或者1

int stream\_index;

int flags;

//析构函数

void(\*destruct)(struct AVPacket\*);

} AVPacket;

说明：

AVPacket 代表音视频数据帧，固有的属性是一些标记，时钟信息，和压缩数据首地址，大小等信息。
## **4.12  AVPacketList 结构体**
typedef struct AVPacketList

{

AVPacket pkt;

struct AVPacketList \*next;

} AVPacketList;

说明：AVPacketList 把音视频AVPacket 组成一个小链表。

## **4.13 AVFrame结构体**
typedef struct AVFrame {

#define AV\_NUM\_DATA\_POINTERS 8

`    `uint8\_t \*data[AV\_NUM\_DATA\_POINTERS];

`    `int linesize[AV\_NUM\_DATA\_POINTERS];

uint8\_t \*\*extended\_data;

`    `/\*\*宽高 \*/

`    `int width, height;

`    `int nb\_samples;

int format;

`    `/\*\*是否是关键帧\*/

`    `int key\_frame;

`    `/\*\*帧类型（I,B,P）\*/

`    `enum AVPictureType pict\_type;

`    `uint8\_t \*base[AV\_NUM\_DATA\_POINTERS];

`    `AVRational sample\_aspect\_ratio;

`    `int64\_t pts;

`    `int64\_t pkt\_pts;

`    `int64\_t pkt\_dts;

`    `int coded\_picture\_number;

`    `int display\_picture\_number;

`    `int quality;

`    `int reference;

`    `/\*\*QP表\*/

`    `int8\_t \*qscale\_table;



`    `int qstride;

`    `int qscale\_type;

`    `/\*\*跳过宏块表 \*/

`    `uint8\_t \*mbskip\_table;

`    `/\*\*运动矢量表\*/

`    `int16\_t (\*motion\_val[2])[2];

`    `/\*\*宏块类型表 \*/

`    `uint32\_t \*mb\_type;

`    `/\*\*DCT系数 \*/

`    `short \*dct\_coeff;

`    `/\*\*参考帧列表 \*/

`    `int8\_t \*ref\_index[2];

`    `void \*opaque;

`    `uint64\_t error[AV\_NUM\_DATA\_POINTERS];

`    `int type;

`    `int repeat\_pict;

`    `int interlaced\_frame;

`    `int top\_field\_first;

`    `int palette\_has\_changed;

`    `int buffer\_hints;

`    `AVPanScan \*pan\_scan;

`    `int64\_t reordered\_opaque;

`    `void \*hwaccel\_picture\_private;

`    `struct AVCodecContext \*owner;

`    `void \*thread\_opaque;

`    `/\*\*

`     `\* log2 of the size of the block which a single vector in motion\_val represents:

`     `\* (4->16x16, 3->8x8, 2-> 4x4, 1-> 2x2)

`     `\* - encoding: unused

`     `\* - decoding: Set by libavcodec.

`     `\*/

`    `uint8\_t motion\_subsample\_log2;

`    `/\*\*（音频）采样率     \*/

`    `int sample\_rate;

`    `uint64\_t channel\_layout;

`    `int64\_t best\_effort\_timestamp;

`    `int64\_t pkt\_pos;

`    `int64\_t pkt\_duration;

`    `AVDictionary \*metadata;

`    `int decode\_error\_flags;

#define FF\_DECODE\_ERROR\_INVALID\_BITSTREAM   1

#define FF\_DECODE\_ERROR\_MISSING\_REFERENCE   2

`    `int64\_t channels;

} AVFrame;

AVFrame结构体一般用于存储原始数据（即非压缩数据，例如对视频来说是YUV，RGB，对音频来说是PCM），此外还包含了一些相关的信息。比如说，解码的时候存储了宏块类型表，QP表，运动矢量表等数据。编码的时候也存储了相关的数据。因此在使用FFMPEG进行码流分析的时候，AVFrame是一个很重要的结构体。

下面看几个主要变量的作用（在这里考虑解码的情况）：

uint8\_t \*data[AV\_NUM\_DATA\_POINTERS]：解码后原始数据（对视频来说是YUV，RGB，对音频来说是PCM）

int linesize[AV\_NUM\_DATA\_POINTERS]：data的大小

int width, height：视频帧宽和高（1920x1080,1280x720...）

int nb\_samples：音频的一个AVFrame中可能包含多个音频帧，在此标记包含了几个

int format：解码后原始数据类型（YUV420，YUV422，RGB24...）

int key\_frame：是否是关键帧

enum AVPictureType pict\_type：帧类型（I,B,P...）

AVRational sample\_aspect\_ratio：宽高比（16:9，4:3...）

int64\_t pts：显示时间戳

int coded\_picture\_number：编码帧序号

int display\_picture\_number：显示帧序号

int8\_t \*qscale\_table：QP表

uint8\_t \*mbskip\_table：跳过宏块表

int16\_t (\*motion\_val[2])[2]：运动矢量表

uint32\_t \*mb\_type：宏块类型表

short \*dct\_coeff：DCT系数，这个没有提取过

int8\_t \*ref\_index[2]：运动估计参考帧列表（貌似H.264这种比较新的标准才会涉及到多参考帧）

int interlaced\_frame：是否是隔行扫描

uint8\_t motion\_subsample\_log2：一个宏块中的运动矢量采样个数，取log的

其他的变量不再一一列举，源代码中都有详细的说明。在这里重点分析一下几个需要一定的理解的变量：

1.data[]

对于packed格式的数据（例如RGB24），会存到data[0]里面。

对于planar格式的数据（例如YUV420P），则会分开成data[0]，data[1]，data[2]...（YUV420P中data[0]存Y，data[1]存U，data[2]存V）

具体参见：FFMPEG 实现 YUV，RGB各种图像原始数据之间的转换（swscale）

2.pict\_type

包含以下类型：

py

enum AVPictureType {  

`    `AV\_PICTURE\_TYPE\_NONE = 0, ///< Undefined  

`    `AV\_PICTURE\_TYPE\_I,     ///< Intra  

`    `AV\_PICTURE\_TYPE\_P,     ///< Predicted  

`    `AV\_PICTURE\_TYPE\_B,     ///< Bi-dir predicted  

`    `AV\_PICTURE\_TYPE\_S,     ///< S(GMC)-VOP MPEG4  

`    `AV\_PICTURE\_TYPE\_SI,    ///< Switching Intra  

`    `AV\_PICTURE\_TYPE\_SP,    ///< Switching Predicted  

`    `AV\_PICTURE\_TYPE\_BI,    ///< BI type  

};  

3.sample\_aspect\_ratio

宽高比是一个分数，FFMPEG中用AVRational表达分数：

/\*\* 

` `\* rational number numerator/denominator 

` `\*/  

typedef struct AVRational{  

`    `int num; ///< numerator  

`    `int den; ///< denominator  

} AVRational;  

4.qscale\_table

QP表指向一块内存，里面存储的是每个宏块的QP值。宏块的标号是从左往右，一行一行的来的。每个宏块对应1个QP。

qscale\_table[0]就是第1行第1列宏块的QP值；qscale\_table[1]就是第1行第2列宏块的QP值；qscale\_table[2]就是第1行第3列宏块的QP值。以此类推...

宏块的个数用下式计算：

注：宏块大小是16x16的。

每行宏块数：

int mb\_stride = pCodecCtx->width/16+1  

宏块的总数：

int mb\_sum = ((pCodecCtx->height+15)>>4)\*(pCodecCtx->width/16+1)  

5.motion\_subsample\_log2

1个运动矢量所能代表的画面大小（用宽或者高表示，单位是像素），注意，这里取了log2。

代码注释中给出以下数据：

4->16x16, 3->8x8, 2-> 4x4, 1-> 2x2

即1个运动矢量代表16x16的画面的时候，该值取4；1个运动矢量代表8x8的画面的时候，该值取3...以此类推

6.motion\_val

运动矢量表存储了一帧视频中的所有运动矢量。

该值的存储方式比较特别：

int16\_t (\*motion\_val[2])[2];  

为了弄清楚该值究竟是怎么存的，花了我好一阵子功夫...

注释中给了一段代码：

int mv\_sample\_log2= 4 - motion\_subsample\_log2;  

int mb\_width= (width+15)>>4;  

int mv\_stride= (mb\_width << mv\_sample\_log2) + 1;  

motion\_val[direction][x + y\*mv\_stride][0->mv\_x, 1->mv\_y];  

大概知道了该数据的结构：

1.首先分为两个列表L0和L1

2.每个列表（L0或L1）存储了一系列的MV（每个MV对应一个画面，大小由motion\_subsample\_log2决定）

3.每个MV分为横坐标和纵坐标（x,y）

注意，在FFMPEG中MV和MB在存储的结构上是没有什么关联的，第1个MV是屏幕上左上角画面的MV（画面的大小取决于motion\_subsample\_log2），第2个MV是屏幕上第1行第2列的画面的MV，以此类推。因此在一个宏块（16x16）的运动矢量很有可能如下图所示（line代表一行运动矢量的个数）：

//例如8x8划分的运动矢量与宏块的关系：  

`                `//-------------------------  

`                `//|          |            |  

`                `//|mv[x]     |mv[x+1]     |  

`                `//-------------------------  

`                `//|          |            |  

`                `//|mv[x+line]|mv[x+line+1]|  

`                `//-------------------------  

7.mb\_type

宏块类型表存储了一帧视频中的所有宏块的类型。其存储方式和QP表差不多。只不过其是uint32类型的，而QP表是uint8类型的。每个宏块对应一个宏块类型变量。

宏块类型如下定义所示：

//The following defines may change, don't expect compatibility if you use them.  

#define MB\_TYPE\_INTRA4x4   0x0001  

#define MB\_TYPE\_INTRA16x16 0x0002 //FIXME H.264-specific  

#define MB\_TYPE\_INTRA\_PCM  0x0004 //FIXME H.264-specific  

#define MB\_TYPE\_16x16      0x0008  

#define MB\_TYPE\_16x8       0x0010  

#define MB\_TYPE\_8x16       0x0020  

#define MB\_TYPE\_8x8        0x0040  

#define MB\_TYPE\_INTERLACED 0x0080  

#define MB\_TYPE\_DIRECT2    0x0100 //FIXME  

#define MB\_TYPE\_ACPRED     0x0200  

#define MB\_TYPE\_GMC        0x0400  

#define MB\_TYPE\_SKIP       0x0800  

#define MB\_TYPE\_P0L0       0x1000  

#define MB\_TYPE\_P1L0       0x2000  

#define MB\_TYPE\_P0L1       0x4000  

#define MB\_TYPE\_P1L1       0x8000  

#define MB\_TYPE\_L0         (MB\_TYPE\_P0L0 | MB\_TYPE\_P1L0)  

#define MB\_TYPE\_L1         (MB\_TYPE\_P0L1 | MB\_TYPE\_P1L1)  

#define MB\_TYPE\_L0L1       (MB\_TYPE\_L0   | MB\_TYPE\_L1)  

#define MB\_TYPE\_QUANT      0x00010000  

#define MB\_TYPE\_CBP        0x00020000  

//Note bits 24-31 are reserved for codec specific use (h264 ref0, mpeg1 0mv, ...)  

一个宏块如果包含上述定义中的一种或两种类型，则其对应的宏块变量的对应位会被置1。

注：一个宏块可以包含好几种类型，但是有些类型是不能重复包含的，比如说一个宏块不可能既是16x16又是8x8。

8.ref\_index

运动估计参考帧列表存储了一帧视频中所有宏块的参考帧索引。这个列表其实在比较早的压缩编码标准中是没有什么用的。只有像H.264这样的编码标准才有多参考帧的概念。但是这个字段目前我还没有研究透。只是知道每个宏块包含有4个该值，该值反映的是参考帧的索引。以后有机会再进行细研究吧。

在这里展示一下自己做的码流分析软件的运行结果。将上文介绍的几个列表图像化显示了出来（在这里是使用MFC的绘图函数画出来的）

视频帧：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.022.jpeg)

QP参数提取的结果：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.023.jpeg)

美化过的（加上了颜色）：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.024.jpeg)

宏块类型参数提取的结果：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.025.jpeg)

美化过的（加上了颜色，更清晰一些，s代表skip宏块）：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.026.jpeg)

运动矢量参数提取的结果（在这里是List0）：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.027.jpeg)

运动估计参考帧参数提取的结果：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.028.jpeg)


# **第五章 重要模块**
介绍几个常用模块及其函数实现，有贴代码的嫌疑。（下面分析的代码是较老版本的，新版本部分已经不适用了，但是具有一定参考价值，初期熟悉api的时候可以不理会具体的代码实现）

ps ：下列文件列表中的大小均为裁剪后的大小，非源码中实际代码带大小。
## **5.1 libavutil公共模块**
### **1 文件列表**

|文件类型|文件名|大小(bytes)|
| - | - | - |
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|common.h|1515|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|bswap.h|489|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|rational.h|257|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|mathematics.h|153|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|avutil.h|1978|
### **2 common.h 文件**
2.1 功能描述

ffplay 使用的工具类数据类型定义，宏定义和两个简单的内联函数,基本上是自注释的。

2.2 文件注释

1

2	#ifndef COMMON\_H

3	#define COMMON\_H

4

5	#include <stdlib.h>

6	#include <stdio.h>

7	#include <string.h>

8	#include <ctype.h>

9

10	#if defined(WIN32) && !defined( MINGW32 ) && !defined( CYGWIN )

11	#define CONFIG\_WIN32

12	#endif

13![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.030.png)

内联函数的关键字在 linux gcc 和 w indow s vc 中的定义是不同的，gcc 是 in line，vc 是    in line。因为代

码是从 linu x 下移植过来的，在这里做一个宏定义修改相对简单。

14	#ifdef CONFIG\_WIN32

15	#define inline  inline

16	#endif

17

简单的数据类型定义， linux gcc 和 w indow s vc 编译器有稍许不同，用宏开关 CONFIG\_WIN32 来屏蔽 64

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.031.png)位整数类型的差别。![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

18	typedef signed char int8\_t;

19	typedef signed short int16\_t;

20	typedef signed int int32\_t;

21	typedef unsigned char uint8\_t;

22	typedef unsigned short uint16\_t;

23	typedef unsigned int uint32\_t;

24

25	#ifdef CONFIG\_WIN32

26	typedef signed  int64 int64\_t;

27	typedef unsigned  int64 uint64\_t;

28	#else

29	typedef signed long long int64\_t;

30	typedef unsigned long long uint64\_t;

31	#endif

32

64 位整数的定义语法，linux gcc 和 w indow s vc 编译器有稍许不同，用宏开关 CONFIG\_WIN32 来屏蔽 64

位整数定义的差别。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.032.png)Linu x 用 LL/ ULL 来表示 64 位整数，VC 用 i64 来表示 64 位整数。

\## 是连接符，把##前后的两个字符串连接成一个字符串。

33	#ifdef CONFIG\_WIN32

34	#define int64\_t\_C(c)	(c ## i64)

35	#define uint64\_t\_C(c)	(c ## i64)

36	#else

37	#define int64\_t\_C(c)	(c ## LL)

38	#define uint64\_t\_C(c)	(c ## ULL)

39	#endif

40![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.033.png)

定义最大的 64 位整数。

41	#ifndef INT64\_MAX

42	#define INT64\_MAX int64\_t\_C(9223372036854775807)

43	#endif

44![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.033.png)

大小写敏感的字符串比较函数。在 ffplay 中只关心是否相等，不关心谁大谁小。

45	static int strcasecmp(char \*s1, const char \*s2)

46	{

47	while (toupper((unsigned char) \*s1) == toupper((unsigned char) \*s2++))

48	if (\*s1++ == '\0')

49	return 0;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

50

51	return (toupper((unsigned char) \*s1) - toupper((unsigned char) \*--s2));

52	}

53

限幅函数，这个函数使用简单的比较逻辑来实现，比较语句多，容易中断 CPU 的指令流水线，导致性

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.034.png)能低下。如果变量 a 的取值范围比较小，可以用常规的空间换时间的查表方法来优化。

54	static inline int clip(int a, int amin, int amax)

55	{

56	if (a < amin)

57	return amin;

58	else if (a > amax)

59	return amax;

60	else

61	return a;

62	}

63

64 #endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **3 bswap.h 文件**
3.1 功能描述

short 和 int 整数类型字节顺序交换，通常和 CPU 大端或小端有关。

对 int 型整数，小端 CPU 低地址内存存低位字节，高地址内存存高位字节。 对 int 型整数，大端 CPU 低地址内存存高位字节，高地址内存存低位字节。

常见的 CPU 中，Intel X86 序列及其兼容序列只能是小端，Motorola 68 序列只能是大端，ARM 大端小端都 支持，但默认小端。

3.2 文件注释

1	#ifndef   BSWAP\_H 	

2	#define   BSWAP\_H 	

3![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.035.png)

Int 16 位短整数字节交换，简单的移位再或运算。

4	static inline uint16\_t bswap\_16(uint16\_t x)

5	{

6	return (x >> 8) | (x << 8);

7	}

8

Int 32 位长整数字节交换，看遍所有的开源代码，这个代码是最简洁的 C 代码，并且和上面 16 位短

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.036.png)整数字节交换一脉相承。

9	static inline uint32\_t bswap\_32(uint32\_t x)

10	{

11	x = ((x << 8) &0xFF00FF00) | ((x >> 8) &0x00FF00FF);

12	return (x >> 16) | (x << 16);

13	}

14

15	// be2me ... BigEndian to MachineEndian

16	// le2me ... LittleEndian to MachineEndian

17

18	#define be2me\_16(x) bswap\_16(x)

19	#define be2me\_32(x) bswap\_32(x)

20	#define le2me\_16(x) (x)

21	#define le2me\_32(x) (x)

22

23 #endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **4 rational.h 文件**
4.1 功能描述

用两整数精确表示分数。常规的可以用一个 float 或 double 型数来表示分数，但不是精确表示，在需要相 对比较精确计算的时候，为避免非精确表示带来的计算误差，采用两整数来精确表示。

4.2 文件注释

1	#ifndef RATIONAL\_H

2	#define RATIONAL\_H

3![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.037.png)

用分数最原始的分子和分母的定义来表示，用分子和分母的组合来表示分数。

4	typedef struct AVRational

5	{

6	int num; // numerator	// 分子

7	int den; // denominator // 分母

8	} AVRational;

9![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.037.png)

用 float 或 double  表示分数值，强制类型转换后，简单的除法运算。

10	static inline double av\_q2d(AVRational a)

11	{

12	return a.num / (double)a.den;

13	}

1415	#endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **5 mathematics.h 文件**
5.1 功能描述

数学上的缩放运算。为避免计算误差，缩放因子用两整数表示做精确的整数运算。为防止计算溢出，强制转 换为 int 64 位整数后计算。

此处做了一些简化，运算精度会降低，但普通的人很难感知到计算误差。

5.2 文件注释

1	#ifndef MATHEMATICS\_H

2	#define MATHEMATICS\_H

3![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.038.png)

数学上的缩放运算，此处简化了很多，虽然计算结果有稍许误差，但不影响播放效果。

4	static inline int64\_t av\_rescale(int64\_t a, int64\_t b, int64\_t c)

5	{

6	return a \* b / c;

7	}

9	#endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **6 avutil.h 文件**
6.1 功能描述

ffplay 基础工具库使用的一些常数和宏的定义。

6.2 文件注释

1	#ifndef AVUTIL\_H

2	#define AVUTIL\_H

3

4	#ifdef  cplusplus

5	extern "C" {

6	#endif

7![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.039.png)

代码 8 到 15 行是一些版本信息标示的宏定义，便于各位网友和原始版本比对，更深入地学习 ffmpeg。

8	#define AV\_STRINGIFY(s)	AV\_TOSTRING(s)

9	#define AV\_TOSTRING(s) #s

10

11	#define LIBAVUTIL\_VERSION\_INT	((49<<16)+(0<<8)+0)

12	#define LIBAVUTIL\_VERSION	49.0.0

13	#define LIBAVUTIL\_BUILD	LIBAVUTIL\_VERSION\_INT

14

15	#define LIBAVUTIL\_IDENT	"Lavu" AV\_STRINGIFY(LIBAVUTIL\_VERSION)

16

17	#include "common.h"

18	#include "mathematics.h"

19	#include "rational.h"

20![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.039.png)

像素格式的宏定义，便于代码编写和维护。把一些常数定义成有意义的宏是一个值得鼓励的好习惯。

21	enum PixelFormat

22	{

23	PIX\_FMT\_NONE= -1,

24	PIX\_FMT\_YUV420P,	// Planar YUV 4:2:0 (1 Cr & Cb sample per 2x2 Y samples)

25	PIX\_FMT\_YUV422,	// Packed pixel, Y0 Cb Y1 Cr

26	PIX\_FMT\_RGB24,	// Packed pixel, 3 bytes per pixel, RGBRGB...

27	PIX\_FMT\_BGR24,	// Packed pixel, 3 bytes per pixel, BGRBGR...

28	PIX\_FMT\_YUV422P,	// Planar YUV 4:2:2 (1 Cr & Cb sample per 2x1 Y samples)

29	PIX\_FMT\_YUV444P,	// Planar YUV 4:4:4 (1 Cr & Cb sample per 1x1 Y samples)

30	PIX\_FMT\_RGBA32,	// Packed pixel, 4 bytes per pixel, BGRABGRA..., stored in cpu endianness![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

31	PIX\_FMT\_YUV410P,	// Planar YUV 4:1:0 (1 Cr & Cb sample per 4x4 Y samples)

32	PIX\_FMT\_YUV411P,	// Planar YUV 4:1:1 (1 Cr & Cb sample per 4x1 Y samples)

33	PIX\_FMT\_RGB565,	// always stored in cpu endianness

34	PIX\_FMT\_RGB555,	// always stored in cpu endianness, most significant bit to 1

35	PIX\_FMT\_GRAY8,

36	PIX\_FMT\_MONOWHITE, // 0 is white

37	PIX\_FMT\_MONOBLACK, // 0 is black

38	PIX\_FMT\_PAL8,	// 8 bit with RGBA palette

39	PIX\_FMT\_YUVJ420P,	// Planar YUV 4:2:0 full scale (jpeg)

40	PIX\_FMT\_YUVJ422P,	// Planar YUV 4:2:2 full scale (jpeg)

41	PIX\_FMT\_YUVJ444P,	// Planar YUV 4:4:4 full scale (jpeg)

42	PIX\_FMT\_XVMC\_MPEG2\_MC,// XVideo Motion Acceleration via common packet passing(xvmc\_render.h)

43	PIX\_FMT\_XVMC\_MPEG2\_IDCT,

|44|PIX\_FMT\_UYVY422,|// Packed pixel, Cb Y0 Cr Y1|
| - | - | - |
|45|PIX\_FMT\_UYVY411,|// Packed pixel, Cb Y0 Y1 Cr Y2 Y3|
|46|PIX\_FMT\_NB,||
|47|};||
|48|||
|49|#ifdef  cplusplus||
|50|}||
|51|#endif||
|52|||
|53|#endif||
## **5.2 libavcodec编解码模块**
### **1 文件列表**

|文件类型|文件名|大小(bytes)|
| - | - | - |
||||

|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|文件名|大小(bytes)|
| - | - | - |
||avcodec.h|4943|
||allcodecs.c|310|
||dsputil.h|163|
||dsputil.c|350|
||imgconvert\_template.h|22311|
||imgconvert.c|47834|
||msrle.c|8387|
||turespeech\_data.h|4584|
||turespeech.c|9622|
||utils\_codec.c|8973|

|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|avcodec.h|4943|
| - | - | - |
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|allcodecs.c|310|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|dsputil.h|163|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|dsputil.c|350|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|imgconvert\_template.h|22311|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|imgconvert.c|47834|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|msrle.c|8387|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|turespeech\_data.h|4584|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|turespeech.c|9622|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|utils\_codec.c|8973|
### **2 avcodec.h 文件**
2.1 功能描述

定义编解码器库使用的宏、数据结构和函数，通常这些宏、数据结构和函数在此模块内相对全局有效。

2.2 文件注释

1	#ifndef AVCODEC\_H

2	#define AVCODEC\_H

3

4	#ifdef  cplusplus

5	extern "C"

6	{

7	#endif

8

9	#include "../libavutil/avutil.h"

10	#include <sys/types.h> // size\_t

11![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.041.png)

和版本信息有关的几个宏定义

12	#define FFMPEG\_VERSION\_INT	0x000409

13	#define FFMPEG\_VERSION	"CVS"

14

15	#define AV\_STRINGIFY(s)	AV\_TOSTRING(s)

16	#define AV\_TOSTRING(s) #s

17![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

18	#define LIBAVCODEC\_VERSION\_INT	((51<<16)+(8<<8)+0)

19	#define LIBAVCODEC\_VERSION	51.8.0

20	#define LIBAVCODEC\_BUILD	LIBAVCODEC\_VERSION\_INT

21

22	#define LIBAVCODEC\_IDENT	"Lavc" AV\_STRINGIFY(LIBAVCODEC\_VERSION)

23

24	#define AV\_NOPTS\_VALUE	int64\_t\_C(0x8000000000000000)

25	#define AV\_TIME\_BASE	1000000

26![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.041.png)

Codec ID 宏定义，瘦身后的 ffplay 只支持这两种 codec，其他的都删掉了。

27	enum CodecID

28	{

29	CODEC\_ID\_TRUESPEECH,

30	CODEC\_ID\_MSRLE,

31	CODEC\_ID\_NONE

32	};

33![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.041.png)

Codec  类型定义，瘦身后的 ffplay 只支持视频和音频。

34	enum CodecType

35	{

36	CODEC\_TYPE\_UNKNOWN =	- 1,

37	CODEC\_TYPE\_VIDEO,

38	CODEC\_TYPE\_AUDIO,

39	CODEC\_TYPE\_DATA

40	};

41

42	#define AVCODEC\_MAX\_AUDIO\_FRAME\_SIZE 192000 // 1 second of 48khz 32bit audio

43

44	#define FF\_INPUT\_BUFFER\_PADDING\_SIZE 8

45

AVPicture 和 AVFrame 主要表示解码过程中的使用缓存，通常帧缓存是 YUV 格式，输出格式有 YUV

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.042.png)也有 RGB 格式，所以定义了 4 个 data 指针来表示分量。

46	typedef struct AVPicture

47	{

48	uint8\_t \*data[4];

49	int linesize[4];

50	} AVPicture;

51![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

52	typedef struct AVFrame

53	{

54	uint8\_t \*data[4]; //  有多重意义，其一用 NULL 来判断是否被占用

55	int linesize[4];

56	uint8\_t \*base[4]; //  有多重意义，其一用 NULL 来判断是否分配内存

57	} AVFrame;

58

程序运行时当前 Codec 使用的上下文，着重于所有 Codec 共有的属性(并且是在程序运行时才能确定其

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.042.png)值)，codec 和 priv\_data 关联其他结构的字段，便于在数据结构间跳转。

59	typedef struct AVCodecContext

60	{

61	int bit\_rate;

62	int frame\_number;	// audio or video frame number

63

64	unsigned char \*extradata; // codec 的私有数据,对 Audio 是 WAVEFORMATEX 扩展结构。

65	int extradata\_size;	//	对 Video 是 BITMAPINFOHEADER 扩展结构

66

67	int width, height;	// video only

68

69	enum PixelFormat pix\_fmt; // 输出像素格式/视频图像格式

70

71	int sample\_rate;	// samples per sec	// audio only

72	int channels;

73	int bits\_per\_sample;

74	int block\_align;

75

76	struct AVCodec \*codec;	// 指向 Codec 的指针，

77	void \*priv\_data;	// 具体解码器属性，在本例中指向 MsrleContext 或 TSContext

78

79	enum CodecType codec\_type;// see CODEC\_TYPE\_xxx

80	enum CodecID codec\_id;	// see CODEC\_ID\_xxx

81

82	int(\*get\_buffer)(struct AVCodecContext \*c, AVFrame \*pic);

83	void(\*release\_buffer)(struct AVCodecContext \*c, AVFrame \*pic);

84	int(\*reget\_buffer)(struct AVCodecContext \*c, AVFrame \*pic);

85

86	int internal\_buffer\_count;

87	void \*internal\_buffer;

88

89	struct AVPaletteControl \*palctrl;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

90	}AVCodecContext;

91

类似 COM 接口的数据结构，表示音视频编解码器，着重于功能函数，一种媒体类型对应一个 AVCodec

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.042.png)结构，在程序运行时有多个实例串联成链表便于查找。

92	typedef struct AVCodec

93	{

94	const char \*name;	// 便于阅读的友好字符串，表征编解码器名称，比如"msrle","truespeech"

95	enum CodecType type;	// 编解码器类型，有效取值为 CODEC\_TYPE\_VIDEO 或 CODEC\_TYPE\_AUDIO

96	enum CodecID id;	// 编解码器 ID 值，

97	int priv\_data\_size;	// 具体编解码属性结构的大小，取代很多的 if-else 语句

98	int(\*init)(AVCodecContext\*);

99	int(\*encode)(AVCodecContext \*, uint8\_t \*buf, int buf\_size, void \*data);

100	int(\*close)(AVCodecContext\*);

101	int(\*decode)(AVCodecContext \*, void \*outdata, int \*outdata\_size, uint8\_t \*buf, int buf\_size);

102	int capabilities;

103

104	struct AVCodec \*next; // 把所有的编解码器串联成链表便于查找

105 }AVCodec;

106![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.042.png)

调色板大小和大小宏定义，每个调色板四字节(R,G,B,α)。有很多的视频图像颜色种类比较少，用索引 间接表示每个像素的颜色值，就可以用调色板和索引值实现简单的大约的 4:1 压缩比。

107 #define AVPALETTE\_SIZE 1024

108 #define AVPALETTE\_COUNT 256

109![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.043.png)

调色板数据结构定义，保存调色板数据。

110 typedef struct AVPaletteControl

111 {

112	// demuxer sets this to 1 to indicate the palette has changed; decoder resets to 0

113	int palette\_changed;

114

115	/\* 4-byte ARGB palette entries, stored in native byte order; note that

116	\* the individual palette components should be on a 8-bit scale; if

117	\* the palette data comes from a IBM VGA native format, the component

118	\* data is probably 6 bits in size and needs to be scaled \*/

119	unsigned int palette[AVPALETTE\_COUNT];

120

121 } AVPaletteControl;

122![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.044.png)

编解码库使用的函数声明。

123 int avpicture\_alloc(AVPicture \*picture, int pix\_fmt, int width, int height);

124

125 void avpicture\_free(AVPicture \*picture);

126

127 int avpicture\_fill(AVPicture \*picture, uint8\_t \*ptr, int pix\_fmt, int width, int height);

128 int avpicture\_get\_size(int pix\_fmt, int width, int height);

129 void avcodec\_get\_chroma\_sub\_sample(int pix\_fmt, int \*h\_shift, int \*v\_shift);

130

131 int img\_convert(AVPicture \*dst, int dst\_pix\_fmt, const AVPicture \*src, int pix\_fmt,

132	int width, int height);

133

134 void avcodec\_init(void);

135

136 void register\_avcodec(AVCodec \*format);

137 AVCodec \*avcodec\_find\_decoder(enum CodecID id);

138

139 AVCodecContext \*avcodec\_alloc\_context(void);

140

141 int avcodec\_default\_get\_buffer(AVCodecContext \*s, AVFrame \*pic);

142 void avcodec\_default\_release\_buffer(AVCodecContext \*s, AVFrame \*pic);

143 int avcodec\_default\_reget\_buffer(AVCodecContext \*s, AVFrame \*pic);

144 void avcodec\_align\_dimensions(AVCodecContext \*s, int \*width, int \*height);

145 int avcodec\_check\_dimensions(void \*av\_log\_ctx, unsigned int w, unsigned int h);

146

147 int avcodec\_open(AVCodecContext \*avctx, AVCodec \*codec);

148

149 int avcodec\_decode\_audio(AVCodecContext \*avctx, int16\_t \*samples, int \*frame\_size\_ptr,

150	uint8\_t \*buf, int buf\_size);

151 int avcodec\_decode\_video(AVCodecContext \*avctx, AVFrame \*picture, int \*got\_picture\_ptr,

152	uint8\_t \*buf, int buf\_size);

153

154 int avcodec\_close(AVCodecContext \*avctx);

155

156 void avcodec\_register\_all(void);

157

158 void avcodec\_default\_free\_buffers(AVCodecContext \*s);

159

160 void \*av\_malloc(unsigned int size);

161 void \*av\_mallocz(unsigned int size);

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)162 void \*av\_realloc(void \*ptr, unsigned int size);

163 void av\_free(void \*ptr);

164 void av\_freep(void \*ptr);

165 void \*av\_fast\_realloc(void \*ptr, unsigned int \*size, unsigned int min\_size);

166

167 void img\_copy(AVPicture \*dst, const AVPicture \*src, int pix\_fmt, int width, int height);

168

169 #ifdef  cplusplus

170 }

171

172 #endif

173

174 #endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **3 allcodec.c 文件**
3.1 功能描述

简单的注册/初始化函数，把编解码器用相应的链表串起来便于查找识别。

3.2 文件注释

1	#include "avcodec.h"

2

3	extern AVCodec truespeech\_decoder;

4	extern AVCodec msrle\_decoder;

5

6	void avcodec\_register\_all(void)

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.045.png)7	{

8 到 13 行，in ited 变量声明成 static，做一下比较是为了避免此函数多次调用。

编程基本原则之一，初始化函数只调用一次，不能随意多次调用。

8	static int inited = 0;

9

10	if (inited != 0)

11	return ;

12

13	inited = 1;

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)14

把 msrle\_decoder 解码器串接到解码器链表，链表头指针是 first\_avcodec。

15	register\_avcodec(&msrle\_decoder);

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)16

把 truespeech\_decoder 解码器串接到解码器链表，链表头指针是 first\_avcodec。

17	register\_avcodec(&truespeech\_decoder);

18	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **4 dsputil.h 文件**
4.1 功能描述

定义 dsp 优化限幅运算使用的查找表及其初始化函数。

4.2 文件注释

1	#ifndef DSPUTIL\_H

2	#define DSPUTIL\_H

3

4	#define MAX\_NEG\_CROP 1024

5

6	extern uint8\_t cropTbl[256+2 \* MAX\_NEG\_CROP];

7

8	void dsputil\_static\_init(void);

9

10	#endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **5 dsputil.c 文件**
5.1 功能描述

定义 dsp 优化限幅运算使用的查找表，实现其初始化函数。

5.2 文件注释

1	#include "avcodec.h"

2	#include "dsputil.h"

3

4	uint8\_t cropTbl[256+2 \* MAX\_NEG\_CROP] = {0, };

5

6	void dsputil\_static\_init(void)

7	{

8	int i;

9

初始化限幅运算查找表，最后的结果是：前 MAX\_NEG\_CROP 个数组项为 0，接着的 256 个数组项分别为

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.047.png)0 到 255，后面 MAX\_NEG\_CROP 个数组项为 255。用查表代替比较实现限幅运算。

10	for (i = 0; i < 256; i++)

11	cropTbl[i + MAX\_NEG\_CROP] = i;

12

13	for (i = 0; i < MAX\_NEG\_CROP; i++)

14	{

15	cropTbl[i] = 0;

16	cropTbl[i + MAX\_NEG\_CROP + 256] = 255;

17	}

18	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **6 utils\_codec.c 文件**
6.1 功能描述

编解码库使用的帮助和工具函数，

6.2 文件注释

1	#include "avcodec.h"

2	#include "dsputil.h"

3

1	#include <assert.h>

2	#include "avcodec.h"

3	#include "dsputil.h"

4

5	#define EDGE\_WIDTH	16

6	#define STRIDE\_ALIGN 16

7

8	#define INT\_MAX 2147483647

9

10	#define FFMAX(a,b) ((a) > (b) ? (a) : (b))

11![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

内存动态分配函数，做一下简单参数校验后调用系统函数

12	void \*av\_malloc(unsigned int size)

13	{

14	void \*ptr;

15

16	if (size > INT\_MAX)

17	return NULL;

18	ptr = malloc(size);

19

20	return ptr;

21	}

22![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

内存动态重分配函数，做一下简单参数校验后调用系统函数

23	void \*av\_realloc(void \*ptr, unsigned int size)

24	{

25	if (size > INT\_MAX)

26	return NULL;

27

28	return realloc(ptr, size);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

29	}

30![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

内存动态释放函数，做一下简单参数校验后调用系统函数

31	void av\_free(void \*ptr)

32	{

33	if (ptr)

34	free(ptr);

35	}

36

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.049.png)内存动态分配函数，复用 av\_malloc()函数，再把分配的内存清 0.

37	void \*av\_mallocz(unsigned int size)

38	{

39	void \*ptr;

40

41	ptr = av\_malloc(size);

42	if (!ptr)

43	return NULL;

44

45	memset(ptr, 0, size);

46	return ptr;

47	}

48![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

快速内存动态分配函数，预分配一些内存来避免多次调用系统函数达到快速的目的。

49	void \*av\_fast\_realloc(void \*ptr, unsigned int \*size, unsigned int min\_size)

50	{

51	if (min\_size <	\*size)

52	return ptr;

53

54	\*size = FFMAX(17 \*min\_size / 16+32, min\_size);

55

56	return av\_realloc(ptr,	\*size);

57	}

58![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.050.png)

动态内存释放函数，注意传入的变量的类型。

59	void av\_freep(void \*arg)

60	{

61	void \*\*ptr = (void \*\*)arg;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

62	av\_free(\*ptr);

63	\*ptr = NULL;

64	}

65

66	AVCodec \*first\_avcodec = NULL;

67![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.050.png)

把编解码器串联成一个链表，便于查找。

68	void register\_avcodec(AVCodec \*format)

69	{

70	AVCodec \*\*p;

71	p = &first\_avcodec;

72	while (\*p != NULL)

73	p = &(\*p)->next;

74	\*p = format;

75	format->next = NULL;

76	}

77

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.051.png)编解码库内部使用的缓存区，因为视频图像有 RGB 或 YUV 分量格式，所以每个数组有四个分量。

78	typedef struct InternalBuffer

79	{

80	uint8\_t \*base[4];

81	uint8\_t \*data[4];

82	int	linesize[4];

83	} InternalBuffer;

84

85	#define INTERNAL\_BUFFER\_SIZE 32

86

87	#define ALIGN(x, a) (((x)+(a)-1)&~((a)-1))

88![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

计算各种图像格式要求的图像长宽的字节对齐数，是 1 个还是 2 个，4 个，8 个，16 个字节对齐。

89	void avcodec\_align\_dimensions(AVCodecContext \*s, int \*width, int \*height)

90	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

默认长宽是 1 个字节对齐。

91	int w\_align = 1;

92	int h\_align = 1;

93

94	switch (s->pix\_fmt)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

95	{

96	case PIX\_FMT\_YUV420P:

97	case PIX\_FMT\_YUV422:

98	case PIX\_FMT\_UYVY422:

99	case PIX\_FMT\_YUV422P:

100	case PIX\_FMT\_YUV444P:

101	case PIX\_FMT\_GRAY8:

102	case PIX\_FMT\_YUVJ420P:

103	case PIX\_FMT\_YUVJ422P:

104	case PIX\_FMT\_YUVJ444P: //FIXME check for non mpeg style codecs and use less alignment

105	w\_align = 16;

106	h\_align = 16;

107	break;

108	case PIX\_FMT\_YUV411P:

109	case PIX\_FMT\_UYVY411:

110	w\_align = 32;

111	h\_align = 8;

112	break;

113	case PIX\_FMT\_YUV410P:

114	case PIX\_FMT\_RGB555:

115	case PIX\_FMT\_PAL8:

116	break;

117	case PIX\_FMT\_BGR24:

118	break;

119	default:

120	w\_align = 1;

121	h\_align = 1;

122	break;

123	}

124

125	\*width = ALIGN(\*width, w\_align);

126	\*height = ALIGN(\*height, h\_align);

127 }

128![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

校验视频图像的长宽是否合法。

129 int avcodec\_check\_dimensions(void \*av\_log\_ctx, unsigned int w, unsigned int h)

130 {

131	if ((int)w > 0 && (int)h > 0 && (w + 128)\*(uint64\_t)(h + 128) < INT\_MAX / 4)

132	return 0;

133![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

134	return	- 1;

135 }

136

每次取 internal\_buffer\_count 数据项，用 base[0]来判断是否已分配内存，用 data[0]来判断是否

已被占用。base[]和 data[]有多重意义。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.052.png)在 avcodec\_alloc\_context 中已把 internal\_buffer 各项清 0，所以可以用 base[0]来判断。

137 int avcodec\_default\_get\_buffer(AVCodecContext \*s, AVFrame \*pic)

138 {

139	int i;

140	int w = s->width;

141	int h = s->height;

142	int align\_off;

143	InternalBuffer \*buf;

144

145	assert(pic->data[0] == NULL);

146	assert(INTERNAL\_BUFFER\_SIZE > s->internal\_buffer\_count);

147![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

校验视频图像的长宽是否合法。

148	if (avcodec\_check\_dimensions(s, w, h))

149	return	- 1;

150![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

如果没有分配内存，就分配动态内存并清 0。

151	if (s->internal\_buffer == NULL)

152	s->internal\_buffer = av\_mallocz(INTERNAL\_BUFFER\_SIZE \*sizeof(InternalBuffer));

153![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.050.png)

取缓存中的第一个没有占用内存。

154	buf = &((InternalBuffer\*)s->internal\_buffer)[s->internal\_buffer\_count];

155

156	if (buf->base[0])

157	{ /\* 如果内存已分配就跳过 \*/ }

158	else

159	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

如果没有分配内存就按照图像格式要求分配内存，并设置一些标记和计算一些参数值。

160	int h\_chroma\_shift, v\_chroma\_shift;

161	int pixel\_size, size[3];

162![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

163	AVPicture picture;

164![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

计算 CbCr 色度分量长宽的与 Y 亮度分量长宽的比，最后用移位实现。

165	avcodec\_get\_chroma\_sub\_sample(s->pix\_fmt, &h\_chroma\_shift, &v\_chroma\_shift);

166![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.041.png)

规整长宽满足特定图像像素格式的要求。

167	avcodec\_align\_dimensions(s, &w, &h);

168

把长宽放大一些，比如在 mpeg4 视频中编码算法中的运动估计要把原始图像做扩展来满足不受限制运

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.053.png)动矢量的要求(运动矢量可以超出原始图像边界)。

169	w+= EDGE\_WIDTH\*2;

170	h+= EDGE\_WIDTH\*2;

171![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

计算特定格式的图像参数，包括各分量的大小，单行长度(linesi ze/stride) 等等。

172	avpicture\_fill(&picture, NULL, s->pix\_fmt, w, h);

173	pixel\_size = picture.linesize[0] \* 8 / w;

174	assert(pixel\_size >= 1);

175

176	if (pixel\_size == 3 \*8)

177	w = ALIGN(w, STRIDE\_ALIGN << h\_chroma\_shift);

178	else

179	w = ALIGN(pixel\_size \*w, STRIDE\_ALIGN << (h\_chroma\_shift + 3)) / pixel\_size;

180

181	size[1] = avpicture\_fill(&picture, NULL, s->pix\_fmt, w, h);

182	size[0] = picture.linesize[0] \*h;

183	size[1] -= size[0];

184	if (picture.data[2])

185	size[1] = size[2] = size[1] / 2;

186	else

187	size[2] = 0;

188![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

注意 base[]和 data[]数组还有作为标记的用途，free()时的非 NULL 判断，这里要清 0。

189	memset(buf->base, 0, sizeof(buf->base));

190	memset(buf->data, 0, sizeof(buf->data));

191

192	for (i = 0; i < 3 && size[i]; i++)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

193	{

194	const int h\_shift = i == 0 ? 0 : h\_chroma\_shift;

195	const int v\_shift = i == 0 ? 0 : v\_chroma\_shift;

196

197	buf->linesize[i] = picture.linesize[i];

198![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

实质性分配内存，并且在 202 行把内存清 0。

199	buf->base[i] = av\_malloc(size[i] + 16); //FIXME 16

200	if (buf->base[i] == NULL)

201	return	- 1;

202	memset(buf->base[i], 128, size[i]);

203![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

内存对齐计算。

204	align\_off=ALIGN((buf->linesize[i]\*EDGE\_WIDTH>>v\_shift)+(EDGE\_WIDTH>>h\_shift),STRIDE\_ALIGN);

205

206	if ((s->pix\_fmt == PIX\_FMT\_PAL8) || !size[2])

207	buf->data[i] = buf->base[i];

208	else

209	buf->data[i] = buf->base[i] + align\_off;

210	}

211	}

212

213	for (i = 0; i < 4; i++)

214	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.050.png)

把分配的内存参数赋值到 pic 指向的结构中，传递出去。


|215||pic->base[i] = buf->base[i];|
| - | - | - |
|216||pic->data[i] = buf->data[i];|
|217||pic->linesize[i] = buf->linesize[i];|
|218|}||
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)内存数组计数+1，注意释放时的操作，保证计数对应的内存数组是空闲的。

219	s->internal\_buffer\_count++;

220

221	return 0;

222 }

223![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

释放占用的内存数组项。保证从 0 到 internal\_buffer\_count-1 数据项为有效数据，其他是空闲数据项![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

224 void avcodec\_default\_release\_buffer(AVCodecContext \*s, AVFrame \*pic)

225 {

226	int i;

227	InternalBuffer \*buf,	\*last, temp;

228![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

简单的参数校验，内存必须是已经分配过。

229	assert(s->internal\_buffer\_count);

230

231	buf = NULL;

232	for (i = 0; i < s->internal\_buffer\_count; i++)

233	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

遍历内存数组，查找对应 pic 的内存数组项，以 data[0]内存地址为比较判别标记。

234	buf = &((InternalBuffer\*)s->internal\_buffer)[i]; //just 3-5 checks so is not worth to optimize

235	if (buf->data[0] == pic->data[0])

236	break;

237	}

238	assert(i < s->internal\_buffer\_count);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.050.png)

内存数组计数-1, 删除最后一项.

239	s->internal\_buffer\_count--;

240	last = &((InternalBuffer\*)s->internal\_buffer)[s->internal\_buffer\_count];

241

把将要空闲的数组项和数组最后一项交换，保证 internal\_buffer\_count 计算正确无误。注意这里并

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.047.png)没有内存释放的动作，便于下次复用已分配的内存。

242	temp =	\*buf;

243	\*buf =	\*last;

244	\*last = temp;

245

246	for (i = 0; i < 3; i++)

247	{

把 data[i]置空，指示本块内存没有被占用，实际分配的首地址保持在 base[]中。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.054.png)整个程序最多分配 INTERNAL\_ BUFFER\_SIZE 次 avframe，其他次循环使用。

248	pic->data[i] = NULL;

249	}

250 }

251![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.041.png)

重新获得缓存。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)252 int avcodec\_default\_reget\_buffer(AVCodecContext \*s, AVFrame \*pic)

253 {

254	if (pic->data[0] == NULL)	// If no picture return a new buffer

255	{

256	return s->get\_buffer(s, pic);

257	}

258

259	return 0;

260 }

261![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.041.png)

释放内存数组项占用的内存。

262 void avcodec\_default\_free\_buffers(AVCodecContext \*s)

263 {

264	int i, j;

265

266	if (s->internal\_buffer == NULL)

267	return ;

268

269	for (i = 0; i < INTERNAL\_BUFFER\_SIZE; i++)

270	{

271	InternalBuffer \*buf = &((InternalBuffer\*)s->internal\_buffer)[i];

272	for (j = 0; j < 4; j++)

273	{

av\_freep()函数调用的 av\_free()函数做了非 NULL 判断，并且分配时已置 NULL，所以内循环可以到 4，

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.055.png)外循环可以到 INTERNAL\_BUFFER\_SIZE。

274	av\_freep(&buf->base[j]);

275	buf->data[j] = NULL;

276	}

277	}

278	av\_freep(&s->internal\_buffer);

279

280	s->internal\_buffer\_count = 0;

281 }

282![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

分配编解码器上下文占用的内存，清 0 后部分参数赋初值。

283 AVCodecContext \*avcodec\_alloc\_context(void)

284 {![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

285	AVCodecContext \*s = av\_malloc(sizeof(AVCodecContext));

286

287	if (s == NULL)

288	return NULL;

289![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

注意这里的清 0。

290	memset(s, 0, sizeof(AVCodecContext));

291

292	s->get\_buffer = avcodec\_default\_get\_buffer;

293	s->release\_buffer = avcodec\_default\_release\_buffer;

294

295	s->pix\_fmt = PIX\_FMT\_NONE;

296

297	s->palctrl = NULL;

298	s->reget\_buffer = avcodec\_default\_reget\_buffer;

299

300	return s;

301 }

302![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

打开编解码器，分配具体编解码器使用的上下文，简单变量赋初值，调用初始化函数初始化编解码器

303 int avcodec\_open(AVCodecContext \*avctx, AVCodec \*codec)

304 {

305	int ret =	- 1;

306

307	if (avctx->codec)

308	goto end;

309

310	if (codec->priv\_data\_size > 0)

311	{

这里体现了 priv\_data\_size 参数的重大作用，如果没有这个参数，就要用 codec 结构的名字比较确

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.056.png)定具体编解码器使用的上下文结构大小，超级长的 if-else 语句。

312	avctx->priv\_data = av\_mallocz(codec->priv\_data\_size);

313	if (!avctx->priv\_data)

314	goto end;

315	}

316	else

317	{

318	avctx->priv\_data = NULL;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

319	}

320

321	avctx->codec = codec;

322	avctx->codec\_id = codec->id;

323	avctx->frame\_number = 0;

324	ret = avctx->codec->init(avctx);

325	if (ret < 0)

326	{

327	av\_freep(&avctx->priv\_data);

328	avctx->codec = NULL;

329	goto end;

330	}

331	ret = 0;

332 end:

333	return ret;

334 }

335![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

视频解码，简单的跳转

336 int avcodec\_decode\_video(AVCodecContext \*avctx, AVFrame \*picture, int \*got\_picture\_ptr,

337	uint8\_t \*buf, int buf\_size)

338 {

339	int ret;

340

341	\*got\_picture\_ptr = 0;

342

343	if (buf\_size)

344	{

345	ret = avctx->codec->decode(avctx, picture, got\_picture\_ptr, buf, buf\_size);

346

347	if (\*got\_picture\_ptr)

348	avctx->frame\_number++;

349	}

350	else

351	ret = 0;

352

353	return ret;

354 }

355![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

音频解码，简单的跳转![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

356 int avcodec\_decode\_audio(AVCodecContext \*avctx, int16\_t \*samples, int \*frame\_size\_ptr,

357	uint8\_t \*buf, int buf\_size)

358 {

359	int ret;

360

361	\*frame\_size\_ptr = 0;

362	if (buf\_size)

363	{

364	ret = avctx->codec->decode(avctx, samples, frame\_size\_ptr, buf, buf\_size);

365	avctx->frame\_number++;

366	}

367	else

368	ret = 0;

369	return ret;

370 }

371![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.048.png)

关闭解码器，释放动态分配的内存

372 int avcodec\_close(AVCodecContext \*avctx)

373 {

374	if (avctx->codec->close)

375	avctx->codec->close(avctx);

376	avcodec\_default\_free\_buffers(avctx);

377	av\_freep(&avctx->priv\_data);

378	avctx->codec = NULL;

379	return 0;

380 }

381

查找编解码器，在本例中，读 avi 文件头得到 codec FOURCC ，再由 FOURCC 查找 codec\_bmp\_tags

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.057.png)或 codec\_wav\_tags 得到 CodecID 传给此函数。

382 AVCodec \*avcodec\_find\_decoder(enum CodecID id)

383 {

384	AVCodec \*p;

385	p = first\_avcodec;

386	while (p)

387	{

388	if (p->decode != NULL && p->id == id)

389	return p;

390	p = p->next;

391	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

392	return NULL;

393 }

394![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

初始化编解码库，在本例中仅初始化限幅数组/查找表。

395 void avcodec\_init(void)

396 {

397	static int inited = 0;

398

399	if (inited != 0)

400	return ;

401	inited = 1;

402

403	dsputil\_static\_init();

404 }![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **7 imgconvert\_template.h 文件**
7.1 功能描述

定义并实现图像颜色空间转换使用的函数和宏，此文件请各位自己仔细分析。

7.2 文件注释

1	#ifndef RGB\_OUT

2	#define RGB\_OUT(d, r, g, b) RGBA\_OUT(d, r, g, b, 0xff)

3	#endif

4

5	#pragma warning (disable:4305 4244)

6![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

此文件请各位读者自行分析，都是些颜色空间转换函数。

7	static void glue(yuv420p\_to\_, RGB\_NAME)(AVPicture \*dst, const AVPicture \*src, int width, int height)

8	{

9	const uint8\_t \*y1\_ptr,	\*y2\_ptr,	\*cb\_ptr,	\*cr\_ptr;

10	uint8\_t \*d,	\*d1,	\*d2;

11	int w, y, cb, cr, r\_add, g\_add, b\_add, width2;

12	uint8\_t \*cm = cropTbl + MAX\_NEG\_CROP;

13	unsigned int r, g, b;

14

15	d = dst->data[0];

16	y1\_ptr = src->data[0];

17	cb\_ptr = src->data[1];

18	cr\_ptr = src->data[2];

19	width2 = (width + 1) >> 1;

20

21	for (; height >= 2; height -= 2)

22	{

23	d1 = d;

24	d2 = d + dst->linesize[0];

25	y2\_ptr = y1\_ptr + src->linesize[0];

26	for (w = width; w >= 2; w -= 2)

27	{

28	YUV\_TO\_RGB1\_CCIR(cb\_ptr[0], cr\_ptr[0]);

29

30	YUV\_TO\_RGB2\_CCIR(r, g, b, y1\_ptr[0]);	/\* output 4 pixels \*/

31	RGB\_OUT(d1, r, g, b);

32

33	YUV\_TO\_RGB2\_CCIR(r, g, b, y1\_ptr[1]);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

34	RGB\_OUT(d1 + BPP, r, g, b);

35

36	YUV\_TO\_RGB2\_CCIR(r, g, b, y2\_ptr[0]);

37	RGB\_OUT(d2, r, g, b);

38

39	YUV\_TO\_RGB2\_CCIR(r, g, b, y2\_ptr[1]);

40	RGB\_OUT(d2 + BPP, r, g, b);

41

42	d1 += 2 \* BPP;

43	d2 += 2 \* BPP;

44

45	y1\_ptr += 2;

46	y2\_ptr += 2;

47	cb\_ptr++;

48	cr\_ptr++;

49	}

50

51	if (w)	/\* handle odd width \*/

52	{

53	YUV\_TO\_RGB1\_CCIR(cb\_ptr[0], cr\_ptr[0]);

54	YUV\_TO\_RGB2\_CCIR(r, g, b, y1\_ptr[0]);

55	RGB\_OUT(d1, r, g, b);

56

57	YUV\_TO\_RGB2\_CCIR(r, g, b, y2\_ptr[0]);

58	RGB\_OUT(d2, r, g, b);

59	d1 += BPP;

60	d2 += BPP;

61	y1\_ptr++;

62	y2\_ptr++;

63	cb\_ptr++;

64	cr\_ptr++;

65	}

66	d += 2 \* dst->linesize[0];

67	y1\_ptr += 2 \* src->linesize[0] - width;

68	cb\_ptr += src->linesize[1] - width2;

69	cr\_ptr += src->linesize[2] - width2;

70	}

71

72	if (height)	/\* handle odd height \*/

73	{

74	d1 = d;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

75	for (w = width; w >= 2; w -= 2)

76	{

77	YUV\_TO\_RGB1\_CCIR(cb\_ptr[0], cr\_ptr[0]);

78

79	YUV\_TO\_RGB2\_CCIR(r, g, b, y1\_ptr[0]);	/\* output 2 pixels \*/

80	RGB\_OUT(d1, r, g, b);

81

82	YUV\_TO\_RGB2\_CCIR(r, g, b, y1\_ptr[1]);

83	RGB\_OUT(d1 + BPP, r, g, b);

84

85	d1 += 2 \* BPP;

86

87	y1\_ptr += 2;

88	cb\_ptr++;

89	cr\_ptr++;

90	}

91

92	if (w)	/\* handle width \*/

93	{

94	YUV\_TO\_RGB1\_CCIR(cb\_ptr[0], cr\_ptr[0]);

95

96	YUV\_TO\_RGB2\_CCIR(r, g, b, y1\_ptr[0]);	/\* output 2 pixels \*/

97	RGB\_OUT(d1, r, g, b);

98	d1 += BPP;

99

100	y1\_ptr++;

101	cb\_ptr++;

102	cr\_ptr++;

103	}

104	}

105 }

106

107 static void glue(yuvj420p\_to\_, RGB\_NAME)(AVPicture \*dst, const AVPicture \*src, int width, int height)

108 {

109	const uint8\_t \*y1\_ptr,	\*y2\_ptr,	\*cb\_ptr,	\*cr\_ptr;

110	uint8\_t \*d,	\*d1,	\*d2;

111	int w, y, cb, cr, r\_add, g\_add, b\_add, width2;

112	uint8\_t \*cm = cropTbl + MAX\_NEG\_CROP;

113	unsigned int r, g, b;

114

115	d = dst->data[0];![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

116	y1\_ptr = src->data[0];

117	cb\_ptr = src->data[1];

118	cr\_ptr = src->data[2];

119	width2 = (width + 1) >> 1;

120

121	for (; height >= 2; height -= 2)

122	{

123	d1 = d;

124	d2 = d + dst->linesize[0];

125	y2\_ptr = y1\_ptr + src->linesize[0];

126	for (w = width; w >= 2; w -= 2)

127	{

128	YUV\_TO\_RGB1(cb\_ptr[0], cr\_ptr[0]);

129

130	YUV\_TO\_RGB2(r, g, b, y1\_ptr[0]);	/\* output 4 pixels \*/

131	RGB\_OUT(d1, r, g, b);

132

133	YUV\_TO\_RGB2(r, g, b, y1\_ptr[1]);

134	RGB\_OUT(d1 + BPP, r, g, b);

135

136	YUV\_TO\_RGB2(r, g, b, y2\_ptr[0]);

137	RGB\_OUT(d2, r, g, b);

138

139	YUV\_TO\_RGB2(r, g, b, y2\_ptr[1]);

140	RGB\_OUT(d2 + BPP, r, g, b);

141

142	d1 += 2 \* BPP;

143	d2 += 2 \* BPP;

144

145	y1\_ptr += 2;

146	y2\_ptr += 2;

147	cb\_ptr++;

148	cr\_ptr++;

149	}

150

151	if (w)	/\* handle odd width \*/

152	{

153	YUV\_TO\_RGB1(cb\_ptr[0], cr\_ptr[0]);

154	YUV\_TO\_RGB2(r, g, b, y1\_ptr[0]);

155	RGB\_OUT(d1, r, g, b);

156![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

157	YUV\_TO\_RGB2(r, g, b, y2\_ptr[0]);

158	RGB\_OUT(d2, r, g, b);

159	d1 += BPP;

160	d2 += BPP;

161	y1\_ptr++;

162	y2\_ptr++;

163	cb\_ptr++;

164	cr\_ptr++;

165	}

166	d += 2 \* dst->linesize[0];

167	y1\_ptr += 2 \* src->linesize[0] - width;

168	cb\_ptr += src->linesize[1] - width2;

169	cr\_ptr += src->linesize[2] - width2;

170	}

171

172	if (height)	/\* handle odd height \*/

173	{

174	d1 = d;

175	for (w = width; w >= 2; w -= 2)

176	{

177	YUV\_TO\_RGB1(cb\_ptr[0], cr\_ptr[0]);

178

179	YUV\_TO\_RGB2(r, g, b, y1\_ptr[0]);	/\* output 2 pixels \*/

180	RGB\_OUT(d1, r, g, b);

181

182	YUV\_TO\_RGB2(r, g, b, y1\_ptr[1]);

183	RGB\_OUT(d1 + BPP, r, g, b);

184

185	d1 += 2 \* BPP;

186

187	y1\_ptr += 2;

188	cb\_ptr++;

189	cr\_ptr++;

190	}

191

192	if (w)	/\* handle width \*/

193	{

194	YUV\_TO\_RGB1(cb\_ptr[0], cr\_ptr[0]);

195

196	YUV\_TO\_RGB2(r, g, b, y1\_ptr[0]);	/\* output 2 pixels \*/

197	RGB\_OUT(d1, r, g, b);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

198	d1 += BPP;

199

200	y1\_ptr++;

201	cb\_ptr++;

202	cr\_ptr++;

203	}

204	}

205 }

206

207 static void glue(RGB\_NAME, \_to\_yuv420p)(AVPicture \*dst, const AVPicture \*src, int width, int height)

208 {

209	int wrap, wrap3, width2;

210	int r, g, b, r1, g1, b1, w;

211	uint8\_t \*lum,	\*cb,	\*cr;

212	const uint8\_t \*p;

213

214	lum = dst->data[0];

215	cb = dst->data[1];

216	cr = dst->data[2];

217

218	width2 = (width + 1) >> 1;

219	wrap = dst->linesize[0];

220	wrap3 = src->linesize[0];

221	p = src->data[0];

222	for (; height >= 2; height -= 2)

223	{

224	for (w = width; w >= 2; w -= 2)

225	{

226	RGB\_IN(r, g, b, p);

227	r1 = r;

228	g1 = g;

229	b1 = b;

230	lum[0] = RGB\_TO\_Y\_CCIR(r, g, b);

231

232	RGB\_IN(r, g, b, p + BPP);

233	r1 += r;

234	g1 += g;

235	b1 += b;

236	lum[1] = RGB\_TO\_Y\_CCIR(r, g, b);

237	p += wrap3;

238	lum += wrap;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

239

240	RGB\_IN(r, g, b, p);

241	r1 += r;

242	g1 += g;

243	b1 += b;

244	lum[0] = RGB\_TO\_Y\_CCIR(r, g, b);

245

246	RGB\_IN(r, g, b, p + BPP);

247	r1 += r;

248	g1 += g;

249	b1 += b;

250	lum[1] = RGB\_TO\_Y\_CCIR(r, g, b);

251

252	cb[0] = RGB\_TO\_U\_CCIR(r1, g1, b1, 2);

253	cr[0] = RGB\_TO\_V\_CCIR(r1, g1, b1, 2);

254

255	cb++;

256	cr++;

257	p +=	- wrap3 + 2 \* BPP;

258	lum +=	- wrap + 2;

259	}

260	if (w)

261	{

262	RGB\_IN(r, g, b, p);

263	r1 = r;

264	g1 = g;

265	b1 = b;

266	lum[0] = RGB\_TO\_Y\_CCIR(r, g, b);

267	p += wrap3;

268	lum += wrap;

269	RGB\_IN(r, g, b, p);

270	r1 += r;

271	g1 += g;

272	b1 += b;

273	lum[0] = RGB\_TO\_Y\_CCIR(r, g, b);

274	cb[0] = RGB\_TO\_U\_CCIR(r1, g1, b1, 1);

275	cr[0] = RGB\_TO\_V\_CCIR(r1, g1, b1, 1);

276	cb++;

277	cr++;

278	p +=	- wrap3 + BPP;

279	lum +=	- wrap + 1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

280	}

281	p += wrap3 + (wrap3 - width \* BPP);

282	lum += wrap + (wrap - width);

283	cb += dst->linesize[1] - width2;

284	cr += dst->linesize[2] - width2;

285	}

286

287	if (height)	/\* handle odd height \*/

288	{

289	for (w = width; w >= 2; w -= 2)

290	{

291	RGB\_IN(r, g, b, p);

292	r1 = r;

293	g1 = g;

294	b1 = b;

295	lum[0] = RGB\_TO\_Y\_CCIR(r, g, b);

296

297	RGB\_IN(r, g, b, p + BPP);

298	r1 += r;

299	g1 += g;

300	b1 += b;

301	lum[1] = RGB\_TO\_Y\_CCIR(r, g, b);

302	cb[0] = RGB\_TO\_U\_CCIR(r1, g1, b1, 1);

303	cr[0] = RGB\_TO\_V\_CCIR(r1, g1, b1, 1);

304	cb++;

305	cr++;

306	p += 2 \* BPP;

307	lum += 2;

308	}

309	if (w)

310	{

311	RGB\_IN(r, g, b, p);

312	lum[0] = RGB\_TO\_Y\_CCIR(r, g, b);

313	cb[0] = RGB\_TO\_U\_CCIR(r, g, b, 0);

314	cr[0] = RGB\_TO\_V\_CCIR(r, g, b, 0);

315	}

316	}

317 }

318

319 static void glue(RGB\_NAME, \_to\_gray)(AVPicture \*dst, const AVPicture \*src, int width, int height)

320 {![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

321	const unsigned char \*p;

322	unsigned char \*q;

323	int r, g, b, dst\_wrap, src\_wrap;

324	int x, y;

325

326	p = src->data[0];

327	src\_wrap = src->linesize[0] - BPP \* width;

328

329	q = dst->data[0];

330	dst\_wrap = dst->linesize[0] - width;

331

332	for (y = 0; y < height; y++)

333	{

334	for (x = 0; x < width; x++)

335	{

336	RGB\_IN(r, g, b, p);

337	q[0] = RGB\_TO\_Y(r, g, b);

338	q++;

339	p += BPP;

340	}

341	p += src\_wrap;

342	q += dst\_wrap;

343	}

344 }

345

346 static void glue(gray\_to\_, RGB\_NAME)(AVPicture \*dst, const AVPicture \*src, int width, int height)

347 {

348	const unsigned char \*p;

349	unsigned char \*q;

350	int r, dst\_wrap, src\_wrap;

351	int x, y;

352

353	p = src->data[0];

354	src\_wrap = src->linesize[0] - width;

355

356	q = dst->data[0];

357	dst\_wrap = dst->linesize[0] - BPP \* width;

358

359	for (y = 0; y < height; y++)

360	{

361	for (x = 0; x < width; x++)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

362	{

363	r = p[0];

364	RGB\_OUT(q, r, r, r);

365	q += BPP;

366	p++;

367	}

368	p += src\_wrap;

369	q += dst\_wrap;

370	}

371 }

372

373 static void glue(pal8\_to\_, RGB\_NAME)(AVPicture \*dst, const AVPicture \*src, int width, int height)

374 {

375	const unsigned char \*p;

376	unsigned char \*q;

377	int r, g, b, dst\_wrap, src\_wrap;

378	int x, y;

379	uint32\_t v;

380	const uint32\_t \*palette;

381

382	p = src->data[0];

383	src\_wrap = src->linesize[0] - width;

384	palette = (uint32\_t\*)src->data[1];

385

386	q = dst->data[0];

387	dst\_wrap = dst->linesize[0] - BPP \* width;

388

389	for (y = 0; y < height; y++)

390	{

391	for (x = 0; x < width; x++)

392	{

393	v = palette[p[0]];

394	r = (v >> 16) &0xff;

395	g = (v >> 8) &0xff;

396	b = (v) &0xff;

397 #ifdef RGBA\_OUT

398	{

399	int a;

400	a = (v >> 24) &0xff;

401	RGBA\_OUT(q, r, g, b, a);

402	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

403 #else

404	RGB\_OUT(q, r, g, b);

405 #endif

406	q += BPP;

407	p++;

408	}

409	p += src\_wrap;

410	q += dst\_wrap;

411	}

412 }

413

414 #if !defined(FMT\_RGBA32) && defined(RGBA\_OUT)

415 /\* alpha support \*/

416

417 static void glue(rgba32\_to\_, RGB\_NAME)(AVPicture \*dst, const AVPicture \*src, int width, int height)

418 {

419	const uint8\_t \*s;

420	uint8\_t \*d;

421	int src\_wrap, dst\_wrap, j, y;

422	unsigned int v, r, g, b, a;

423

424	s = src->data[0];

425	src\_wrap = src->linesize[0] - width \* 4;

426

427	d = dst->data[0];

428	dst\_wrap = dst->linesize[0] - width \* BPP;

429

430	for (y = 0; y < height; y++)

431	{

432	for (j = 0; j < width; j++)

433	{

434	v = ((const uint32\_t\*)(s))[0];

435	a = (v >> 24) &0xff;

436	r = (v >> 16) &0xff;

437	g = (v >> 8) &0xff;

438	b = v &0xff;

439	RGBA\_OUT(d, r, g, b, a);

440	s += 4;

441	d += BPP;

442	}

443	s += src\_wrap;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

444	d += dst\_wrap;

445	}

446 }

447

448 static void glue(RGB\_NAME, \_to\_rgba32)(AVPicture \*dst, const AVPicture \*src, int width, int height)

449 {

450	const uint8\_t \*s;

451	uint8\_t \*d;

452	int src\_wrap, dst\_wrap, j, y;

453	unsigned int r, g, b, a;

454

455	s = src->data[0];

456	src\_wrap = src->linesize[0] - width \* BPP;

457

458	d = dst->data[0];

459	dst\_wrap = dst->linesize[0] - width \* 4;

460

461	for (y = 0; y < height; y++)

462	{

463	for (j = 0; j < width; j++)

464	{

465	RGBA\_IN(r, g, b, a, s);

466	((uint32\_t\*)(d))[0] = (a << 24) | (r << 16) | (g << 8) | b;

467	d += 4;

468	s += BPP;

469	}

470	s += src\_wrap;

471	d += dst\_wrap;

472	}

473 }

474

475 #endif /\* !defined(FMT\_RGBA32) && defined(RGBA\_IN) \*/

476

477 #ifndef FMT\_RGB24

478

479 static void glue(rgb24\_to\_, RGB\_NAME)(AVPicture \*dst, const AVPicture \*src, int width, int height)

480 {

481	const uint8\_t \*s;

482	uint8\_t \*d;

483	int src\_wrap, dst\_wrap, j, y;

484	unsigned int r, g, b;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

485

486	s = src->data[0];

487	src\_wrap = src->linesize[0] - width \* 3;

488

489	d = dst->data[0];

490	dst\_wrap = dst->linesize[0] - width \* BPP;

491

492	for (y = 0; y < height; y++)

493	{

494	for (j = 0; j < width; j++)

495	{

496	r = s[0];

497	g = s[1];

498	b = s[2];

499	RGB\_OUT(d, r, g, b);

500	s += 3;

501	d += BPP;

502	}

503	s += src\_wrap;

504	d += dst\_wrap;

505	}

506 }

507

508 static void glue(RGB\_NAME, \_to\_rgb24)(AVPicture \*dst, const AVPicture \*src, int width, int height)

509 {

510	const uint8\_t \*s;

511	uint8\_t \*d;

512	int src\_wrap, dst\_wrap, j, y;

513	unsigned int r, g, b;

514

515	s = src->data[0];

516	src\_wrap = src->linesize[0] - width \* BPP;

517

518	d = dst->data[0];

519	dst\_wrap = dst->linesize[0] - width \* 3;

520

521	for (y = 0; y < height; y++)

522	{

523	for (j = 0; j < width; j++)

524	{

525	RGB\_IN(r, g, b, s)d[0] = r;


|526||d[1]|= g;|
| - | - | - | - |
|527||d[2]|= b;|
|528||d +=|3;|
|529||s +=|BPP;|
|530|}|||
531	s += src\_wrap;

532	d += dst\_wrap;

533	}

534 }

535

536 #endif /\* !FMT\_RGB24 \*/

537

538 #ifdef FMT\_RGB24

539

540 static void yuv444p\_to\_rgb24(AVPicture \*dst, const AVPicture \*src, int width, int height)

541 {

542	const uint8\_t \*y1\_ptr,	\*cb\_ptr,	\*cr\_ptr;

543	uint8\_t \*d,	\*d1;

544	int w, y, cb, cr, r\_add, g\_add, b\_add;

545	uint8\_t \*cm = cropTbl + MAX\_NEG\_CROP;

546	unsigned int r, g, b;

547

548	d = dst->data[0];

549	y1\_ptr = src->data[0];

550	cb\_ptr = src->data[1];

551	cr\_ptr = src->data[2];

552	for (; height > 0; height--)

553	{

554	d1 = d;

555	for (w = width; w > 0; w--)

556	{

557	YUV\_TO\_RGB1\_CCIR(cb\_ptr[0], cr\_ptr[0]);

558

559	YUV\_TO\_RGB2\_CCIR(r, g, b, y1\_ptr[0]);

560	RGB\_OUT(d1, r, g, b);

561	d1 += BPP;

562

563	y1\_ptr++;

564	cb\_ptr++;

565	cr\_ptr++;

566	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

567	d += dst->linesize[0];

568	y1\_ptr += src->linesize[0] - width;

569	cb\_ptr += src->linesize[1] - width;

570	cr\_ptr += src->linesize[2] - width;

571	}

572 }

573

574 static void yuvj444p\_to\_rgb24(AVPicture \*dst, const AVPicture \*src, int width, int height)

575 {

576	const uint8\_t \*y1\_ptr,	\*cb\_ptr,	\*cr\_ptr;

577	uint8\_t \*d,	\*d1;

578	int w, y, cb, cr, r\_add, g\_add, b\_add;

579	uint8\_t \*cm = cropTbl + MAX\_NEG\_CROP;

580	unsigned int r, g, b;

581

582	d = dst->data[0];

583	y1\_ptr = src->data[0];

584	cb\_ptr = src->data[1];

585	cr\_ptr = src->data[2];

586	for (; height > 0; height--)

587	{

588	d1 = d;

589	for (w = width; w > 0; w--)

590	{

591	YUV\_TO\_RGB1(cb\_ptr[0], cr\_ptr[0]);

592

593	YUV\_TO\_RGB2(r, g, b, y1\_ptr[0]);

594	RGB\_OUT(d1, r, g, b);

595	d1 += BPP;

596

597	y1\_ptr++;

598	cb\_ptr++;

599	cr\_ptr++;

600	}

601	d += dst->linesize[0];

602	y1\_ptr += src->linesize[0] - width;

603	cb\_ptr += src->linesize[1] - width;

604	cr\_ptr += src->linesize[2] - width;

605	}

606 }

607![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

608 static void rgb24\_to\_yuv444p(AVPicture \*dst, const AVPicture \*src, int width, int height)

609 {

610	int src\_wrap, x, y;

611	int r, g, b;

612	uint8\_t \*lum,	\*cb,	\*cr;

613	const uint8\_t \*p;

614

615	lum = dst->data[0];

616	cb = dst->data[1];

617	cr = dst->data[2];

618

619	src\_wrap = src->linesize[0] - width \* BPP;

620	p = src->data[0];

621

622	for (y = 0; y < height; y++)

623	{

624	for (x = 0; x < width; x++)

625	{

626	RGB\_IN(r, g, b, p);

627	lum[0] = RGB\_TO\_Y\_CCIR(r, g, b);

628	cb[0] = RGB\_TO\_U\_CCIR(r, g, b, 0);

629	cr[0] = RGB\_TO\_V\_CCIR(r, g, b, 0);

630	p += BPP;

631	cb++;

632	cr++;

633	lum++;

634	}

635	p += src\_wrap;

636	lum += dst->linesize[0] - width;

637	cb += dst->linesize[1] - width;

638	cr += dst->linesize[2] - width;

639	}

640 }

641

642 static void rgb24\_to\_yuvj420p(AVPicture \*dst, const AVPicture \*src, int width, int height)

643 {

644	int wrap, wrap3, width2;

645	int r, g, b, r1, g1, b1, w;

646	uint8\_t \*lum,	\*cb,	\*cr;

647	const uint8\_t \*p;

648![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

649	lum = dst->data[0];

650	cb = dst->data[1];

651	cr = dst->data[2];

652

653	width2 = (width + 1) >> 1;

654	wrap = dst->linesize[0];

655	wrap3 = src->linesize[0];

656	p = src->data[0];

657	for (; height >= 2; height -= 2)

658	{

659	for (w = width; w >= 2; w -= 2)

660	{

661	RGB\_IN(r, g, b, p);

662	r1 = r;

663	g1 = g;

664	b1 = b;

665	lum[0] = RGB\_TO\_Y(r, g, b);

666

667	RGB\_IN(r, g, b, p + BPP);

668	r1 += r;

669	g1 += g;

670	b1 += b;

671	lum[1] = RGB\_TO\_Y(r, g, b);

672	p += wrap3;

673	lum += wrap;

674

675	RGB\_IN(r, g, b, p);

676	r1 += r;

677	g1 += g;

678	b1 += b;

679	lum[0] = RGB\_TO\_Y(r, g, b);

680

681	RGB\_IN(r, g, b, p + BPP);

682	r1 += r;

683	g1 += g;

684	b1 += b;

685	lum[1] = RGB\_TO\_Y(r, g, b);

686

687	cb[0] = RGB\_TO\_U(r1, g1, b1, 2);

688	cr[0] = RGB\_TO\_V(r1, g1, b1, 2);

689


|690||cb++;|
| - | - | - |
|691||cr++;|
|692||p +=	- wrap3 + 2 \* BPP;|
|693||lum +=	- wrap + 2;|
|694|}||
695	if (w)

696	{

697	RGB\_IN(r, g, b, p);

698	r1 = r;

699	g1 = g;

700	b1 = b;

701	lum[0] = RGB\_TO\_Y(r, g, b);

702	p += wrap3;

703	lum += wrap;

704	RGB\_IN(r, g, b, p);

705	r1 += r;

706	g1 += g;

707	b1 += b;

708	lum[0] = RGB\_TO\_Y(r, g, b);

709	cb[0] = RGB\_TO\_U(r1, g1, b1, 1);

710	cr[0] = RGB\_TO\_V(r1, g1, b1, 1);

711	cb++;

712	cr++;

713	p +=	- wrap3 + BPP;

714	lum +=	- wrap + 1;

715	}

716	p += wrap3 + (wrap3 - width \* BPP);

717	lum += wrap + (wrap - width);

718	cb += dst->linesize[1] - width2;

719	cr += dst->linesize[2] - width2;

720	}

721

722	if (height)	/\* handle odd height \*/

723	{

724	for (w = width; w >= 2; w -= 2)

725	{

726	RGB\_IN(r, g, b, p);

727	r1 = r;

728	g1 = g;

729	b1 = b;

730	lum[0] = RGB\_TO\_Y(r, g, b);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

731

732	RGB\_IN(r, g, b, p + BPP);

733	r1 += r;

734	g1 += g;

735	b1 += b;

736	lum[1] = RGB\_TO\_Y(r, g, b);

737	cb[0] = RGB\_TO\_U(r1, g1, b1, 1);

738	cr[0] = RGB\_TO\_V(r1, g1, b1, 1);

739	cb++;

740	cr++;

741	p += 2 \* BPP;

742	lum += 2;

743	}

744	if (w)

745	{

746	RGB\_IN(r, g, b, p);

747	lum[0] = RGB\_TO\_Y(r, g, b);

748	cb[0] = RGB\_TO\_U(r, g, b, 0);

749	cr[0] = RGB\_TO\_V(r, g, b, 0);

750	}

751	}

752 }

753

754 static void rgb24\_to\_yuvj444p(AVPicture \*dst, const AVPicture \*src, int width, int height)

755 {

756	int src\_wrap, x, y;

757	int r, g, b;

758	uint8\_t \*lum,	\*cb,	\*cr;

759	const uint8\_t \*p;

760

761	lum = dst->data[0];

762	cb = dst->data[1];

763	cr = dst->data[2];

764

765	src\_wrap = src->linesize[0] - width \* BPP;

766	p = src->data[0];

767	for (y = 0; y < height; y++)

768	{

769	for (x = 0; x < width; x++)

770	{

771	RGB\_IN(r, g, b, p);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

772	lum[0] = RGB\_TO\_Y(r, g, b);

773	cb[0] = RGB\_TO\_U(r, g, b, 0);

774	cr[0] = RGB\_TO\_V(r, g, b, 0);

775	p += BPP;

776	cb++;

777	cr++;

778	lum++;

779	}

780	p += src\_wrap;

781	lum += dst->linesize[0] - width;

782	cb += dst->linesize[1] - width;

783	cr += dst->linesize[2] - width;

784	}

785 }

786

787 #endif /\* FMT\_RGB24 \*/

788

789 #if defined(FMT\_RGB24) || defined(FMT\_RGBA32)

790

791 static void glue(RGB\_NAME, \_to\_pal8)(AVPicture \*dst, const AVPicture \*src, int width, int height)

792 {

793	const unsigned char \*p;

794	unsigned char \*q;

795	int dst\_wrap, src\_wrap;

796	int x, y, has\_alpha;

797	unsigned int r, g, b;

798

799	p = src->data[0];

800	src\_wrap = src->linesize[0] - BPP \* width;

801

802	q = dst->data[0];

803	dst\_wrap = dst->linesize[0] - width;

804	has\_alpha = 0;

805

806	for (y = 0; y < height; y++)

807	{

808	for (x = 0; x < width; x++)

809	{

810 #ifdef RGBA\_IN

811	{

812	unsigned int a;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

813	RGBA\_IN(r, g, b, a, p);

814

815	if (a < 0x80)	/\* crude approximation for alpha ! \*/

816	{

817	has\_alpha = 1;

818	q[0] = TRANSP\_INDEX;

819	}

820	else

821	{

822	q[0] = gif\_clut\_index(r, g, b);

823	}

824	}

825 #else

826	RGB\_IN(r, g, b, p);

827	q[0] = gif\_clut\_index(r, g, b);

828 #endif

829	q++;

830	p += BPP;

831	}

832	p += src\_wrap;

833	q += dst\_wrap;

834	}

835

836	build\_rgb\_palette(dst->data[1], has\_alpha);

837 }

838

839 #endif /\* defined(FMT\_RGB24) || defined(FMT\_RGBA32) \*/

840

841 #ifdef RGBA\_IN

842

843 #define FF\_ALPHA\_TRANSP	0x0001 /\* image has some totally transparent pixels \*/

844 #define FF\_ALPHA\_SEMI\_TRANSP	0x0002 /\* image has some transparent pixels \*/

845

846 static int glue(get\_alpha\_info\_, RGB\_NAME)(const AVPicture \*src, int width, int height)

847 {

848	const unsigned char \*p;

849	int src\_wrap, ret, x, y;

850	unsigned int r, g, b, a;

851

852	p = src->data[0];

853	src\_wrap = src->linesize[0] - BPP \* width;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

854	ret = 0;

855	for (y = 0; y < height; y++)

856	{

857	for (x = 0; x < width; x++)

858	{

859	RGBA\_IN(r, g, b, a, p);

860	if (a == 0x00)

861	{

862	ret |= FF\_ALPHA\_TRANSP;

863	}

864	else if (a != 0xff)

865	{

866	ret |= FF\_ALPHA\_SEMI\_TRANSP;

867	}

868	p += BPP;

869	}

870	p += src\_wrap;

871	}

872	return ret;

873 }

874

875 #endif /\* RGBA\_IN \*/

876

877 #undef RGB\_IN

878 #undef RGBA\_IN

879 #undef RGB\_OUT

880 #undef RGBA\_OUT

881 #undef BPP

882 #undef RGB\_NAME

883 #undef FMT\_RGB24

884 #undef FMT\_RGBA32![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **8 imgconvert.c 文件**
8.1 功能描述

定义并实现图像颜色空间转换使用的函数和宏，此文件大部分请各位自己仔细分析。

8.2 文件注释

1	#include "avcodec.h"

2	#include "dsputil.h"

3

4	#define xglue(x, y) x ## y

5	#define glue(x, y) xglue(x, y)

6

7	#define FF\_COLOR\_RGB	0 // RGB color space

8	#define FF\_COLOR\_GRAY	1 // gray color space

9	#define FF\_COLOR\_YUV	2 // YUV color space. 16 <= Y <= 235, 16 <= U, V <= 240

10	#define FF\_COLOR\_YUV\_JPEG 3 // YUV color space. 0 <= Y <= 255, 0 <= U, V <= 255

11

12	#define FF\_PIXEL\_PLANAR	0 // each channel has one component in AVPicture

13	#define FF\_PIXEL\_PACKED	1 // only one components containing all the channels

14	#define FF\_PIXEL\_PALETTE	2 // one components containing indexes for a palette

15![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.059.png)

定义视频图像格式信息类型。

16	typedef struct PixFmtInfo

17	{

18	const char \*name;

19	uint8\_t nb\_channels; // number of channels (including alpha)

20	uint8\_t color\_type; // color type (see FF\_COLOR\_xxx constants)

21	uint8\_t pixel\_type; // pixel storage type (see FF\_PIXEL\_xxx constants)

22	uint8\_t is\_alpha; // true if alpha can be specified

23	uint8\_t x\_chroma\_shift; // X chroma subsampling factor is 2 ^ shift

24	uint8\_t y\_chroma\_shift; // Y chroma subsampling factor is 2 ^ shift

25	uint8\_t depth; // bit depth of the color components

26	} PixFmtInfo;

27![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.059.png)

定义支持的视频图像格式信息。

28	// this table gives more information about formats

29	static PixFmtInfo pix\_fmt\_info[PIX\_FMT\_NB] =

30	{

31	{ "yuv420p",	3, FF\_COLOR\_YUV, FF\_PIXEL\_PLANAR, 0, 1, 1, 8},![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

32	{ "yuv422",	1, FF\_COLOR\_YUV,

33	{ "rgb24",	3, FF\_COLOR\_RGB,

34	{ "bgr24",	3, FF\_COLOR\_RGB,

35	{ "yuv422p",	3, FF\_COLOR\_YUV,

36	{ "yuv444p",	3, FF\_COLOR\_YUV,

37	{ "rgba32",	4, FF\_COLOR\_RGB,

38	{ "yuv410p",	3, FF\_COLOR\_YUV,

39	{ "yuv411p",	3, FF\_COLOR\_YUV,

40	{ "rgb565",	3, FF\_COLOR\_RGB,

41	{ "rgb555",	4, FF\_COLOR\_RGB,

FF\_PIXEL\_PACKED, 0, 1, 0, 8}, FF\_PIXEL\_PACKED, 0, 0, 0, 8}, FF\_PIXEL\_PACKED, 0, 0, 0, 8}, FF\_PIXEL\_PLANAR, 0, 1, 0, 8}, FF\_PIXEL\_PLANAR, 0, 0, 0, 8}, FF\_PIXEL\_PACKED, 1, 0, 0, 8}, FF\_PIXEL\_PLANAR, 0, 2, 2, 8}, FF\_PIXEL\_PLANAR, 0, 2, 0, 8}, FF\_PIXEL\_PACKED, 0, 0, 0, 5}, FF\_PIXEL\_PACKED, 1, 0, 0, 5},

568
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.060.png)

42	{ "gray",	1, FF\_COLOR\_GRAY, FF\_PIXEL\_PLANAR, 0, 0, 0, 8},

43	{ "monow",	1, FF\_COLOR\_GRAY, FF\_PIXEL\_PLANAR, 0, 0, 0, 1},

44	{ "monob",	1, FF\_COLOR\_GRAY, FF\_PIXEL\_PLANAR, 0, 0, 0, 1},

45	{ "pal8",	4, FF\_COLOR\_RGB, FF\_PIXEL\_PALETTE, 1, 0, 0, 8},

46	{ "yuvj420p", 3, FF\_COLOR\_YUV\_JPEG, FF\_PIXEL\_PLANAR, 0, 1, 1, 8},

47	{ "yuvj422p", 3, FF\_COLOR\_YUV\_JPEG, FF\_PIXEL\_PLANAR, 0, 1, 0, 8},

48	{ "yuvj444p", 3, FF\_COLOR\_YUV\_JPEG, FF\_PIXEL\_PLANAR, 0, 0, 0, 8},

49	{ "xvmcmc",	},

50	{ "xvmcidct",},

51	{ "uyvy422",	1, FF\_COLOR\_YUV, FF\_PIXEL\_PACKED, 0, 1, 0, 8},

52	{ "uyvy411",	1, FF\_COLOR\_YUV, FF\_PIXEL\_PACKED, 0, 2, 0, 8},

53	};

54![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

读取视频图像格式信息中色度相对亮度采样比例(用移位的位数表示)。

55	void avcodec\_get\_chroma\_sub\_sample(int pix\_fmt, int \*h\_shift, int \*v\_shift)

56	{

57	\*h\_shift = pix\_fmt\_info[pix\_fmt].x\_chroma\_shift;

58	\*v\_shift = pix\_fmt\_info[pix\_fmt].y\_chroma\_shift;

59	}

60![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

填充各种视频图像格式对应的 AVPicture 结构字段，返回图像大小。

61	// Picture field are filled with 'ptr' addresses. Also return size

62	int avpicture\_fill(AVPicture \*picture, uint8\_t \*ptr, int pix\_fmt, int width, int height)

63	{

64	int size, w2, h2, size2;

65	PixFmtInfo \*pinfo;

66![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.061.png)

图像像素大小规整，比如 YUV420P 宽度和高度必须是 2 的整数倍，如果不符合，程序自动填充补足。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)67	if (avcodec\_check\_dimensions(NULL, width, height))

68	goto fail;

69

70	pinfo = &pix\_fmt\_info[pix\_fmt];

71	size = width \* height;

72	switch (pix\_fmt)

73	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

按照图像格式，分别计算 AVPicture 结构字段的值。

74	case PIX\_FMT\_YUV420P:

75	case PIX\_FMT\_YUV422P:

76	case PIX\_FMT\_YUV444P:

77	case PIX\_FMT\_YUV410P:

78	case PIX\_FMT\_YUV411P:

79	case PIX\_FMT\_YUVJ420P:

80	case PIX\_FMT\_YUVJ422P:

81	case PIX\_FMT\_YUVJ444P:

82	w2 = (width + (1 << pinfo->x\_chroma\_shift) - 1) >> pinfo->x\_chroma\_shift;

83	h2 = (height + (1 << pinfo->y\_chroma\_shift) - 1) >> pinfo->y\_chroma\_shift;

84	size2 = w2 \* h2;

85	picture->data[0] = ptr;

86	picture->data[1] = picture->data[0] + size;

87	picture->data[2] = picture->data[1] + size2;

88	picture->linesize[0] = width;

89	picture->linesize[1] = w2;

90	picture->linesize[2] = w2;

91	return size + 2 \* size2;

92	case PIX\_FMT\_RGB24:

93	case PIX\_FMT\_BGR24:

94	picture->data[0] = ptr;

95	picture->data[1] = NULL;

96	picture->data[2] = NULL;

97	picture->linesize[0] = width \* 3;

98	return size \*3;

99	case PIX\_FMT\_RGBA32:

100	picture->data[0] = ptr;

101	picture->data[1] = NULL;

102	picture->data[2] = NULL;

103	picture->linesize[0] = width \* 4;

104	return size \*4;

105	case PIX\_FMT\_RGB555:

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)106	case PIX\_FMT\_RGB565:

107	case PIX\_FMT\_YUV422:

108	picture->data[0] = ptr;

109	picture->data[1] = NULL;

110	picture->data[2] = NULL;

111	picture->linesize[0] = width \* 2;

112	return size \*2;

113	case PIX\_FMT\_UYVY422:

114	picture->data[0] = ptr;

115	picture->data[1] = NULL;

116	picture->data[2] = NULL;

117	picture->linesize[0] = width \* 2;

118	return size \*2;

119	case PIX\_FMT\_UYVY411:

120	picture->data[0] = ptr;

121	picture->data[1] = NULL;

122	picture->data[2] = NULL;

123	picture->linesize[0] = width + width / 2;

124	return size + size / 2;

125	case PIX\_FMT\_GRAY8:

126	picture->data[0] = ptr;

127	picture->data[1] = NULL;

128	picture->data[2] = NULL;

129	picture->linesize[0] = width;

130	return size;

131	case PIX\_FMT\_MONOWHITE:

132	case PIX\_FMT\_MONOBLACK:

133	picture->data[0] = ptr;

134	picture->data[1] = NULL;

135	picture->data[2] = NULL;

136	picture->linesize[0] = (width + 7) >> 3;

137	return picture->linesize[0] \*height;

138	case PIX\_FMT\_PAL8:

139	size2 = (size + 3) &~3;

140	picture->data[0] = ptr;

141	picture->data[1] = ptr + size2; // palette is stored here as 256 32 bit words

142	picture->data[2] = NULL;

143	picture->linesize[0] = width;

144	picture->linesize[1] = 4;

145	return size2 + 256 \* 4;

146	default:

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)147	fail:

148	picture->data[0] = NULL;

149	picture->data[1] = NULL;

150	picture->data[2] = NULL;

151	picture->data[3] = NULL;

152	return	- 1;

153	}

154	}

155![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

传入像素格式，图像长宽，计算图像大小。程序简单的复用 avpicture\_fill()函数的返回值。

156	int avpicture\_get\_size(int pix\_fmt, int width, int height)

157	{

158	AVPicture dummy\_pict;

159	return avpicture\_fill(&dummy\_pict, NULL, pix\_fmt, width, height);

160	}

161![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.061.png)

初始化 AVPicture 结构。输入像素格式和长宽，计算图像大小，分配图像缓存，填充 AVPicture 结构 。

162	int avpicture\_alloc(AVPicture \*picture, int pix\_fmt, int width, int height)

163	{

164	unsigned int size;

165	void \*ptr;

166![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.061.png)

调用函数计算图像大小。

167	size = avpicture\_get\_size(pix\_fmt, width, height);

168	if (size < 0)

169	goto fail;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.061.png)

调用函数分配图像缓存。

170	ptr = av\_malloc(size);

171	if (!ptr)

172	goto fail;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.061.png)

填充 AVPicture 结构。

173	avpicture\_fill(picture, ptr, pix\_fmt, width, height);

174	return 0;

175	fail:

176	memset(picture, 0, sizeof(AVPicture));

177	return	- 1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

178	}

179![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

释放 AVPicture 分配的内存，因为内存首地址在 picture->data[0]中，所以可以简单的释放。

180	void avpicture\_free(AVPicture \*picture)

181	{

182	av\_free(picture->data[0]);

183	}

184![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

计算各种图像格式平均每个像素占用的 bit 位数。

185	static int avg\_bits\_per\_pixel(int pix\_fmt)

186	{

187	int bits;

188	const PixFmtInfo \*pf;

189

190	pf = &pix\_fmt\_info[pix\_fmt];

191	switch (pf->pixel\_type)

192	{

193	case FF\_PIXEL\_PACKED:

194	switch (pix\_fmt)

195	{

196	case PIX\_FMT\_YUV422:

197	case PIX\_FMT\_UYVY422:

198	case PIX\_FMT\_RGB565:

199	case PIX\_FMT\_RGB555:

200	bits = 16;

201	break;

202	case PIX\_FMT\_UYVY411:

203	bits = 12;

204	break;

205	default:

206	bits = pf->depth \*pf->nb\_channels;

207	break;

208	}

209	break;

210	case FF\_PIXEL\_PLANAR:

211	if (pf->x\_chroma\_shift == 0 && pf->y\_chroma\_shift == 0)

212	{

213	bits = pf->depth \*pf->nb\_channels;

214	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

215	else

216	{

217	bits = pf->depth + ((2 \*pf->depth) >> (pf->x\_chroma\_shift + pf->y\_chroma\_shift));

218	}

219	break;

220	case FF\_PIXEL\_PALETTE:

221	bits = 8;

222	break;

223	default:

224	bits =	- 1;

225	break;

226	}

227	return bits;

228	}

229

230	////////////////////////////

231![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.061.png)

图像数据平面拷贝，由于宽度可能有差别，只能一行一行的拷贝。

232	void ff\_img\_copy\_plane(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

233	{

234	if ((!dst) || (!src))

235	return ;

236	for (; height > 0; height--)

237	{

238	memcpy(dst, src, width);

239	dst += dst\_wrap;

240	src += src\_wrap;

241	}

242	}

243![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.061.png)

各种图像格式的图像数据拷贝。

244	void img\_copy(AVPicture \*dst, const AVPicture \*src, int pix\_fmt, int width, int height)

245	{

246	int bwidth, bits, i;

247	PixFmtInfo \*pf = &pix\_fmt\_info[pix\_fmt];

248

249	pf = &pix\_fmt\_info[pix\_fmt];

250	switch (pf->pixel\_type)

251	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

252	case FF\_PIXEL\_PACKED:

253	switch (pix\_fmt)

254	{

255	case PIX\_FMT\_YUV422:

256	case PIX\_FMT\_UYVY422:

257	case PIX\_FMT\_RGB565:

258	case PIX\_FMT\_RGB555:

259	bits = 16;

260	break;

261	case PIX\_FMT\_UYVY411:

262	bits = 12;

263	break;

264	default:

265	bits = pf->depth \*pf->nb\_channels;

266	break;

267	}

268	bwidth = (width \*bits + 7) >> 3;

269	ff\_img\_copy\_plane(dst->data[0], dst->linesize[0], src->data[0], src->linesize[0], bwidth, height);

270	break;

271	case FF\_PIXEL\_PLANAR:

272	for (i = 0; i < pf->nb\_channels; i++)

273	{

274	int w, h;

275	w = width;

276	h = height;

277	if (i == 1 || i == 2)

278	{

279	w >>= pf->x\_chroma\_shift;

280	h >>= pf->y\_chroma\_shift;

281	}

282	bwidth = (w \*pf->depth + 7) >> 3;

283	ff\_img\_copy\_plane(dst->data[i], dst->linesize[i], src->data[i], src->linesize[i], bwidth, h);

284	}

285	break;

286	case FF\_PIXEL\_PALETTE:

287	ff\_img\_copy\_plane(dst->data[0], dst->linesize[0], src->data[0], src->linesize[0], width, height);

288	// copy the palette

289	ff\_img\_copy\_plane(dst->data[1], dst->linesize[1], src->data[1], src->linesize[1], 4,

256);

290	break;

291	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

292	}

293

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.061.png)本文件的后面部分请各位自行仔细分析。

294	static void yuv422\_to\_yuv420p(AVPicture \*dst, const AVPicture \*src, int width, int height)

295	{

296	const uint8\_t \*p,	\*p1;

297	uint8\_t \*lum,	\*cr,	\*cb,	\*lum1,	\*cr1,	\*cb1;

298	int w;

299

300	p1 = src->data[0];

301	lum1 = dst->data[0];

302	cb1 = dst->data[1];

303	cr1 = dst->data[2];

304

305	for (; height >= 1; height -= 2)

306	{

307	p = p1;

308	lum = lum1;

309	cb = cb1;

310	cr = cr1;

311	for (w = width; w >= 2; w -= 2)

312	{

313	lum[0] = p[0];

314	cb[0] = p[1];

315	lum[1] = p[2];

316	cr[0] = p[3];

317	p += 4;

318	lum += 2;

319	cb++;

320	cr++;

321	}

322	if (w)

323	{

324	lum[0] = p[0];

325	cb[0] = p[1];

326	cr[0] = p[3];

327	cb++;

328	cr++;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

329	}

330	p1 += src->linesize[0];

331	lum1 += dst->linesize[0];

332	if (height > 1)

333	{

334	p = p1;

335	lum = lum1;

336	for (w = width; w >= 2; w -= 2)

337	{

338	lum[0] = p[0];

339	lum[1] = p[2];

340	p += 4;

341	lum += 2;

342	}

343	if (w)

344	{

345	lum[0] = p[0];

346	}

347	p1 += src->linesize[0];

348	lum1 += dst->linesize[0];

349	}

350	cb1 += dst->linesize[1];

351	cr1 += dst->linesize[2];

352	}

353	}

354

355	static void uyvy422\_to\_yuv420p(AVPicture \*dst, const AVPicture \*src, int width, int height)

356	{

357	const uint8\_t \*p,	\*p1;

358	uint8\_t \*lum,	\*cr,	\*cb,	\*lum1,	\*cr1,	\*cb1;

359	int w;

360

361	p1 = src->data[0];

362

363	lum1 = dst->data[0];

364	cb1 = dst->data[1];

365	cr1 = dst->data[2];

366

367	for (; height >= 1; height -= 2)

368	{

369	p = p1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

370	lum = lum1;

371	cb = cb1;

372	cr = cr1;

373	for (w = width; w >= 2; w -= 2)

374	{

375	lum[0] = p[1];

376	cb[0] = p[0];

377	lum[1] = p[3];

378	cr[0] = p[2];

379	p += 4;

380	lum += 2;

381	cb++;

382	cr++;

383	}

384	if (w)

385	{

386	lum[0] = p[1];

387	cb[0] = p[0];

388	cr[0] = p[2];

389	cb++;

390	cr++;

391	}

392	p1 += src->linesize[0];

393	lum1 += dst->linesize[0];

394	if (height > 1)

395	{

396	p = p1;

397	lum = lum1;

398	for (w = width; w >= 2; w -= 2)

399	{

400	lum[0] = p[1];

401	lum[1] = p[3];

402	p += 4;

403	lum += 2;

404	}

405	if (w)

406	{

407	lum[0] = p[1];

408	}

409	p1 += src->linesize[0];

410	lum1 += dst->linesize[0];![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

411	}

412	cb1 += dst->linesize[1];

413	cr1 += dst->linesize[2];

414	}

415	}

416

417	static void uyvy422\_to\_yuv422p(AVPicture \*dst, const AVPicture \*src, int width, int height)

418	{

419	const uint8\_t \*p,	\*p1;

420	uint8\_t \*lum,	\*cr,	\*cb,	\*lum1,	\*cr1,	\*cb1;

421	int w;

422

423	p1 = src->data[0];

424	lum1 = dst->data[0];

425	cb1 = dst->data[1];

426	cr1 = dst->data[2];

427	for (; height > 0; height--)

428	{

429	p = p1;

430	lum = lum1;

431	cb = cb1;

432	cr = cr1;

433	for (w = width; w >= 2; w -= 2)

434	{

435	lum[0] = p[1];

436	cb[0] = p[0];

437	lum[1] = p[3];

438	cr[0] = p[2];

439	p += 4;

440	lum += 2;

441	cb++;

442	cr++;

443	}

444	p1 += src->linesize[0];

445	lum1 += dst->linesize[0];

446	cb1 += dst->linesize[1];

447	cr1 += dst->linesize[2];

448	}

449	}

450

451	static void yuv422\_to\_yuv422p(AVPicture \*dst, const AVPicture \*src, int width, int height)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

452	{

453	const uint8\_t \*p,	\*p1;

454	uint8\_t \*lum,	\*cr,	\*cb,	\*lum1,	\*cr1,	\*cb1;

455	int w;

456

457	p1 = src->data[0];

458	lum1 = dst->data[0];

459	cb1 = dst->data[1];

460	cr1 = dst->data[2];

461	for (; height > 0; height--)

462	{

463	p = p1;

464	lum = lum1;

465	cb = cb1;

466	cr = cr1;

467	for (w = width; w >= 2; w -= 2)

468	{

469	lum[0] = p[0];

470	cb[0] = p[1];

471	lum[1] = p[2];

472	cr[0] = p[3];

473	p += 4;

474	lum += 2;

475	cb++;

476	cr++;

477	}

478	p1 += src->linesize[0];

479	lum1 += dst->linesize[0];

480	cb1 += dst->linesize[1];

481	cr1 += dst->linesize[2];

482	}

483	}

484

485	static void yuv422p\_to\_yuv422(AVPicture \*dst, const AVPicture \*src, int width, int height)

486	{

|487|uint8\_t \*p,	\*p1;||
| - | - | - |
|488|const uint8\_t \*lum,	\*cr,	\*cb,	\*lum1,	\*cr1,|\*cb1;|
|489|int w;||
|490|||
|491|p1 = dst->data[0];||
|492|lum1 = src->data[0];||

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)493	cb1 = src->data[1];

494	cr1 = src->data[2];

495	for (; height > 0; height--)

496	{

497	p = p1;

498	lum = lum1;

499	cb = cb1;

500	cr = cr1;

501	for (w = width; w >= 2; w -= 2)

502	{

503	p[0] = lum[0];

504	p[1] = cb[0];

505	p[2] = lum[1];

506	p[3] = cr[0];

507	p += 4;

508	lum += 2;

509	cb++;

510	cr++;

511	}

512	p1 += dst->linesize[0];

513	lum1 += src->linesize[0];

514	cb1 += src->linesize[1];

515	cr1 += src->linesize[2];

516	}

517	}

518

519	static void yuv422p\_to\_uyvy422(AVPicture \*dst, const AVPicture \*src, int width, int height)

520	{

521	uint8\_t \*p,	\*p1;

522	const uint8\_t \*lum,	\*cr,	\*cb,	\*lum1,	\*cr1,	\*cb1;

523	int w;

524

525	p1 = dst->data[0];

526	lum1 = src->data[0];

527	cb1 = src->data[1];

528	cr1 = src->data[2];

529	for (; height > 0; height--)

530	{

531	p = p1;

532	lum = lum1;

533	cb = cb1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

534	cr = cr1;

535	for (w = width; w >= 2; w -= 2)

536	{

537	p[1] = lum[0];

538	p[0] = cb[0];

539	p[3] = lum[1];

540	p[2] = cr[0];

541	p += 4;

542	lum += 2;

543	cb++;

544	cr++;

545	}

546	p1 += dst->linesize[0];

547	lum1 += src->linesize[0];

548	cb1 += src->linesize[1];

549	cr1 += src->linesize[2];

550	}

551	}

552

553	static void uyvy411\_to\_yuv411p(AVPicture \*dst, const AVPicture \*src, int width, int height)

554	{

555	const uint8\_t \*p,	\*p1;

556	uint8\_t \*lum,	\*cr,	\*cb,	\*lum1,	\*cr1,	\*cb1;

557	int w;

558

559	p1 = src->data[0];

560	lum1 = dst->data[0];

561	cb1 = dst->data[1];

562	cr1 = dst->data[2];

563	for (; height > 0; height--)

564	{

565	p = p1;

566	lum = lum1;

567	cb = cb1;

568	cr = cr1;

569	for (w = width; w >= 4; w -= 4)

570	{

571	cb[0] = p[0];

572	lum[0] = p[1];

573	lum[1] = p[2];

574	cr[0] = p[3];![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

575	lum[2] = p[4];

576	lum[3] = p[5];

577	p += 6;

578	lum += 4;

579	cb++;

580	cr++;

581	}

582	p1 += src->linesize[0];

583	lum1 += dst->linesize[0];

584	cb1 += dst->linesize[1];

585	cr1 += dst->linesize[2];

586	}

587	}

588

589	static void yuv420p\_to\_yuv422(AVPicture \*dst, const AVPicture \*src, int width, int height)

590	{

591	int w, h;

592	uint8\_t \*line1,	\*line2,	\*linesrc = dst->data[0];

593	uint8\_t \*lum1,	\*lum2,	\*lumsrc = src->data[0];

594	uint8\_t \*cb1,	\*cb2 = src->data[1];

595	uint8\_t \*cr1,	\*cr2 = src->data[2];

596

597	for (h = height / 2; h--;)

598	{

599	line1 = linesrc;

600	line2 = linesrc + dst->linesize[0];

601

602	lum1 = lumsrc;

603	lum2 = lumsrc + src->linesize[0];

604

605	cb1 = cb2;

606	cr1 = cr2;

607

608	for (w = width / 2; w--;)

609	{

610	\*line1++ =	\*lum1++;

611	\*line2++ =	\*lum2++;

612	\*line1++ =	\*line2++ =	\*cb1++;

613	\*line1++ =	\*lum1++;

614	\*line2++ =	\*lum2++;

615	\*line1++ =	\*line2++ =	\*cr1++;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

616	}

617

618	linesrc += dst->linesize[0] \*2;

619	lumsrc += src->linesize[0] \*2;

620	cb2 += src->linesize[1];

621	cr2 += src->linesize[2];

622	}

623	}

624

625	static void yuv420p\_to\_uyvy422(AVPicture \*dst, const AVPicture \*src, int width, int height)

626	{

627	int w, h;

628	uint8\_t \*line1,	\*line2,	\*linesrc = dst->data[0];

629	uint8\_t \*lum1,	\*lum2,	\*lumsrc = src->data[0];

630	uint8\_t \*cb1,	\*cb2 = src->data[1];

631	uint8\_t \*cr1,	\*cr2 = src->data[2];

632

633	for (h = height / 2; h--;)

634	{

635	line1 = linesrc;

636	line2 = linesrc + dst->linesize[0];

637

638	lum1 = lumsrc;

639	lum2 = lumsrc + src->linesize[0];

640

641	cb1 = cb2;

642	cr1 = cr2;

643

644	for (w = width / 2; w--;)

645	{

646	\*line1++ =	\*line2++ =	\*cb1++;

647	\*line1++ =	\*lum1++;

648	\*line2++ =	\*lum2++;

649	\*line1++ =	\*line2++ =	\*cr1++;

650	\*line1++ =	\*lum1++;

651	\*line2++ =	\*lum2++;

652	}

653

654	linesrc += dst->linesize[0] \*2;

655	lumsrc += src->linesize[0] \*2;

656	cb2 += src->linesize[1];![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

657	cr2 += src->linesize[2];

658	}

659	}

660

661	#define SCALEBITS 10

662	#define ONE\_HALF	(1 << (SCALEBITS - 1))

663	#define FIX(x)	((int) ((x) \* (1<<SCALEBITS) + 0.5))

664

665	#define YUV\_TO\_RGB1\_CCIR(cb1, cr1)\

666	{\

667	cb = (cb1) - 128;\

668	cr = (cr1) - 128;\

669	r\_add = FIX(1.40200\*255.0/224.0) \* cr + ONE\_HALF;\

670	g\_add = - FIX(0.34414\*255.0/224.0) \* cb - FIX(0.71414\*255.0/224.0) \* cr + \

671	ONE\_HALF;\

672	b\_add = FIX(1.77200\*255.0/224.0) \* cb + ONE\_HALF;\

673	}

674

675	#define YUV\_TO\_RGB2\_CCIR(r, g, b, y1)\

676	{\

677	y = ((y1) - 16) \* FIX(255.0/219.0);\

678	r = cm[(y + r\_add) >> SCALEBITS];\

679	g = cm[(y + g\_add) >> SCALEBITS];\

680	b = cm[(y + b\_add) >> SCALEBITS];\

681	}

682

683	#define YUV\_TO\_RGB1(cb1, cr1)\

684	{\

685	cb = (cb1) - 128;\

686	cr = (cr1) - 128;\

687	r\_add = FIX(1.40200) \* cr + ONE\_HALF;\

688	g\_add = - FIX(0.34414) \* cb - FIX(0.71414) \* cr + ONE\_HALF;\

689	b\_add = FIX(1.77200) \* cb + ONE\_HALF;\

690	}

691

692	#define YUV\_TO\_RGB2(r, g, b, y1)\

693	{\

694	y = (y1) << SCALEBITS;\

695	r = cm[(y + r\_add) >> SCALEBITS];\

696	g = cm[(y + g\_add) >> SCALEBITS];\

697	b = cm[(y + b\_add) >> SCALEBITS];\![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

698	}

699

700	#define Y\_CCIR\_TO\_JPEG(y)\

701	cm[((y) \* FIX(255.0/219.0) + (ONE\_HALF - 16 \* FIX(255.0/219.0))) >> SCALEBITS]

702

703	#define Y\_JPEG\_TO\_CCIR(y)\

704	(((y) \* FIX(219.0/255.0) + (ONE\_HALF + (16 << SCALEBITS))) >> SCALEBITS)

705

706	#define C\_CCIR\_TO\_JPEG(y)\

707	cm[(((y) - 128) \* FIX(127.0/112.0) + (ONE\_HALF + (128 << SCALEBITS))) >> SCALEBITS]

708

709	/\* NOTE: the clamp is really necessary! \*/

710	static inline int C\_JPEG\_TO\_CCIR(int y)

711	{

712	y = (((y - 128) \*FIX(112.0 / 127.0) + (ONE\_HALF + (128 << SCALEBITS))) >> SCALEBITS);

713	if (y < 16)

714	y = 16;

715	return y;

716	}

717

718	#define RGB\_TO\_Y(r, g, b) \

719	((FIX(0.29900) \* (r) + FIX(0.58700) \* (g) + \

720	FIX(0.11400) \* (b) + ONE\_HALF) >> SCALEBITS)

721

722	#define RGB\_TO\_U(r1, g1, b1, shift)\

723	(((- FIX(0.16874) \* r1 - FIX(0.33126) \* g1 +	\

724	FIX(0.50000) \* b1 + (ONE\_HALF << shift) - 1) >> (SCALEBITS + shift)) + 128)

725

726	#define RGB\_TO\_V(r1, g1, b1, shift)\

727	(((FIX(0.50000) \* r1 - FIX(0.41869) \* g1 -	\

728	FIX(0.08131) \* b1 + (ONE\_HALF << shift) - 1) >> (SCALEBITS + shift)) + 128)

729

730	#define RGB\_TO\_Y\_CCIR(r, g, b) \

731	((FIX(0.29900\*219.0/255.0) \* (r) + FIX(0.58700\*219.0/255.0) \* (g) + \

732	FIX(0.11400\*219.0/255.0) \* (b) + (ONE\_HALF + (16 << SCALEBITS))) >> SCALEBITS)

733

734	#define RGB\_TO\_U\_CCIR(r1, g1, b1, shift)\

735	(((- FIX(0.16874\*224.0/255.0) \* r1 - FIX(0.33126\*224.0/255.0) \* g1 +	\

736	FIX(0.50000\*224.0/255.0) \* b1 + (ONE\_HALF << shift) - 1) >> (SCALEBITS + shift)) + 128)

737

738	#define RGB\_TO\_V\_CCIR(r1, g1, b1, shift)\![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

739	(((FIX(0.50000\*224.0/255.0) \* r1 - FIX(0.41869\*224.0/255.0) \* g1 -	\

740	FIX(0.08131\*224.0/255.0) \* b1 + (ONE\_HALF << shift) - 1) >> (SCALEBITS + shift)) + 128)

741

742	static uint8\_t y\_ccir\_to\_jpeg[256];

743	static uint8\_t y\_jpeg\_to\_ccir[256];

744	static uint8\_t c\_ccir\_to\_jpeg[256];

745	static uint8\_t c\_jpeg\_to\_ccir[256];

746

747	/\* apply to each pixel the given table \*/

748	static void img\_apply\_table(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap,

749	int width, int height, const uint8\_t \*table1)

750	{

751	int n;

752	const uint8\_t \*s;

753	uint8\_t \*d;

754	const uint8\_t \*table;

755

756	table = table1;

757	for (; height > 0; height--)

758	{

759	s = src;

760	d = dst;

761	n = width;

762	while (n >= 4)

763	{

764	d[0] = table[s[0]];

765	d[1] = table[s[1]];

766	d[2] = table[s[2]];

767	d[3] = table[s[3]];

768	d += 4;

769	s += 4;

770	n -= 4;

771	}

772	while (n > 0)

773	{

774	d[0] = table[s[0]];

775	d++;

776	s++;

777	n--;

778	}

779	dst += dst\_wrap;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

780	src += src\_wrap;

781	}

782	}

783

784	/\* XXX: use generic filter ? \*/

785	/\* XXX: in most cases, the sampling position is incorrect \*/

786

787	/\* 4x1 -> 1x1 \*/

788	static void shrink41(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

789	{

790	int w;

791	const uint8\_t \*s;

792	uint8\_t \*d;

793

794	for (; height > 0; height--)

795	{

796	s = src;

797	d = dst;

798	for (w = width; w > 0; w--)

799	{

800	d[0] = (s[0] + s[1] + s[2] + s[3] + 2) >> 2;

801	s += 4;

802	d++;

803	}

804	src += src\_wrap;

805	dst += dst\_wrap;

806	}

807	}

808

809	/\* 2x1 -> 1x1 \*/

810	static void shrink21(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

811	{

812	int w;

813	const uint8\_t \*s;

814	uint8\_t \*d;

815

816	for (; height > 0; height--)

817	{

818	s = src;

819	d = dst;

820	for (w = width; w > 0; w--)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

821	{

822	d[0] = (s[0] + s[1]) >> 1;

823	s += 2;

824	d++;

825	}

826	src += src\_wrap;

827	dst += dst\_wrap;

828	}

829	}

830

831	/\* 1x2 -> 1x1 \*/

832	static void shrink12(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

833	{

834	int w;

835	uint8\_t \*d;

836	const uint8\_t \*s1,	\*s2;

837

838	for (; height > 0; height--)

839	{

840	s1 = src;

841	s2 = s1 + src\_wrap;

842	d = dst;

843	for (w = width; w >= 4; w -= 4)

844	{

845	d[0] = (s1[0] + s2[0]) >> 1;

846	d[1] = (s1[1] + s2[1]) >> 1;

847	d[2] = (s1[2] + s2[2]) >> 1;

848	d[3] = (s1[3] + s2[3]) >> 1;

849	s1 += 4;

850	s2 += 4;

851	d += 4;

852	}

853	for (; w > 0; w--)

854	{

855	d[0] = (s1[0] + s2[0]) >> 1;

856	s1++;

857	s2++;

858	d++;

859	}

860	src += 2 \* src\_wrap;

861	dst += dst\_wrap;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

862	}

863	}

864

865	/\* 2x2 -> 1x1 \*/

866	void ff\_shrink22(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

867	{

868	int w;

869	const uint8\_t \*s1,	\*s2;

870	uint8\_t \*d;

871

872	for (; height > 0; height--)

873	{

874	s1 = src;

875	s2 = s1 + src\_wrap;

876	d = dst;

877	for (w = width; w >= 4; w -= 4)

878	{

879	d[0] = (s1[0] + s1[1] + s2[0] + s2[1] + 2) >> 2;

880	d[1] = (s1[2] + s1[3] + s2[2] + s2[3] + 2) >> 2;

881	d[2] = (s1[4] + s1[5] + s2[4] + s2[5] + 2) >> 2;

882	d[3] = (s1[6] + s1[7] + s2[6] + s2[7] + 2) >> 2;

883	s1 += 8;

884	s2 += 8;

885	d += 4;

886	}

887	for (; w > 0; w--)

888	{

889	d[0] = (s1[0] + s1[1] + s2[0] + s2[1] + 2) >> 2;

890	s1 += 2;

891	s2 += 2;

892	d++;

893	}

894	src += 2 \* src\_wrap;

895	dst += dst\_wrap;

896	}

897	}

898

899	/\* 4x4 -> 1x1 \*/

900	void ff\_shrink44(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

901	{

902	int w;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

903	const uint8\_t \*s1,	\*s2,	\*s3,	\*s4;

904	uint8\_t \*d;

905

906	for (; height > 0; height--)

907	{

908	s1 = src;

909	s2 = s1 + src\_wrap;

910	s3 = s2 + src\_wrap;

911	s4 = s3 + src\_wrap;

912	d = dst;

913	for (w = width; w > 0; w--)

914	{

915	d[0] = (s1[0] + s1[1] + s1[2] + s1[3] + s2[0] + s2[1] + s2[2] + s2[3] +

916	s3[0] + s3[1] + s3[2] + s3[3] + s4[0] + s4[1] + s4[2] + s4[3] + 8) >> 4;

917	s1 += 4;

918	s2 += 4;

919	s3 += 4;

920	s4 += 4;

921	d++;

922	}

923	src += 4 \* src\_wrap;

924	dst += dst\_wrap;

925	}

926	}

927

928	static void grow21\_line(uint8\_t \*dst, const uint8\_t \*src, int width)

929	{

930	int w;

931	const uint8\_t \*s1;

932	uint8\_t \*d;

933

934	s1 = src;

935	d = dst;

936	for (w = width; w >= 4; w -= 4)

937	{

938	d[1] = d[0] = s1[0];

939	d[3] = d[2] = s1[1];

940	s1 += 2;

941	d += 4;

942	}

943	for (; w >= 2; w -= 2)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

944	{

945	d[1] = d[0] = s1[0];

946	s1++;

947	d += 2;

948	}

949	/\* only needed if width is not a multiple of two \*/

950	/\* XXX: veryfy that \*/

951	if (w)

952	{

953	d[0] = s1[0];

954	}

955	}

956

957	static void grow41\_line(uint8\_t \*dst, const uint8\_t \*src, int width)

958	{

959	int w, v;

960	const uint8\_t \*s1;

961	uint8\_t \*d;

962

963	s1 = src;

964	d = dst;

965	for (w = width; w >= 4; w -= 4)

966	{

967	v = s1[0];

968	d[0] = v;

969	d[1] = v;

970	d[2] = v;

971	d[3] = v;

972	s1++;

973	d += 4;

974	}

975	}

976

977	/\* 1x1 -> 2x1 \*/

978	static void grow21(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

979	{

980	for (; height > 0; height--)

981	{

982	grow21\_line(dst, src, width);

983	src += src\_wrap;

984	dst += dst\_wrap;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

985	}

986	}

987

988	/\* 1x1 -> 2x2 \*/

989	static void grow22(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

990	{

991	for (; height > 0; height--)

992	{

993	grow21\_line(dst, src, width);

994	if (height % 2)

995	src += src\_wrap;

996	dst += dst\_wrap;

997	}

998	}

999

1000 /\* 1x1 -> 4x1 \*/

1001 static void grow41(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

1002 {

1003	for (; height > 0; height--)

1004	{

1005	grow41\_line(dst, src, width);

1006	src += src\_wrap;

1007	dst += dst\_wrap;

1008	}

1009 }

1010

1011 /\* 1x1 -> 4x4 \*/

1012 static void grow44(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

1013 {

1014	for (; height > 0; height--)

1015	{

1016	grow41\_line(dst, src, width);

1017	if ((height &3) == 1)

1018	src += src\_wrap;

1019	dst += dst\_wrap;

1020	}

1021 }

1022

1023 /\* 1x2 -> 2x1 \*/

1024 static void conv411(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap, int width, int height)

1025 {![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1026	int w, c;

1027	const uint8\_t \*s1,	\*s2;

1028	uint8\_t \*d;

1029

1030	width >>= 1;

1031

1032	for (; height > 0; height--)

1033	{

1034	s1 = src;

1035	s2 = src + src\_wrap;

1036	d = dst;

1037	for (w = width; w > 0; w--)

1038	{

1039	c = (s1[0] + s2[0]) >> 1;

1040	d[0] = c;

1041	d[1] = c;

1042	s1++;

1043	s2++;

1044	d += 2;

1045	}

1046	src += src\_wrap \* 2;

1047	dst += dst\_wrap;

1048	}

1049 }

1050

1051 /\* XXX: add jpeg quantize code \*/

1052

1053 #define TRANSP\_INDEX (6\*6\*6)

1054

1055 /\* this is maybe slow, but allows for extensions \*/

1056 static inline unsigned char gif\_clut\_index(uint8\_t r, uint8\_t g, uint8\_t b)

1057 {

1058	return ((((r) / 47) % 6) \*6 \* 6+(((g) / 47) % 6) \*6+(((b) / 47) % 6));

1059 }

1060

1061 static void build\_rgb\_palette(uint8\_t \*palette, int has\_alpha)

1062 {

1063	uint32\_t \*pal;

1064	static const uint8\_t pal\_value[6] = {0x00, 0x33, 0x66, 0x99, 0xcc, 0xff };

1065	int i, r, g, b;

1066![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1067	pal = (uint32\_t\*)palette;

1068	i = 0;

1069	for (r = 0; r < 6; r++)

1070	{

1071	for (g = 0; g < 6; g++)

1072	{

1073	for (b = 0; b < 6; b++)

1074	{

1075	pal[i++] = (0xff << 24) | (pal\_value[r] << 16) | (pal\_value[g] << 8) | pal\_value[b];

1076	}

1077	}

1078	}

1079	if (has\_alpha)

1080	pal[i++] = 0;

1081	while (i < 256)

1082	pal[i++] = 0xff000000;

1083 }

1084

1085 /\* copy bit n to bits 0 ... n - 1 \*/

1086 static inline unsigned int bitcopy\_n(unsigned int a, int n)

1087 {

1088	int mask;

1089	mask = (1 << n) - 1;

1090	return (a &(0xff &~mask)) | (( - ((a >> n) &1)) &mask);

1091 }

1092

1093 /\* rgb555 handling \*/

1094

1095 #define RGB\_NAME rgb555

1096

1097 #define RGB\_IN(r, g, b, s)\

1098 {\

1099	unsigned int v = ((const uint16\_t \*)(s))[0];\

1100	r = bitcopy\_n(v >> (10 - 3), 3);\

1101	g = bitcopy\_n(v >> (5 - 3), 3);\

1102	b = bitcopy\_n(v << 3, 3);\

1103 }

1104

1105 #define RGBA\_IN(r, g, b, a, s)\

1106 {\

1107	unsigned int v = ((const uint16\_t \*)(s))[0];\![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1108	r = bitcopy\_n(v >> (10 - 3), 3);\

1109	g = bitcopy\_n(v >> (5 - 3), 3);\

1110	b = bitcopy\_n(v << 3, 3);\

1111	a = (-(v >> 15)) & 0xff;\

1112 }

1113

1114 #define RGBA\_OUT(d, r, g, b, a)\

1115 {\

1116	((uint16\_t \*)(d))[0] = ((r >> 3) << 10) | ((g >> 3) << 5) | (b >> 3) | \

1117	((a << 8) & 0x8000);\

1118 }

1119

1120 #define BPP 2

1121

1122 #include "imgconvert\_template.h"

1123

1124 /\* rgb565 handling \*/

1125

1126 #define RGB\_NAME rgb565

1127

1128 #define RGB\_IN(r, g, b, s)\

1129 {\

1130	unsigned int v = ((const uint16\_t \*)(s))[0];\

1131	r = bitcopy\_n(v >> (11 - 3), 3);\

1132	g = bitcopy\_n(v >> (5 - 2), 2);\

1133	b = bitcopy\_n(v << 3, 3);\

1134 }

1135

1136 #define RGB\_OUT(d, r, g, b)\

1137 {\

1138	((uint16\_t \*)(d))[0] = ((r >> 3) << 11) | ((g >> 2) << 5) | (b >> 3);\

1139 }

1140

1141 #define BPP 2

1142

1143 #include "imgconvert\_template.h"

1144

1145 /\* bgr24 handling \*/

1146

1147 #define RGB\_NAME bgr24

1148![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1149 #define RGB\_IN(r, g, b, s)\

1150 {\

1151	b = (s)[0];\

1152	g = (s)[1];\

1153	r = (s)[2];\

1154 }

1155

1156 #define RGB\_OUT(d, r, g, b)\

1157 {\

1158	(d)[0] = b;\

1159	(d)[1] = g;\

1160	(d)[2] = r;\

1161 }

1162

1163 #define BPP 3

1164

1165 #include "imgconvert\_template.h"

1166

1167 #undef RGB\_IN

1168 #undef RGB\_OUT

1169 #undef BPP

1170

1171 /\* rgb24 handling \*/

1172

1173 #define RGB\_NAME rgb24

1174 #define FMT\_RGB24

1175

1176 #define RGB\_IN(r, g, b, s)\

1177 {\

1178	r = (s)[0];\

1179	g = (s)[1];\

1180	b = (s)[2];\

1181 }

1182

1183 #define RGB\_OUT(d, r, g, b)\

1184 {\

1185	(d)[0] = r;\

1186	(d)[1] = g;\

1187	(d)[2] = b;\

1188 }

1189![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1190 #define BPP 3

1191

1192 #include "imgconvert\_template.h"

1193

1194 /\* rgba32 handling \*/

1195

1196 #define RGB\_NAME rgba32

1197 #define FMT\_RGBA32

1198

1199 #define RGB\_IN(r, g, b, s)\

1200 {\

1201	unsigned int v = ((const uint32\_t \*)(s))[0];\

1202	r = (v >> 16) & 0xff;\

1203	g = (v >> 8) & 0xff;\

1204	b = v & 0xff;\

1205 }

1206

1207 #define RGBA\_IN(r, g, b, a, s)\

1208 {\

1209	unsigned int v = ((const uint32\_t \*)(s))[0];\

1210	a = (v >> 24) & 0xff;\

1211	r = (v >> 16) & 0xff;\

1212	g = (v >> 8) & 0xff;\

1213	b = v & 0xff;\

1214 }

1215

1216 #define RGBA\_OUT(d, r, g, b, a)\

1217 {\

1218	((uint32\_t \*)(d))[0] = (a << 24) | (r << 16) | (g << 8) | b;\

1219 }

1220

1221 #define BPP 4

1222

1223 #include "imgconvert\_template.h"

1224

1225 static void mono\_to\_gray(AVPicture \*dst, const AVPicture \*src, int width, int height, int xor\_mask)

1226 {

1227	const unsigned char \*p;

1228	unsigned char \*q;

1229	int v, dst\_wrap, src\_wrap;

1230	int y, w;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1231

1232	p = src->data[0];

1233	src\_wrap = src->linesize[0] - ((width + 7) >> 3);

1234

1235	q = dst->data[0];

1236	dst\_wrap = dst->linesize[0] - width;

1237	for (y = 0; y < height; y++)

1238	{

1239	w = width;

1240	while (w >= 8)

1241	{

1242	v =	\*p++ ^ xor\_mask;

1243	q[0] =	- (v >> 7);

1244	q[1] =	- ((v >> 6) &1);

1245	q[2] =	- ((v >> 5) &1);

1246	q[3] =	- ((v >> 4) &1);

1247	q[4] =	- ((v >> 3) &1);

1248	q[5] =	- ((v >> 2) &1);

1249	q[6] =	- ((v >> 1) &1);

1250	q[7] =	- ((v >> 0) &1);

1251	w -= 8;

1252	q += 8;

1253	}

1254	if (w > 0)

1255	{

1256	v =	\*p++ ^ xor\_mask;

1257	do

1258	{

1259	q[0] =	- ((v >> 7) &1);

1260	q++;

1261	v <<= 1;

1262	}

1263	while (--w);

1264	}

1265	p += src\_wrap;

1266	q += dst\_wrap;

1267	}

1268 }

1269

1270 static void monowhite\_to\_gray(AVPicture \*dst, const AVPicture \*src, int width, int height)

1271 {![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1272	mono\_to\_gray(dst, src, width, height, 0xff);

1273 }

1274

1275 static void monoblack\_to\_gray(AVPicture \*dst, const AVPicture \*src, int width, int height)

1276 {

1277	mono\_to\_gray(dst, src, width, height, 0x00);

1278 }

1279

1280 static void gray\_to\_mono(AVPicture \*dst, const AVPicture \*src, int width, int height, int xor\_mask)

1281 {

1282	int n;

1283	const uint8\_t \*s;

1284	uint8\_t \*d;

1285	int j, b, v, n1, src\_wrap, dst\_wrap, y;

1286

1287	s = src->data[0];

1288	src\_wrap = src->linesize[0] - width;

1289

1290	d = dst->data[0];

1291	dst\_wrap = dst->linesize[0] - ((width + 7) >> 3);

1292

1293	for (y = 0; y < height; y++)

1294	{

1295	n = width;

1296	while (n >= 8)

1297	{

1298	v = 0;

1299	for (j = 0; j < 8; j++)

1300	{

1301	b = s[0];

1302	s++;

1303	v = (v << 1) | (b >> 7);

|1304||}|
| - | - | - |
|1305||d[0] = v ^ xor\_mask;|
|1306||d++;|
|1307||n -= 8;|
|1308|}||
|1309	if (n > 0)|
|1310|{||
|1311||n1 = n;|
|1312||v = 0;|


|1313|||while (n > 0)|
| - | - | - | - |
|1314|||{|
|1315|||b = s[0];|
|1316|||s++;|
|1317|||v = (v << 1) | (b >> 7);|
|1318|||n--;|
|1319|||}|
|1320|||d[0] = (v << (8-(n1 &7))) ^ xor\_mask;|
|1321|||d++;|
|1322|||}|
|1323|||s += src\_wrap;|
|1324|||d += dst\_wrap;|
|1325||}||
|1326|}|||
|1327||||
1328 static void gray\_to\_monowhite(AVPicture \*dst, const AVPicture \*src, int width, int height)

1329 {

1330	gray\_to\_mono(dst, src, width, height, 0xff);

1331 }

1332

1333 static void gray\_to\_monoblack(AVPicture \*dst, const AVPicture \*src, int width, int height)

1334 {

1335	gray\_to\_mono(dst, src, width, height, 0x00);

1336 }

1337

1338 typedef struct ConvertEntry

1339 {

1340	void(\*convert)(AVPicture \*dst, const AVPicture \*src, int width, int height);

1341 } ConvertEntry;

1342

1343 /\* Add each new convertion function in this table. In order to be able

1344 to convert from any format to any format, the following constraints must be satisfied:

1345

1346	- all FF\_COLOR\_RGB formats must convert to and from PIX\_FMT\_RGB24

1347

1348	- all FF\_COLOR\_GRAY formats must convert to and from PIX\_FMT\_GRAY8

1349

1350	- all FF\_COLOR\_RGB formats with alpha must convert to and from PIX\_FMT\_RGBA32

1351

1352	- PIX\_FMT\_YUV444P and PIX\_FMT\_YUVJ444P must convert to and from PIX\_FMT\_RGB24.

1353![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1354	- PIX\_FMT\_422 must convert to and from PIX\_FMT\_422P.

1355

1356	The other conversion functions are just optimisations for common cases.

1357 \*/

1358

1359 static ConvertEntry convert\_table[PIX\_FMT\_NB][PIX\_FMT\_NB];

1360

1361 static void img\_convert\_init(void)

1362 {

1363	int i;

1364	uint8\_t \*cm = cropTbl + MAX\_NEG\_CROP;

1365

1366	for (i = 0; i < 256; i++)

1367	{

1368	y\_ccir\_to\_jpeg[i] = Y\_CCIR\_TO\_JPEG(i);

1369	y\_jpeg\_to\_ccir[i] = Y\_JPEG\_TO\_CCIR(i);

1370	c\_ccir\_to\_jpeg[i] = C\_CCIR\_TO\_JPEG(i);

1371	c\_jpeg\_to\_ccir[i] = C\_JPEG\_TO\_CCIR(i);

1372	}

1373

1374	convert\_table[PIX\_FMT\_YUV420P][PIX\_FMT\_YUV422].convert = yuv420p\_to\_yuv422;

1375	convert\_table[PIX\_FMT\_YUV420P][PIX\_FMT\_YUV422].convert = yuv420p\_to\_yuv422;

1376	convert\_table[PIX\_FMT\_YUV420P][PIX\_FMT\_RGB555].convert = yuv420p\_to\_rgb555;

1377	convert\_table[PIX\_FMT\_YUV420P][PIX\_FMT\_RGB565].convert = yuv420p\_to\_rgb565;

1378	convert\_table[PIX\_FMT\_YUV420P][PIX\_FMT\_BGR24].convert = yuv420p\_to\_bgr24;

1379	convert\_table[PIX\_FMT\_YUV420P][PIX\_FMT\_RGB24].convert = yuv420p\_to\_rgb24;

1380	convert\_table[PIX\_FMT\_YUV420P][PIX\_FMT\_RGBA32].convert = yuv420p\_to\_rgba32;

1381	convert\_table[PIX\_FMT\_YUV420P][PIX\_FMT\_UYVY422].convert = yuv420p\_to\_uyvy422;

1382

1383	convert\_table[PIX\_FMT\_YUV422P][PIX\_FMT\_YUV422].convert = yuv422p\_to\_yuv422;

1384	convert\_table[PIX\_FMT\_YUV422P][PIX\_FMT\_UYVY422].convert = yuv422p\_to\_uyvy422;

1385

1386	convert\_table[PIX\_FMT\_YUV444P][PIX\_FMT\_RGB24].convert = yuv444p\_to\_rgb24;

1387

1388	convert\_table[PIX\_FMT\_YUVJ420P][PIX\_FMT\_RGB555].convert = yuvj420p\_to\_rgb555;

1389	convert\_table[PIX\_FMT\_YUVJ420P][PIX\_FMT\_RGB565].convert = yuvj420p\_to\_rgb565;

1390	convert\_table[PIX\_FMT\_YUVJ420P][PIX\_FMT\_BGR24].convert = yuvj420p\_to\_bgr24;

1391	convert\_table[PIX\_FMT\_YUVJ420P][PIX\_FMT\_RGB24].convert = yuvj420p\_to\_rgb24;

1392	convert\_table[PIX\_FMT\_YUVJ420P][PIX\_FMT\_RGBA32].convert = yuvj420p\_to\_rgba32;

1393

1394	convert\_table[PIX\_FMT\_YUVJ444P][PIX\_FMT\_RGB24].convert = yuvj444p\_to\_rgb24;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1395

1396	convert\_table[PIX\_FMT\_YUV422][PIX\_FMT\_YUV420P].convert = yuv422\_to\_yuv420p;

1397	convert\_table[PIX\_FMT\_YUV422][PIX\_FMT\_YUV422P].convert = yuv422\_to\_yuv422p;

1398

1399	convert\_table[PIX\_FMT\_UYVY422][PIX\_FMT\_YUV420P].convert = uyvy422\_to\_yuv420p;

1400	convert\_table[PIX\_FMT\_UYVY422][PIX\_FMT\_YUV422P].convert = uyvy422\_to\_yuv422p;

1401

1402	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_YUV420P].convert = rgb24\_to\_yuv420p;

1403	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_RGB565].convert = rgb24\_to\_rgb565;

1404	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_RGB555].convert = rgb24\_to\_rgb555;

1405	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_RGBA32].convert = rgb24\_to\_rgba32;

1406	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_BGR24].convert = rgb24\_to\_bgr24;

1407	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_GRAY8].convert = rgb24\_to\_gray;

1408	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_PAL8].convert = rgb24\_to\_pal8;

1409	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_YUV444P].convert = rgb24\_to\_yuv444p;

1410	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_YUVJ420P].convert = rgb24\_to\_yuvj420p;

1411	convert\_table[PIX\_FMT\_RGB24][PIX\_FMT\_YUVJ444P].convert = rgb24\_to\_yuvj444p;

1412

1413	convert\_table[PIX\_FMT\_RGBA32][PIX\_FMT\_RGB24].convert = rgba32\_to\_rgb24;

1414	convert\_table[PIX\_FMT\_RGBA32][PIX\_FMT\_RGB555].convert = rgba32\_to\_rgb555;

1415	convert\_table[PIX\_FMT\_RGBA32][PIX\_FMT\_PAL8].convert = rgba32\_to\_pal8;

1416	convert\_table[PIX\_FMT\_RGBA32][PIX\_FMT\_YUV420P].convert = rgba32\_to\_yuv420p;

1417	convert\_table[PIX\_FMT\_RGBA32][PIX\_FMT\_GRAY8].convert = rgba32\_to\_gray;

1418

1419	convert\_table[PIX\_FMT\_BGR24][PIX\_FMT\_RGB24].convert = bgr24\_to\_rgb24;

1420	convert\_table[PIX\_FMT\_BGR24][PIX\_FMT\_YUV420P].convert = bgr24\_to\_yuv420p;

1421	convert\_table[PIX\_FMT\_BGR24][PIX\_FMT\_GRAY8].convert = bgr24\_to\_gray;

1422

1423	convert\_table[PIX\_FMT\_RGB555][PIX\_FMT\_RGB24].convert = rgb555\_to\_rgb24;

1424	convert\_table[PIX\_FMT\_RGB555][PIX\_FMT\_RGBA32].convert = rgb555\_to\_rgba32;

1425	convert\_table[PIX\_FMT\_RGB555][PIX\_FMT\_YUV420P].convert = rgb555\_to\_yuv420p;

1426	convert\_table[PIX\_FMT\_RGB555][PIX\_FMT\_GRAY8].convert = rgb555\_to\_gray;

1427

1428	convert\_table[PIX\_FMT\_RGB565][PIX\_FMT\_RGB24].convert = rgb565\_to\_rgb24;

1429	convert\_table[PIX\_FMT\_RGB565][PIX\_FMT\_YUV420P].convert = rgb565\_to\_yuv420p;

1430	convert\_table[PIX\_FMT\_RGB565][PIX\_FMT\_GRAY8].convert = rgb565\_to\_gray;

1431

1432	convert\_table[PIX\_FMT\_GRAY8][PIX\_FMT\_RGB555].convert = gray\_to\_rgb555;

1433	convert\_table[PIX\_FMT\_GRAY8][PIX\_FMT\_RGB565].convert = gray\_to\_rgb565;

1434	convert\_table[PIX\_FMT\_GRAY8][PIX\_FMT\_RGB24].convert = gray\_to\_rgb24;

1435	convert\_table[PIX\_FMT\_GRAY8][PIX\_FMT\_BGR24].convert = gray\_to\_bgr24;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1436	convert\_table[PIX\_FMT\_GRAY8][PIX\_FMT\_RGBA32].convert = gray\_to\_rgba32;

1437	convert\_table[PIX\_FMT\_GRAY8][PIX\_FMT\_MONOWHITE].convert = gray\_to\_monowhite;

1438	convert\_table[PIX\_FMT\_GRAY8][PIX\_FMT\_MONOBLACK].convert = gray\_to\_monoblack;

1439

1440	convert\_table[PIX\_FMT\_MONOWHITE][PIX\_FMT\_GRAY8].convert = monowhite\_to\_gray;

1441

1442	convert\_table[PIX\_FMT\_MONOBLACK][PIX\_FMT\_GRAY8].convert = monoblack\_to\_gray;

1443

1444	convert\_table[PIX\_FMT\_PAL8][PIX\_FMT\_RGB555].convert = pal8\_to\_rgb555;

1445	convert\_table[PIX\_FMT\_PAL8][PIX\_FMT\_RGB565].convert = pal8\_to\_rgb565;

1446	convert\_table[PIX\_FMT\_PAL8][PIX\_FMT\_BGR24].convert = pal8\_to\_bgr24;

1447	convert\_table[PIX\_FMT\_PAL8][PIX\_FMT\_RGB24].convert = pal8\_to\_rgb24;

1448	convert\_table[PIX\_FMT\_PAL8][PIX\_FMT\_RGBA32].convert = pal8\_to\_rgba32;

1449

1450	convert\_table[PIX\_FMT\_UYVY411][PIX\_FMT\_YUV411P].convert = uyvy411\_to\_yuv411p;

1451 }

1452

1453 static inline int is\_yuv\_planar(PixFmtInfo \*ps)

1454 {

1455	return (ps->color\_type == FF\_COLOR\_YUV || ps->color\_type == FF\_COLOR\_YUV\_JPEG)

1456	&& ps->pixel\_type == FF\_PIXEL\_PLANAR;

1457 }

1458

1459 int img\_convert(AVPicture \*dst, int dst\_pix\_fmt, const AVPicture \*src, int src\_pix\_fmt,

1460	int src\_width, int src\_height)

1461 {

1462	static int inited;

1463	int i, ret, dst\_width, dst\_height, int\_pix\_fmt;

1464	PixFmtInfo \*src\_pix,	\*dst\_pix;

1465	ConvertEntry \*ce;

1466	AVPicture tmp1,	\*tmp = &tmp1;

1467

1468	if (src\_pix\_fmt < 0 || src\_pix\_fmt >= PIX\_FMT\_NB || dst\_pix\_fmt < 0 || dst\_pix\_fmt >= PIX\_FMT\_NB)

1469	return	- 1;

1470

1471	if (src\_width <= 0 || src\_height <= 0)

1472	return 0;

1473

1474	if (!inited)

1475	{

1476	inited = 1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1477	img\_convert\_init();

1478	}

1479

1480	dst\_width = src\_width;

1481	dst\_height = src\_height;

1482

1483	dst\_pix = &pix\_fmt\_info[dst\_pix\_fmt];

1484	src\_pix = &pix\_fmt\_info[src\_pix\_fmt];

1485

1486	if (src\_pix\_fmt == dst\_pix\_fmt)	// no conversion needed: just copy

1487	{

1488	img\_copy(dst, src, dst\_pix\_fmt, dst\_width, dst\_height);

1489	return 0;

1490	}

1491

1492	ce = &convert\_table[src\_pix\_fmt][dst\_pix\_fmt];

1493	if (ce->convert)

1494	{

1495	ce->convert(dst, src, dst\_width, dst\_height); // specific conversion routine

1496	return 0;

1497	}

1498

1499	if (is\_yuv\_planar(dst\_pix) && src\_pix\_fmt == PIX\_FMT\_GRAY8) // gray to YUV

1500	{

1501	int w, h, y;

1502	uint8\_t \*d;

1503

1504	if (dst\_pix->color\_type == FF\_COLOR\_YUV\_JPEG)

1505	{

1506	ff\_img\_copy\_plane(dst->data[0], dst->linesize[0], src->data[0], src->linesize[0] ,

1507	dst\_width, dst\_height);

1508	}

1509	else

1510	{

1511	img\_apply\_table(dst->data[0], dst->linesize[0], src->data[0], src->linesize[0],

1512	dst\_width, dst\_height, y\_jpeg\_to\_ccir);

1513	}

1514

1515	w = dst\_width;	// fill U and V with 128

1516	h = dst\_height;

1517	w >>= dst\_pix->x\_chroma\_shift;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1518	h >>= dst\_pix->y\_chroma\_shift;

1519	for (i = 1; i <= 2; i++)

1520	{

1521	d = dst->data[i];

1522	for (y = 0; y < h; y++)

1523	{

1524	memset(d, 128, w);

1525	d += dst->linesize[i];

1526	}

1527	}

1528	return 0;

1529	}

1530

1531	if (is\_yuv\_planar(src\_pix) && dst\_pix\_fmt == PIX\_FMT\_GRAY8)	// YUV to gray

1532	{

1533	if (src\_pix->color\_type == FF\_COLOR\_YUV\_JPEG)

1534	{

1535	ff\_img\_copy\_plane(dst->data[0], dst->linesize[0], src->data[0], src->linesize[0] ,

1536	dst\_width, dst\_height);

1537	}

1538	else

1539	{

1540	img\_apply\_table(dst->data[0], dst->linesize[0], src->data[0], src->linesize[0],

1541	dst\_width, dst\_height, y\_ccir\_to\_jpeg);

1542	}

1543	return 0;

1544	}

1545

1546	if (is\_yuv\_planar(dst\_pix) && is\_yuv\_planar(src\_pix))	// YUV to YUV planar

1547	{

1548	int x\_shift, y\_shift, w, h, xy\_shift;

1549	void(\*resize\_func)(uint8\_t \*dst, int dst\_wrap, const uint8\_t \*src, int src\_wrap,

1550	int width, int height);

1551

1552	// compute chroma size of the smallest dimensions

1553	w = dst\_width;

1554	h = dst\_height;

1555	if (dst\_pix->x\_chroma\_shift >= src\_pix->x\_chroma\_shift)

1556	w >>= dst\_pix->x\_chroma\_shift;

1557	else

1558	w >>= src\_pix->x\_chroma\_shift;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1559	if (dst\_pix->y\_chroma\_shift >= src\_pix->y\_chroma\_shift)

1560	h >>= dst\_pix->y\_chroma\_shift;

1561	else

1562	h >>= src\_pix->y\_chroma\_shift;

1563

1564	x\_shift = (dst\_pix->x\_chroma\_shift - src\_pix->x\_chroma\_shift);

1565	y\_shift = (dst\_pix->y\_chroma\_shift - src\_pix->y\_chroma\_shift);

1566	xy\_shift = ((x\_shift &0xf) << 4) | (y\_shift &0xf);

1567

1568	// there must be filters for conversion at least from and to YUV444 format

1569	switch (xy\_shift)

1570	{

1571	case 0x00:

1572	resize\_func = ff\_img\_copy\_plane;

1573	break;

1574	case 0x10:

1575	resize\_func = shrink21;

1576	break;

1577	case 0x20:

1578	resize\_func = shrink41;

1579	break;

1580	case 0x01:

1581	resize\_func = shrink12;

1582	break;

1583	case 0x11:

1584	resize\_func = ff\_shrink22;

1585	break;

1586	case 0x22:

1587	resize\_func = ff\_shrink44;

1588	break;

1589	case 0xf0:

1590	resize\_func = grow21;

1591	break;

1592	case 0xe0:

1593	resize\_func = grow41;

1594	break;

1595	case 0xff:

1596	resize\_func = grow22;

1597	break;

1598	case 0xee:

1599	resize\_func = grow44;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1600	break;

1601	case 0xf1:

1602	resize\_func = conv411;

1603	break;

1604	default:

1605	goto no\_chroma\_filter; // currently not handled

1606	}

1607

1608	ff\_img\_copy\_plane(dst->data[0], dst->linesize[0], src->data[0], src->linesize[0],

1609	dst\_width, dst\_height);

1610

1611	for (i = 1; i <= 2; i++)

1612	resize\_func(dst->data[i], dst->linesize[i], src->data[i], src->linesize[i],

1613	dst\_width >> dst\_pix->x\_chroma\_shift, dst\_height >> dst\_pix->y\_chroma\_shift);

1614

1615	// if yuv color space conversion is needed, we do it here on the destination image

1616	if (dst\_pix->color\_type != src\_pix->color\_type)

1617	{

1618	const uint8\_t \*y\_table,	\*c\_table;

1619	if (dst\_pix->color\_type == FF\_COLOR\_YUV)

1620	{

1621	y\_table = y\_jpeg\_to\_ccir;

1622	c\_table = c\_jpeg\_to\_ccir;

1623	}

1624	else

1625	{

1626	y\_table = y\_ccir\_to\_jpeg;

1627	c\_table = c\_ccir\_to\_jpeg;

1628	}

1629

1630	img\_apply\_table(dst->data[0], dst->linesize[0], dst->data[0], dst->linesize[0],

1631	dst\_width, dst\_height, y\_table);

1632

1633	for (i = 1; i <= 2; i++)

1634	img\_apply\_table(dst->data[i], dst->linesize[i], dst->data[i], dst->linesize[i],

1635	dst\_width >> dst\_pix->x\_chroma\_shift, dst\_height >> dst\_pix->y\_chroma\_shift, c\_table);

1636	}

1637	return 0;

1638	}

1639

1640 no\_chroma\_filter:	// try to use an intermediate format![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1641

1642	if (src\_pix\_fmt == PIX\_FMT\_YUV422 || dst\_pix\_fmt == PIX\_FMT\_YUV422)

1643	{

1644	int\_pix\_fmt = PIX\_FMT\_YUV422P; // specific case: convert to YUV422P first

1645	}

1646	else if (src\_pix\_fmt == PIX\_FMT\_UYVY422 || dst\_pix\_fmt == PIX\_FMT\_UYVY422)

1647	{

1648

1649	int\_pix\_fmt = PIX\_FMT\_YUV422P; // specific case: convert to YUV422P first

1650	}

1651	else if (src\_pix\_fmt == PIX\_FMT\_UYVY411 || dst\_pix\_fmt == PIX\_FMT\_UYVY411)

1652	{

1653

1654	int\_pix\_fmt = PIX\_FMT\_YUV411P; // specific case: convert to YUV411P first

1655	}

1656	else if ((src\_pix->color\_type == FF\_COLOR\_GRAY && src\_pix\_fmt != PIX\_FMT\_GRAY8)

1657	|| (dst\_pix->color\_type == FF\_COLOR\_GRAY && dst\_pix\_fmt != PIX\_FMT\_GRAY8))

1658	{

1659

1660	int\_pix\_fmt = PIX\_FMT\_GRAY8;	// gray8 is the normalized format

1661	}

1662	else if ((is\_yuv\_planar(src\_pix) && src\_pix\_fmt != PIX\_FMT\_YUV444P

1663	&& src\_pix\_fmt != PIX\_FMT\_YUVJ444P))

1664	{

1665	if (src\_pix->color\_type == FF\_COLOR\_YUV\_JPEG) // yuv444 is the normalized format

1666	int\_pix\_fmt = PIX\_FMT\_YUVJ444P;

1667	else

1668	int\_pix\_fmt = PIX\_FMT\_YUV444P;

1669	}

1670	else if ((is\_yuv\_planar(dst\_pix) && dst\_pix\_fmt != PIX\_FMT\_YUV444P

1671	&& dst\_pix\_fmt != PIX\_FMT\_YUVJ444P))

1672	{

1673	if (dst\_pix->color\_type == FF\_COLOR\_YUV\_JPEG) // yuv444 is the normalized format

1674	int\_pix\_fmt = PIX\_FMT\_YUVJ444P;

1675	else

1676	int\_pix\_fmt = PIX\_FMT\_YUV444P;

1677	}

1678	else	// the two formats are rgb or gray8 or yuv[j]444p

1679	{

1680	if (src\_pix->is\_alpha && dst\_pix->is\_alpha)

1681	int\_pix\_fmt = PIX\_FMT\_RGBA32;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

1682	else

1683	int\_pix\_fmt = PIX\_FMT\_RGB24;

1684	}

1685

1686	if (avpicture\_alloc(tmp, int\_pix\_fmt, dst\_width, dst\_height) < 0)

1687	return	- 1;

1688

1689	ret =	- 1;

1690

1691	if (img\_convert(tmp, int\_pix\_fmt, src, src\_pix\_fmt, src\_width, src\_height) < 0)

1692	goto fail1;

1693

1694	if (img\_convert(dst, dst\_pix\_fmt, tmp, int\_pix\_fmt, dst\_width, dst\_height) < 0)

1695	goto fail1;

1696	ret = 0;

1697

1698 fail1:

1699	avpicture\_free(tmp);

1700	return ret;

1701 }

1702

1703 #undef FIX

### ![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)**9 msrle.c 文件**
9.1 功能描述

此文件实现微软行程长度压缩算法解码器，此文件请各位参考压缩算法自己仔细分析。

9.2 文件注释

1	#include <stdio.h>

2	#include <stdlib.h>

3	#include <string.h>

4

5	#include "../libavutil/common.h"

6	#include "avcodec.h"

7	#include "dsputil.h"

8

9	#define FF\_BUFFER\_HINTS\_VALID	0x01 // Buffer hints value is meaningful (if 0 ignore)

10	#define FF\_BUFFER\_HINTS\_READABLE 0x02 // Codec will read from buffer

11	#define FF\_BUFFER\_HINTS\_PRESERVE 0x04 // User must not alter buffer content

12	#define FF\_BUFFER\_HINTS\_REUSABLE 0x08 // Codec will reuse the buffer (update)

13![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

此文件请各位参考压缩算法自己仔细分析。

14	typedef struct MsrleContext

15	{

16	AVCodecContext \*avctx;

17	AVFrame frame;

18

19	unsigned char \*buf;

20	int size;

21

22	} MsrleContext;

23

24	#define FETCH\_NEXT\_STREAM\_BYTE() \

25	if (stream\_ptr >= s->size) \

26	{ \

27	return; \

28	} \

29	stream\_byte = s->buf[stream\_ptr++];

30

31	static void msrle\_decode\_pal4(MsrleContext \*s)

32	{

33	int stream\_ptr = 0;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

34	unsigned char rle\_code;

35	unsigned char extra\_byte, odd\_pixel;

36	unsigned char stream\_byte;

37	int pixel\_ptr = 0;

38	int row\_dec = s->frame.linesize[0];

39	int row\_ptr = (s->avctx->height - 1) \*row\_dec;

40	int frame\_size = row\_dec \* s->avctx->height;

41	int i;

42

43	// make the palette available

44	memcpy(s->frame.data[1], s->avctx->palctrl->palette, AVPALETTE\_SIZE);

45	if (s->avctx->palctrl->palette\_changed)

46	{

47	//	s->frame.palette\_has\_changed = 1;

48	s->avctx->palctrl->palette\_changed = 0;

49	}

50

51	while (row\_ptr >= 0)

52	{

53	FETCH\_NEXT\_STREAM\_BYTE();

54	rle\_code = stream\_byte;

55	if (rle\_code == 0)

56	{

57	// fetch the next byte to see how to handle escape code

58	FETCH\_NEXT\_STREAM\_BYTE();

59	if (stream\_byte == 0)

60	{

61	// line is done, goto the next one

62	row\_ptr -= row\_dec;

63	pixel\_ptr = 0;

64	}

65	else if (stream\_byte == 1)

66	{

67	// decode is done

68	return ;

69	}

70	else if (stream\_byte == 2)

71	{

72	// reposition frame decode coordinates

73	FETCH\_NEXT\_STREAM\_BYTE();

74	pixel\_ptr += stream\_byte;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

75	FETCH\_NEXT\_STREAM\_BYTE();

76	row\_ptr -= stream\_byte \* row\_dec;

77	}

78	else

79	{

80	// copy pixels from encoded stream

81	odd\_pixel = stream\_byte &1;

82	rle\_code = (stream\_byte + 1) / 2;

83	extra\_byte = rle\_code &0x01;

84	if ((row\_ptr + pixel\_ptr + stream\_byte > frame\_size) || (row\_ptr < 0))

85	{

86	return ;

87	}

88

89	for (i = 0; i < rle\_code; i++)

90	{

91	if (pixel\_ptr >= s->avctx->width)

92	break;

93	FETCH\_NEXT\_STREAM\_BYTE();

94	s->frame.data[0][row\_ptr + pixel\_ptr] = stream\_byte >> 4;

95	pixel\_ptr++;

96	if (i + 1 == rle\_code && odd\_pixel)

97	break;

98	if (pixel\_ptr >= s->avctx->width)

99	break;

100	s->frame.data[0][row\_ptr + pixel\_ptr] = stream\_byte &0x0F;

101	pixel\_ptr++;

102	}

103

104	// if the RLE code is odd, skip a byte in the stream

105	if (extra\_byte)

106	stream\_ptr++;

107	}

108	}

109	else

110	{

111	// decode a run of data

112	if ((row\_ptr + pixel\_ptr + stream\_byte > frame\_size) || (row\_ptr < 0))

113	{

114	return ;

115	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

116	FETCH\_NEXT\_STREAM\_BYTE();

117	for (i = 0; i < rle\_code; i++)

118	{

119	if (pixel\_ptr >= s->avctx->width)

120	break;

121	if ((i &1) == 0)

122	s->frame.data[0][row\_ptr + pixel\_ptr] = stream\_byte >> 4;

123	else

124	s->frame.data[0][row\_ptr + pixel\_ptr] = stream\_byte &0x0F;

125	pixel\_ptr++;

126	}

127	}

128	}

129

130	// one last sanity check on the way out

131	if (stream\_ptr < s->size)

132	{

133	// error

134	}

135 }

136

137 static void msrle\_decode\_pal8(MsrleContext \*s)

138 {

139	int stream\_ptr = 0;

140	unsigned char rle\_code;

141	unsigned char extra\_byte;

142	unsigned char stream\_byte;

143	int pixel\_ptr = 0;

144	int row\_dec = s->frame.linesize[0];

145	int row\_ptr = (s->avctx->height - 1) \*row\_dec;

146	int frame\_size = row\_dec \* s->avctx->height;

147

148	// make the palette available

149	memcpy(s->frame.data[1], s->avctx->palctrl->palette, AVPALETTE\_SIZE);

150	if (s->avctx->palctrl->palette\_changed)

151	{

152 //	s->frame.palette\_has\_changed = 1;

153	s->avctx->palctrl->palette\_changed = 0;

154	}

155

156	while (row\_ptr >= 0)


|157|{||
| - | - | - |
|158||FETCH\_NEXT\_STREAM\_BYTE();|
|159||rle\_code = stream\_byte;|
160	if (rle\_code == 0)

161	{

162	// fetch the next byte to see how to handle escape code

163	FETCH\_NEXT\_STREAM\_BYTE();

164	if (stream\_byte == 0)

165	{

166	// line is done, goto the next one

167	row\_ptr -= row\_dec;

168	pixel\_ptr = 0;

169	}

170	else if (stream\_byte == 1)

171	{

172	// decode is done

173	return ;

174	}

175	else if (stream\_byte == 2)

176	{

177	// reposition frame decode coordinates

178	FETCH\_NEXT\_STREAM\_BYTE();

179	pixel\_ptr += stream\_byte;

180	FETCH\_NEXT\_STREAM\_BYTE();

181	row\_ptr -= stream\_byte \* row\_dec;

182	}

183	else

184	{

185	// copy pixels from encoded stream

186	if ((row\_ptr + pixel\_ptr + stream\_byte > frame\_size) || (row\_ptr < 0))

187	{

188	return ;

189	}

190

191	rle\_code = stream\_byte;

192	extra\_byte = stream\_byte &0x01;

193	if (stream\_ptr + rle\_code + extra\_byte > s->size)

194	{

195	return ;

196	}

197![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

198	while (rle\_code--)

199	{

200	FETCH\_NEXT\_STREAM\_BYTE();

201	s->frame.data[0][row\_ptr + pixel\_ptr] = stream\_byte;

202	pixel\_ptr++;

203	}

204

205	// if the RLE code is odd, skip a byte in the stream

206	if (extra\_byte)

207	stream\_ptr++;

208	}

209	}

210	else

211	{

212	// decode a run of data

213	if ((row\_ptr + pixel\_ptr + stream\_byte > frame\_size) || (row\_ptr < 0))

214	{

215	return ;

216	}

217

218	FETCH\_NEXT\_STREAM\_BYTE();

219

220	while (rle\_code--)

221	{

222	s->frame.data[0][row\_ptr + pixel\_ptr] = stream\_byte;

223	pixel\_ptr++;

224	}

225	}

226	}

227

228	// one last sanity check on the way out

229	if (stream\_ptr < s->size)

230	{

231	// error

232	}

233 }

234

235 static int msrle\_decode\_init(AVCodecContext \*avctx)

236 {

237	MsrleContext \*s = (MsrleContext\*)avctx->priv\_data;

238![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

239	s->avctx = avctx;

240

241	avctx->pix\_fmt = PIX\_FMT\_PAL8;

242

243	s->frame.data[0] = NULL;

244

245	return 0;

246 }

247

248 static int msrle\_decode\_frame(AVCodecContext \*avctx, void \*data, int \*data\_size, uint8\_t \*buf, int buf\_size)

249 {

250	MsrleContext \*s = (MsrleContext\*)avctx->priv\_data;

251

252	s->buf = buf;

253	s->size = buf\_size;

254

255	if (avctx->reget\_buffer(avctx, &s->frame))

256	return	- 1;

257

258	switch (avctx->bits\_per\_sample)

259	{

260	case 8:

261	msrle\_decode\_pal8(s);

262	break;

263	case 4:

264	msrle\_decode\_pal4(s);

265	break;

266	default:

267	break;

268	}

269

270	\*data\_size = sizeof(AVFrame);

271	\*(AVFrame\*)data = s->frame;

272

273	// report that the buffer was completely consumed

274	return buf\_size;

275 }

276

277 static int msrle\_decode\_end(AVCodecContext \*avctx)

278 {

279	MsrleContext \*s = (MsrleContext\*)avctx->priv\_data;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

280

281	// release the last frame

282	if (s->frame.data[0])

283	avctx->release\_buffer(avctx, &s->frame);

284

285	return 0;

286 }

287

288 AVCodec msrle\_decoder =

289 {

290	"msrle",

291	CODEC\_TYPE\_VIDEO,

292	CODEC\_ID\_MSRLE,

293	sizeof(MsrleContext),

294	msrle\_decode\_init,

295	NULL,

296	msrle\_decode\_end,

297	msrle\_decode\_frame

298 };![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **10 turespeech\_data.h 文件**
10.1 功能描述

此文件定义 true speed 音频解码器使用的常数，此文件请各位参考 TrueSpeed 压缩算法自己仔细分析。

10.2 文件注释

1	#ifndef   TRUESPEECH\_DATA 	

2	#define   TRUESPEECH\_DATA 	

3

4	#pragma warning(disable:4305 )

5![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

此文件请各位参考 TrueSpeed 压缩算法自己仔细分析。

6	/\* codebooks fo expanding input filter \*/

7	static const int16\_t ts\_cb\_0[32] =

8	{

9	0x8240, 0x8364, 0x84CE, 0x865D, 0x8805, 0x89DE, 0x8BD7, 0x8DF4,

10	0x9051, 0x92E2, 0x95DE, 0x990F, 0x9C81, 0xA079, 0xA54C, 0xAAD2,

11	0xB18A, 0xB90A, 0xC124, 0xC9CC, 0xD339, 0xDDD3, 0xE9D6, 0xF893,

12	0x096F, 0x1ACA, 0x29EC, 0x381F, 0x45F9, 0x546A, 0x63C3, 0x73B5,

13	};

14

15	static const int16\_t ts\_cb\_1[32] =

16	{

17	0x9F65, 0xB56B, 0xC583, 0xD371, 0xE018, 0xEBB4, 0xF61C, 0xFF59,

18	0x085B, 0x1106, 0x1952, 0x214A, 0x28C9, 0x2FF8, 0x36E6, 0x3D92,

19	0x43DF, 0x49BB, 0x4F46, 0x5467, 0x5930, 0x5DA3, 0x61EC, 0x65F9,

20	0x69D4, 0x6D5A, 0x709E, 0x73AD, 0x766B, 0x78F0, 0x7B5A, 0x7DA5,

21	};

22

23	static const int16\_t ts\_cb\_2[16] =

24	{

25	0x96F8, 0xA3B4, 0xAF45, 0xBA53, 0xC4B1, 0xCECC, 0xD86F, 0xE21E,

26	0xEBF3, 0xF640, 0x00F7, 0x0C20, 0x1881, 0x269A, 0x376B, 0x4D60,

27	};

28

29	static const int16\_t ts\_cb\_3[16] =

30	{

31	0xC654, 0xDEF2, 0xEFAA, 0xFD94, 0x096A, 0x143F, 0x1E7B, 0x282C,

32	0x3176, 0x3A89, 0x439F, 0x4CA2, 0x557F, 0x5E50, 0x6718, 0x6F8D,

33	};![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

34

35	static const int16\_t ts\_cb\_4[16] =

36	{

37	0xABE7, 0xBBA8, 0xC81C, 0xD326, 0xDD0E, 0xE5D4, 0xEE22, 0xF618,

38	0xFE28, 0x064F, 0x0EB7, 0x17B8, 0x21AA, 0x2D8B, 0x3BA2, 0x4DF9,

39	};

40

41	static const int16\_t ts\_cb\_5[8] = { 0xD51B, 0xF12E, 0x042E, 0x13C7, 0x2260, 0x311B, 0x40DE, 0x5385,};

42

43	static const int16\_t ts\_cb\_6[8] = { 0xB550, 0xC825, 0xD980, 0xE997, 0xF883, 0x0752, 0x1811, 0x2E18,};

44

45	static const int16\_t ts\_cb\_7[8] = { 0xCEF0, 0xE4F9, 0xF6BB, 0x0646, 0x14F5, 0x23FF, 0x356F, 0x4A8D,};

46

47	static const int16\_t \*ts\_codebook[8] = {ts\_cb\_0, ts\_cb\_1, ts\_cb\_2, ts\_cb\_3,

48	ts\_cb\_4, ts\_cb\_5, ts\_cb\_6, ts\_cb\_7};

49	/\* table used for decoding pulse positions \*/

50	static const int16\_t ts\_140[120] =

51	{

52	0x0E46, 0x0CCC, 0x0B6D, 0x0A28, 0x08FC, 0x07E8, 0x06EB, 0x0604,

53	0x0532, 0x0474, 0x03C9, 0x0330, 0x02A8, 0x0230, 0x01C7, 0x016C,

54	0x011E, 0x00DC, 0x00A5, 0x0078, 0x0054, 0x0038, 0x0023, 0x0014,

55	0x000A, 0x0004, 0x0001, 0x0000, 0x0000, 0x0000,

56

57	0x0196, 0x017A, 0x015F, 0x0145, 0x012C, 0x0114, 0x00FD, 0x00E7,

58	0x00D2, 0x00BE, 0x00AB, 0x0099, 0x0088, 0x0078, 0x0069, 0x005B,

59	0x004E, 0x0042, 0x0037, 0x002D, 0x0024, 0x001C, 0x0015, 0x000F,

60	0x000A, 0x0006, 0x0003, 0x0001, 0x0000, 0x0000,

61

62	0x001D, 0x001C, 0x001B, 0x001A, 0x0019, 0x0018, 0x0017, 0x0016,

63	0x0015, 0x0014, 0x0013, 0x0012, 0x0011, 0x0010, 0x000F, 0x000E,

64	0x000D, 0x000C, 0x000B, 0x000A, 0x0009, 0x0008, 0x0007, 0x0006,

65	0x0005, 0x0004, 0x0003, 0x0002, 0x0001, 0x0000,

66

67	0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001,

68	0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001,

69	0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001,

70	0x0001, 0x0001, 0x0001, 0x0001, 0x0001, 0x0001

71	};

72

73	/\* filter for correlated input filter \*/

74	static const int16\_t ts\_230[8] = { 0x7F3B, 0x7E78, 0x7DB6, 0x7CF5, 0x7C35, 0x7B76, 0x7AB8, 0x79FC };![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

75

76	/\* two-point filters table \*/

77	static const int16\_t ts\_240[25 \* 2] =

78	{

79	0xED2F, 0x5239,

80	0x54F1, 0xE4A9,

81	0x2620, 0xEE3E,

82	0x09D6, 0x2C40,

83	0xEFB5, 0x2BE0,

84

85	0x3FE1, 0x3339,

86	0x442F, 0xE6FE,

87	0x4458, 0xF9DF,

88	0xF231, 0x43DB,

89	0x3DB0, 0xF705,

90

91	0x4F7B, 0xFEFB,

92	0x26AD, 0x0CDC,

93	0x33C2, 0x0739,

94	0x12BE, 0x43A2,

95	0x1BDF, 0x1F3E,

96

97	0x0211, 0x0796,

98	0x2AEB, 0x163F,

99	0x050D, 0x3A38,

100	0x0D1E, 0x0D78,

101	0x150F, 0x3346,

102

103	0x38A4, 0x0B7D,

104	0x2D5D, 0x1FDF,

105	0x19B7, 0x2822,

106	0x0D99, 0x1F12,

107	0x194C, 0x0CE6

108 };

109

110 /\* possible pulse values \*/

111 static const int16\_t ts\_562[64] =

112 {

113	0x0002, 0x0006, 0xFFFE, 0xFFFA,

114	0x0004, 0x000C, 0xFFFC, 0xFFF4,

115	0x0006, 0x0012, 0xFFFA, 0xFFEE,![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

116	0x000A, 0x001E, 0xFFF6, 0xFFE2,

117	0x0010, 0x0030, 0xFFF0, 0xFFD0,

118	0x0019, 0x004B, 0xFFE7, 0xFFB5,

119	0x0028, 0x0078, 0xFFD8, 0xFF88,

120	0x0040, 0x00C0, 0xFFC0, 0xFF40,

121	0x0065, 0x012F, 0xFF9B, 0xFED1,

122	0x00A1, 0x01E3, 0xFF5F, 0xFE1D,

123	0x0100, 0x0300, 0xFF00, 0xFD00,

124	0x0196, 0x04C2, 0xFE6A, 0xFB3E,

125	0x0285, 0x078F, 0xFD7B, 0xF871,

126	0x0400, 0x0C00, 0xFC00, 0xF400,

127	0x0659, 0x130B, 0xF9A7, 0xECF5,

128	0x0A14, 0x1E3C, 0xF5EC, 0xE1C4

129 };

130

131 /\* filters used in final output calculations \*/

132 static const int16\_t ts\_5E2[8] = { 0x4666, 0x26B8, 0x154C, 0x0BB6, 0x0671, 0x038B, 0x01F3, 0x0112 };

133

134 static const int16\_t ts\_5F2[8] = { 0x6000, 0x4800, 0x3600, 0x2880, 0x1E60, 0x16C8, 0x1116, 0x0CD1 };

135

136 #endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **11 turespeech.c 文件**
11.1 功能描述

此文件实现 true speed 音频解码器，此文件请各位参考压缩算法自己仔细分析。

11.2 文件注释

1	#include "avcodec.h"

2

3	#include "truespeech\_data.h"

4

5	// TrueSpeech decoder context

6![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.058.png)

此文件请各位参考 TrueSpeed 压缩算法自己仔细分析。

7	typedef struct TSContext

8	{

9	// input data

10	int16\_t vector[8];	// input vector: 5/5/4/4/4/3/3/3

11	int offset1[2];	// 8-bit value, used in one copying offset

12	int offset2[4];	// 7-bit value, encodes offsets for copying and for two-point filter

13	int pulseoff[4];	// 4-bit offset of pulse values block

14	int pulsepos[4];	// 27-bit variable, encodes 7 pulse positions

15	int pulseval[4];	// 7x2-bit pulse values

16	int flag;	// 1-bit flag, shows how to choose filters

17	// temporary data

18	int filtbuf[146];	// some big vector used for storing filters

19	int prevfilt[8];	// filter from previous frame

20	int16\_t tmp1[8];	// coefficients for adding to out

21	int16\_t tmp2[8];	// coefficients for adding to out

22	int16\_t tmp3[8];	// coefficients for adding to out

23	int16\_t cvector[8];	// correlated input vector

24	int filtval;	// gain value for one function

25	int16\_t newvec[60];	// tmp vector

26	int16\_t filters[32]; // filters for every subframe

27	} TSContext;

28

29	#if !defined(LE\_32)

30	#define LE\_32(x)	((((uint8\_t\*)(x))[3] << 24)| (((uint8\_t\*)(x))[2] << 16) |	\

31	(((uint8\_t\*)(x))[1] << 8) | ((uint8\_t\*)(x))[0])

32	#endif

33![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

34	static int truespeech\_decode\_init(AVCodecContext \*avctx)

35	{

36	return 0;

37	}

38

39	static void truespeech\_read\_frame(TSContext \*dec, uint8\_t \*input)

40	{

41	uint32\_t t;

42

43	t = LE\_32(input); // first dword

44	input += 4;

45

46	dec->flag = t &1;

47

48	dec->vector[0] = ts\_codebook[0][(t >> 1) &0x1F];

49	dec->vector[1] = ts\_codebook[1][(t >> 6) &0x1F];

50	dec->vector[2] = ts\_codebook[2][(t >> 11) &0xF];

51	dec->vector[3] = ts\_codebook[3][(t >> 15) &0xF];

52	dec->vector[4] = ts\_codebook[4][(t >> 19) &0xF];

53	dec->vector[5] = ts\_codebook[5][(t >> 23) &0x7];

54	dec->vector[6] = ts\_codebook[6][(t >> 26) &0x7];

55	dec->vector[7] = ts\_codebook[7][(t >> 29) &0x7];

56

57

58	t = LE\_32(input); // second dword

59	input += 4;

60

61	dec->offset2[0] = (t >> 0) &0x7F;

62	dec->offset2[1] = (t >> 7) &0x7F;

63	dec->offset2[2] = (t >> 14) &0x7F;

64	dec->offset2[3] = (t >> 21) &0x7F;

65

66	dec->offset1[0] = ((t >> 28) &0xF) << 4;

67

68

69	t = LE\_32(input); // third dword

70	input += 4;

71

72	dec->pulseval[0] = (t >> 0) &0x3FFF;

73	dec->pulseval[1] = (t >> 14) &0x3FFF;

74![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

75	dec->offset1[1] = (t >> 28) &0x0F;

76

77

78	t = LE\_32(input); // fourth dword

79	input += 4;

80

81	dec->pulseval[2] = (t >> 0) &0x3FFF;

82	dec->pulseval[3] = (t >> 14) &0x3FFF;

83

84	dec->offset1[1] |= ((t >> 28) &0x0F) << 4;

85

86

87	t = LE\_32(input); // fifth dword

88	input += 4;

89

90	dec->pulsepos[0] = (t >> 4) &0x7FFFFFF;

91

92	dec->pulseoff[0] = (t >> 0) &0xF;

93

94	dec->offset1[0] |= (t >> 31) &1;

95

96

97	t = LE\_32(input); // sixth dword

98	input += 4;

99

100	dec->pulsepos[1] = (t >> 4) &0x7FFFFFF;

101

102	dec->pulseoff[1] = (t >> 0) &0xF;

103

104	dec->offset1[0] |= ((t >> 31) &1) << 1;

105

106

107	t = LE\_32(input); // seventh dword

108	input += 4;

109

110	dec->pulsepos[2] = (t >> 4) &0x7FFFFFF;

111

112	dec->pulseoff[2] = (t >> 0) &0xF;

113

114	dec->offset1[0] |= ((t >> 31) &1) << 2;

115![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

116

117	t = LE\_32(input); // eighth dword

118	input += 4;

119

120	dec->pulsepos[3] = (t >> 4) &0x7FFFFFF;

121

122	dec->pulseoff[3] = (t >> 0) &0xF;

123

124	dec->offset1[0] |= ((t >> 31) &1) << 3;

125 }

126

127 static void truespeech\_correlate\_filter(TSContext \*dec)

128 {

129	int16\_t tmp[8];

130	int i, j;

131

132	for (i = 0; i < 8; i++)

133	{

134	if (i > 0)

135	{

136	memcpy(tmp, dec->cvector, i \*2);

137	for (j = 0; j < i; j++)

138	dec->cvector[j] =((tmp[i-j-1]\*dec->vector[i])+(dec->cvector[j]<< 15)+0x4000)>>15;

139	}

140	dec->cvector[i] = (8-dec->vector[i]) >> 3;

141	}

142

143	for (i = 0; i < 8; i++)

144	dec->cvector[i] = (dec->cvector[i] \*ts\_230[i]) >> 15;

145

146	dec->filtval = dec->vector[0];

147 }

148

149 static void truespeech\_filters\_merge(TSContext \*dec)

150 {

151	int i;

152

153	if (!dec->flag)

|154|{||
| - | - | - |
|155||for (i = 0; i < 8; i++)|
|156||{|

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)157	dec->filters[i + 0] = dec->prevfilt[i];

158	dec->filters[i + 8] = dec->prevfilt[i];

159	}

160	}

161	else

162	{

163	for (i = 0; i < 8; i++)

164	{

165	dec->filters[i + 0] = (dec->cvector[i] \*21846+dec->prevfilt[i] \*10923+16384) >>

15;

166	dec->filters[i + 8] = (dec->cvector[i] \*10923+dec->prevfilt[i] \*21846+16384) >>

15;

167	}

168	}

169	for (i = 0; i < 8; i++)

170	{

171	dec->filters[i + 16] = dec->cvector[i];

172	dec->filters[i + 24] = dec->cvector[i];

173	}

174 }

175

176 static void truespeech\_apply\_twopoint\_filter(TSContext \*dec, int quart)

177 {

178	int16\_t tmp[146+60],	\*ptr0,	\*ptr1,	\*filter;

179	int i, t, off;

180

181	t = dec->offset2[quart];

182	if (t == 127)

183	{

184	memset(dec->newvec, 0, 60 \*2);

185	return ;

186	}

187

188	for (i = 0; i < 146; i++)

189	tmp[i] = dec->filtbuf[i];

190

191	off = (t / 25) + dec->offset1[quart >> 1] + 18;

192	ptr0 = tmp + 145-off;

193	ptr1 = tmp + 146;

194	filter = (int16\_t\*)ts\_240 + (t % 25) \*2;

195	for (i = 0; i < 60; i++)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

196	{

197	t = (ptr0[0] \*filter[0] + ptr0[1] \*filter[1] + 0x2000) >> 14;

198	ptr0++;

199	dec->newvec[i] = t;

200	ptr1[i] = t;

201	}

202 }

203

204 static void truespeech\_place\_pulses(TSContext \*dec, int16\_t \*out, int quart)

205 {

206	int16\_t tmp[7];

207	int i, j, t;

208	int16\_t \*ptr1,	\*ptr2;

209	int coef;

210

211	memset(out, 0, 60 \*2);

212	for (i = 0; i < 7; i++)

213	{

214	t = dec->pulseval[quart] &3;

215	dec->pulseval[quart] >>= 2;

216	tmp[6-i] = ts\_562[dec->pulseoff[quart] \*4+t];

217	}

218

219	coef = dec->pulsepos[quart] >> 15;

220	ptr1 = (int16\_t\*)ts\_140 + 30;

221	ptr2 = tmp;

222	for (i = 0, j = 3; (i < 30) && (j > 0); i++)

223	{

224	t =	\*ptr1++;

225	if (coef >= t)

226	coef -= t;

227	else

228	{

229	out[i] =	\*ptr2++;

230	ptr1 += 30;

231	j--;

232	}

233	}

234	coef = dec->pulsepos[quart] &0x7FFF;

235	ptr1 = (int16\_t\*)ts\_140;

236	for (i = 30, j = 4; (i < 60) && (j > 0); i++)


|237|{||
| - | - | - |
|238||t =	\*ptr1++;|
|239||if (coef >= t)|
240	coef -= t;

241	else

242	{

243	out[i] =	\*ptr2++;

244	ptr1 += 30;

245	j--;

246	}

247	}

248 }

249

250 static void truespeech\_update\_filters(TSContext \*dec, int16\_t \*out, int quart)

251 {

252	int i;

253

254	for (i = 0; i < 86; i++)

255	dec->filtbuf[i] = dec->filtbuf[i + 60];

256

257	for (i = 0; i < 60; i++)

258	{

259	dec->filtbuf[i + 86] = out[i] + dec->newvec[i] - (dec->newvec[i] >> 3);

260	out[i] += dec->newvec[i];

261	}

262 }

263

264 static void truespeech\_synth(TSContext \*dec, int16\_t \*out, int quart)

265 {

266	int i, k;

267	int t[8];

268	int16\_t \*ptr0,	\*ptr1;

269

270	ptr0 = dec->tmp1;

271	ptr1 = dec->filters + quart \* 8;

272	for (i = 0; i < 60; i++)

273	{

274	int sum = 0;

275	for (k = 0; k < 8; k++)

276	sum += ptr0[k] \*ptr1[k];

277	sum = (sum + (out[i] << 12) + 0x800) >> 12;


|278||out[i] = clip(sum,	- 0x7FFE, 0x7FFE);|
| - | - | - |
|279||for (k = 7; k > 0; k--)|
|280||ptr0[k] = ptr0[k - 1];|
|281||ptr0[0] = out[i];|
|282|}||
|283|||
284	for (i = 0; i < 8; i++)

285	t[i] = (ts\_5E2[i] \*ptr1[i]) >> 15;

286

287	ptr0 = dec->tmp2;

288	for (i = 0; i < 60; i++)

289	{

290	int sum = 0;

291	for (k = 0; k < 8; k++)

292	sum += ptr0[k] \*t[k];

293	for (k = 7; k > 0; k--)

294	ptr0[k] = ptr0[k - 1];

295	ptr0[0] = out[i];

296	out[i] = ((out[i] << 12) - sum) >> 12;

297	}

298

299	for (i = 0; i < 8; i++)

300	t[i] = (ts\_5F2[i] \*ptr1[i]) >> 15;

301

302	ptr0 = dec->tmp3;

303	for (i = 0; i < 60; i++)

304	{

305	int sum = out[i] << 12;

306	for (k = 0; k < 8; k++)

307	sum += ptr0[k] \*t[k];

308	for (k = 7; k > 0; k--)

309	ptr0[k] = ptr0[k - 1];

310	ptr0[0] = clip((sum + 0x800) >> 12,	- 0x7FFE, 0x7FFE);

311

312	sum = ((ptr0[1]\*(dec->filtval - (dec->filtval >> 2))) >> 4) + sum;

313	sum = sum - (sum >> 3);

314	out[i] = clip((sum + 0x800) >> 12,	- 0x7FFE, 0x7FFE);

315	}

316 }

317

318 static void truespeech\_save\_prevvec(TSContext \*c)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

319 {

320	int i;

321

322	for (i = 0; i < 8; i++)

323	c->prevfilt[i] = c->cvector[i];

324 }

325

326 int truespeech\_decode\_frame(AVCodecContext \*avctx, void \*data, int \*data\_size, uint8\_t \*buf, int buf\_size)

327 {

328	TSContext \*c = avctx->priv\_data;

329

330	int i;

331	short \*samples = data;

332	int consumed = 0;

333	int16\_t out\_buf[240];

334

335	if (!buf\_size)

336	return 0;

337

338	while (consumed < buf\_size)

339	{

340	truespeech\_read\_frame(c, buf + consumed);

341	consumed += 32;

342

343	truespeech\_correlate\_filter(c);

344	truespeech\_filters\_merge(c);

345

346	memset(out\_buf, 0, 240 \*2);

347	for (i = 0; i < 4; i++)

348	{

349	truespeech\_apply\_twopoint\_filter(c, i);

350	truespeech\_place\_pulses(c, out\_buf + i \* 60, i);

351	truespeech\_update\_filters(c, out\_buf + i \* 60, i);

352	truespeech\_synth(c, out\_buf + i \* 60, i);

353	}

354

355	truespeech\_save\_prevvec(c);

356

357	for (i = 0; i < 240; i++)	// finally output decoded frame

358	\*samples++ = out\_buf[i];

359![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

360	}

361

362	\*data\_size = consumed \* 15;

363

364	return buf\_size;

365 }

366

367 AVCodec truespeech\_decoder =

368 {

369	"truespeech",

370	CODEC\_TYPE\_AUDIO,

371	CODEC\_ID\_TRUESPEECH,

372	sizeof(TSContext),

373	truespeech\_decode\_init,

374	NULL,

375	NULL,

376	truespeech\_decode\_frame,

377 };
## **5.3 libavformat容器模块**
### **1 文件列表**

|文件类型|文件名|大小(bytes)|
| - | - | - |
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|avformat.h|5352|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|allformats.c|299|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|cutils.c|606|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|file.c|1504|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.029.png)|avio.h|3103|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|avio.c|2286|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|aviobuf.c|6887|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|utils\_format.c|7662|
|![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.040.png)|avidec.c|21713|
### **2 avformat.h 文件**
2.1 功能描述

定义识别文件格式和媒体类型库使用的宏、数据结构和函数，通常这些宏、数据结构和函数在此模块内相 对全局有效。

2.2 文件注释

1	#ifndef AVFORMAT\_H

2	#define AVFORMAT\_H

3

4	#ifdef  cplusplus

5	extern "C"

6	{

7	#endif

8

9	#define LIBAVFORMAT\_VERSION\_INT ((50<<16)+(4<<8)+0)

10	#define LIBAVFORMAT\_VERSION	50.4.0

11	#define LIBAVFORMAT\_BUILD	LIBAVFORMAT\_VERSION\_INT

12

13	#define LIBAVFORMAT\_IDENT	"Lavf" AV\_STRINGIFY(LIBAVFORMAT\_VERSION)

14

15	#include "../libavcodec/avcodec.h"

16	#include "avio.h"

17![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.062.png)

一些简单的宏定义

18	#define AVERROR\_UNKNOWN	(-1)	// unknown error

19	#define AVERROR\_IO	(-2)	// i/o error

20	#define AVERROR\_NUMEXPECTED (-3)	// number syntax expected in filename

21	#define AVERROR\_INVALIDDATA (-4)	// invalid data found

22	#define AVERROR\_NOMEM	(-5)	// not enough memory

23	#define AVERROR\_NOFMT	(-6)	// unknown format

24	#define AVERROR\_NOTSUPP	(-7)	// operation not supported

25

26	#define AVSEEK\_FLAG\_BACKWARD 1	// seek backward

27	#define AVSEEK\_FLAG\_BYTE	2	// seeking based on position in bytes

28	#define AVSEEK\_FLAG\_ANY	4	// seek to any frame, even non keyframes

29

30	#define AVFMT\_NOFILE	0x0001	// no file should be opened

31

32	#define PKT\_FLAG\_KEY	0x0001

33

34	#define AVINDEX\_KEYFRAME	0x0001

35

36	#define AVPROBE\_SCORE\_MAX	100

37

38	#define MAX\_STREAMS 20

39

音视频数据包定义，在瘦身后的 ffplay 中，每一个包是一个完整的数据帧。注意保存音视频数据包的内存

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.063.png)是 malloc 出来的，用完后应及时用 free 归还给系统。

40	typedef struct AVPacket

41	{

42	int64\_t pts; // presentation time stamp in time\_base units // 表示时间，对视频是显示时间

43	int64\_t dts; // decompression time stamp in time\_base units// 解码时间，这个不是很重要

44	int64\_t pos; // byte position in stream, -1 if unknown

45	uint8\_t \*data;	// 实际保存音视频数据缓存的首地址

46	int size;	// 实际保存音视频数据缓存的大小

47	int stream\_index; // 当前音视频数据包对应的流索引，在本例中用于区别音频还是视频。

48	int flags;	// 数据包的一些标记，比如是否是关键帧等。

49	void(\*destruct)(struct AVPacket\*);

50	} AVPacket;

51

音视频数据包链表定义，注意每一个 AVPacketList 仅含有一个 AVPacket，和传统的很多很多节点的 list

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.063.png)不同，不要被 list 名字迷惑。![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

52	typedef struct AVPacketList

53	{

54	AVPacket pkt;

55	struct AVPacketList \*next; // 用于把各个 AVPacketList 串联起来。

56	} AVPacketList;

57![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.064.png)

释放掉音视频数据包占用的内存，把首地址置空是一个很好的习惯。

58	static inline void av\_destruct\_packet(AVPacket \*pkt)

59	{

60	av\_free(pkt->data);

61	pkt->data = NULL;

62	pkt->size = 0;

63	}

64![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.065.png)

判断一些指针，中转一下，释放掉音视频数据包占用的内存。

65	static inline void av\_free\_packet(AVPacket \*pkt)

66	{

67	if (pkt && pkt->destruct)

68	pkt->destruct(pkt);

69	}

70![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.066.png)

读文件往数据包中填数据，注意程序跑到这里时，文件偏移量已确定，要读数据的大小也确定，但是

数据包的缓存没有分配。分配好内存后，要初始化包的一些变量。

71	static inline int av\_get\_packet(ByteIOContext \*s, AVPacket \*pkt, int size)

72	{

73	int ret;

74	unsigned char \*data;

75	if ((unsigned)size > (unsigned)size + FF\_INPUT\_BUFFER\_PADDING\_SIZE)

76	return AVERROR\_NOMEM;

77![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.065.png)

分配数据包缓存

78	data = av\_malloc(size + FF\_INPUT\_BUFFER\_PADDING\_SIZE);

79	if (!data)

80	return AVERROR\_NOMEM;

81![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.064.png)

把数据包中 pad 部分清 0，这是一个很好的习惯。 缓存清 0 不管在什么情况下都是好习惯。![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

82	memset(data + size, 0, FF\_INPUT\_BUFFER\_PADDING\_SIZE);

83![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.064.png)

设置 AVPacket 其他的成员变量，能确定的就赋确定值，不能确定的赋初值。

84	pkt->pts = AV\_NOPTS\_VALUE;

85	pkt->dts = AV\_NOPTS\_VALUE;

86	pkt->pos =	- 1;

87	pkt->flags = 0;

88	pkt->stream\_index = 0;

89	pkt->data = data;

90	pkt->size = size;

91	pkt->destruct = av\_destruct\_packet;

92

93	pkt->pos = url\_ftell(s);

94![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.065.png)

实际读广义文件填充数据包，如果读文件错误时通常是到了末尾，要归还刚刚 malloc 出来的内存。

95	ret = url\_fread(s, pkt->data, size);

96	if (ret <= 0)

97	av\_free\_packet(pkt);

98	else

99	pkt->size = ret;

100

101	return ret;

102 }

103![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.067.png)

为识别文 件格 式， 要读 一部 分文 件头数 据来 分析 匹配 ffplay 支持的文 件格 式文 件特 征。 于是

AVProbeData 结构就定义了文件名，首地址和大小。此处的读独立于其他文件操作。

104 typedef struct AVProbeData

105 {

106	const char \*filename;

107	unsigned char \*buf;

108	int buf\_size;

109 } AVProbeData;

110![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.065.png)

文件索引结构，flags 和 size 位定义是为了节省内存。

111 typedef struct AVIndexEntry

112 {

113	int64\_t pos;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

114	int64\_t timestamp;

115	int flags: 2;

116	int size: 30;

117 } AVIndexEntry;

118![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.065.png)

AVStream 抽象的表示一个媒体流，定义了所有媒体一些通用的属性。

119 typedef struct AVStream

120 {

121	AVCodecContext \*actx;// 关联到解码器//codec context,change from AVCodecContext \*codec;

122

123	void \*priv\_data;	// 在本例中，关联到 AVIStream

124

125	AVRational time\_base; // 由 av\_set\_pts\_info()函数初始化

126

127	AVIndexEntry \*index\_entries; // only used if the format does not support seeking natively

128	int nb\_index\_entries;

129	int index\_entries\_allocated\_size;

130

131	double frame\_last\_delay;	// 帧最后延迟

132 } AVStream;

133![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.064.png)

AVFormatParameters 结构在瘦身后的 ffplay 中没有实际意义，为保证函数接口不变，没有删除。

134 typedef struct AVFormatParameters

135 {

136	int dbg; //only for debug

137 } AVFormatParameters;

138

AVInputFormat 定义输入文件容器格式，着重于功能函数，一种文件容器格式对应一个 AVInputFormat

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.068.png)结构，在程序运行时有多个实例，但瘦身后 ffplay 仅一个实例。

139 typedef struct AVInputFormat

140 {

141	const char \*name;	// 文件容器格式名，用于人性化阅读，维护代码

142

143	int priv\_data\_size; // 程序运行时，文件容器格式对应的上下文结构大小，便于内存分配。

144

145	int(\*read\_probe)(AVProbeData\*); // 功能性函数

146

147	int(\*read\_header)(struct AVFormatContext \*, AVFormatParameters \*ap);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

148

149	int(\*read\_packet)(struct AVFormatContext \*, AVPacket \*pkt);

150

151	int(\*read\_close)(struct AVFormatContext\*);

152

153	const char \*extensions;	// 此种文件容器格式对应的文件扩展名，识别文件格式的最后办法。

154

155	struct AVInputFormat \*next; // 用于把 ffplay 支持的所有文件容器格式链成一个链表。

156

157 } AVInputFormat;

158

AVFormatContext 结构表示程序运行的当前文件容器格式使用的上下文，着重于所有文件容器共有的属

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.068.png)性，程序运行后仅一个实例。

159 typedef struct AVFormatContext	// format I/O context

160 {

161	struct AVInputFormat \*iformat; // 关联程序运行时，实际的文件容器格式指针。

162

163	void \*priv\_data;	// 关联具体文件容器格式上下文的指针，在本例中是 AVIContext

164

165	ByteIOContext pb;	// 关联广义输入文件

166

167	int nb\_streams;	// 广义输入文件中媒体流计数

168

169	AVStream \*streams[MAX\_STREAMS];// 关联广义输入文件中的媒体流

170

171 } AVFormatContext;

172![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.065.png)

相关函数说明参考相应的 c 实现文件。

173 int avidec\_init(void);

174

175 void av\_register\_input\_format(AVInputFormat \*format);

176

177 void av\_register\_all(void);

178

179 AVInputFormat \*av\_probe\_input\_format(AVProbeData \*pd, int is\_opened);

180 int match\_ext(const char \*filename, const char \*extensions);

181

182 int av\_open\_input\_stream(AVFormatContext \*\*ic\_ptr, ByteIOContext \*pb, const char \*filename,

183	AVInputFormat \*fmt, AVFormatParameters \*ap);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

184

185 int av\_open\_input\_file(AVFormatContext \*\*ic\_ptr, const char \*filename, AVInputFormat \*fmt,

186	int buf\_size, AVFormatParameters \*ap);

187

188 int av\_read\_frame(AVFormatContext \*s, AVPacket \*pkt);

189 int av\_read\_packet(AVFormatContext \*s, AVPacket \*pkt);

190 void av\_close\_input\_file(AVFormatContext \*s);

191 AVStream \*av\_new\_stream(AVFormatContext \*s, int id);

192 void av\_set\_pts\_info(AVStream \*s, int pts\_wrap\_bits, int pts\_num, int pts\_den);

193

194 int av\_index\_search\_timestamp(AVStream \*st, int64\_t timestamp, int flags);

195 int av\_add\_index\_entry(AVStream \*st, int64\_t pos, int64\_t timestamp, int size, int distance, int flags);

196

197 int strstart(const char \*str, const char \*val, const char \*\*ptr);

198 void pstrcpy(char \*buf, int buf\_size, const char \*str);

199

200 #ifdef  cplusplus

201 }

202

203 #endif

204

205 #endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **3 allformat.c 文件**
3.1 功能描述

简单的注册/初始化函数，把相应的协议，文件格式，解码器等用相应的链表串起来便于查找。

3.2 文件注释

1	#include "avformat.h"

2

3	extern URLProtocol file\_protocol;

4

5	void av\_register\_all(void)

6	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.069.png)

7 到 11 行，in ited  变量声明成 static ，做一下比较是为了避免此函数多次调用。

编程基本原则之一，初始化函数只调用一次，不能随意多次调用。

7	static int inited = 0;

8

9	if (inited != 0)

10	return ;

11	inited = 1;

12![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.070.png)

ffplay 把 CPU 当做一个广义的 DSP。有些计算可以用 CPU 自带的加速指令来优化，ffplay 把这类函数

独立出来放到 dsputil.h 和 dsputil.c 文件中，用函数指针的方法映射到各个 CPU 具体的加速优化实现函数， 此处初始化这些函数指针。

13	avcodec\_init();

14![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.071.png)

把所有的解码器用链表的方式都串连起来，链表头指针是 first\_avcodec。

15	avcodec\_register\_all()

16![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.071.png)

把所有的输入文件格式用链表的方式都串连起来，链表头指针是 first\_iformat。

17	avidec\_init();

18![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.071.png)

把所有的输入协议用链表的方式都串连起来，比如 tcp/udp/file 等，链表头指针是 first\_protocol。

19	register\_protocol(&file\_protocol);

20	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **4 cutils.c 文件**
4.1 功能描述

ffplay 文件格式分析模块使用的两个工具类函数，都是对字符串的操作。

4.2 文件注释

1	#include "avformat.h"

2

strstart 实际的功能就是在 str 字符串中搜索 val 字符串指示的头，并且去掉头后用\*ptr 返回。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.072.png)在本例中，在播本地文件时，在命令行输入时可能会在文件路径名前加前缀"file:", 为调用系统的 open

函数，需要把这几个前导字符去掉，仅仅传入完整有效的文件路径名。 和 rtsp://等网络协议相对应，播本地文件时应加 file:前缀。

3	int strstart(const char \*str, const char \*val, const char \*\*ptr)

4	{

5	const char \*p,	\*q;

6	p = str;

7	q = val;

8	while (\*q != '\0')

9	{

10	if (\*p !=	\*q)

11	return 0;

12	p++;

13	q++;

14	}

15	if (ptr)

16	\*ptr = p;

17	return 1;

18	}

19![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.073.png)

字符串拷贝函数，拷贝的字符数由 buf\_size 指定，更安全的字符串拷贝操作。

传统的 strcpy()函数是拷贝一个完整的字符串，如果目标字符串缓冲区小于源字符串长度，那么就会 发生缓冲区溢出导致错误，并且这种错误很难发现。

20	void pstrcpy(char \*buf, int buf\_size, const char \*str)

21	{

22	int c;

23	char \*q = buf;

24

25	if (buf\_size <= 0)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

26	return ;

27

28	for (;;)

29	{

30	c =	\*str++;

31	if (c == 0 || q >= buf + buf\_size - 1)

32	break;

33	\*q++ = c;

34	}

35	\*q = '\0';

36	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **5 file.c 文件**
5.1 功能描述

ffplay 把 file 当做类似于 rtsp，rtp，tcp 等协议的一种协议，用 file:前缀标示 file 协议。 URLContext 结构抽象统一表示这些广义上的协议，对外提供统一的抽象接口。 各具体的广义协议实现文件实现 URLContext 接口。此文件实现了 file 广义协议的 URLContext 接口。

5.2 文件注释

1	#include "../berrno.h"

2

3	#include "avformat.h"

4	#include <fcntl.h>

5

6	#ifndef CONFIG\_WIN32

7	#include <unistd.h>

8	#include <sys/ioctl.h>

9	#include <sys/time.h>

10	#else

11	#include <io.h>

12	#define open(fname,oflag,pmode) \_open(fname,oflag,pmode)

13	#endif

14![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.074.png)

打开本地媒体文件，把本地文件句柄作为广义文件句柄存放在 priv\_data 中。

15	static int file\_open(URLContext \*h, const char \*filename, int flags)

16	{

17	int access;

18	int fd;

19![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.075.png)

规整本地路径文件名，去掉前面可能的"file:" 字符串。ffplay 把本地文件看做广义 URL 协议。

20	strstart(filename, "file:", &filename);

21![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.075.png)

设置本地文件存取属性。

22	if (flags &URL\_RDWR)

23	access = O\_CREAT | O\_TRUNC | O\_RDWR;

24	else if (flags &URL\_WRONLY)

25	access = O\_CREAT | O\_TRUNC | O\_WRONLY;

26	else

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)27	access = O\_RDONLY;

28	#if defined(CONFIG\_WIN32) || defined(CONFIG\_OS2) || defined( CYGWIN )

29	access |= O\_BINARY;

30	#endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.075.png)

调用 open()打开本地文件，并把本地文件句柄作为广义的 URL 句柄存放在 priv\_data 变量中。


|31||fd = open(filename, access, 0666);|
| - | - | - |
|32||if (fd < 0)|
|33||return	- ENOENT;|
|34||h->priv\_data = (void\*)(size\_t)fd;|
|35||return 0;|
|36|}||
|37|||
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.075.png)转换广义 URL 句柄为本地文件句柄，调用 read()函数读本地文件。

38	static int file\_read(URLContext \*h, unsigned char \*buf, int size)

39	{

40	int fd = (size\_t)h->priv\_data;

41	return read(fd, buf, size);

42	}

43![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.074.png)

转换广义 URL 句柄为本地文件句柄，调用 w ite()函数写本地文件，本播放器没实际使用此函数。

44	static int file\_write(URLContext \*h, unsigned char \*buf, int size)

45	{

46	int fd = (size\_t)h->priv\_data;

47	return write(fd, buf, size);

48	}

49![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.075.png)

转换广义 URL 句柄为本地文件句柄，调用 lseek()函数设置本地文件读指针。

50	static offset\_t file\_seek(URLContext \*h, offset\_t pos, int whence)

51	{

52	int fd = (size\_t)h->priv\_data;

53	return lseek(fd, pos, whence);

54	}

55![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.075.png)

转换广义 URL 句柄为本地文件句柄，调用 close()函数关闭本地文件。

56	static int file\_close(URLContext \*h)

57	{

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)58	int fd = (size\_t)h->priv\_data;

59	return close(fd);

60	}

61![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.074.png)

用 file 协议相应函数初始化 URLProtocol 结构。

62	URLProtocol file\_protocol =

63	{

64	"file",

65	file\_open,

66	file\_read,

67	file\_write,

68	file\_seek,

69	file\_close,

70	};![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **6 avio.h 文件**
6.1 功能描述

文件读写模块定义的数据结构和函数声明，ffplay 把这些全部放到这个.h 文件中。

6.2 文件注释

1	#ifndef AVIO\_H

2	#define AVIO\_H

3

4	#define URL\_EOF (-1)

5

6	typedef int64\_t offset\_t;

7![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.076.png)

简单的文件存取宏定义

8	#define URL\_RDONLY 0

9	#define URL\_WRONLY 1

10	#define URL\_RDWR	2

11![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.077.png)

URLContex t 结构表示程序运行的当前广义文件协议使用的上下文，着重于所有广义文件协议共有的 属性(并且是在程序运行时才能确定其值)和关联其他结构的字段。

12	typedef struct URLContext

13	{

14	struct URLProtocol \*prot; // 关联相应的广义输入文件协议。

15	int flags;

16	int max\_packet\_size;	// 如果非 0，表示最大包大小，用于分配足够的缓存。

17	void \*priv\_data;	// 在本例中，关联一个文件句柄

18	char filename[1];	// 在本例中，存取本地文件名，filename 仅指示本地文件名首地址。

19	} URLContext;

20![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.078.png)

URLProtocol 定义广义的文件协议，着重于功能函数，一种广义的文件协议对应一个 URLProtocol 结 构，本例删掉了 pipe，udp，tcp 等输入协议，仅保留一个 file 协议。

21	typedef struct URLProtocol

22	{

23	const char \*name;	// 协议文件名，便于人性化阅读理解。

24	int(\*url\_open)(URLContext \*h, const char \*filename, int flags);

25	int(\*url\_read)(URLContext \*h, unsigned char \*buf, int size);

26	int(\*url\_write)(URLContext \*h, unsigned char \*buf, int size);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

27	offset\_t(\*url\_seek)(URLContext \*h, offset\_t pos, int whence);

28	int(\*url\_close)(URLContext \*h);

29	struct URLProtocol \*next;	// 把所有支持的输入协议串链起来，便于遍历查找。

30	} URLProtocol;

31

ByteIOCon tex t 结构扩展 URLProtocol 结构成内部有缓冲机制的广泛意义上的文件，改善广义输入

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.080.png)


![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.079.png)文件的 IO 性能。 主要变量间的逻辑位置关系简单示意如下：





32	typedef struct ByteIOContext

33	{

34	unsigned char \*buffer; // 缓存首地址

35	int buffer\_size;	// 缓存大小

36	unsigned char \*buf\_ptr,	\*buf\_end; // 缓存读指针和末指针

37	void \*opaque;	// 指向 URLContext 结构的指针，便于跳转

38	int(\*read\_packet)(void \*opaque, uint8\_t \*buf, int buf\_size);

39	int(\*write\_packet)(void \*opaque, uint8\_t \*buf, int buf\_size);

40	offset\_t(\*seek)(void \*opaque, offset\_t offset, int whence);

41	offset\_t pos;	// position in the file of the current buffer

42	int must\_flush;	// true if the next seek should flush

43	int eof\_reached;	// true if eof reached

44	int write\_flag;	// true if open for writing

45	int max\_packet\_size;	// 如果非 0，表示最大数据帧大小，用于分配足够的缓存。

46	int error;	// contains the error code or 0 if no error happened

47	} ByteIOContext;

48

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.081.png)相关函数说明参考相应的 c 实现文件。

49	int url\_open(URLContext \*\*h, const char \*filename, int flags);

50	int url\_read(URLContext \*h, unsigned char \*buf, int size);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

51	int url\_write(URLContext \*h, unsigned char \*buf, int size);

52	offset\_t url\_seek(URLContext \*h, offset\_t pos, int whence);

53	int url\_close(URLContext \*h);

54	int url\_get\_max\_packet\_size(URLContext \*h);

55

56	int register\_protocol(URLProtocol \*protocol);

57

58	int init\_put\_byte(ByteIOContext \*s,

59	unsigned char \*buffer,

60	int buffer\_size,

61	int write\_flag,

62	void \*opaque,

63	int(\*read\_buf)(void \*opaque, uint8\_t \*buf, int buf\_size),

64	int(\*write\_buf)(void \*opaque, uint8\_t \*buf, int buf\_size),

65	offset\_t(\*seek)(void \*opaque, offset\_t offset, int whence));

66

67	offset\_t url\_fseek(ByteIOContext \*s, offset\_t offset, int whence);

68	void url\_fskip(ByteIOContext \*s, offset\_t offset);

69	offset\_t url\_ftell(ByteIOContext \*s);

70	offset\_t url\_fsize(ByteIOContext \*s);

71	int url\_feof(ByteIOContext \*s);

72	int url\_ferror(ByteIOContext \*s);

73

74	int url\_fread(ByteIOContext \*s, unsigned char \*buf, int size); // get\_buffer

75	int get\_byte(ByteIOContext \*s);

76	unsigned int get\_le32(ByteIOContext \*s);

77	unsigned int get\_le16(ByteIOContext \*s);

78

79	int url\_setbufsize(ByteIOContext \*s, int buf\_size);

80	int url\_fopen(ByteIOContext \*s, const char \*filename, int flags);

81	int url\_fclose(ByteIOContext \*s);

82

83	int url\_open\_buf(ByteIOContext \*s, uint8\_t \*buf, int buf\_size, int flags);

84	int url\_close\_buf(ByteIOContext \*s);

85

86	#endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **7 avio.c 文件**
7.1 功能描述

此文件实现了 URLProtocol 抽象层广义文件操作函数，由于 URLProtocol 是底层其他具体文件 (file,pipe 等)

的简单封装，这一层只是一个中转站，大部分函数都是简单中转到底层的具体实现函数。

7.2 文件注释

1	#include "../berrno.h"

2	#include "avformat.h"

3

4	URLProtocol \*first\_protocol = NULL;

5

ffplay 抽象底层的 file ，pipe 等为 URLProtocol，然后把这些 URLProtocol 串联起来做成链表，便于查找 。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.082.png)register\_protocol 实际就是串联的各个 URLProtocol，全局表头为 first\_protocol。

6	int register\_protocol(URLProtocol \*protocol)

7	{

8	URLProtocol \*\*p;

9	p = &first\_protocol;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.083.png)

移动指针到 URLProtocol 链表末尾。

10	while (\*p != NULL)

11	p = &(\*p)->next;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.084.png)

在 URLProtocol 链表末尾直接挂接当前的 URLProtocol 指针。

12	\*p = protocol;

13	protocol->next = NULL;

14	return 0;

15	}

16![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.085.png)

打开广义输入文件。此函数主要有三部分逻辑，首先从文件路径名中分离出协议字符串到 proto\_str

字符数组中，接着遍历 URLProtocol 链表查找匹配 proto\_str 字符数组中的字符串来确定使用的协议，最 后调用相应的文件协议的打开函数打开输入文件。

17	int url\_open(URLContext \*\*puc, const char \*filename, int flags)

18	{

19	URLContext \*uc;

20	URLProtocol \*up;

21	const char \*p;

22	char proto\_str[128],	\*q;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

23	int err;

24

以冒号和结束符作为边界从文件名中分离出的协议字符串到 proto\_str 字符数组。由于协议只能是字符 ，

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.086.png)所以在边界前识别到非字符就断定是 file。

25	p = filename;

26	q = proto\_str;

27	while (\*p != '\0' &&	\*p != ':')

28	{

29	if (!isalpha(\*p))	// protocols can only contain alphabetic chars

30	goto file\_proto;

31	if ((q - proto\_str) < sizeof(proto\_str) - 1)

32	\*q++ =	\*p;

33	p++;

34	}

35![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.087.png)

如果协议字符串只有一个字符，我们就认为是 w indow s 下的逻辑盘符，断定是 file 。

36	if (\*p == '\0' || (q - proto\_str) <= 1)

37	{

38	file\_proto:

39	strcpy(proto\_str, "file");

40	}

41	else

42	{

43	\*q = '\0';

44	}

45![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.087.png)

遍历 URLProtocol 链表匹配使用的协议，如果没有找到就返回错误码。

46	up = first\_protocol;

47	while (up != NULL)

48	{

49	if (!strcmp(proto\_str, up->name))

50	goto found;

51	up = up->next;

52	}

53	err =	- ENOENT;

54	goto fail;

55	found:![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

如果找到就分配 URLContext 结构内存，特别注意内存大小要加上文件名长度，文件名字符串结束标

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.088.png)记 0 也要预先分配 1 个字节内存，这 1 个字节就是 URLContext 结构中的 char filename[1]。

56	uc = av\_malloc(sizeof(URLContext) + strlen(filename));

57	if (!uc)

58	{

59	err =	- ENOMEM;

60	goto fail;

61	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.089.png)

strcpy 函数会自动在 filename 字符数组后面补 0 作为字符串结束标记，所以不用特别赋值为 0。

62	strcpy(uc->filename, filename);

63	uc->prot = up;

64	uc->flags = flags;

65	uc->max\_packet\_size = 0; // default: stream file

接着调用相应协议的文件打开函数实质打开文件。如果文件打开错误，就需要释放 malloc 出来的内

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.056.png)存，并返回错误码。

66	err = up->url\_open(uc, filename, flags);

67	if (err < 0)

68	{

69	av\_free(uc);	// 打开失败，释放刚刚分配的内存。

70	\*puc = NULL;

71	return err;

72	}

73	\*puc = uc;

74	return 0;

75	fail:

76	\*puc = NULL;

77	return err;

78	}

79![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

简单的中转读操作到底层协议的读函数，完成读操作。

80	int url\_read(URLContext \*h, unsigned char \*buf, int size)

81	{

82	int ret;

83	if (h->flags &URL\_WRONLY)

84	return AVERROR\_IO;

85	ret = h->prot->url\_read(h, buf, size);

86	return ret;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

87	}

88![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.046.png)

简单的中转 seek 操作到底层协议的 seek 函数，完成 seek 操作。

89	offset\_t url\_seek(URLContext \*h, offset\_t pos, int whence)

90	{

91	offset\_t ret;

92

93	if (!h->prot->url\_seek)

94	return	- EPIPE;

95	ret = h->prot->url\_seek(h, pos, whence);

96	return ret;

97	}

98![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.090.png)

简单的中转关闭操作到底层协议的关闭函数，完成关闭操作，并释放在 url\_open()函数中 malloc 出

来的内存。

99	int url\_close(URLContext \*h)

100 {

101	int ret;

102

103	ret = h->prot->url\_close(h);

104	av\_free(h);

105	return ret;

106 }

107![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.061.png)

取最大数据包大小，如果非 0，必须是实质有效的。

108 int url\_get\_max\_packet\_size(URLContext \*h)

109 {

110	return h->max\_packet\_size;

111 }![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **8 aviobuf.c 文件**
8.1 功能描述

有缓存的广义文件 ByteIOContext 相关的文件操作，比如 open，read，close，seek 等等。

8.2 文件注释

1	#include "../berrno.h"

2	#include "avformat.h"

3	#include "avio.h"

4	#include <stdarg.h>

5

6	#define IO\_BUFFER\_SIZE 32768

7![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

初始化广义文件 ByteIOContext 结构，一些简单的赋值操作。

8	int init\_put\_byte(ByteIOContext \*s,

|9||unsigned char \*buffer,|
| - | - | - |
|10||int buffer\_size,|
|11||int write\_flag,|
|12||void \*opaque,|
|13||int(\*read\_buf)(void \*opaque, uint8\_t \*buf, int buf\_size),|
|14||int(\*write\_buf)(void \*opaque, uint8\_t \*buf, int buf\_size),|
|15||offset\_t(\*seek)(void \*opaque, offset\_t offset, int whence))|
|16|{||
|17||s->buffer = buffer;|
|18||s->buffer\_size = buffer\_size;|
|19||s->buf\_ptr = buffer;|
|20||s->write\_flag = write\_flag;|
|21||if (!s->write\_flag)|
|22||s->buf\_end = buffer; // 初始情况下，缓存中没有效数据，所以 buf\_end 指向缓存首地址。|
|23||else|
|24||s->buf\_end = buffer + buffer\_size;|
|25||s->opaque = opaque;|
|26||s->write\_buf = write\_buf;|
|27||s->read\_buf = read\_buf;|
|28||s->seek = seek;|
|29||s->pos = 0;|
|30||s->must\_flush = 0;|
|31||s->eof\_reached = 0;|
|32||s->error = 0;|

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)33	s->max\_packet\_size = 0;

34	return 0;

35	}

36

广义文件 ByteIOContext 的 seek 操作。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.092.png)输入变量：s 为广义文件句柄，offset 为偏移量，whence 为定位方式。 输出变量：相对广义文件开始的偏移量。

37	offset\_t url\_fseek(ByteIOContext \*s, offset\_t offset, int whence)

38	{

39	offset\_t offset1;

40![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.092.png)

只支持 SEEK\_CU R 和 SEEK\_SET 定位方式，不支持 SEEK\_END 方式。

SEEK\_CUR:从文件当前读写位置为基准偏移 offset 字节。 SEEK\_SET:从文件开始位置偏移 offset 字节。

41	if (whence != SEEK\_CUR && whence != SEEK\_SET)

42	return	- EINVAL;

43

ffplay 把 SEEK\_CU R 和 SEEK\_SET 统一成 SEEK\_SET 方式处理，所以如果是 SEEK\_CU R 方式就要转 换成 SEEK\_SET 的偏移量。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.093.png)offset1 = s->pos - (s->buf\_end - s->buffer) + (s->buf\_ptr - s->buffer) 算式关系请参照 3.6

节的示意图，表示广义文件的当前实际偏移。

44	if (whence == SEEK\_CUR)

|45|{||
| - | - | - |
|46||offset1 = s->pos - (s->buf\_end - s->buffer) + (s->buf\_ptr - s->buffer);|
|47||if (offset == 0)|
|48||return offset1; // 如果偏移量为 0，返回实际偏移位置。|
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)计算绝对偏移量，赋值给 offset。

49	offset += offset1;	// 加上实际偏移量，统一成相对广义文件开始的绝对偏移量

50	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

计算绝对偏移量相对当前缓存的偏移量，赋值给 offset1。

51	offset1 = offset - (s->pos - (s->buf\_end - s->buffer));![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

判断绝对偏移量是否在当前缓存中，如果在当前缓存中，就简单的修改 buf\_ptr 指针。

52	if (offset1 >= 0 && offset1 <= (s->buf\_end - s->buffer))

53	{

54	s->buf\_ptr = s->buffer + offset1; // can do the seek inside the buffer![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

55	}

56	else

57	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

判断当前广义文件是否可以 seek，如果不能 seek 就返回错误。

58	if (!s->seek)

59	return	- EPIPE;

调用底层具体的文件系统的 seek 函数完成实际的 seek 操作，此时缓存需重新初始化，buf\_end 重新指

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.095.png)向缓存首地址，并修改 pos 变量为广义文件当前实际偏移量。

60	s->buf\_ptr = s->buffer;

61	s->buf\_end = s->buffer;

62	if (s->seek(s->opaque, offset, SEEK\_SET) == (offset\_t) - EPIPE)

63	return	- EPIPE;

64	s->pos = offset;

65	}

66	s->eof\_reached = 0;

67![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

返回广义文件当前的实际偏移量。

68	return offset;

69	}

70![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

广义文件 ByteIOContext 的当前实际偏移量再偏移 offset 字节，调用 url\_fseek 实现。

71	void url\_fskip(ByteIOContext \*s, offset\_t offset)

72	{

73	url\_fseek(s, offset, SEEK\_CUR);

74	}

75![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

返回广义文件 ByteIOContext 的当前实际偏移量。

76	offset\_t url\_ftell(ByteIOContext \*s)

77	{

78	return url\_fseek(s, 0, SEEK\_CUR);

79	}

80![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

返回广义文件 ByteIOContext 的大小。

81	offset\_t url\_fsize(ByteIOContext \*s)

82	{

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)83	offset\_t size;

84![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

判断当前广义文件 ByteIOContext 是否能 seek，如果不能就返回错误

85	if (!s->seek)

86	return	- EPIPE;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

调用底层的 seek 函数取得文件大小。

87	size = s->seek(s->opaque,	- 1, SEEK\_END) + 1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

注意 seek 操作改变了读指针，所以要重新 seek 到当前读指针位置。

88	s->seek(s->opaque, s->pos, SEEK\_SET);

89	return size;

90	}

91![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

判断当前广义文件 ByteIOContext 是否到末尾

92	int url\_feof(ByteIOContext \*s)

93	{

94	return s->eof\_reached;

95	}

96![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

返回当前广义文件 ByteIOContext 操作错误码

97	int url\_ferror(ByteIOContext \*s)

98	{

99	return s->error;

100 }

101

102 // Input stream

103![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

填充广义文件 ByteIOContext 内部的数据缓存区。

104 static void fill\_buffer(ByteIOContext \*s)

105 {

106	int len;

107![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果到了广义文件 ByteIOContext 末尾就直接返回。

108	if (s->eof\_reached)

109	return ;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

110![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.096.png)

调用底层文件系统的读函数实际读数据填到缓存，注意这里经过了好几次跳转才到底层读函数。首先

跳转的 url\_read\_buf()函数，再跳转到 url\_read()，再跳转到实际文件协议的读函数完成读操作。

111	len = s->read\_buf(s->opaque, s->buffer, s->buffer\_size); // url\_read\_buf //

112	if (len <= 0)

113	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

如果是到达文件末尾就不要改 buffer 参数，这样不用重新读数据就可以做 seek back 操作。

114	s->eof\_reached = 1;

115![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

设置错误码，便于分析定位。

116	if (len < 0)

117	s->error = len;

118	}

119	else

120	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

如果正确读取，修改一下基本参数。参加 3.6 节中的示意图。


|121||s->pos += len;|
| - | - | - |
|122||s->buf\_ptr = s->buffer;|
|123||s->buf\_end = s->buffer + len;|
|124|}||
125 }

126![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

从广义文件 ByteIOContext 中读取一个字节。

127 int get\_byte(ByteIOContext \*s)

128 {

129	if (s->buf\_ptr < s->buf\_end)

130	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果广义文件 ByteIOContext 内部缓存有数据，就修改读指针，返回读取的数据。

131	return	\*s->buf\_ptr++;

132	}

133	else

134	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

如果广义文件 ByteIOContext 内部缓存没有数据，就先填充内部缓存。

135	fill\_buffer(s);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

如果广义文件 ByteIOContext 内部缓存有数据，就修改读指针，返回读取的数据。如果没有数据就是

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.097.png)到了文件末尾，返回 0。

NOTE: return 0 if EOF, so you cannot use it if EOF handling is necessary

136	if (s->buf\_ptr < s->buf\_end)

137	return	\*s->buf\_ptr++;

138	else

139	return 0;

140	}

141 }

142![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

从广义文件 ByteIOContext 中以小端方式读取两个字节,实现代码充分复用 get\_byte()函数。

143 unsigned int get\_le16(ByteIOContext \*s)

144 {

145	unsigned int val;

146	val = get\_byte(s);

147	val |= get\_byte(s) << 8;

148	return val;

149 }

150![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

从广义文件 ByteIOContext 中以小端方式读取四个字节,实现代码充分复用 get\_le16()函数。

151 unsigned int get\_le32(ByteIOContext \*s)

152 {

153	unsigned int val;

154	val = get\_le16(s);

155	val |= get\_le16(s) << 16;

156	return val;

157 }

158

159 #define url\_write\_buf NULL

160![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

简单中转读操作函数。

161 static int url\_read\_buf(void \*opaque, uint8\_t \*buf, int buf\_size)

162 {

163	URLContext \*h = opaque;

164	return url\_read(h, buf, buf\_size);

165 }

166![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.098.png)

简单中转 seek 操作函数。

167 static offset\_t url\_seek\_buf(void \*opaque, offset\_t offset, int whence)

168 {

169	URLContext \*h = opaque;

170	return url\_seek(h, offset, whence);

171 }

172![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

设置并分配广义文件 ByteIOContext 内部缓存的大小。更多的应用在修改内部缓存大小场合。

173 int url\_setbufsize(ByteIOContext \*s, int buf\_size) // must be called before any I/O

174 {

175	uint8\_t \*buffer;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

分配广义文件 ByteIOContext 内部缓存。

176	buffer = av\_malloc(buf\_size);

177	if (!buffer)

178	return	- ENOMEM;

179![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

释放掉原来广义文件 ByteIOContext 的内部缓存，这是一个保险的操作。

180	av\_free(s->buffer);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

设置广义文件 ByteIOContext 内部缓存相关参数。

181	s->buffer = buffer;

182	s->buffer\_size = buf\_size;

183	s->buf\_ptr = buffer;

184	if (!s->write\_flag)

185	s->buf\_end = buffer; // 因为此时只是分配了内存,并没有读入数据,所以 buf\_end 指向首地址

186	else

187	s->buf\_end = buffer + buf\_size;

188	return 0;

189 }

190![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

打开广义文件 ByteIOContext

191 int url\_fopen(ByteIOContext \*s, const char \*filename, int flags)

192 {

193	URLContext \*h;

194	uint8\_t \*buffer;

195	int buffer\_size, max\_packet\_size;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

196	int err;

197![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

调用底层文件系统的 open 函数实质性打开文件

198	err = url\_open(&h, filename, flags);

199	if (err < 0)

200	return err;

201

读取底层文件系统支持的最大包大小。如果非 0，则设置为内部缓存的大小；否则内部缓存设置为默认

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.099.png)大小 IO\_BUFFER\_SIZE(32768 字节)。

202	max\_packet\_size = url\_get\_max\_packet\_size(h);

203	if (max\_packet\_size)

204	{

205	buffer\_size = max\_packet\_size; // no need to bufferize more than one packet

206	}

207	else

208	{

209	buffer\_size = IO\_BUFFER\_SIZE;

210	}

211![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.100.png)

分配广义文件 ByteIOContext 内部缓存，如果错误就关闭文件返回错误码。

212	buffer = av\_malloc(buffer\_size);

213	if (!buffer)

214	{

215	url\_close(h);

216	return	- ENOMEM;

217	}

218![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

初始化广义文件 ByteIOContext 数据结构，如果错误就关闭文件，释放内部缓存，返回错误码

219	if (init\_put\_byte(s,

|220||buffer,|
| - | - | - |
|221||buffer\_size,|
|222||(h->flags &URL\_WRONLY || h->flags &URL\_RDWR),|
|223||h,|
|224||url\_read\_buf,|
|225||url\_write\_buf,|
|226||url\_seek\_buf) < 0)|
|227|{||

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)228	url\_close(h);

229	av\_free(buffer);

230	return AVERROR\_IO;

231	}

232![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.101.png)

保存最大包大小。

233	s->max\_packet\_size = max\_packet\_size;

234

235	return 0;

236 }

237

关闭广义文件 ByteIOContext，首先释放掉内部使用的缓存，再把自己的字段置 0，最后转入底层文件

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.096.png)系统的关闭函数实质性关闭文件。

238 int url\_fclose(ByteIOContext \*s)

239 {

240	URLContext \*h = s->opaque;

241

242	av\_free(s->buffer);

243	memset(s, 0, sizeof(ByteIOContext));

244	return url\_close(h);

245 }

246

广义文件 ByteIOContext 读操作，注意此函数从 get\_buffer 改名而来，更贴切函数功能，也为了完备

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.095.png)广义文件操作函数集。

247 int url\_fread(ByteIOContext \*s, unsigned char \*buf, int size) // get\_buffer

248 {

249	int len, size1;

250

考虑到 size 可能比缓存中的数据大得多，此时就多次读缓存，所以用 size1 保存要读取的总字节数，size

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.095.png)意义变更为还需要读取的字节数。

251	size1 = size;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

如果还需要读的字节数大于 0，就进入循环继续读。

252	while (size > 0)

253	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.103.png)

计算当次循环应该读取的字节数 len ，首先设置 len 为内部缓存数据长度，再和需要读的字节数 size 比，

有条件修正 len 的值。

254	len = s->buf\_end - s->buf\_ptr;

255	if (len > size)

256	len = size;

257	if (len == 0)

258	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果内部缓存没有数据。

259	if (size > s->buffer\_size) // 读操作是否绕过内部缓存的判别条件

260	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果要读取的数据量比内部缓存数据量大，就调用底层函数读取数据绕过内部缓存直接到目标缓存。

261	len = s->read\_buf(s->opaque, buf, size);

262	if (len <= 0)

263	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果底层文件系统读错误，设置文件末尾标记和错误码，跳出循环，返回实际读到的字节数。

264	s->eof\_reached = 1;

265	if (len < 0)

266	s->error = len;

267	break;

268	}

269	else

270	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

如果底层文件系统正确读，修改相关参数，进入下一轮循环。特别注意此处读文件绕过了内部缓存。


|271||s->pos += len;|
| - | - | - |
|<p>272</p><p>273</p><p></p>||<p>size -= len;</p><p>buf += len;	// 因为绕过了内部缓存，特别注意此处的修改</p><p></p>|
|<p>274</p><p></p>||<p>s->buf\_ptr = s->buffer;</p><p></p>|
|<p>275</p><p></p>||<p>s->buf\_end = s->buffer /\* +len \*/;//因为绕过了内部缓存,特别注意此处</p><p></p>|
|276|<p>}</p><p></p>||
|277|<p>}</p><p></p>||
|278|<p>else</p><p></p>||
|279|<p>{</p><p></p>||
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)如果要读取的数据量比内部缓存数据量小，就调用底层函数读取数据到内部缓存，判断读成果否。

280	fill\_buffer(s);

281	len = s->buf\_end - s->buf\_ptr;


|282||if (len == 0)|
| - | - | - |
|283||break;|
|284|}||
|285|}||
|286|else||
|287|{||
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)如果内部缓存有数据，就拷贝 len 长度的数据到缓存区，并修改相关参数，进入下一个循环的条件判断。

288	memcpy(buf, s->buf\_ptr, len);

289	buf += len;

290	s->buf\_ptr += len;

291	size -= len;

292	}

293	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

返回实际读取的字节数。

294	return size1 - size;

295 }![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)
### **9 utils\_format.c 文件**
9.1 功能描述

识别文件格式和媒体格式部分使用的一些工具类函数。

9.2 文件注释

1	#include "../berrno.h"

2	#include "avformat.h"

3	#include <assert.h>

4

5	#define UINT\_MAX	(0xffffffff)

6

7	#define PROBE\_BUF\_MIN 2048

8	#define PROBE\_BUF\_MAX 131072

9

10	AVInputFormat \*first\_iformat = NULL;

11![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

注册文件容器格式。ffplay 把所有支持的文件容器格式用链表串联起来，表头是 first\_iformat。

12	void av\_register\_input\_format(AVInputFormat \*format)

13	{

14	AVInputFormat \*\*p;

15	p = &first\_iformat;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

循环移动节点指针到最后一个文件容器格式。

16	while (\*p != NULL)

17	p = &(\*p)->next;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

直接挂接要注册的文件容器格式。

18	\*p = format;

19	format->next = NULL;

20	}

21![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

比较文件的扩展名来识别文件类型。

22	int match\_ext(const char \*filename, const char \*extensions)

23	{

24	const char \*ext,	\*p;

25	char ext1[32],	\*q;

26![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.104.png)

如果输入文件为空就直接返回。

27	if (!filename)

28	return 0;

29![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

用'.'号作为扩展名分割符，在文件名中找扩展名分割符。

30	ext = strrchr(filename, '.');

31	if (ext)

|32|{||
| - | - | - |
|33||ext++;|
|34||p = extensions;|
|35||for (;;)|
|36||{|
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.099.png)文件名中可能有多个标点符号，取两个标点符号间或一个标点和一个结束符间的字符串和扩展名比较 来判断文件类型，所以可能要多次比较，所以这里有一个循环。

37	q = ext1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

定位下一个标点符号或字符串结束符，把这之间的字符拷贝到扩展名字符数组中。

38	while (\*p != '\0' &&	\*p != ',' && q - ext1 < sizeof(ext1) - 1)

39	\*q++ = \*p++;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

添加扩展名字符串结束标记 0。

40	\*q = '\0';![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

比较识别的扩展名是否后给定的扩展名相同，如果相同就返回 1，否则继续。

41	if (!strcasecmp(ext1, ext))

42	return 1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

判断是否到了文件名末尾，如果是就返回，否则进入下一个循环

43	if (\*p == '\0')

44	break;

45	p++;

46	}

47	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果在前面的循环中没有匹配到扩展名，就是不识别的文件类型，返回 0

48	return 0;

49	}

50

探测输入的文件容器格式，返回识别出来的文件格式。如果没有识别出来，就返回初始值 NULL。

51	AVInputFormat \*av\_probe\_input\_format(AVProbeData \*pd, int is\_opened)

52	{

53	AVInputFormat \*fmt1,	\*fmt;

54	int score, score\_max;

55

56	fmt = NULL;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.105.png)

score，score\_max 可以理解识别文件容器格式的正确级别。文件容器格式识别结果，如果完全正确可

以设定为 100，如果可能正确可以设定为 50，没识别出来设定为 0。识别方法不同导致等级不同。

57	score\_max = 0;

58	for (fmt1 = first\_iformat; fmt1 != NULL; fmt1 = fmt1->next)

59	{

60	if (!is\_opened)

61	continue;

62

63	score = 0;

64	if (fmt1->read\_probe)

65	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.106.png)

读取文件头，判断文件头的内容来识别文件容器格式，这种识别方法非常可靠，设定 score 为 100。

66	score = fmt1->read\_probe(pd);

67	}

68	else if (fmt1->extensions)

69	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.096.png)

通过文件扩展名来识别文件容器格式，因为文件扩展名任何人都可以改，如果改变扩展名，这种方法

就错误，如果不改变扩展名，这种识别方法有点可靠，综合等级为 50。


|70||if (match\_ext(pd->filename, fmt1->extensions))|
| - | - | - |
|71||score = 50;|
|72|}||
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.107.png)如果识别出来的等级大于最大要求的等级，就认为正确识别，相关参数赋值后，进下一个循环，最后 返回最高级别对应的文件容器格式。

73	if (score > score\_max)

74	{

75	score\_max = score;

76	fmt = fmt1;

77	}

78	}

返回文件容器格式，如果没有识别出来，返回的是初始值 NULL。

79	return fmt;

80	}

81![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

打开输入流，其中 AVFormatParameters \*ap 参数在瘦身后的 ffplay 中没有用到，保留为了不改变接口。

82	int av\_open\_input\_stream(AVFormatContext \*\*ic\_ptr, ByteIOContext \*pb, const char \*filename,

83	AVInputFormat \*fmt, AVFormatParameters \*ap)

84	{

85	int err;

86	AVFormatContext \*ic;

87	AVFormatParameters default\_ap;

88

89	if (!ap)

90	{

91	ap = &default\_ap;

92	memset(ap, 0, sizeof(default\_ap));

93	}

94

分配 AVFormatContext 内存，部分成员变量在接下来的程序代码中赋值，部分成员变量在下面调用的

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.099.png)ic->iformat->read\_header(ic, ap)函数中赋值。

95	ic = av\_mallocz(sizeof(AVFormatContext));

96	if (!ic)

97	{

98	err = AVERROR\_NOMEM;

99	goto fail;

100	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

关联 AVFormatContext 和 AVInputFormat

101	ic->iformat = fmt;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

关联 AVFormatContext 和广义文件 ByteIOContext

102	if (pb)

103	ic->pb =	\*pb;

104

105	if (fmt->priv\_data\_size > 0)

106	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

分配 priv\_data 指向的内存。![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

107	ic->priv\_data = av\_mallocz(fmt->priv\_data\_size);

108	if (!ic->priv\_data)

109	{

110	err = AVERROR\_NOMEM;

111	goto fail;

112	}

113	}

114	else

115	{

116	ic->priv\_data = NULL;

117	}

118![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

读取文件头，识别媒体流格式。

119	err = ic->iformat->read\_header(ic, ap);

120	if (err < 0)

121	goto fail;

122

123	\*ic\_ptr = ic;

124	return 0;

125![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

简单常规的错误处理。

126 fail:

127	if (ic)

128	av\_freep(&ic->priv\_data);

129

130	av\_free(ic);

131	\*ic\_ptr = NULL;

132	return err;

133 }

134![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

打开输入文件，并识别文件格式，然后调用函数识别媒体流格式。

135 int av\_open\_input\_file(AVFormatContext \*\*ic\_ptr, const char \*filename, AVInputFormat \*fmt,

136	int buf\_size, AVFormatParameters \*ap)

137 {

138	int err, must\_open\_file, file\_opened, probe\_size;

139	AVProbeData probe\_data,	\*pd = &probe\_data;

140	ByteIOContext pb1,	\*pb = &pb1;

141![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

142	file\_opened = 0;

143	pd->filename = "";

144	if (filename)

145	pd->filename = filename;

146	pd->buf = NULL;

147	pd->buf\_size = 0;

148

149	must\_open\_file = 1;

150

151	if (!fmt || must\_open\_file)

152	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

打开输入文件，关联 ByteIOContext，经过跳转几次后才实质调用文件系统 open()函数实质打开文件。

153	if (url\_fopen(pb, filename, URL\_RDONLY) < 0)

154	{

155	err = AVERROR\_IO;

156	goto fail;

157	}

158	file\_opened = 1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果程序指定 ByteIOContext 内部使用的缓存大小，就重新设置内部缓存大小。通常不指定大小。

159	if (buf\_size > 0)

160	url\_setbufsize(pb, buf\_size);

161

先读 PROBE\_ BUF\_ MIN(2048)字节文件开始数据识别文件格式，如果不能识别文件格式，就把识别文

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.108.png)件缓存以 2 倍的增长扩大再读文件开始数据识别，直到识别出文件格式或者超过 131072 字节缓存。

162	for (probe\_size = PROBE\_BUF\_MIN; probe\_size <= PROBE\_BUF\_MAX && !fmt; probe\_size <<= 1)

163	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

重新分配缓存，重新读文件开始数据。

164	pd->buf = av\_realloc(pd->buf, probe\_size);

165	pd->buf\_size = url\_fread(pb, pd->buf, probe\_size);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

把文件读指针 seek 到文件开始处，便于下一次读。

166	if (url\_fseek(pb, 0, SEEK\_SET) == (offset\_t) - EPIPE)

167	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

如果 seek 错误，关闭文件，再重新打开。

168	url\_fclose(pb);

169	if (url\_fopen(pb, filename, URL\_RDONLY) < 0)

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)170	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

重新打开文件出错，设置错误码，跳到错误处理。

171	file\_opened = 0;

172	err = AVERROR\_IO;

173	goto fail;

174	}

175	}

176![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

重新识别文件格式，因为一次比一次数据多，数据少的时候可能识别不出，数据多了可能就可以了。

177	fmt = av\_probe\_input\_format(pd, 1);

178	}

179	av\_freep(&pd->buf);

180	}

181

182	if (!fmt)

183	{

184	err = AVERROR\_NOFMT;

185	goto fail;

186	}

187![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

识别出文件格式后，调用函数识别流 av\_open\_input\_stream 格式。

188	err = av\_open\_input\_stream(ic\_ptr, pb, filename, fmt, ap);

189	if (err)

190	goto fail;

191	return 0;

192

193 fail:![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

简单的异常错误处理。

194	av\_freep(&pd->buf);

195	if (file\_opened)

196	url\_fclose(pb);

197	\*ic\_ptr = NULL;

198	return err;

199 }

200![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

一次读取一个数据包，在瘦身后的 ffplay 中，一次读取一个完整的数据帧，数据包。![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

201 int av\_read\_packet(AVFormatContext \*s, AVPacket \*pkt)

202 {

203	return s->iformat->read\_packet(s, pkt);

204 }

205

添加索引到索引表。有些媒体文件为便于 seek，有音视频数据帧有索引，ffplay 把这些索引以时间排

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.109.png)序放到一个数据中。返回值添加项的索引。

206 int av\_add\_index\_entry(AVStream \*st, int64\_t pos, int64\_t timestamp, int size, int distance, int flags)

207 {

208	AVIndexEntry \*entries,	\*ie;

209	int index;

210![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

索引项越界判断，如果占有内存达到 UINT\_MAX 时，返回。

211	if ((unsigned)st->nb\_index\_entries + 1 >= UINT\_MAX / sizeof(AVIndexEntry))

212	return	- 1;

213

重新分配索引内存。注意 av\_fast\_realloc()函数并不是每次调用就一定会重新分配内存，那样效率就

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.105.png)太低了。

214	entries = av\_fast\_realloc(st->index\_entries, &st->index\_entries\_allocated\_size,

215	(st->nb\_index\_entries + 1) \* sizeof(AVIndexEntry));

216	if (!entries)

217	return	- 1;

218![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.110.png)

保持重新分配内存后，索引的首地址。

219	st->index\_entries = entries;

220![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.110.png)

以时间为顺序查找当前索引应该插在索引表的位置。

221	index = av\_index\_search\_timestamp(st, timestamp, AVSEEK\_FLAG\_ANY);

222

223	if (index < 0)

224	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.110.png)

续补，既接着最后一个插入，索引计算加 1，取得索引项指针，便于后面赋值操作。

225	index = st->nb\_index\_entries++;

226	ie = &entries[index];

227	assert(index == 0 || ie[ - 1].timestamp < timestamp);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

228	}

229	else

230	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.110.png)

中插，既插入索引表的中间，取得索引项指针，便于后面赋值操作。

231	ie = &entries[index];

232	if (ie->timestamp != timestamp)

233	{

234	if (ie->timestamp <= timestamp)

235	return	- 1;

236![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.110.png)

把索引项后面的项全部后移一项，空出当前索引项。

237	memmove(entries + index + 1, entries + index,

238	sizeof(AVIndexEntry)\*(st->nb\_index\_entries - index));

239![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.110.png)

索引项计数加 1。

240	st->nb\_index\_entries++;

241	}

242	}

243![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.110.png)

修改索引项参数，完成排序添加。

244	ie->pos = pos;

245	ie->timestamp = timestamp;

246	ie->size = size;

247	ie->flags = flags;

248![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.110.png)

返回索引。

249	return index;

250 }

251![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

以时间为关键字查找当前索引应排在索引表中的位置。

252 int av\_index\_search\_timestamp(AVStream \*st, int64\_t wanted\_timestamp, int flags)

253 {

254	AVIndexEntry \*entries = st->index\_entries;

255	int nb\_entries = st->nb\_index\_entries;

256	int a, b, m;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

257	int64\_t timestamp;

258

259	a =	- 1;

260	b = nb\_entries;

261![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

以时间为关键字折半查找位置，请仔细理解。

262	while (b - a > 1)

263	{

264	m = (a + b) >> 1;

265	timestamp = entries[m].timestamp;

266	if (timestamp >= wanted\_timestamp)

267	b = m;

268	if (timestamp <= wanted\_timestamp)

269	a = m;

270	}

271

272	m = (flags &AVSEEK\_FLAG\_BACKWARD) ? a : b;

273

274	if (!(flags &AVSEEK\_FLAG\_ANY))

275	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

Seek 时，找关键帧，从关键帧开始解码，注意有些帧解码但不显示。

276	while (m >= 0 && m < nb\_entries && !(entries[m].flags &AVINDEX\_KEYFRAME))

277	{

278	m += (flags &AVSEEK\_FLAG\_BACKWARD) ?	- 1: 1;

279	}

280	}

281

282	if (m == nb\_entries)

283	return	- 1;

284![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

返回找到的位置。

285	return m;

286 }

287![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

关闭输入媒体文件，一大堆的关闭释放操作。

288 void av\_close\_input\_file(AVFormatContext \*s)

289 {![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

290	int i;

291	AVStream \*st;

292

293	if (s->iformat->read\_close)

294	s->iformat->read\_close(s);

295

296	for (i = 0; i < s->nb\_streams; i++)

297	{

298	st = s->streams[i];

299	av\_free(st->index\_entries);

300	av\_free(st->actx);

301	av\_free(st);

302	}

303

304	url\_fclose(&s->pb);

305

306	av\_freep(&s->priv\_data);

307	av\_free(s);

308 }

309![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

new 一个新的媒体流，返回 AVStream 指针

310 AVStream \*av\_new\_stream(AVFormatContext \*s, int id)

311 {

312	AVStream \*st;

313![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

判断媒体流的数目是否超限，如果超过就丢弃当前流返回 NULL。

314	if (s->nb\_streams >= MAX\_STREAMS)

315	return NULL;

316![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

分配一块 AVStream 内存。

317	st = av\_mallocz(sizeof(AVStream));

318	if (!st)

319	return NULL;

320![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

通过 avcodec\_alloc\_context 分配一块 AVFormatContext 内存，并关联到 AVStream。

321	st->actx = avcodec\_alloc\_context();

322![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.111.png)

关联 AVFormatContext 和 AVStream。

323	s->streams[s->nb\_streams++] = st;

324	return st;

325 }

326![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

设置计算 pts 时钟的相关参数。

327 void av\_set\_pts\_info(AVStream \*s, int pts\_wrap\_bits, int pts\_num, int pts\_den)

328 {

329	s->time\_base.num = pts\_num;

330	s->time\_base.den = pts\_den;

331 }

### ![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)**10 avidec.c 文件**
10.1 功能描述

AVI 文件解析的相关函数，注意有些地方有些技巧性代码。

注意 1：AVI 文件容器媒体数据有两种存放方式，非交织存放和交织存放。交织存放就是音视频数据以帧为最 小连续单位，相互间隔存放，这样音视频帧互相交织在一起，并且存放的间隔没有特别规定；非交织存放就是把 单一媒体的所有数据帧连续存放在一起，非交织存放的 avi 文件很少。

注意 2：AVI 文件索引结构 AVIINDEXENTRY 中的 dwChunkOffset 字段指示的偏移有的是相对文件开始字节的偏 移，有的事相对文件数据块 chunk 的偏移。

注意 3：附带的 avi 测试文件是交织存放的。

10.2 文件注释

1	#include "avformat.h"

2

3	#include <assert.h>

4![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

几个简单的宏定义。

5	#define AVIIF\_INDEX	0x10

6

7	#define AVIF\_HASINDEX	0x00000010	// Index at end of file?

8	#define AVIF\_MUSTUSEINDEX	0x00000020

9

10	#define INT\_MAX 2147483647

11

12	#define MKTAG(a,b,c,d) (a | (b << 8) | (c << 16) | (d << 24))

13

14	#define FFMIN(a,b) ((a) > (b) ? (b) : (a))

15	#define FFMAX(a,b) ((a) > (b) ? (a) : (b))

16

17	static int avi\_load\_index(AVFormatContext \*s);

18	static int guess\_ni\_flag(AVFormatContext \*s);

19![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

AVI 文件中的流参数定义，和 AVStream 数据结构协作。

20	typedef struct AVIStream

21	{

22	int64\_t frame\_offset; // 帧偏移，视频用帧计数，音频用字节计数，用于计算 pts 表示时间

23	int remaining;	// 表示需要读的数据大小，初值是帧裸数组大小，全部读完后为 0。

24	int packet\_size;	// 包大小，非交织和帧裸数据大小相同，交织比帧裸数据大小大 8 字节。![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

25

26	int scale;

27	int rate;

28	int sample\_size; // size of one sample (or packet) (in the rate/scale sense) in bytes

29

30	int64\_t cum\_len; // temporary storage (used during seek)

31

32	int prefix;	// normally 'd'<<8 + 'c' or 'w'<<8 + 'b'

33	int prefix\_count;

34	} AVIStream;

35![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

AVI 文件中的文件格式参数相关定义，和 AVFormatContext 协作。

36	typedef struct

37	{

38	int64\_t riff\_end;	// RIFF 块大小

39	int64\_t movi\_list;	// 媒体数据块开始字节相对文件开始字节的偏移

40	int64\_t movi\_end;	// 媒体数据块开始字节相对文件开始字节的偏移

41	int non\_interleaved;// 指示是否是非交织 AVI

42	int stream\_index\_2; // 为了和 AVPacket 中的 stream\_index 相区别加一个后缀。

// 指示当前应该读取的流的索引。初值为-1，表示没有确定应该读的流。

// 实际表示 AVFormatContext 结构中 AVStream \*streams[] 数组中的索引。

43	} AVIContext;

44![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

CodecTag 数据结构，用于关联具体媒体格式的 ID 和 Tag 标签。

45	typedef struct CodecTag

46	{

47	int id;	// ID 号码

48	unsigned int tag; // 标签

49	} CodecTag;

50![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

瘦身后的 ffplay 支持的一些视频媒体 ID 和 Tag 标签数组。

51	const CodecTag codec\_bmp\_tags[] =

52	{

53	{CODEC\_ID\_MSRLE, MKTAG('m', 'r', 'l', 'e')},

54	{CODEC\_ID\_MSRLE, MKTAG(0x1, 0x0, 0x0, 0x0)},

55	{CODEC\_ID\_NONE,	0},

56	};

57![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.112.png)

瘦身后的 ffplay 支持的一些音频媒体 ID 和 Tag 标签数组。

58	const CodecTag codec\_wav\_tags[] =

59	{

60	{CODEC\_ID\_TRUESPEECH, 0x22},

61	{0, 0},

62	};

63![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

以媒体 tag 标签为关键字，查找 codec\_bmp\_tags 或 codec\_wav\_tags 数组，返回媒体 ID。

64	enum CodecID codec\_get\_id(const CodecTag \*tags, unsigned int tag)

65	{

66	while (tags->id != CODEC\_ID\_NONE)

67	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

比较 Tag 关键字，相等时返回对应媒体 ID。

68	if (toupper((tag >> 0) &0xFF) == toupper((tags->tag >> 0) &0xFF)

69	&& toupper((tag >> 8) &0xFF) == toupper((tags->tag >> 8) &0xFF)

70	&& toupper((tag >> 16)&0xFF) == toupper((tags->tag >> 16)&0xFF)

71	&& toupper((tag >> 24)&0xFF) == toupper((tags->tag >> 24)&0xFF))

72	return tags->id;

73![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

比较 Tag 关键字，不等移到数组的下一项。

74	tags++;

75	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

所有关键字都不匹配，返回 CODEC\_ID\_NONE。

76	return CODEC\_ID\_NONE;

77	}

78![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

校验 AVI 文件，读取 AVI 文件媒体数据块的偏移大小信息，和 avi\_probe()函数部分相同。

79	static int get\_riff(AVIContext \*avi, ByteIOContext \*pb)

80	{

81	uint32\_t tag;

82	tag = get\_le32(pb);

83![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

校验 AVI 文件开始关键字串"RIFF"。

84	if (tag != MKTAG('R', 'I', 'F', 'F'))![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

85	return	- 1;

86

87	avi->riff\_end = get\_le32(pb); // RIFF chunk size

88	avi->riff\_end += url\_ftell(pb); // RIFF chunk end

89	tag = get\_le32(pb);

90![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

校验 AVI 文件关键字串"AVI "或"AVIX"。

91	if (tag != MKTAG('A', 'V', 'I', ' ') && tag != MKTAG('A', 'V', 'I', 'X'))

92	return	- 1;

93![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果通过 AVI 文件关键字串"RIFF"和"AVI "或"AVIX"校验，就认为是 AVI 文件，这种方式非常可靠。

94	return 0;

95	}

96![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

排序建立 AVI 索引表，函数名为 clean\_index,不准确，功能以具体的实现代码为准。

97	static void clean\_index(AVFormatContext \*s)

98	{

99	int i, j;

100

101	for (i = 0; i < s->nb\_streams; i++)

102	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

对每个流都建一个独立的索引表。

103	AVStream \*st = s->streams[i];

104	AVIStream \*ast = st->priv\_data;

105	int n = st->nb\_index\_entries;

106	int max = ast->sample\_size;

107	int64\_t pos, size, ts;

108![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果索引表项大于 1，则认为索引表已建好，不再排序重建。如果 sample\_size 为 0,则没办法重建。

109	if (n != 1 || ast->sample\_size == 0)

110	continue;

111![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.113.png)

此种情况多半是用在非交织存储的 avi 音频流。不管交织还是非交织存储，视频流通常都有索引。

防止包太小需要太多的索引项占有大量内存，设定最小帧 size 阈值为 1024。比如有些音频流，最小解 码帧只十多个字节，如果文件比较大则在索引上耗费太多内存。![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

112	while (max < 1024)

113	max += max;

114![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

取位置，大小，时钟等基本参数。

115	pos = st->index\_entries[0].pos;

116	size = st->index\_entries[0].size;

117	ts = st->index\_entries[0].timestamp;

118

119	for (j = 0; j < size; j += max)

120	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

以 max 指定的字节打包成帧，添加到索引表。

121	av\_add\_index\_entry(st, pos + j, ts + j / ast->sample\_size, FFMIN(max, size - j), 0, AVINDEX\_KEYFRAME);

122	}

123	}

124 }

125![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

读取 AVI 文件头，读取 AVI 文件索引，并识别具体的媒体格式，关联一些数据结构。

126 static int avi\_read\_header(AVFormatContext \*s, AVFormatParameters \*ap)

127 {

128	AVIContext \*avi = s->priv\_data;

129	ByteIOContext \*pb = &s->pb;

130	uint32\_t tag, tag1, handler;

131	int codec\_type, stream\_index, frame\_period, bit\_rate;

132	unsigned int size, nb\_frames;

133	int i, n;

134	AVStream \*st;

135	AVIStream \*ast;

136![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

当前应该读取的流的索引赋初值为-1，表示没有确定应该读的流。

137	avi->stream\_index\_2 =	- 1;

138![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

校验 AVI 文件，读取 AVI 文件媒体数据块的偏移大小信息。

139	if (get\_riff(avi, pb) < 0)

140	return	- 1;

141![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.114.png)

简单变量符初值。

142	stream\_index =	- 1; // first list tag

143	codec\_type =	- 1;

144	frame\_period = 0;

145

146	for (;;)

147	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

AVI 文件的基本结构是块，一个文件有多个块，并且块还可以内嵌，在这里循环读文件头中的块。

148	if (url\_feof(pb))

149	goto fail;

150![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

读取每个块的标签和大小。

151	tag = get\_le32(pb);

152	size = get\_le32(pb);

153

154	switch (tag)

155	{

156	case MKTAG('L', 'I', 'S', 'T'):	// ignored, except when start of video packets

157	tag1 = get\_le32(pb);

158	if (tag1 == MKTAG('m', 'o', 'v', 'i'))

159	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

读取 movi 媒体数据块的偏移和大小。

160	avi->movi\_list = url\_ftell(pb) - 4;

161	if (size)

162	avi->movi\_end = avi->movi\_list + size;

163	else

164	avi->movi\_end = url\_fsize(pb);

165![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

AVI 文件头后面是 movi 媒体数据块，所以到了 movi 块，文件头肯定读完，需要跳出循环。

166	goto end\_of\_header; //

167	}

168	break;

169	case MKTAG('a', 'v', 'i', 'h'):	// avi header, using frame\_period is bad idea

170	frame\_period = get\_le32(pb);

171	bit\_rate = get\_le32(pb) \*8;

172	get\_le32(pb);

读取 non\_interleaved 的初值。

173	avi->non\_interleaved |= get\_le32(pb) & AVIF\_MUSTUSEINDEX;

174

175	url\_fskip(pb, 2 \*4);

176	n = get\_le32(pb);

177	for (i = 0; i < n; i++)

178	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.115.png)

读取流数目 n 后，分配 AVStream 和 AVIStream 数据结构，在 187 行把它们关联起来。

特别注意 av\_new\_stream()函数关联 AVFormatContext 和 AVStream 结构，分配关联 AVCodecContext 结构

179	AVIStream \*ast;

180	st = av\_new\_stream(s, i);

181	if (!st)

182	goto fail;

183

184	ast = av\_mallocz(sizeof(AVIStream));

185	if (!ast)

186	goto fail;

187	st->priv\_data = ast;

188

189	st->actx->bit\_rate = bit\_rate;

190	}

191	url\_fskip(pb, size - 7 \* 4);

192	break;

193	case MKTAG('s', 't', 'r', 'h'):	// stream header![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

指示当前流在 AVFormatContext 结构中 AVStream \*streams[MAX\_STREAMS]数组中的索引。

194	stream\_index++;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

从 strh 块读取所有流共有的一些信息，跳过有些不用的字段，填写需要的字段。

195	tag1 = get\_le32(pb);

196	handler = get\_le32(pb);

197

198	if (stream\_index >= s->nb\_streams)

199	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

出现这种情况通常代表媒体文件数据有错，ffplay 简单的跳过。


|200||url\_fskip(pb, size - 8);|
| - | - | - |
|201||break;|
|202|}||

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)203	st = s->streams[stream\_index];

204	ast = st->priv\_data;

205

206	get\_le32(pb); // flags

207	get\_le16(pb); // priority

208	get\_le16(pb); // language

209	get\_le32(pb); // initial frame

210	ast->scale = get\_le32(pb);

211	ast->rate = get\_le32(pb);

212	if (ast->scale && ast->rate)

213	{}

214	else if (frame\_period)

215	{

216	ast->rate = 1000000;

217	ast->scale = frame\_period;

218	}

219	else

220	{

221	ast->rate = 25;

222	ast->scale = 1;

223	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

设置当前流的时间信息，用于计算 pts 表示时间，进而同步。

224	av\_set\_pts\_info(st, 64, ast->scale, ast->rate);

225

226	ast->cum\_len = get\_le32(pb); // start

227	nb\_frames = get\_le32(pb);

228

229	get\_le32(pb); // buffer size

230	get\_le32(pb); // quality

231	ast->sample\_size = get\_le32(pb); // sample ssize

232

233	switch (tag1)

234	{

235	case MKTAG('v', 'i', 'd', 's'): codec\_type = CODEC\_TYPE\_VIDEO;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

特别注意视频流的每一帧大小不同，所以 sample\_size 设置为 0；对比音频流每一帧大小固定的情况。

236	ast->sample\_size = 0;

237	break;

238	case MKTAG('a', 'u', 'd', 's'): codec\_type = CODEC\_TYPE\_AUDIO;

239	break;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

240	case MKTAG('t', 'x', 't', 's'):	//FIXME

241	codec\_type = CODEC\_TYPE\_DATA; //CODEC\_TYPE\_SUB ?	FIXME

242	break;

243	case MKTAG('p', 'a', 'd', 's'): codec\_type = CODEC\_TYPE\_UNKNOWN;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果是填充流，stream\_index 减 1 就实现了简单的丢弃，不计入流数目总数。

244	stream\_index--;

245	break;

246	default:

247	goto fail;

248	}

249	ast->frame\_offset = ast->cum\_len \* FFMAX(ast->sample\_size, 1);

250	url\_fskip(pb, size - 12 \* 4);

251	break;

252	case MKTAG('s', 't', 'r', 'f'):	// stream header

从 strf 块读取流中编解码器的一些信息，跳过有些不用的字段，填写需要的字段。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.109.png)注意有些编解码器需要的附加信息从此块中读出，保持至 extradata 并最终传给相应的编解码器。

253	if (stream\_index >= s->nb\_streams)

254	{

255	url\_fskip(pb, size);

256	}

257	else

258	{

259	st = s->streams[stream\_index];

260	switch (codec\_type)

261	{

262	case CODEC\_TYPE\_VIDEO:	// BITMAPINFOHEADER

263	get\_le32(pb); // size

264	st->actx->width = get\_le32(pb);

265	st->actx->height = get\_le32(pb);

266	get\_le16(pb); // panes

267	st->actx->bits\_per\_sample = get\_le16(pb); // depth

268	tag1 = get\_le32(pb);

269	get\_le32(pb); // ImageSize

270	get\_le32(pb); // XPelsPerMeter

271	get\_le32(pb); // YPelsPerMeter

272	get\_le32(pb); // ClrUsed

273	get\_le32(pb); // ClrImportant

274

275	if (size > 10 \*4 && size < (1 << 30))![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

276	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

对视频，extradata 通常是保存的是 BITMAPINFO

277	st->actx->extradata\_size = size - 10 \* 4;

278	st->actx->extradata = av\_malloc(st->actx->extradata\_size +

279	FF\_INPUT\_BUFFER\_PADDING\_SIZE);

280	url\_fread(pb, st->actx->extradata, st->actx->extradata\_size);

281	}

282

283	if (st->actx->extradata\_size &1)

284	get\_byte(pb);

285

286	/\* Extract palette from extradata if bpp <= 8 \*/

287	/\* This code assumes that extradata contains only palette \*/

288	/\* This is true for all paletted codecs implemented in ffmpeg \*/

289	if (st->actx->extradata\_size && (st->actx->bits\_per\_sample <= 8))

290	{

291	int min = FFMIN(st->actx->extradata\_size, AVPALETTE\_SIZE);

292

293	st->actx->palctrl = av\_mallocz(sizeof(AVPaletteControl));

294	memcpy(st->actx->palctrl->palette, st->actx->extradata, min);

295	st->actx->palctrl->palette\_changed = 1;

296	}

297

298	st->actx->codec\_type = CODEC\_TYPE\_VIDEO;

299	st->actx->codec\_id = codec\_get\_id(codec\_bmp\_tags, tag1);

300

301	st->frame\_last\_delay = 1.0 \* ast->scale / ast->rate;

302

303	break;

304	case CODEC\_TYPE\_AUDIO:

|305|{||
| - | - | - |
|306||AVCodecContext \*actx = st->actx;|
|307|||
|308||int id = get\_le16(pb);|
|309||actx->codec\_type = CODEC\_TYPE\_AUDIO;|
|310||actx->channels = get\_le16(pb);|
|311||actx->sample\_rate = get\_le32(pb);|
|312||actx->bit\_rate = get\_le32(pb) \*8;|
|313||actx->block\_align = get\_le16(pb);|
|314||if (size == 14)	// We're dealing with plain vanilla WAVEFORMAT|

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)315	actx->bits\_per\_sample = 8;

316	else

317	actx->bits\_per\_sample = get\_le16(pb);

318	actx->codec\_id = codec\_get\_id(codec\_wav\_tags, id);

319

320	if (size > 16)

|321|{||
| - | - | - |
|322||actx->extradata\_size = get\_le16(pb);|
|323||if (actx->extradata\_size > 0)|
|324||{|
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)对音频，extradata 通常是保存的是 WAVEFORMATEX

325	if (actx->extradata\_size > size - 18)

326	actx->extradata\_size = size - 18;

327	actx->extradata = av\_mallocz(actx->extradata\_size +

328	FF\_INPUT\_BUFFER\_PADDING\_SIZE);

329	url\_fread(pb, actx->extradata, actx->extradata\_size);

330	}

331	else

332	{

333	actx->extradata\_size = 0;

334	}

335

336	// It is possible for the chunk to contain garbage at the end

337	if (size - actx->extradata\_size - 18 > 0)

338	url\_fskip(pb, size - actx->extradata\_size - 18);

339	}

340	}

341

342	if (size % 2) // 2-aligned (fix for Stargate SG-1 - 3x18 - Shades of

Grey.avi)

343	url\_fskip(pb, 1);

344

345	break;

346	default:![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

对其他流类型，ffplay 简单的设置为 data 流。常规的是音频流和视频流，其他的少见。

347	st->actx->codec\_type = CODEC\_TYPE\_DATA;

348	st->actx->codec\_id = CODEC\_ID\_NONE;

349	url\_fskip(pb, size);

350	break;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

351	}

352	}

353	break;

354	default:	// skip tag![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

对其他不识别的块 chunk，跳过。

355	size += (size &1);

356	url\_fskip(pb, size);

357	break;

358	}

359	}

360

361 end\_of\_header:

362	if (stream\_index != s->nb\_streams - 1)

363	{

364 fail:![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

校验流的数目，如果有误，释放相关资源，返回-1 错误。

365	for (i = 0; i < s->nb\_streams; i++)

366	{

367	av\_freep(&s->streams[i]->actx->extradata);

368	av\_freep(&s->streams[i]);

369	}

370	return	- 1;

371	}

372![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

加载 AVI 文件索引。

373	avi\_load\_index(s);

374![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

判别是否是非交织 avi。

375	avi->non\_interleaved |= guess\_ni\_flag(s);

376	if (avi->non\_interleaved)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

对那些非交织存储的媒体流，人工的补上索引，便于读取操作。

377	clean\_index(s);

378

379	return 0;

380 }

381

avi 文件可以简单认为音视频媒体数据时间基相同，因此音视频数据需要同步读取，同步解码，播放才

能同步。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.116.png)交织存储的 avi 文件，临近存储的音视频帧解码时间表示时间相近，微小的解码时间表示时间差别可 以用帧缓存队列抵消，所以可以简单的按照文件顺序读取媒体数据。

非交织存储的 avi 文件，视频和音频这两种媒体数据相隔甚远，小缓存简单的顺序读文件时，不能同 时读到音频和视频数据，最后导致不同步，ffplay 采取按最近时间点来决定读音频还是视频数据。

382 int avi\_read\_packet(AVFormatContext \*s, AVPacket \*pkt)

383 {

384	AVIContext \*avi = s->priv\_data;

385	ByteIOContext \*pb = &s->pb;

386	int n, d[8], size;

387	offset\_t i, sync;

388

389	if (avi->non\_interleaved)

390	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果是非交织 AVI，用最近时间点来决定读取视频还是音频数据。

391	int best\_stream\_index = 0;

392	AVStream \*best\_st = NULL;

393	AVIStream \*best\_ast;

394	int64\_t best\_ts = INT64\_MAX;

395	int i;

396

397	for (i = 0; i < s->nb\_streams; i++)

398	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

遍历所有媒体流，按照已经播放的流数据，计算下一个最近的时间点。

399	AVStream \*st = s->streams[i];

400	AVIStream \*ast = st->priv\_data;

401	int64\_t ts = ast->frame\_offset;

402![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

把帧偏移换算成帧数。

403	if (ast->sample\_size)

404	ts /= ast->sample\_size;

405![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

把帧数换算成 pts 表示时间。

406	ts = av\_rescale(ts, AV\_TIME\_BASE \*(int64\_t)st->time\_base.num, st->time\_base.den);

407![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.117.png)

取最小的时间点对应的时间，流指针，流索引作为要读取的最佳 (读取)流参数。

408	if (ts < best\_ts) // 每次读取时间点(ast->frame\_offset)最近的包

409	{

410	best\_ts = ts;

411	best\_st = st;

412	best\_stream\_index = i;

413	}

414	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

保存最佳流对应的 AVIStream，便于 432 行赋值并传递参数 packet\_size 和 remaining。

415	best\_ast = best\_st->priv\_data;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.096.png)

换算最小的时间点，查找索引表取出对应的索引。在缓存足够大，一次性完整读取帧数据时，此时

best\_ast->remaining 参数为 0。

416	best\_ts = av\_rescale(best\_ts,best\_st->time\_base.den,AV\_TIME\_BASE \*(int64\_t)best\_st->time\_base.num);

417	if (best\_ast->remaining)

418	i = av\_index\_search\_timestamp(best\_st, best\_ts, AVSEEK\_FLAG\_ANY | AVSEEK\_FLAG\_BACKWARD);

419	else

420	i = av\_index\_search\_timestamp(best\_st, best\_ts, AVSEEK\_FLAG\_ANY);

421

422	if (i >= 0)

423	{

找到最佳索引，取出其他参数，在 426 行 seek 到相应位置，在 430 行保存最佳流索引，在 432 行保存

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.096.png)并传递要读取的数据大小(通过最佳流索引找到最佳流，再找到对应 AVIStream 结构，再找到数据大小)。

424	int64\_t pos = best\_st->index\_entries[i].pos;

425	pos += best\_ast->packet\_size - best\_ast->remaining;

426	url\_fseek(&s->pb, pos + 8, SEEK\_SET);

427

428	assert(best\_ast->remaining <= best\_ast->packet\_size);

429

430	avi->stream\_index\_2 = best\_stream\_index;

431	if (!best\_ast->remaining)

432	best\_ast->packet\_size = best\_ast->remaining = best\_st->index\_entries[i].size;

433	}

434	}

435

436 resync:

437

438	if (avi->stream\_index\_2 >= 0)

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)439	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

如果找到最佳流索引，以此为根参数，取出其他参数和读取媒体数据。

440	AVStream \*st = s->streams[avi->stream\_index\_2];

441	AVIStream \*ast = st->priv\_data;

442	int size;

443

444	if (ast->sample\_size <= 1) // minorityreport.AVI block\_align=1024 sample\_size=1 IMA- ADPCM

445	size = INT\_MAX;

446	else if (ast->sample\_size < 32)

447	size = 64 \* ast->sample\_size;

448	else

449	size = ast->sample\_size;

450![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

在缓存足够大，一次全部读取一帧媒体数据的情况下，451 行判断不成立，size 等于 ast->sample\_size

451	if (size > ast->remaining)

452	size = ast->remaining;

453![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

调用 av\_get\_packet()函数实际读取媒体数据到 pkt 包中。

454	av\_get\_packet(pb, pkt, size);

455![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

修改媒体流的一些其他参数。

456	pkt->dts = ast->frame\_offset;

457

458	if (ast->sample\_size)

459	pkt->dts /= ast->sample\_size;

460

461	pkt->stream\_index = avi->stream\_index\_2;

462![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

在简单情况顺序播放时，463 行到 487 行没有什么实际意义。

463	if (st->actx->codec\_type == CODEC\_TYPE\_VIDEO)

464	{

465	if (st->index\_entries)

466	{

467	AVIndexEntry \*e;

468	int index;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

469

470	index = av\_index\_search\_timestamp(st, pkt->dts, 0);

471	e = &st->index\_entries[index];

472

473	if (index >= 0 && e->timestamp == ast->frame\_offset)

474	{

475	if (e->flags &AVINDEX\_KEYFRAME)

476	pkt->flags |= PKT\_FLAG\_KEY;

477	}

478	}

479	else

480	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果没有索引，较好的办法是把所有帧都设为关键帧。


|481||pkt->flags |= PKT\_FLAG\_KEY;|
| - | - | - |
|482|}||
|483|}||
|484|else||
|485|{||
486	pkt->flags |= PKT\_FLAG\_KEY;

487	}

488![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

修改帧偏移。

489	if (ast->sample\_size)

490	ast->frame\_offset += pkt->size;

491	else

492	ast->frame\_offset++;

493

494	ast->remaining -= size;

495	if (!ast->remaining)

496	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

缓存足够大时，程序一定跑到这里，复位标志性参数。

497	avi->stream\_index\_2 =	- 1;

498	ast->packet\_size = 0;

499	if (size &1)

|500|{||
| - | - | - |
|501||get\_byte(pb);|
|502||size++;|
|503|}||

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)504	}

505![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

返回实际读到的数据大小。

506	return size;

507	}

508

509	memset(d,	- 1, sizeof(int) \*8);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

把数组 d[8]清为-1，为了在下面的流标记查找时不会出错。

510	for (i = sync = url\_ftell(pb); !url\_feof(pb); i++)

511	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

交织 avi 时顺序读取文件，媒体数据。

512	int j;

513

514	if (i >= avi->movi\_end)

515	break;

516

首先要找到流标记，比如 00db,00dc,01w b 等。在 32bit CPU 上为存取数据方便，把 avi 文件中的帧标记

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.095.png)和帧大小共 8 个字节对应赋值到 in t 型数组 d[8]中，这样每次是整数操作。

517	for (j = 0; j < 7; j++)

518	d[j] = d[j + 1];

519![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

518 行把整型缓存前移一个单位。520 行从文件中读一个字节补充到整型缓存，计算包大小和流索引。

520	d[7] = get\_byte(pb);

521

522	size = d[4] + (d[5] << 8) + (d[6] << 16) + (d[7] << 24);

523

524	if (d[2] >= '0' && d[2] <= '9' && d[3] >= '0' && d[3] <= '9')

525	{

526	n = (d[2] - '0') \*10+(d[3] - '0');

527	}

528	else

529	{

530	n = 100; //invalid stream id

531	}

532![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.118.png)

校验 size 大小，如果偏移位置加 size 超过数据块大小就不是有效的流标记。

校验流索引，如果<0 就不是有效的流标记。流索引从 0 开始计数，媒体文件通常不超过 10 个流。

533	if (i + size > avi->movi\_end || d[0] < 0)

534	continue;

535![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

536 行到 541 行代码处理诸如 jun k 等需要跳过的块。

536	if ((d[0] == 'i' && d[1] == 'x' && n < s->nb\_streams)

537	|| (d[0] == 'J' && d[1] == 'U' && d[2] == 'N' && d[3] == 'K'))

538	{

539	url\_fskip(pb, size);

540	goto resync;

541	}

542![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

计算流索引号 n。

543	if (d[0] >= '0' && d[0] <= '9' && d[1] >= '0' && d[1] <= '9')

544	{

545	n = (d[0] - '0') \*10+(d[1] - '0');

546	}

547	else

548	{

549	n = 100; //invalid stream id

550	}

551

552	//parse ##dc/##wb

553	if (n < s->nb\_streams)

554	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果流索引号 n 比流总数小，认为有效。(我个人认为这个校验不太严格。)

555	AVStream \*st;

556	AVIStream \*ast;

557	st = s->streams[n];

558	ast = st->priv\_data;

559

560	if (((ast->prefix\_count < 5 || sync + 9 > i) && d[2] < 128 && d[3] < 128)

561	|| d[2] \* 256 + d[3] == ast->prefix)

562	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

if(d[2]\*256+d[3]==ast->prefix)为真表示 "db","dc","wb"等字串匹配，找到正确帧标记。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.119.png)判断 d[2]<128 && d[3]<128 是因为 'd','b','c','w'等字符的 ascii 码小于 128。

判断 ast->prefix\_count<5 || sync + 9 > i，是判断单一媒体的 5 帧内或找帧标记超过 9 个字节。

563 行到 569 行是单一媒体帧边界初次识别成功和以后识别成功的简单处理，计数自增或保存标记。

563	if (d[2] \* 256 + d[3] == ast->prefix)

564	ast->prefix\_count++;

565	else

566	{

567	ast->prefix = d[2] \*256+d[3];

568	ast->prefix\_count = 0;

569	}

570![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

找到相应的流索引后，保存相关参数，跳转到实质性读媒体程序。

571	avi->stream\_index\_2 = n;

572	ast->packet\_size = size + 8;

573	ast->remaining = size;

574	goto resync;

575	}

576	}

577	// palette changed chunk

578	if (d[0] >= '0' && d[0] <= '9' && d[1] >= '0' && d[1] <= '9'

579	&& (d[2] == 'p' && d[3] == 'c') && n < s->nb\_streams && i + size <= avi->movi\_end)

580	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.102.png)

处理调色板改变块数据，读取调色板数据到编解码器上下文的调色板数组中。

581	AVStream \*st;

582	int first, clr, flags, k, p;

583

584	st = s->streams[n];

585

586	first = get\_byte(pb);

587	clr = get\_byte(pb);

588	if (!clr) // all 256 colors used

589	clr = 256;

590	flags = get\_le16(pb);

591	p = 4;

592	for (k = first; k < clr + first; k++)

593	{

594	int r, g, b;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

595	r = get\_byte(pb);

596	g = get\_byte(pb);

597	b = get\_byte(pb);

598	get\_byte(pb);

599	st->actx->palctrl->palette[k] = b + (g << 8) + (r << 16);

600	}

601	st->actx->palctrl->palette\_changed = 1;

602	goto resync;

603	}

604	}

605

606	return	- 1;

607 }

608![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

实质读取 AVI 文件的索引。

609 static int avi\_read\_idx1(AVFormatContext \*s, int size)

610 {

611	AVIContext \*avi = s->priv\_data;

612	ByteIOContext \*pb = &s->pb;

613	int nb\_index\_entries, i;

614	AVStream \*st;

615	AVIStream \*ast;

616	unsigned int index, tag, flags, pos, len;

617	unsigned last\_pos =	- 1;

618

619	nb\_index\_entries = size / 16;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

如果没有索引块 chunk，直接返回。

620	if (nb\_index\_entries <= 0)

621	return	- 1;

622![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

遍历整个索引项。

623	for (i = 0; i < nb\_index\_entries; i++)

624	{

625	tag = get\_le32(pb);

626	flags = get\_le32(pb);

627	pos = get\_le32(pb);

628	len = get\_le32(pb);

629

如果第一个索引指示的偏移量大于数据块的偏移量，则索引指示的偏移量是相对文件开始字节的偏移

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.120.png)量。索引加载到内存后，如果是相对数据块的偏移量就要换算成相对于文件开始字节的偏移量，便于 seek

操作。在 631 行和 633 行统一处理这两个情况。

630	if (i == 0 && pos > avi->movi\_list)

631	avi->movi\_list = 0;

632

633	pos += avi->movi\_list;

634![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

计算流 ID，如索引块中的 00dc，01w b 等关键字表示的流 ID 分别为数字 0 和 1。

635	index = ((tag &0xff) - '0') \*10;

636	index += ((tag >> 8) &0xff) - '0';

637	if (index >= s->nb\_streams)

638	continue;

639

640	st = s->streams[index];

641	ast = st->priv\_data;

642

643	if (last\_pos == pos)

644	avi->non\_interleaved = 1;

645	else

646	av\_add\_index\_entry(st, pos, ast->cum\_len, len, 0, (flags&AVIIF\_INDEX)?AVINDEX\_KEYFRAME:0);

647

648	if (ast->sample\_size)

649	ast->cum\_len += len / ast->sample\_size;

650	else

651	ast->cum\_len++;

652	last\_pos = pos;

653	}

654	return 0;

655 }

656

判断是否是非交织存放媒体数据，其中 ni 是 non\_interleaved 的缩写，非交织的意思。如果是非交织

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.121.png)存放返回 1，交织存放返回 0。

非交织存放的 avi 文件，如果有多个媒体流，肯定有某个流的开始字节文件偏移量大于其他某个流的 末尾字节的文件偏移量。程序利用这个来判断是否是非交织存放，否则认定为交织存放。

657 static int guess\_ni\_flag(AVFormatContext \*s)

658 {

659	int i;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

660	int64\_t last\_start = 0;

661	int64\_t first\_end = INT64\_MAX;

662![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.101.png)

遍历 AVI 文件中所有的索引，取流开始偏移量的最大值和末尾偏移量的最小值判断。

663	for (i = 0; i < s->nb\_streams; i++)

664	{

665	AVStream \*st = s->streams[i];

666	int n = st->nb\_index\_entries;

667![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.101.png)

如果某个流没有 index 项，认为这个流没有数据，这个流忽略不计。

668	if (n <= 0)

669	continue;

670![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.101.png)

遍历 AVI 文件中所有的索引，取流开始偏移量的最大值。

671	if (st->index\_entries[0].pos > last\_start)

672	last\_start = st->index\_entries[0].pos;

673![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.101.png)

遍历 AVI 文件中所有的索引，取流末尾偏移量的最小值。

674	if (st->index\_entries[n - 1].pos < first\_end)

675	first\_end = st->index\_entries[n - 1].pos;

676	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.100.png)

如果某个流的开始最大值大于某个流的末尾最小值，认为是非交织存储，否则是交织存储。

677	return last\_start > first\_end;

678 }

679

加载 AVI 文件索引块 chunk，特别注意在 avi\_read\_ idx1()函数调用的 av\_add\_index\_entry()函数是分媒

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.109.png)体类型按照时间顺序重新排序的。

680 static int avi\_load\_index(AVFormatContext \*s)

681 {

682	AVIContext \*avi = s->priv\_data;

683	ByteIOContext \*pb = &s->pb;

684	uint32\_t tag, size;

685	offset\_t pos = url\_ftell(pb);

686

687	url\_fseek(pb, avi->movi\_end, SEEK\_SET);

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)688

689	for (;;)

690	{

691	if (url\_feof(pb))

692	break;

693	tag = get\_le32(pb);

694	size = get\_le32(pb);

695

696	switch (tag)

697	{

698	case MKTAG('i', 'd', 'x', '1'):

699	if (avi\_read\_idx1(s, size) < 0)

700	goto skip;

701	else

702	goto the\_end;

703	break;

704	default:

705 skip:

706	size += (size &1);

707	url\_fskip(pb, size);

708	break;

709	}

710	}

711 the\_end:

712	url\_fseek(pb, pos, SEEK\_SET);

713	return 0;

714 }

715![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.094.png)

关闭 AVI 文件，释放内存和其他相关资源。

716 static int avi\_read\_close(AVFormatContext \*s)

717 {

718	int i;

719	AVIContext \*avi = s->priv\_data;

720

721	for (i = 0; i < s->nb\_streams; i++)

722	{

723	AVStream \*st = s->streams[i];

724	AVIStream \*ast = st->priv\_data;

725	av\_free(ast);

726	av\_free(st->actx->extradata);

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)727	av\_free(st->actx->palctrl);

728	}

729

730	return 0;

731 }

732![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

AVI 文件判断，取 AVI 文件的关键字串"RIFF"和"AVI "判断，和 get\_riff()函数部分相同。

733 static int avi\_probe(AVProbeData \*p)

734 {

735	if (p->buf\_size <= 32) // check file header

736	return 0;

737	if (p->buf[0] == 'R' && p->buf[1] == 'I' && p->buf[2] == 'F' && p->buf[3] == 'F'

738	&& p->buf[8] == 'A' && p->buf[9] == 'V' && p->buf[10] == 'I'&& p->buf[11] == ' ')

739	return AVPROBE\_SCORE\_MAX;

740	else

741	return 0;

742 }

743![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

初始化 AVI 文件格式 AVInputFormat 结构，直接的赋值操作。

744 AVInputFormat avi\_iformat =

745 {

746	"avi",

747	sizeof(AVIContext),

748	avi\_probe,

749	avi\_read\_header,

750	avi\_read\_packet,

751	avi\_read\_close,

752 };

753![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.091.png)

注册 avi 文件格式，ffplay 把所有支持的文件格式用链表串联起来，表头是 first\_iformat，便于查找。

754 int avidec\_init(void)

755 {

756	av\_register\_input\_format(&avi\_iformat);

757	return 0;

758 }

759


## **5.4 libswscale视频色彩空间转换**
## **5.5 libswresample音频重采样**
## **5.6 libavfilter音视频滤器**
## **5.7 libavdevice设备输入和输出容器**
## **5.8 libpostproc视频后期处理**
# **第六章 播放器**
## **6.1 视频播放器**
### **6.1.1 ffmpeg库的配置**
从http://ffmpeg.zeranoe.com/builds/网站上

1.下载Dev版本，里面包含了ffmpeg的xxx.h头文件以及xxx.lib库文件；

2.下载Shared版本，里面包含了ffmpeg的dll文件；

3.将这两部分文件拷贝到VC工程下面就可以了。

**FFMPEG 库移植到 VC 需要的步骤：**

在VC下使用FFMPEG编译好的库，不仅仅是把.h，.lib，.dll拷贝到工程中就行了，还需要做以下几步。（此方法适用于自己使用MinGW编译的库，也同样适用于从网上下载的编译好的库，例如http://ffmpeg.zeranoe.com/builds/）。

（1）像其他额外库一样，设置VC的Include路径为你c:\msys\local\include,设置VClib路径为次c:\msys\local\bin，增加操作系统的一个Path c:\msys\local\bin（这一步好像不是必须的）。

（2）将mingw安装目录下的include的inttypes.h，stdint.h，\_mingw.h三个文件拷到你ffmpeg库的目录下的include

（3）在\_mingw.h文件的结尾处(在#endif 一行之前)添加了一行：

#define \_\_restrict\_\_

（4）把所有long long改成了\_\_int64，如果是直接在vs2008下编译，则这个修改应该是不需要的(这步我没有遇到)

（5）

#ifdef \_\_cplusplus

#include "stdio.h"

#include "stdlib.h"

#include "string.h"

#include "SDL/SDL.h"

//#include "windows.h"

extern "C"

{

`        `#include "ffmpeg/avutil.h"

`        `#include "ffmpeg/avcodec.h"

`        `#include "ffmpeg/avformat.h"

}

#endif



#pragma comment(lib,"avutil.lib")

#pragma comment(lib,"avcodec.lib")

#pragma comment(lib,"avformat.lib")

（6）如果遇到error C3861: 'UINT64\_C': identifier not found

在common.h里加入定义如下：

#ifndef INT64\_C

#define INT64\_C(c) (c ## LL)

#define UINT64\_C(c) (c ## ULL)

#endif
### **6.1.2 一个简单的视频播放器**
该播放器虽然简单，但是几乎包含了使用FFMPEG播放一个视频所有必备的API，并且使用SDL显示解码出来的视频。

并且支持流媒体等多种视频输入，处于简单考虑，没有音频部分，同时视频播放采用直接延时40ms的方式

平台使用VC2010

使用了最新的FFMPEG类库

int \_tmain(int argc, \_TCHAR\* argv[])

{

`	`AVFormatContext	\*pFormatCtx;

`	`int				i, videoindex;

`	`AVCodecContext	\*pCodecCtx;

`	`AVCodec			\*pCodec;

`	`char filepath[]="nwn.mp4";

`	`av\_register\_all();

`	`avformat\_network\_init();

`	`pFormatCtx = avformat\_alloc\_context();

`	`if(avformat\_open\_input(&pFormatCtx,filepath,NULL,NULL)!=0){

`		`printf("无法打开文件\n");

`		`return -1;

`	`}

`	`if(av\_find\_stream\_info(pFormatCtx)<0)

`	`{

`		`printf("Couldn't find stream information.\n");

`		`return -1;

`	`}

`	`videoindex=-1;

`	`for(i=0; i<pFormatCtx->nb\_streams; i++) 

`		`if(pFormatCtx->streams[i]->codec->codec\_type==AVMEDIA\_TYPE\_VIDEO)

`		`{

`			`videoindex=i;

`			`break;

`		`}

`		`if(videoindex==-1)

`		`{

`			`printf("Didn't find a video stream.\n");

`			`return -1;

`		`}

`		`pCodecCtx=pFormatCtx->streams[videoindex]->codec;

`		`pCodec=avcodec\_find\_decoder(pCodecCtx->codec\_id);

`		`if(pCodec==NULL)

`		`{

`			`printf("Codec not found.\n");

`			`return -1;

`		`}

`		`if(avcodec\_open(pCodecCtx, pCodec)<0)

`		`{

`			`printf("Could not open codec.\n");

`			`return -1;

`		`}

`		`AVFrame	\*pFrame,\*pFrameYUV;

`		`pFrame=avcodec\_alloc\_frame();

`		`pFrameYUV=avcodec\_alloc\_frame();

`		`uint8\_t \*out\_buffer;

`		`out\_buffer=new uint8\_t[avpicture\_get\_size(PIX\_FMT\_YUV420P, pCodecCtx->width, pCodecCtx->height)];

`		`avpicture\_fill((AVPicture \*)pFrameYUV, out\_buffer, PIX\_FMT\_YUV420P, pCodecCtx->width, pCodecCtx->height);

//------------SDL----------------

`		`if(SDL\_Init(SDL\_INIT\_VIDEO | SDL\_INIT\_AUDIO | SDL\_INIT\_TIMER)) {  

`			`printf( "Could not initialize SDL - %s\n", SDL\_GetError()); 

`			`exit(1);

`		`} 

`		`SDL\_Surface \*screen; 

`		`screen = SDL\_SetVideoMode(pCodecCtx->width, pCodecCtx->height, 0, 0);

`		`if(!screen) {  printf("SDL: could not set video mode - exiting\n");  

`		`exit(1);

`		`}

`		`SDL\_Overlay \*bmp; 

`		`bmp = SDL\_CreateYUVOverlay(pCodecCtx->width, pCodecCtx->height,SDL\_YV12\_OVERLAY, screen); 

`		`SDL\_Rect rect;

//---------------

`		`int ret, got\_picture;

`		`static struct SwsContext \*img\_convert\_ctx;

`		`int y\_size = pCodecCtx->width \* pCodecCtx->height;

`		`AVPacket \*packet=(AVPacket \*)malloc(sizeof(AVPacket));

`		`av\_new\_packet(packet, y\_size);

`		`//输出一下信息-----------------------------

`		`printf("文件信息-----------------------------------------\n");

`		`av\_dump\_format(pFormatCtx,0,filepath,0);

`		`printf("-------------------------------------------------\n");

`		`//------------------------------

`		`while(av\_read\_frame(pFormatCtx, packet)>=0)

`		`{

`			`if(packet->stream\_index==videoindex)

`			`{

`				`ret = avcodec\_decode\_video2(pCodecCtx, pFrame, &got\_picture, packet);

`				`if(ret < 0)

`				`{

`					`printf("解码错误\n");

`					`return -1;

`				`}

`				`if(got\_picture)

`				`{

`					`img\_convert\_ctx = sws\_getContext(pCodecCtx->width, pCodecCtx->height, pCodecCtx->pix\_fmt, pCodecCtx->width, pCodecCtx->height, PIX\_FMT\_YUV420P, SWS\_BICUBIC, NULL, NULL, NULL); 

`					`sws\_scale(img\_convert\_ctx, (const uint8\_t\* const\*)pFrame->data, pFrame->linesize, 0, pCodecCtx->height, pFrameYUV->data, pFrameYUV->linesize);

`					`SDL\_LockYUVOverlay(bmp);

`					`bmp->pixels[0]=pFrameYUV->data[0];

`					`bmp->pixels[2]=pFrameYUV->data[1];

`					`bmp->pixels[1]=pFrameYUV->data[2];     

`					`bmp->pitches[0]=pFrameYUV->linesize[0];

`					`bmp->pitches[2]=pFrameYUV->linesize[1];   

`					`bmp->pitches[1]=pFrameYUV->linesize[2];

`					`SDL\_UnlockYUVOverlay(bmp); 

`					`rect.x = 0;    

`					`rect.y = 0;    

`					`rect.w = pCodecCtx->width;    

`					`rect.h = pCodecCtx->height;    

`					`SDL\_DisplayYUVOverlay(bmp, &rect); 

`					`//延时40ms

`					`SDL\_Delay(40);

`				`}

`			`}

`			`av\_free\_packet(packet);

`		`}

`		`delete[] out\_buffer;

`		`av\_free(pFrameYUV);

`		`avcodec\_close(pCodecCtx);

`		`avformat\_close\_input(&pFormatCtx);

`		`return 0;

}
## **6.2 音频播放器**
注意：

1.程序输出的解码后PCM音频数据可以使用Audition打开播放

2.m4a,aac文件可以直接播放。mp3文件需要调整SDL音频帧大小为4608（默认是4096），否则播放会不流畅

3.也可以播放视频中的音频

#include <stdlib.h>

#include <string.h>

extern "C"

{

#include "libavcodec/avcodec.h"

#include "libavformat/avformat.h"

//SDL

#include "sdl/SDL.h"

#include "sdl/SDL\_thread.h"

};

#include "decoder.h"

//#include "wave.h"

//#define \_WAVE\_

//全局变量---------------------

`	`static  Uint8  \*audio\_chunk; 

`	`static  Uint32  audio\_len; 

`	`static  Uint8  \*audio\_pos; 

//-----------------

`	`/\*  The audio function callback takes the following parameters: 

`	`stream: A pointer to the audio buffer to be filled 

`	`len: The length (in bytes) of the audio buffer (这是固定的4096？)

`	`回调函数

`	`注意：mp3为什么播放不顺畅？

`	`len=4096;audio\_len=4608;两个相差512！为了这512，还得再调用一次回调函数。。。

`	`m4a,aac就不存在此问题(都是4096)！

`	`\*/ 

`	`void  fill\_audio(void \*udata,Uint8 \*stream,int len){ 

`		`/\*  Only  play  if  we  have  data  left  \*/ 

`	`if(audio\_len==0) 

`			`return; 

`		`/\*  Mix  as  much  data  as  possible  \*/ 

`	`len=(len>audio\_len?audio\_len:len); 

`	`SDL\_MixAudio(stream,audio\_pos,len,SDL\_MIX\_MAXVOLUME);

`	`audio\_pos += len; 

`	`audio\_len -= len; 

`	`} 

//-----------------

int decode\_audio(char\* no\_use)

{

`	`AVFormatContext	\*pFormatCtx;

`	`int				i, audioStream;

`	`AVCodecContext	\*pCodecCtx;

`	`AVCodec			\*pCodec;

`	`char url[300]={0};

`	`strcpy(url,no\_use);

`	`//Register all available file formats and codecs

`	`av\_register\_all();

`	`//支持网络流输入

`	`avformat\_network\_init();

`	`//初始化

`	`pFormatCtx = avformat\_alloc\_context();

`	`//有参数avdic

`	`//if(avformat\_open\_input(&pFormatCtx,url,NULL,&avdic)!=0){

`	`if(avformat\_open\_input(&pFormatCtx,url,NULL,NULL)!=0){

`		`printf("Couldn't open file.\n");

`		`return -1;

`	`}



`	`// Retrieve stream information

`	`if(av\_find\_stream\_info(pFormatCtx)<0)

`	`{

`		`printf("Couldn't find stream information.\n");

`		`return -1;

`	`}

`	`// Dump valid information onto standard error

`	`av\_dump\_format(pFormatCtx, 0, url, false);

`	`// Find the first audio stream

`	`audioStream=-1;

`	`for(i=0; i < pFormatCtx->nb\_streams; i++)

`		`//原为codec\_type==CODEC\_TYPE\_AUDIO

`		`if(pFormatCtx->streams[i]->codec->codec\_type==AVMEDIA\_TYPE\_AUDIO)

`		`{

`			`audioStream=i;

`			`break;

`		`}

`	`if(audioStream==-1)

`	`{

`		`printf("Didn't find a audio stream.\n");

`		`return -1;

`	`}

`	`// Get a pointer to the codec context for the audio stream

`	`pCodecCtx=pFormatCtx->streams[audioStream]->codec;

`	`// Find the decoder for the audio stream

`	`pCodec=avcodec\_find\_decoder(pCodecCtx->codec\_id);

`	`if(pCodec==NULL)

`	`{

`		`printf("Codec not found.\n");

`		`return -1;

`	`}

`	`// Open codec

`	`if(avcodec\_open(pCodecCtx, pCodec)<0)

`	`{

`		`printf("Could not open codec.\n");

`		`return -1;

`	`}

`	`/\*\*\*\*\*\*\*\*\* For output file \*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/

`	`FILE \*pFile;

#ifdef \_WAVE\_

`	`pFile=fopen("output.wav", "wb");

`	`fseek(pFile, 44, SEEK\_SET); //预留文件头的位置

#else

`	`pFile=fopen("output.pcm", "wb");

#endif

`	`// Open the time stamp file

`	`FILE \*pTSFile;

`	`pTSFile=fopen("audio\_time\_stamp.txt", "wb");

`	`if(pTSFile==NULL)

`	`{

`		`printf("Could not open output file.\n");

`		`return -1;

`	`}

`	`fprintf(pTSFile, "Time Base: %d/%d\n", pCodecCtx->time\_base.num, pCodecCtx->time\_base.den);

`	`/\*\*\* Write audio into file \*\*\*\*\*\*/

`	`//把结构体改为指针

`	`AVPacket \*packet=(AVPacket \*)malloc(sizeof(AVPacket));

`	`av\_init\_packet(packet);

`	`//音频和视频解码更加统一！

`	`//新加

`	`AVFrame	\*pFrame;

`	`pFrame=avcodec\_alloc\_frame();

`	`//---------SDL--------------------------------------

`	`//初始化

`	`if(SDL\_Init(SDL\_INIT\_VIDEO | SDL\_INIT\_AUDIO | SDL\_INIT\_TIMER)) {  

`		`printf( "Could not initialize SDL - %s\n", SDL\_GetError()); 

`		`exit(1);

`	`}

`	`//结构体，包含PCM数据的相关信息

`	`SDL\_AudioSpec wanted\_spec;

`	`wanted\_spec.freq = pCodecCtx->sample\_rate; 

`	`wanted\_spec.format = AUDIO\_S16SYS; 

`	`wanted\_spec.channels = pCodecCtx->channels; 

`	`wanted\_spec.silence = 0; 

`	`wanted\_spec.samples = 1024; //播放AAC，M4a，缓冲区的大小

`	`//wanted\_spec.samples = 1152; //播放MP3，WMA时候用

`	`wanted\_spec.callback = fill\_audio; 

`	`wanted\_spec.userdata = pCodecCtx; 

`	`if (SDL\_OpenAudio(&wanted\_spec, NULL)<0)//步骤（2）打开音频设备 

`	`{ 

`		`printf("can't open audio.\n"); 

`		`return 0; 

`	`} 

`	`//-----------------------------------------------------

`	`printf("比特率 %3d\n", pFormatCtx->bit\_rate);

`	`printf("解码器名称 %s\n", pCodecCtx->codec->long\_name);

`	`printf("time\_base  %d \n", pCodecCtx->time\_base);

`	`printf("声道数  %d \n", pCodecCtx->channels);

`	`printf("sample per second  %d \n", pCodecCtx->sample\_rate);

`	`//新版不再需要

//	short decompressed\_audio\_buf[(AVCODEC\_MAX\_AUDIO\_FRAME\_SIZE \* 3) / 2];

//	int decompressed\_audio\_buf\_size;

`	`uint32\_t ret,len = 0;

`	`int got\_picture;

`	`int index = 0;

`	`while(av\_read\_frame(pFormatCtx, packet)>=0)

`	`{

`		`if(packet->stream\_index==audioStream)

`		`{

`			`//decompressed\_audio\_buf\_size = (AVCODEC\_MAX\_AUDIO\_FRAME\_SIZE \* 3) / 2;

`			`//原为avcodec\_decode\_audio2

`				`//ret = avcodec\_decode\_audio4( pCodecCtx, decompressed\_audio\_buf,

`				`//&decompressed\_audio\_buf\_size, packet.data, packet.size );

`			`//改为

`			`ret = avcodec\_decode\_audio4( pCodecCtx, pFrame,

`				`&got\_picture, packet);

`			`if ( ret < 0 ) // if error len = -1

`			`{

`                `printf("Error in decoding audio frame.\n");

`                `exit(0);

`            `}

`			`if ( got\_picture > 0 )

`			`{

#if 1

`				`printf("index %3d\n", index);

`				`printf("pts %5d\n", packet->pts);

`				`printf("dts %5d\n", packet->dts);

`				`printf("packet\_size %5d\n", packet->size);



`				`//printf("test %s\n", rtmp->m\_inChunkSize);

#endif

`				`//直接写入

`				`//注意：数据是data【0】，长度是linesize【0】

#if 1

`				`fwrite(pFrame->data[0], 1, pFrame->linesize[0], pFile);

`				`//fwrite(pFrame, 1, got\_picture, pFile);

`				`//len+=got\_picture;

`				`index++;

`				`//fprintf(pTSFile, "%4d,%5d,%8d\n", index, decompressed\_audio\_buf\_size, packet.pts);

#endif

`			`}

#if 1

`			`//---------------------------------------

`			`//printf("begin....\n"); 

`			`//设置音频数据缓冲,PCM数据

`			`audio\_chunk = (Uint8\*) pFrame->data[0]; 

`			`//设置音频数据长度

`			`audio\_len = pFrame->linesize[0];

`			`//audio\_len = 4096;

`			`//播放mp3的时候改为audio\_len = 4096

`			`//则会比较流畅，但是声音会变调！MP3一帧长度4608

`			`//使用一次回调函数（4096字节缓冲）播放不完，所以还要使用一次回调函数，导致播放缓慢。。。

`			`//设置初始播放位置

`			`audio\_pos = audio\_chunk;

`			`//回放音频数据 

`			`SDL\_PauseAudio(0);

`			`//printf("don't close, audio playing...\n"); 

`			`while(audio\_len>0)//等待直到音频数据播放完毕! 

`				`SDL\_Delay(1); 

`			`//---------------------------------------

#endif

`		`}

`		`// Free the packet that was allocated by av\_read\_frame

`		`//已改

`		`av\_free\_packet(packet);

`	`}

`	`//printf("The length of PCM data is %d bytes.\n", len);

#ifdef \_WAVE\_

`	`fseek(pFile, 0, SEEK\_SET);

`	`struct WAVE\_HEADER wh;

`	`memcpy(wh.header.RiffID, "RIFF", 4);

`	`wh.header.RiffSize = 36 + len;

`	`memcpy(wh.header.RiffFormat, "WAVE", 4);

`	`memcpy(wh.format.FmtID, "fmt ", 4);

`	`wh.format.FmtSize = 16;

`	`wh.format.wavFormat.FormatTag = 1;

`	`wh.format.wavFormat.Channels = pCodecCtx->channels;

`	`wh.format.wavFormat.SamplesRate = pCodecCtx->sample\_rate;

`	`wh.format.wavFormat.BitsPerSample = 16;

`	`calformat(wh.format.wavFormat); //Calculate AvgBytesRate and BlockAlign

`	`memcpy(wh.data.DataID, "data", 4);

`	`wh.data.DataSize = len;

`	`fwrite(&wh, 1, sizeof(wh), pFile);

#endif

`	`SDL\_CloseAudio();//关闭音频设备 

`	`// Close file

`	`fclose(pFile);

`	`// Close the codec

`	`avcodec\_close(pCodecCtx);

`	`// Close the video file

`	`av\_close\_input\_file(pFormatCtx);

`	`return 0;

}
## **6.3 一个完整的播放器--ffplay**
### **6.3.1 ffplay流程图**
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.122.jpeg)
### **6.3.2 ffplay源码剖析**
ffplay.c 文件

1 功能描述

主控文件，初始化运行环境，把各个数据结构和功能函数有机组织起来，协调数据流和功能函数，响应用户 操作，启动并控制程序运行。

2 文件注释

1	#include "./libavformat/avformat.h"

2

3	#if defined(CONFIG\_WIN32)

4	#include <sys/types.h>

5	#include <sys/timeb.h>

6	#include <windows.h>

7	#else

8	#include <fcntl.h>

9	#include <sys/time.h>

10	#endif

11

12	#include <time.h>

13

14	#include <math.h>

15	#include <SDL.h>

16	#include <SDL\_thread.h>

17

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.123.png)SDL 里面定义了 main 函数，所以在这里取消 sdl 中的 main 定义，避免重复定义。

18	#ifdef CONFIG\_WIN32

19	#undef main // We don't want SDL to override our main()

20	#endif

21

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.123.png)导入 SDL 库。

22	#pragma comment(lib, "SDL.lib")

23

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.123.png)简单的几个常数定义。

24	#define FF\_QUIT\_EVENT	(SDL\_USEREVENT + 2)

25

26	#define MAX\_VIDEOQ\_SIZE (5 \* 256 \* 1024)

27	#define MAX\_AUDIOQ\_SIZE (5 \* 16 \* 1024)

28

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)29	#define VIDEO\_PICTURE\_QUEUE\_SIZE 1

30

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.123.png)音视频数据包/数据帧队列数据结构定义，几个数据成员一看就明白，不详述。

31	typedef struct PacketQueue

32	{

33	AVPacketList \*first\_pkt,	\*last\_pkt;

34	int size;

35	int abort\_request;

36	SDL\_mutex \*mutex;

37	SDL\_cond \*cond;

38	} PacketQueue;

39

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.123.png)视频图像数据结构定义，几个数据成员一看就明白，不详述。

40	typedef struct VideoPicture

41	{

42	SDL\_Overlay \*bmp;

43	int width, height; // source height & width

44	} VideoPicture;

45

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.123.png)总控数据结构，把其他核心数据结构整合在一起，起一个中转的作用，便于在各个子结构之间跳转。

46	typedef struct VideoState

47	{

48	SDL\_Thread \*parse\_tid;	// Demux 解复用线程指针

49	SDL\_Thread \*video\_tid;	// video 解码线程指针

50

51	int abort\_request;	// 异常退出请求标记

52

53	AVFormatContext \*ic;	// 输入文件格式上下文指针，和 iformat 配套使用

54

55	int audio\_stream;	// 音频流索引，表示 AVFormatContext 中 AVStream \*streams[] 数组索引

56	int video\_stream;	// 视频流索引，表示 AVFormatContext 中 AVStream \*streams[] 数组索引

57

58	AVStream \*audio\_st;	// 音频流指针

59	AVStream \*video\_st;	// 视频流指针

60

61	PacketQueue audioq;	// 音频数据帧/数据包队列

62	PacketQueue videoq;	// 视频数据帧/数据包队列

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)63

64	VideoPicture pictq[VIDEO\_PICTURE\_QUEUE\_SIZE]; // 解码后视频图像队列数组

65	double frame\_last\_delay;	// 视频帧延迟，可简单认为是显示间隔时间

66

67	uint8\_t audio\_buf[(AVCODEC\_MAX\_AUDIO\_FRAME\_SIZE \*3) / 2];	// 输出音频缓存

68	unsigned int audio\_buf\_size;	// 解码后音频数据大小

69	int audio\_buf\_index;	// 已输出音频数据大小

70	AVPacket audio\_pkt;	// 如果一个音频包中有多个帧，用于保存中间状态

71	uint8\_t \*audio\_pkt\_data;	// 音频包数据首地址，配合 audio\_pkt 保存中间状态

72	int audio\_pkt\_size;	// 音频包数据大小，配合 audio\_pkt 保存中间状态

73

74	SDL\_mutex \*video\_decoder\_mutex;	// 视频数据包队列同步操作而定义的互斥量指针

75	SDL\_mutex \*audio\_decoder\_mutex;	// 音频数据包队列同步操作而定义的互斥量指针

76

77	char filename[240];	// 媒体文件名

78

79	} VideoState;

80

81	static AVInputFormat \*file\_iformat;

82	static const char \*input\_filename;

83	static VideoState \*cur\_stream;

84![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

SDL 库需要的显示表面。

85	static SDL\_Surface \*screen;

86![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

取得当前时间，以 1/1000000 秒为单位，为便于在各个平台上移植，由宏开关控制编译的代码。

87	int64\_t av\_gettime(void)

88	{

89	#if defined(CONFIG\_WINCE)

90	return timeGetTime() \*int64\_t\_C(1000);

91	#elif defined(CONFIG\_WIN32)

92	struct \_timeb tb;

93	\_ftime(&tb);

94	return ((int64\_t)tb.time \*int64\_t\_C(1000) + (int64\_t)tb.millitm) \*int64\_t\_C(1000);

95	#else

96	struct timeval tv;

97	gettimeofday(&tv, NULL);

98	return (int64\_t)tv.tv\_sec \*1000000+tv.tv\_usec;

99	#endif![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

100 }

101

数据帧/数据包生命周期：

1：在 av\_get\_packet()函数中调用 av\_malloc()函数分配内存，并调用 url\_fread()填充媒体数据。

2：如果是视频包调用 packet\_queue\_put()进 is->videoq 队列，如果是音频包进 is->audioq 队列， 如果是其他包，就调用 av\_free\_packet()函数直接释放内存。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.126.png)


![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.125.png)3：进入队列的包，用 packet\_queue\_get()取出队列，用 av\_free\_packet()释放内存。









![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)初始化队列，初始化为 0 后再创建线程同步使用的互斥和条件。

102 static void packet\_queue\_init(PacketQueue \*q) // packet queue handling

103 {

104	memset(q, 0, sizeof(PacketQueue));

105	q->mutex = SDL\_CreateMutex();

106	q->cond = SDL\_CreateCond();

107 }

108

刷新队列，释放掉队列中所有动态分配的内存，包括音视频裸数据占用的内存和 AVPacketList 结构占

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.127.png)用的内存，参考上面示意图。

109 static void packet\_queue\_flush(PacketQueue \*q)

110 {![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

111	AVPacketList \*pkt,	\*pkt1;

112![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

由于是多线程程序，需要同步，所以在遍历队列释放所有动态分配内存前，加锁。

113	SDL\_LockMutex(q->mutex);

114	for (pkt = q->first\_pkt; pkt != NULL; pkt = pkt1)

115	{

116	pkt1 = pkt->next;

117	av\_free\_packet(&pkt->pkt); // 释放音视频数据内存

118	av\_freep(&pkt);	// 释放 AVPacketList 结构

119	}

120	q->last\_pkt = NULL;

121	q->first\_pkt = NULL;

122	q->size = 0;

123	SDL\_UnlockMutex(q->mutex);

124 }

125![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

释放队列占用所有资源，首先释放掉所有动态分配的内存，接着释放申请的互斥量和条件量。

126 static void packet\_queue\_end(PacketQueue \*q)

127 {

128	packet\_queue\_flush(q);

129	SDL\_DestroyMutex(q->mutex);

130	SDL\_DestroyCond(q->cond);

131 }

132![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

往音视频队列中挂接音视频数据帧/数据包。

133 static int packet\_queue\_put(PacketQueue \*q, AVPacket \*pkt)

134 {

135	AVPacketList \*pkt1;

136![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

先分配一个 AVPacketList 结构内存，接着，140 行从 AVPacket 浅复制数据，141 行链表尾置空。

137	pkt1 = av\_malloc(sizeof(AVPacketList));

138	if (!pkt1)

139	return	- 1;

140	pkt1->pkt =	\*pkt;

141	pkt1->next = NULL;

142

143	SDL\_LockMutex(q->mutex);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

144![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

往队列中挂接 AVPacketList，并且在 150 行统计缓存的媒体数据大小。

145	if (!q->last\_pkt)

146	q->first\_pkt = pkt1;

147	else

148	q->last\_pkt->next = pkt1;

149	q->last\_pkt = pkt1;

150	q->size += pkt1->pkt.size;

151![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

设置条件量为有信号状态，如果解码线程因等待而睡眠就及时唤醒。

152	SDL\_CondSignal(q->cond);

153

154	SDL\_UnlockMutex(q->mutex);

155	return 0;

156 }

157![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

设置 异常请求退出 状态。

158 static void packet\_queue\_abort(PacketQueue \*q)

159 {

160	SDL\_LockMutex(q->mutex);

161

162	q->abort\_request = 1; // 请求异常退出

163

164	SDL\_CondSignal(q->cond);

165

166	SDL\_UnlockMutex(q->mutex);

167 }

168![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

从队列中取出一帧/包数据。

169 /\* return < 0 if aborted, 0 if no packet and > 0 if packet.	\*/

170 static int packet\_queue\_get(PacketQueue \*q, AVPacket \*pkt, int block)

171 {

172	AVPacketList \*pkt1;

173	int ret;

174

175	SDL\_LockMutex(q->mutex);

176![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

177	for (;;)

178	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

如果异常请求退出标记置位，就带错误码返回。

179	if (q->abort\_request)

180	{

181	ret =	- 1;

182	break;

183	}

184

185	pkt1 = q->first\_pkt;

186	if (pkt1)

187	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

如果队列中有数据，就取第一个数据包，在 191 行修正缓存的媒体大小，在 192 行浅复制帧/包数据

188	q->first\_pkt = pkt1->next;

189	if (!q->first\_pkt)

190	q->last\_pkt = NULL;

191	q->size -= pkt1->pkt.size;

192	\*pkt = pkt1->pkt;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

释放掉 AVPacketList 结构，此结构在 packet\_queue\_put()函数中动态分配(137 行代码处)。

193	av\_free(pkt1);

194	ret = 1;

195	break;

196	}

197	else if (!block)

198	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

如果是非阻塞模式，没数据就直接返回 0。

199	ret = 0;

200	break;

201	}

202	else

203	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

如果是阻塞模式，没数据就进入睡眠状态等待，packet\_queue\_put()中唤醒(152 行代码处)。

204	SDL\_CondWait(q->cond, q->mutex);

205	}

206	}

207	SDL\_UnlockMutex(q->mutex);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

208	return ret;

209 }

210![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.124.png)

分配 SDL 库需要的 Overlay 显示表面，并设置长宽属性。

211 static void alloc\_picture(void \*opaque)

212 {

213	VideoState \*is = opaque;

214	VideoPicture \*vp;

215

216	vp = &is->pictq[0];

217

218	if (vp->bmp)

219	SDL\_FreeYUVOverlay(vp->bmp);

220

221	vp->bmp = SDL\_CreateYUVOverlay(is->video\_st->actx->width,

222	is->video\_st->actx->height,

223	SDL\_YV12\_OVERLAY,

224	screen);

225

226	vp->width = is->video\_st->actx->width;

227	vp->height = is->video\_st->actx->height;

228 }

229

解码后的视频图像在等待显示间隔时间后，做颜色空间转换，调用 SDL 库显示。简单认为 cpu 耗在

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.128.png)前面读文件，解复用，解码的时间为 0，做简单的同步处理逻辑。

230 static int queue\_picture(VideoState \*is, AVFrame \*src\_frame, double pts)

231 {

232	VideoPicture \*vp;

233	int dst\_pix\_fmt;

234	AVPicture pict;

235

236	if (is->videoq.abort\_request)

237	return	- 1;

238

239	vp = &is->pictq[0];

240

241	/\* if the frame is not skipped, then display it \*/

242	if (vp->bmp)

243	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

244	SDL\_Rect rect;

245![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

等待显示间隔时间，调用 Sleep()  函数简单实现。

246	if (pts)

247	Sleep((int)(is->frame\_last\_delay \*1000));

248

249	/\* get a pointer on the bitmap \*/

250	SDL\_LockYUVOverlay(vp->bmp);

251![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

设置显示图像的属性。

252	dst\_pix\_fmt = PIX\_FMT\_YUV420P;

253	pict.data[0] = vp->bmp->pixels[0];

254	pict.data[1] = vp->bmp->pixels[2];

255	pict.data[2] = vp->bmp->pixels[1];

256

257	pict.linesize[0] = vp->bmp->pitches[0];

258	pict.linesize[1] = vp->bmp->pitches[2];

259	pict.linesize[2] = vp->bmp->pitches[1];

260![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

把解码后的颜色空间转换为显示颜色空间。

261	img\_convert(&pict,

262	dst\_pix\_fmt,

263	(AVPicture\*)src\_frame,

264	is->video\_st->actx->pix\_fmt,

265	is->video\_st->actx->width,

266	is->video\_st->actx->height);

267

268	SDL\_UnlockYUVOverlay(vp->bmp); /\* update the bitmap content \*/

269

270	rect.x = 0;

271	rect.y = 0;

272	rect.w = is->video\_st->actx->width;

273	rect.h = is->video\_st->actx->height;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

实质性显示，刷屏操作。

274	SDL\_DisplayYUVOverlay(vp->bmp, &rect);

275	}

276	return 0;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

277 }

278

视频解码线程，主要功能是分配解码帧缓存和 SDL 显示缓存后进入解码循环(从队列中取数据帧，解

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.131.png)码，计算时钟，显示)，释放视频数据帧/数据包缓存。

279 static int video\_thread(void \*arg)

280 {

281	VideoState \*is = arg;

282	AVPacket pkt1,	\*pkt = &pkt1;

283	int len1, got\_picture;

284	double pts = 0;

285![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

分配解码帧缓存

286	AVFrame \*frame = av\_malloc(sizeof(AVFrame));

287	memset(frame, 0, sizeof(AVFrame));

288![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

分配 SDL 显示缓存

289	alloc\_picture(is);

290

291	for (;;)

292	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

从队列中取数据帧/数据包

293	if (packet\_queue\_get(&is->videoq, pkt, 1) < 0)

294	break;

295![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

实质性解码

296	SDL\_LockMutex(is->video\_decoder\_mutex);

297	len1 = avcodec\_decode\_video(is->video\_st->actx, frame, &got\_picture, pkt->data, pkt->size);

298	SDL\_UnlockMutex(is->video\_decoder\_mutex);

299![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

计算同步时钟

300	if (pkt->dts != AV\_NOPTS\_VALUE)

301	pts = av\_q2d(is->video\_st->time\_base) \*pkt->dts;

302

303	if (got\_picture)

304	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.132.png)

判断得到图像，调用显示函数同步显示视频图像。


|305||if (queue\_picture(is, frame, pts) < 0)|
| - | - | - |
|306||goto the\_end;|
|307|}||
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)释放视频数据帧/数据包内存，此数据包内存是在 av\_get\_packet()函数中调用 av\_malloc()分配的。

308	av\_free\_packet(pkt);

309	}

310

311 the\_end:

312	av\_free(frame);

313	return 0;

314 }

315

解码一个音频帧，返回解压的数据大小。特别注意一个音频包可能包含多个音频帧，但一次只解码一

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.133.png)个音频帧，所以一包可能要多次才能解码完。程序首先用 w hile 语句判断包数据是否全部解完，如果没 有就解码当前包中的帧，修改状态参数；否则，释放数据包，再从队列中取，记录初始值，再进循环。

316 /\* decode one audio frame and returns its uncompressed size \*/

317 static int audio\_decode\_frame(VideoState \*is, uint8\_t \*audio\_buf, double \*pts\_ptr)

318 {

319	AVPacket \*pkt = &is->audio\_pkt;

320	int len1, data\_size;

321

322	for (;;)

323	{

324

特别注意，一个音频包可能包含多个音频帧，可能需多次解码，VideoState 用一个 AVPacket 型变量

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.131.png)保存多次解码的中间状态。如果多次解码但不是最后次解码，audio\_decode\_frame 直接进 while 循环。

325	while (is->audio\_pkt\_size > 0)

326	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

调用解码函数解码，avcodec\_decode\_audio()函数返回解码用掉的字节数。

327	SDL\_LockMutex(is->audio\_decoder\_mutex);

328	len1 = avcodec\_decode\_audio(is->audio\_st->actx, (int16\_t\*)audio\_buf,

329	&data\_size, is->audio\_pkt\_data, is->audio\_pkt\_size);

330

331	SDL\_UnlockMutex(is->audio\_decoder\_mutex);

332	if (len1 < 0)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

333	{

334![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

如果发生错误，跳过当前帧，跳出底层循环。

335	is->audio\_pkt\_size = 0;

336	break;

337	}

338![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

修正解码后的音频帧缓存首地址和大小。

339	is->audio\_pkt\_data += len1;

340	is->audio\_pkt\_size -= len1;

341	if (data\_size <= 0)

如果没有得到解码后的数据，继续解码。可能有些帧第一次解码时只解一个帧头就返回，此时需要继

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.131.png)续解码数据帧。

342	continue;

343![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

返回解码后的数据大小。

344	return data\_size;

345	}

346![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

程序到这里，可能是初始时 audio\_pkt 没有赋值；或者一包已经解码完，此时需要释放包数据内存。

347	/\* free the current packet \*/

348	if (pkt->data)

349	av\_free\_packet(pkt);

350![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

读取下一个数据包。

351	/\* read next packet \*/

352	if (packet\_queue\_get(&is->audioq, pkt, 1) < 0)

353	return	- 1;

354

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.134.png)初始化数据包首地址和大小，用于一包中包含多个音频帧需多次解码的情况。

355	is->audio\_pkt\_data = pkt->data;

356	is->audio\_pkt\_size = pkt->size;

357	}

358 }![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

359

音频输出回调函数，每次音频输出缓存为空时，系统就调用此函数填充音频输出缓存。目前采用比较

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.135.png)简单的同步方式，音频按照自己的节拍往前走即可，不需要 synchronize\_audio()函数同步处理。

360 /\* prepare a new audio buffer \*/

361 void sdl\_audio\_callback(void \*opaque, Uint8 \*stream, int len)

362 {

363	VideoState \*is = opaque;

364	int audio\_size, len1;

365	double pts = 0;

366

367	while (len > 0)

368	{

369	if (is->audio\_buf\_index >= is->audio\_buf\_size)

370	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

如果解码后的数据已全部输出，就进行音频解码，并在 381 行保存解码数据大小，在383 行读索引置0。

371	audio\_size = audio\_decode\_frame(is, is->audio\_buf, &pts);

372	if (audio\_size < 0)

373	{

374	/\* if error, just output silence \*/

375	is->audio\_buf\_size = 1024;

376	memset(is->audio\_buf, 0, is->audio\_buf\_size);

377	}

378	else

379	{

380 //	audio\_size = synchronize\_audio(is, (int16\_t\*)is->audio\_buf, audio\_size, pts);

381	is->audio\_buf\_size = audio\_size;

382	}

383	is->audio\_buf\_index = 0;

384	}

385 到 391 行，拷贝适当的数据到输出缓存，并修改解码缓存的参数，进下一轮循环。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.136.png)特别注意：由进下一轮循环可知，程序应填满 SDL 库给出的输出缓存。

385	len1 = is->audio\_buf\_size - is->audio\_buf\_index;

386	if (len1 > len)

387	len1 = len;

388	memcpy(stream, (uint8\_t\*)is->audio\_buf + is->audio\_buf\_index, len1);

389	len -= len1;

390	stream += len1;

391	is->audio\_buf\_index += len1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

392	}

393 }

394

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.134.png)打开流模块，核心功能是打开相应 codec，启动解码线程(我们把音频回调函数看做一个广义的线程)。

395 /\* open a given stream. Return 0 if OK \*/

396 static int stream\_component\_open(VideoState \*is, int stream\_index) // 核心功能 open codec

397 {

398	AVFormatContext \*ic = is->ic;

399	AVCodecContext \*enc;

400	AVCodec \*codec;

401	SDL\_AudioSpec wanted\_spec, spec;

402

403	if (stream\_index < 0 || stream\_index >= ic->nb\_streams)

404	return	- 1;

405![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

找到从文件格式分析中得到的解码器上下文指针，便于引用其中的参数。

406	enc = ic->streams[stream\_index]->actx;

407

408	/\* prepare audio output \*/

409	if (enc->codec\_type == CODEC\_TYPE\_AUDIO)

410	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

初始化音频输出参数，并调用 SDL\_OpenAudio()设置到 SDL 库。

411	wanted\_spec.freq = enc->sample\_rate;

412	wanted\_spec.format = AUDIO\_S16SYS;

413	/\* hack for AC3. XXX: suppress that \*/

414	if (enc->channels > 2)

415	enc->channels = 2;

416	wanted\_spec.channels = enc->channels;

417	wanted\_spec.silence = 0;

418	wanted\_spec.samples = 1024; //SDL\_AUDIO\_BUFFER\_SIZE;

419	wanted\_spec.callback = sdl\_audio\_callback; // 此处设定回调函数

420	wanted\_spec.userdata = is;

421	if (SDL\_OpenAudio(&wanted\_spec, &spec) < 0)

422	{

wanted\_spec 是应用程序设定给 SDL 库的音频参数，spec 是 SDL 库返回给应用程序它能支持的音频

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.137.png)参数，通常是一致的。如果超过 SDL 支持的参数范围，会返回最相近的参数。

423	fprintf(stderr, "SDL\_OpenAudio: %s\n", SDL\_GetError());

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)424	return	- 1;

425	}

426	}

427![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

依照编解码上下文的 codec\_id，遍历编解码器链表，找到相应的功能函数。

428	codec = avcodec\_find\_decoder(enc->codec\_id);

429

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.134.png)核心功能之一,打开编解码器，初始化具体编解码器的运行环境。

430	if (!codec || avcodec\_open(enc, codec) < 0)

431	return	- 1;

432

433	switch (enc->codec\_type)

434	{

435	case CODEC\_TYPE\_AUDIO:![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

在 VideoState 中记录音频流参数。

436	is->audio\_stream = stream\_index;

437	is->audio\_st = ic->streams[stream\_index];

438	is->audio\_buf\_size = 0;

439	is->audio\_buf\_index = 0;

440![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

初始化音频队列，并在 443 行启动广义的音频解码线程。

441	memset(&is->audio\_pkt, 0, sizeof(is->audio\_pkt));

442	packet\_queue\_init(&is->audioq);

443	SDL\_PauseAudio(0);

444	break;

445	case CODEC\_TYPE\_VIDEO:![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

在 VideoState 中记录视频流参数。

446	is->video\_stream = stream\_index;

447	is->video\_st = ic->streams[stream\_index];

448

449	is->frame\_last\_delay = is->video\_st->frame\_last\_delay;

450![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

初始化视频队列，并在 452 行直接启动视频解码线程。

451	packet\_queue\_init(&is->videoq);

452	is->video\_tid = SDL\_CreateThread(video\_thread, is);![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

453	break;

454	default:

455	break;

456	}

457	return 0;

458 }

459![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.131.png)

关闭流模块，停止解码线程，释放队列资源。

通过 packet\_queue\_abort()函数置 abort\_request 标志位，解码线程判别此标志位并安全退出线程。

460 static void stream\_component\_close(VideoState \*is, int stream\_index)

461 {

462	AVFormatContext \*ic = is->ic;

463	AVCodecContext \*enc;

464![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.138.png)

简单的流索引参数校验。

465	if (stream\_index < 0 || stream\_index >= ic->nb\_streams)

466	return ;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.129.png)

找到从文件格式分析中得到的解码器上下文指针，便于引用其中的参数。

467	enc = ic->streams[stream\_index]->actx;

468

469	switch (enc->codec\_type)

470	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

停止解码线程，释放队列资源。

471	case CODEC\_TYPE\_AUDIO:

472	packet\_queue\_abort(&is->audioq);

473	SDL\_CloseAudio();

474	packet\_queue\_end(&is->audioq);

475	break;

476	case CODEC\_TYPE\_VIDEO:

477	packet\_queue\_abort(&is->videoq);

478	SDL\_WaitThread(is->video\_tid, NULL);

479	packet\_queue\_end(&is->videoq);

480	break;

481	default:

482	break;

483	}

484![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.139.png)

释放编解码器上下文资源

485	avcodec\_close(enc);

486 }

487

文件解析线程，函数名有点不名副其实。完成三大功能，直接识别文件格式和间接识别媒体格式，

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.140.png)打开具体的编解码器并启动解码线程，分离音视频媒体包并挂接到相应队列。

488 static int decode\_thread(void \*arg)

489 {

490	VideoState \*is = arg;

491	AVFormatContext \*ic;

492	int err, i, ret, video\_index, audio\_index;

493	AVPacket pkt1,	\*pkt = &pkt1;

494	AVFormatParameters params,	\*ap = &params;

495

496	int flags = SDL\_HWSURFACE | SDL\_ASYNCBLIT | SDL\_HWACCEL | SDL\_RESIZABLE;

497![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

498 到 502 行，初始化基本变量指示没有相应的流。

498	video\_index =	- 1;

499	audio\_index =	- 1;

500

501	is->video\_stream =	- 1;

502	is->audio\_stream =	- 1;

503

504	memset(ap, 0, sizeof(\*ap));

505![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

调用函数直接识别文件格式，在此函数中再调用其他函数间接识别媒体格式。

506	err = av\_open\_input\_file(&ic, is->filename, NULL, 0, ap);

507	if (err < 0)

|508|{||
| - | - | - |
|509||ret =	- 1;|
|510||goto fail;|
|511|}||
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)保存文件格式上下文，便于各数据结构间跳转。

512	is->ic = ic;

513

514	for (i = 0; i < ic->nb\_streams; i++)


|515|{||
| - | - | - |
|516||AVCodecContext \*enc = ic->streams[i]->actx;|
|517||switch (enc->codec\_type)|
|518||{|
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)保存音视频流索引，并把显示视频参数设置到 SDL 库。

519	case CODEC\_TYPE\_AUDIO:

520	if (audio\_index < 0)

521	audio\_index = i;

522	break;

523	case CODEC\_TYPE\_VIDEO:

524	if (video\_index < 0)

525	video\_index = i;

526

527	screen = SDL\_SetVideoMode(enc->width, enc->height, 0, flags);

528

529	SDL\_WM\_SetCaption("FFplay", "FFplay"); // 修改是为了适配视频大小

530

531 //	schedule\_refresh(is, 40);

532	break;

533	default:

534	break;

535	}

536	}

537![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

如果有音频流，就调用函数打开音频编解码器并启动音频广义解码线程。

538	if (audio\_index >= 0)

539	stream\_component\_open(is, audio\_index);

540![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

如果有视频流，就调用函数打开视频编解码器并启动视频解码线程。

541	if (video\_index >= 0)

542	stream\_component\_open(is, video\_index);

543

544	if (is->video\_stream < 0 && is->audio\_stream < 0)

545	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

如果既没有音频流，又没有视频流，就设置错误码返回。

546	fprintf(stderr, "%s: could not open codecs\n", is->filename);

547	ret =	- 1;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

548	goto fail;

549	}

550

551	for (;;)

552	{

553	if (is->abort\_request)![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

如果异常退出请求置位，就退出文件解析线程。

554	break;

555

556	if (is->audioq.size > MAX\_AUDIOQ\_SIZE || is->videoq.size > MAX\_VIDEOQ\_SIZE || url\_feof(&ic->pb))

557	{![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

如果队列满，就稍微延时一下。

558	SDL\_Delay(10); // if the queue are full, no need to read more,wait 10 ms

559	continue;

560	}![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

从媒体文件中完整的读取一包音视频数据。

561	ret = av\_read\_packet(ic, pkt); //av\_read\_frame(ic, pkt);

562	if (ret < 0)

563	{

564	if (url\_ferror(&ic->pb) == 0)

|565||{||
| - | - | - | - |
|566|||SDL\_Delay(100); // wait for user event|
|567|||continue;|
|568||}|
|569||else|
|570||break;|
|571|}||
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)判断包数据的类型，分别挂接到相应队列，如果是不识别的类型，就直接释放丢弃掉。

572	if (pkt->stream\_index == is->audio\_stream)

573	{

574	packet\_queue\_put(&is->audioq, pkt);

575	}

576	else if (pkt->stream\_index == is->video\_stream)

577	{

578	packet\_queue\_put(&is->videoq, pkt);

579	}

580	else![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

581	{

582	av\_free\_packet(pkt);

583	}

584	}

585![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

简单的延时，让后面的线程有机会把数据解码显示完。当然丢弃掉最后的一点点数据也可以。


|586|while (!is->abort\_request)|// wait until the end|
| - | - | - |
|587|{||
|588|SDL\_Delay(100);||
|589|}||
|590|||
|591|ret = 0;||
|592|||
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)释放掉在本线程中分配的各种资源，体现了谁申请谁释放的程序自封闭性。

593 fail:

594	if (is->audio\_stream >= 0)

595	stream\_component\_close(is, is->audio\_stream);

596

597	if (is->video\_stream >= 0)

598	stream\_component\_close(is, is->video\_stream);

599

600	if (is->ic)

601	{

602	av\_close\_input\_file(is->ic);

603	is->ic = NULL;

604	}

605

606	if (ret != 0)

607	{

608	SDL\_Event event;

609

610	event.type = FF\_QUIT\_EVENT;

611	event.user.data1 = is;

612	SDL\_PushEvent(&event);

613	}

614	return 0;

615 }

616![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

打开流，这个名字也有点名不符实。主要功能是分配全局总控数据结构，初始化相关参数，启动文

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.141.png)件解析线程。

617 static VideoState \*stream\_open(const char \*filename, AVInputFormat \*iformat)

618 {

619	VideoState \*is;

620

621	is = av\_mallocz(sizeof(VideoState));

622	if (!is)

623	return NULL;

624	pstrcpy(is->filename, sizeof(is->filename), filename);

625

626	is->audio\_decoder\_mutex = SDL\_CreateMutex();

627	is->video\_decoder\_mutex = SDL\_CreateMutex();

628

629	is->parse\_tid = SDL\_CreateThread(decode\_thread, is);

630	if (!is->parse\_tid)

631	{

632	av\_free(is);

633	return NULL;

634	}

635	return is;

636 }

637![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

关闭流，这个名字也有点名不符实。主要功能是释放资源。

639 static void stream\_close(VideoState \*is)

640 {

641	VideoPicture \*vp;

642	int i;

643

644	is->abort\_request = 1;

645	SDL\_WaitThread(is->parse\_tid, NULL);

646

647	for (i = 0; i < VIDEO\_PICTURE\_QUEUE\_SIZE; i++)

648	{

649	vp = &is->pictq[i];

650	if (vp->bmp)

651	{

652	SDL\_FreeYUVOverlay(vp->bmp);

653	vp->bmp = NULL;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

654	}

655	}

656

657	SDL\_DestroyMutex(is->audio\_decoder\_mutex);

658	SDL\_DestroyMutex(is->video\_decoder\_mutex);

659 }

660![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

程序退出时调用的函数，关闭释放一些资源。

661 void do\_exit(void)

662 {

663	if (cur\_stream)

664	{

665	stream\_close(cur\_stream);

666	cur\_stream = NULL;

667	}

668

669	SDL\_Quit();

670	exit(0);

671 }

672![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

SDL 库的消息事件循环。

673 void event\_loop(void) // handle an event sent by the GUI

674 {

675	SDL\_Event event;

676

677	for (;;)

678	{

679	SDL\_WaitEvent(&event);

680	switch (event.type)

681	{

682	case SDL\_KEYDOWN:

683	switch (event.key.keysym.sym)

684	{

685	case SDLK\_ESCAPE:

686	case SDLK\_q:

687	do\_exit();

688	break;

689	default:

690	break;![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.020.png)

691	}

692	break;

693	case SDL\_QUIT:

694	case FF\_QUIT\_EVENT:

695	do\_exit();

696	break;

697	default:

698	break;

699	}

700	}

701 }

702![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.130.png)

入口函数，初始化 SDL 库，注册 SDL 消息事件，启动文件解析线程，进入消息循环。

703 int main(int argc, char \*\*argv)

704 {

705	int flags = SDL\_INIT\_VIDEO | SDL\_INIT\_AUDIO | SDL\_INIT\_TIMER;

706

707	av\_register\_all();

708

709	input\_filename = "d:/yuv/clocktxt\_320.avi";

710

711	if (SDL\_Init(flags))

712	exit(1);

713

714	SDL\_EventState(SDL\_ACTIVEEVENT, SDL\_IGNORE);

715	SDL\_EventState(SDL\_MOUSEMOTION, SDL\_IGNORE);

716	SDL\_EventState(SDL\_SYSWMEVENT, SDL\_IGNORE);

717	SDL\_EventState(SDL\_USEREVENT, SDL\_IGNORE);

718

719	cur\_stream = stream\_open(input\_filename, file\_iformat);

720

721	event\_loop();

722

723	return 0;

724 }

725
# **第七章 应用开发**
## **7.1 ffmpeg库的使用：编码**
**YUV编码为视频**：

搞视频处理的朋友肯定比较熟悉YUV视频序列，很多测试库提供的视频数据都是YUV视频序列，我们这里就用用YUV视频序列来做视频。关于YUV视频序列，我就不多讲了，可以看书学习，通常的视频序列都是YUV420格式的。

步骤也就那几步，添加视频流，打开编码器，开辟相应的内存空间，然后就可以打开YUV序列逐帧写入数据了，so easy！记得最后要做好文件的关闭和内存的释放，因为FFmpeg是c风格的（不知道新版本是否是c++风格的），这些工作都需要自己做好啊。过多的说明是没用的，直接上代码：

这里我补充一下，大多数的视频格式好像只支持YUV格式的视频帧AVFrame，我试图直接把RGB的视频序列直接编码到视频这条路好像走不通，都需要把RGB的视频帧再转成YUV视频帧才行，不知道高手有没有其他高见。

#include <stdio.h>  

#include <string.h>  



extern "C"  

{  

#include <libavcodec\avcodec.h>  

#include <libavformat\avformat.h>  

#include <libswscale\swscale.h>  

};  



void main(int argc, char \*\* argv)  

{  

`    `AVFormatContext\* oc;  

`    `AVOutputFormat\* fmt;  

`    `AVStream\* video\_st;  

`    `double video\_pts;  

`    `uint8\_t\* video\_outbuf;  

`    `uint8\_t\* picture\_buf;  

`    `AVFrame\* picture;  

//  AVFrame\* pictureRGB;  

`    `int size;  

`    `int ret;  

`    `int video\_outbuf\_size;  



`    `FILE \*fin = fopen("akiyo\_qcif.yuv", "rb"); //视频源文件   



`    `const char\* filename = "test.mpg";  

//  const char\* filename;  

//  filename = argv[1];  



`    `av\_register\_all();  



//  avcodec\_init(); // 初始化codec库  

//  avcodec\_register\_all(); // 注册编码器  



`    `fmt = guess\_format(NULL, filename, NULL);  

`    `oc = av\_alloc\_format\_context();  

`    `oc->oformat = fmt;  

`    `snprintf(oc->filename, sizeof(oc->filename), "%s", filename);  



`    `video\_st = NULL;  

`    `if (fmt->video\_codec != CODEC\_ID\_NONE)  

`    `{  

`        `AVCodecContext\* c;  

`        `video\_st = av\_new\_stream(oc, 0);  

`        `c = video\_st->codec;  

`        `c->codec\_id = fmt->video\_codec;  

`        `c->codec\_type = CODEC\_TYPE\_VIDEO;  

`        `c->bit\_rate = 400000;  

`        `c->width = 176;  

`        `c->height = 144;  

`        `c->time\_base.num = 1;  

`        `c->time\_base.den = 25;   

`        `c->gop\_size = 12;  

`        `c->pix\_fmt = PIX\_FMT\_YUV420P;  

`        `if (c->codec\_id == CODEC\_ID\_MPEG2VIDEO)  

`        `{  

`            `c->max\_b\_frames = 2;  

`        `}  

`        `if (c->codec\_id == CODEC\_ID\_MPEG1VIDEO)  

`        `{  

`            `c->mb\_decision = 2;  

`        `}  

`        `if (!strcmp(oc->oformat->name, "mp4") || !strcmp(oc->oformat->name, "mov") || !strcmp(oc->oformat->name, "3gp"))  

`        `{  

`            `c->flags |= CODEC\_FLAG\_GLOBAL\_HEADER;  

`        `}  

`    `}  



`    `if (av\_set\_parameters(oc, NULL)<0)  

`    `{  

`        `return;  

`    `}  



`    `dump\_format(oc, 0, filename, 1);  

`    `if (video\_st)  

`    `{  

`        `AVCodecContext\* c;  

`        `AVCodec\* codec;  

`        `c = video\_st->codec;  

`        `codec = avcodec\_find\_encoder(c->codec\_id);  

`        `if (!codec)  

`        `{  

`            `return;  

`        `}  

`        `if (avcodec\_open(c, codec) < 0)  

`        `{  

`            `return;  

`        `}  

`        `if (!(oc->oformat->flags & AVFMT\_RAWPICTURE))  

`        `{  

`            `video\_outbuf\_size = 200000;  

`            `video\_outbuf = (uint8\_t\*)av\_malloc(video\_outbuf\_size);  

`        `}  

`        `picture = avcodec\_alloc\_frame();  

`        `size = avpicture\_get\_size(c->pix\_fmt, c->width, c->height);  

`        `picture\_buf = (uint8\_t\*)av\_malloc(size);  

`        `if (!picture\_buf)  

`        `{  

`            `av\_free(picture);  

`        `}  

`        `avpicture\_fill((AVPicture\*)picture, picture\_buf, c->pix\_fmt, c->width, c->height);  

`    `}  



`    `if (!(fmt->flags & AVFMT\_NOFILE))  

`    `{  

`        `if (url\_fopen(&oc->pb, filename, URL\_WRONLY) < 0)  

`        `{  

`            `return;  

`        `}  

`    `}  

`    `av\_write\_header(oc);  



`    `for (int i=0; i<300; i++)  

`    `{  

`        `if (video\_st)  

`        `{  

`            `video\_pts = (double)(video\_st->pts.val \* video\_st->time\_base.num / video\_st->time\_base.den);  

`        `}  

`        `else  

`        `{  

`            `video\_pts = 0.0;  

`        `}  

`        `if (!video\_st/\* || video\_pts >= 5.0\*/)  

`        `{  

`            `break;  

`        `}  

`        `AVCodecContext\* c;  

`        `c = video\_st->codec;  

`        `size = c->width \* c->height;  



`        `if (fread(picture\_buf, 1, size\*3/2, fin) < 0)  

`        `{  

`            `break;  

`        `}  



`        `picture->data[0] = picture\_buf;  // 亮度  

`        `picture->data[1] = picture\_buf+ size;  // 色度   

`        `picture->data[2] = picture\_buf+ size\*5/4; // 色度   



`        `// 如果是rgb序列，可能需要如下代码  

//      SwsContext\* img\_convert\_ctx;  

//      img\_convert\_ctx = sws\_getContext(c->width, c->height, PIX\_FMT\_RGB24, c->width, c->height, c->pix\_fmt, SWS\_BICUBIC, NULL, NULL, NULL);  

//      sws\_scale(img\_convert\_ctx, pictureRGB->data, pictureRGB->linesize, 0, c->height, picture->data, picture->linesize);  



`        `if (oc->oformat->flags & AVFMT\_RAWPICTURE)  

`        `{  

`            `AVPacket pkt;  

`            `av\_init\_packet(&pkt);  

`            `pkt.flags |= PKT\_FLAG\_KEY;  

`            `pkt.stream\_index = video\_st->index;  

`            `pkt.data = (uint8\_t\*)picture;  

`            `pkt.size = sizeof(AVPicture);  

`            `ret = av\_write\_frame(oc, &pkt);  

`        `}  

`        `else  

`        `{  

`            `int out\_size = avcodec\_encode\_video(c, video\_outbuf, video\_outbuf\_size, picture);  

`            `if (out\_size > 0)  

`            `{  

`                `AVPacket pkt;  

`                `av\_init\_packet(&pkt);  

`                `pkt.pts = av\_rescale\_q(c->coded\_frame->pts, c->time\_base, video\_st->time\_base);  

`                `if (c->coded\_frame->key\_frame)  

`                `{  

`                    `pkt.flags |= PKT\_FLAG\_KEY;  

`                `}  

`                `pkt.stream\_index = video\_st->index;  

`                `pkt.data = video\_outbuf;  

`                `pkt.size = out\_size;  

`                `ret = av\_write\_frame(oc, &pkt);  

`            `}  

`        `}  

`    `}  



`    `if (video\_st)  

`    `{  

`        `avcodec\_close(video\_st->codec);  

//      av\_free(picture->data[0]);  

`        `av\_free(picture);  

`        `av\_free(video\_outbuf);  

//      av\_free(picture\_buf);  

`    `}  

`    `av\_write\_trailer(oc);  

`    `for (int i=0; i<oc->nb\_streams; i++)  

`    `{  

`        `av\_freep(&oc->streams[i]->codec);  

`        `av\_freep(&oc->streams[i]);  

`    `}  

`    `if (!(fmt->flags & AVFMT\_NOFILE))  

`    `{  

`        `url\_fclose(oc->pb);  

`    `}  

av\_free(oc);  

}
8. # **关键函数介绍**
此章有必要，因为调取的函数都是最新版的（有些函数第五章已经提及，读者可以对比）。
## **8.1 avformat\_open\_input**
FFMPEG打开媒体的的过程开始于avformat\_open\_input，因此该函数的重要性不可忽视。

在该函数中，FFMPEG完成了：

输入输出结构体AVIOContext的初始化；

输入数据的协议（例如RTMP，或者file）的识别（通过一套评分机制）:1判断文件名的后缀 2读取文件头的数据进行比对；

使用获得最高分的文件协议对应的URLProtocol，通过函数指针的方式，与FFMPEG连接（非专业用词）；

剩下的就是调用该URLProtocol的函数进行open,read等操作了

以下是通过eclipse+MinGW调试FFMPEG源代码获得的函数调用关系图

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.142.jpeg)

可见最终都调用了URLProtocol结构体中的函数指针。

URLProtocol结构是一大堆函数指针的集合（avio.h文件）参见第四章数据结构

URLProtocol功能就是完成各种输入协议的读写等操作

但输入协议种类繁多，它是怎样做到“大一统”的呢？



原来，每个具体的输入协议都有自己对应的URLProtocol。

比如file协议（FFMPEG把文件也当做一种特殊的协议）（\*file.c文件）

URLProtocol ff\_pipe\_protocol = {  

`    `.name                = "pipe",  

`    `.url\_open            = pipe\_open,  

`    `.url\_read            = file\_read,  

`    `.url\_write           = file\_write,  

`    `.url\_get\_file\_handle = file\_get\_handle,  

`    `.url\_check           = file\_check,  

};  

或者rtmp协议（此处使用了librtmp）（librtmp.c文件）

URLProtocol ff\_rtmp\_protocol = {  

`    `.name                = "rtmp",  

`    `.url\_open            = rtmp\_open,  

`    `.url\_read            = rtmp\_read,  

`    `.url\_write           = rtmp\_write,  

`    `.url\_close           = rtmp\_close,  

`    `.url\_read\_pause      = rtmp\_read\_pause,  

`    `.url\_read\_seek       = rtmp\_read\_seek,  

`    `.url\_get\_file\_handle = rtmp\_get\_file\_handle,  

`    `.priv\_data\_size      = sizeof(RTMP),  

`    `.flags               = URL\_PROTOCOL\_FLAG\_NETWORK,  

};  

可见它们把各自的函数指针都赋值给了URLProtocol结构体的函数指针

因此avformat\_open\_input只需调用url\_open,url\_read这些函数就可以完成各种具体输入协议的open,read等操作了
## **8.2 avcodec\_register\_all()**
ffmpeg注册复用器，编码器等的函数av\_register\_all()。该函数在所有基于ffmpeg的应用程序中几乎都是第一个被调用的。只有调用了该函数，才能使用复用器，编码器等。

可见解复用器注册都是用

REGISTER\_DEMUXER  (X,x)

例如：

REGISTER\_DEMUXER  (AAC, aac)

可见复用器注册都是用

REGISTER\_MUXER    (X,x))

例如：

REGISTER\_MUXER    (ADTS, adts)

既有解复用器又有复用器的话，可以用

REGISTER\_MUXDEMUX (X,x));

例如：

REGISTER\_MUXDEMUX (AC3, ac3);

我们来看一下宏的定义，这里以解复用器为例：

py

#define REGISTER\_DEMUXER(X,x) { \  

`    `extern AVInputFormat ff\_##x##\_demuxer; \  

`    `if(CONFIG\_##X##\_DEMUXER) av\_register\_input\_format(&ff\_##x##\_demuxer); }  

注意：define里面的##可能不太常见，它的含义就是拼接两个字符串，比如

#define Conn(x,y) x##y

那么

int  n = Conn(123,456);  结果就是n=123456;

我们以REGISTER\_DEMUXER  (AAC, aac)为例，则它等效于

py

extern AVInputFormat ff\_aac\_demuxer;   

if(CONFIG\_AAC\_DEMUXER) av\_register\_input\_format(&ff\_aac\_demuxer);   

从上面这段代码我们可以看出，真正注册的函数是av\_register\_input\_format(&ff\_aac\_demuxer)，那我就看看这个和函数的作用，查看一下av\_register\_input\_format()的代码：

py

void av\_register\_input\_format(AVInputFormat \*format)  

{  

`    `AVInputFormat \*\*p;  

`    `p = &first\_iformat;  

`    `while (\*p != NULL) p = &(\*p)->next;  

`    `\*p = format;  

`    `format->next = NULL;  

}  

这段代码是比较容易理解的，首先先提一点，first\_iformat是个什么东东呢？其实它是Input Format链表的头部地址，是一个全局静态变量，定义如下：

py

/\*\* head of registered input format linked list \*/  

static AVInputFormat \*first\_iformat = NULL;  

由此我们可以分析出av\_register\_input\_format()的含义，一句话概括就是：遍历链表并把当前的Input Format加到链表的尾部。

至此REGISTER\_DEMUXER  (X, x)分析完毕。

同理，复用器道理是一样的，只是注册函数改为av\_register\_output\_format()；

既有解复用器又有复用器的话，有一个宏定义：

py

#define REGISTER\_MUXDEMUX(X,x)  REGISTER\_MUXER(X,x); REGISTER\_DEMUXER(X,x)  

可见是分别注册了复用器和解复用器。

此外还有网络协议的注册，注册函数为ffurl\_register\_protocol()，在此不再详述。

整个代码没太多可说的，首先确定是不是已经初始化过了（initialized），如果没有，就调用avcodec\_register\_all()注册编解码器（这个先不分析），然后就是注册，注册，注册...直到完成所有注册。
## **8.3 av\_read\_frame()**
ffmpeg中的av\_read\_frame()的作用是读取码流中的音频若干帧或者视频一帧。例如，解码视频的时候，每解码一个视频帧，需要先调用 av\_read\_frame()获得一帧视频的压缩数据，然后才能对该数据进行解码（例如H.264中一帧压缩数据通常对应一个NAL）。

通过av\_read\_packet(\*\*\*)，读取一个包，需要说明的是此函数必须是包含整数帧的，不存在半帧的情况，以ts流为例，是读取一个完整的PES包（一个完整pes包包含若干视频或音频es包），读取完毕后，通过av\_parser\_parse2(\*\*\*)分析出视频一帧（或音频若干帧），返回，下次进入循环的时候，如果上次的数据没有完全取完，则st = s->cur\_st;不会是NULL，即再此进入av\_parser\_parse2(\*\*\*)流程，而不是下面的av\_read\_packet（\*\*）流程，这样就保证了，如果读取一次包含了N帧视频数据（以视频为例），则调用av\_read\_frame（\*\*\*）N次都不会去读数据，而是返回第一次读取的数据，直到全部解析完毕。
## **8.4 avcodec\_decode\_video2()**
ffmpeg中的avcodec\_decode\_video2()的作用是解码一帧视频数据。输入一个压缩编码的结构体AVPacket，输出一个解码后的结构体AVFrame。
## **8.5 transcode\_init()**
transcode\_init()函数是在转换前做准备工作的.此处看一下它的真面目,不废话,看注释吧:

//为转换过程做准备  

static int transcode\_init(OutputFile \*output\_files,  

`        `int nb\_output\_files,  

`        `InputFile \*input\_files,  

`        `int nb\_input\_files)  

{  

`    `int ret = 0, i, j, k;  

`    `AVFormatContext \*oc;  

`    `AVCodecContext \*codec, \*icodec;  

`    `OutputStream \*ost;  

`    `InputStream \*ist;  

`    `char error[1024];  

`    `int want\_sdp = 1;  



`    `/\* init framerate emulation \*/  

`    `//初始化帧率仿真(转换时是不按帧率来的,但如果要求帧率仿真,就可以做到)  

`    `for (i = 0; i < nb\_input\_files; i++)  

`    `{  

`        `InputFile \*ifile = &input\_files[i];  

`        `//如果一个输入文件被要求帧率仿真(指的是即使是转换也像播放那样按照帧率来进行),  

`        `//则为这个文件中所有流记录下开始时间  

`        `if (ifile->rate\_emu)  

`            `for (j = 0; j < ifile->nb\_streams; j++)  

`                `input\_streams[j + ifile->ist\_index].start = av\_gettime();  

`    `}  



`    `/\* output stream init \*/  

`    `for (i = 0; i < nb\_output\_files; i++)  

`    `{  

`        `//什么也没做,只是做了个判断而已  

`        `oc = output\_files[i].ctx;  

`        `if (!oc->nb\_streams && !(oc->oformat->flags & AVFMT\_NOSTREAMS))  

`        `{  

`            `av\_dump\_format(oc, i, oc->filename, 1);  

`            `av\_log(NULL, AV\_LOG\_ERROR,  

`                    `"Output file #%d does not contain any stream\n", i);  

`            `return AVERROR(EINVAL);  

`        `}  

`    `}  



`    `//轮循所有的输出流,跟据对应的输入流,设置其编解码器的参数  

`    `for (i = 0; i < nb\_output\_streams; i++)  

`    `{  

`        `//轮循所有的输出流  

`        `ost = &output\_streams[i];  

`        `//输出流对应的FormatContext  

`        `oc = output\_files[ost->file\_index].ctx;  

`        `//取得输出流对应的输入流  

`        `ist = &input\_streams[ost->source\_index];  



`        `//attachment\_filename是不是这样的东西:一个文件,它单独容纳一个输出流?此处不懂  

`        `if (ost->attachment\_filename)  

`            `continue;  



`        `codec = ost->st->codec;//输出流的编解码器结构  

`        `icodec = ist->st->codec;//输入流的编解码器结构  



`        `//先把能复制的复制一下  

`        `ost->st->disposition = ist->st->disposition;  

`        `codec->bits\_per\_raw\_sample = icodec->bits\_per\_raw\_sample;  

`        `codec->chroma\_sample\_location = icodec->chroma\_sample\_location;  



`        `//如果只是复制一个流(不用解码后再编码),则把输入流的编码参数直接复制给输出流  

`        `//此时是不需要解码也不需要编码的，所以不需打开解码器和编码器  

`        `if (ost->stream\_copy)  

`        `{  

`            `//计算输出流的编解码器的extradata的大小,然后分配容纳extradata的缓冲  

`            `//然后把输入流的编解码器的extradata复制到输出流的编解码器中  

`            `uint64\_t extra\_size = (uint64\_t) icodec->extradata\_size  

`                    `+ FF\_INPUT\_BUFFER\_PADDING\_SIZE;  



`            `if (extra\_size > INT\_MAX)    {  

`                `return AVERROR(EINVAL);  

`            `}  



`            `/\* if stream\_copy is selected, no need to decode or encode \*/  

`            `codec->codec\_id = icodec->codec\_id;  

`            `codec->codec\_type = icodec->codec\_type;  



`            `if (!codec->codec\_tag){  

`                `if (!oc->oformat->codec\_tag  

`                    `||av\_codec\_get\_id(oc->oformat->codec\_tag,icodec->codec\_tag) == codec->codec\_id  

`                    `||av\_codec\_get\_tag(oc->oformat->codec\_tag,icodec->codec\_id) <= 0)  

`                    `codec->codec\_tag = icodec->codec\_tag;  

`            `}  



`            `codec->bit\_rate = icodec->bit\_rate;  

`            `codec->rc\_max\_rate = icodec->rc\_max\_rate;  

`            `codec->rc\_buffer\_size = icodec->rc\_buffer\_size;  

`            `codec->extradata = av\_mallocz(extra\_size);  

`            `if (!codec->extradata){  

`                `return AVERROR(ENOMEM);  

`            `}  

`            `memcpy(codec->extradata, icodec->extradata, icodec->extradata\_size);  

`            `codec->extradata\_size = icodec->extradata\_size;  



`            `//重新鼓捣一下time base(这家伙就是帧率)  

`            `codec->time\_base = ist->st->time\_base;  

`            `//如果输出文件是avi,做一点特殊处理  

`            `if (!strcmp(oc->oformat->name, "avi"))    {  

`                `if (copy\_tb < 0  

`                        `&& av\_q2d(icodec->time\_base) \* icodec->ticks\_per\_frame    >  

`                            `2 \* av\_q2d(ist->st->time\_base)  

`                        `&& av\_q2d(ist->st->time\_base) < 1.0 / 500  

`                        `|| copy\_tb == 0)  

`                `{  

`                    `codec->time\_base = icodec->time\_base;  

`                    `codec->time\_base.num \*= icodec->ticks\_per\_frame;  

`                    `codec->time\_base.den \*= 2;  

`                `}  

`            `}  

`            `else if (!(oc->oformat->flags & AVFMT\_VARIABLE\_FPS))  

`            `{  

`                `if (copy\_tb < 0  

`                        `&& av\_q2d(icodec->time\_base) \* icodec->ticks\_per\_frame  

`                                `> av\_q2d(ist->st->time\_base)  

`                        `&& av\_q2d(ist->st->time\_base) < 1.0 / 500  

`                        `|| copy\_tb == 0)  

`                `{  

`                    `codec->time\_base = icodec->time\_base;  

`                    `codec->time\_base.num \*= icodec->ticks\_per\_frame;  

`                `}  

`            `}  



`            `//再修正一下帧率  

`            `av\_reduce(&codec->time\_base.num, &codec->time\_base.den,  

`                    `codec->time\_base.num, codec->time\_base.den, INT\_MAX);  



`            `//单独复制各不同媒体自己的编码参数  

`            `switch (codec->codec\_type)  

`            `{  

`            `case AVMEDIA\_TYPE\_AUDIO:  

`                `//音频的  

`                `if (audio\_volume != 256){  

`                    `av\_log( NULL,AV\_LOG\_FATAL,  

`                            `"-acodec copy and -vol are incompatible (frames are not decoded)\n");  

`                    `exit\_program(1);  

`                `}  

`                `codec->channel\_layout = icodec->channel\_layout;  

`                `codec->sample\_rate = icodec->sample\_rate;  

`                `codec->channels = icodec->channels;  

`                `codec->frame\_size = icodec->frame\_size;  

`                `codec->audio\_service\_type = icodec->audio\_service\_type;  

`                `codec->block\_align = icodec->block\_align;  

`                `break;  

`            `case AVMEDIA\_TYPE\_VIDEO:  

`                `//视频的  

`                `codec->pix\_fmt = icodec->pix\_fmt;  

`                `codec->width = icodec->width;  

`                `codec->height = icodec->height;  

`                `codec->has\_b\_frames = icodec->has\_b\_frames;  

`                `if (!codec->sample\_aspect\_ratio.num){  

`                    `codec->sample\_aspect\_ratio = ost->st->sample\_aspect\_ratio =  

`                            `ist->st->sample\_aspect\_ratio.num ?ist->st->sample\_aspect\_ratio :  

`                                    `ist->st->codec->sample\_aspect\_ratio.num ?ist->st->codec->sample\_aspect\_ratio :(AVRational){0, 1};  

`                `}  

`                `ost->st->avg\_frame\_rate = ist->st->avg\_frame\_rate;  

`                `break;  

`            `case AVMEDIA\_TYPE\_SUBTITLE:  

`                `//字幕的  

`                `codec->width  = icodec->width;  

`                `codec->height = icodec->height;  

`                `break;  

`            `case AVMEDIA\_TYPE\_DATA:  

`            `case AVMEDIA\_TYPE\_ATTACHMENT:  

`                `//??的  

`                `break;  

`            `default:  

`                `abort();  

`            `}  

`    `}  

`    `else  

`    `{  

`        `//如果不是复制,就麻烦多了  



`        `//获取编码器  

`        `if (!ost->enc)  

`            `ost->enc = avcodec\_find\_encoder(ost->st->codec->codec\_id);  



`        `//因为需要转换,所以既需解码又需编码  

`        `ist->decoding\_needed = 1;  

`        `ost->encoding\_needed = 1;  



`        `switch(codec->codec\_type)  

`        `{  

`        `case AVMEDIA\_TYPE\_AUDIO:  

`            `//鼓捣音频编码器的参数,基本上是把一些不合适的参数替换掉  

`            `ost->fifo = av\_fifo\_alloc(1024);//音频数据所在的缓冲  

`            `if (!ost->fifo)  {  

`                `return AVERROR(ENOMEM);  

`            `}  



`            `//采样率  

`            `if (!codec->sample\_rate)  

`                `codec->sample\_rate = icodec->sample\_rate;  

`            `choose\_sample\_rate(ost->st, ost->enc);  

`            `codec->time\_base = (AVRational){1, codec->sample\_rate};  



`            `//样点格式  

`            `if (codec->sample\_fmt == AV\_SAMPLE\_FMT\_NONE)  

`                `codec->sample\_fmt = icodec->sample\_fmt;  

`            `choose\_sample\_fmt(ost->st, ost->enc);  



`            `//声道  

`            `if (ost->audio\_channels\_mapped)  {  

`                `/\* the requested output channel is set to the number of 

`                 `\* -map\_channel only if no -ac are specified \*/  

`                `if (!codec->channels)    {  

`                    `codec->channels = ost->audio\_channels\_mapped;  

`                    `codec->channel\_layout = av\_get\_default\_channel\_layout(codec->channels);  

`                    `if (!codec->channel\_layout)  {  

`                        `av\_log(NULL, AV\_LOG\_FATAL, "Unable to find an appropriate channel layout for requested number of channel\n);  

`                        `exit\_program(1);  

`                    `}  

`                `}  

`                `/\* fill unused channel mapping with -1 (which means a muted 

`                 `\* channel in case the number of output channels is bigger 

`                 `\* than the number of mapped channel) \*/  

`                `for (j = ost->audio\_channels\_mapped; j < FF\_ARRAY\_ELEMS(ost->audio\_channels\_map); j++)  

`                `<span>  </span>ost->audio\_channels\_map[j] = -1;  

`            `}else if (!codec->channels){  

`                `codec->channels = icodec->channels;  

`                `codec->channel\_layout = icodec->channel\_layout;  

`            `}  

`            `if (av\_get\_channel\_layout\_nb\_channels(codec->channel\_layout) != codec->channels)  

`                `codec->channel\_layout = 0;  



`            `//是否需要重采样  

`            `ost->audio\_resample = codec->sample\_rate != icodec->sample\_rate || audio\_sync\_method > 1;  

`            `ost->audio\_resample |= codec->sample\_fmt != icodec->sample\_fmt ||  

`                    `codec->channel\_layout != icodec->channel\_layout;  

`            `icodec->request\_channels = codec->channels;  

`            `ost->resample\_sample\_fmt = icodec->sample\_fmt;  

`            `ost->resample\_sample\_rate = icodec->sample\_rate;  

`            `ost->resample\_channels = icodec->channels;  

`            `break;  

`        `case AVMEDIA\_TYPE\_VIDEO:  

`            `//鼓捣视频编码器的参数,基本上是把一些不合适的参数替换掉  

`            `if (codec->pix\_fmt == PIX\_FMT\_NONE)  

`                `codec->pix\_fmt = icodec->pix\_fmt;  

`            `choose\_pixel\_fmt(ost->st, ost->enc);  

`            `if (ost->st->codec->pix\_fmt == PIX\_FMT\_NONE){  

`                `av\_log(NULL, AV\_LOG\_FATAL, "Video pixel format is unknown, stream cannot be encoded\n");  

`                `exit\_program(1);  

`            `}  



`            `//宽高  

`            `if (!codec->width || !codec->height){  

`                `codec->width = icodec->width;  

`                `codec->height = icodec->height;  

`            `}  



`            `//视频是否需要重采样  

`            `ost->video\_resample = codec->width != icodec->width ||  

`                    `codec->height != icodec->height ||  

`                    `codec->pix\_fmt != icodec->pix\_fmt;  

`            `if (ost->video\_resample){  

`                `codec->bits\_per\_raw\_sample= frame\_bits\_per\_raw\_sample;  

`            `}  



`            `ost->resample\_height = icodec->height;  

`            `ost->resample\_width = icodec->width;  

`            `ost->resample\_pix\_fmt = icodec->pix\_fmt;  



`            `//计算帧率  

`            `if (!ost->frame\_rate.num)  

`                `ost->frame\_rate = ist->st->r\_frame\_rate.num ?  

`                        `ist->st->r\_frame\_rate : (AVRational){25,1};  

`            `if (ost->enc && ost->enc->supported\_framerates && !ost->force\_fps)  {  

`                `int idx = av\_find\_nearest\_q\_idx(ost->frame\_rate,ost->enc->supported\_framerates);  

`                `ost->frame\_rate = ost->enc->supported\_framerates[idx];  

`            `}  

`            `codec->time\_base = (AVRational)  {ost->frame\_rate.den, ost->frame\_rate.num};  

`            `if( av\_q2d(codec->time\_base) < 0.001 &&  

`                    `video\_sync\_method &&  

`                    `(video\_sync\_method==1 ||  

`                        `(video\_sync\_method<0 &&  !  

`                            `(oc->oformat->flags & AVFMT\_VARIABLE\_FPS))))  

`            `{  

`                `av\_log(oc, AV\_LOG\_WARNING, "Frame rate very high for a muxer not effciciently supporting it.\n"  

`                        `"Please consider specifiying a lower framerate, a different muxer or -vsync 2\n");  

`            `}  

`        `<span>  </span>for (j = 0; j < ost->forced\_kf\_count; j++)  

`                `ost->forced\_kf\_pts[j] = av\_rescale\_q(ost->forced\_kf\_pts[j],  

`                        `AV\_TIME\_BASE\_Q, codec->time\_base);  

`                `break;  

`            `case AVMEDIA\_TYPE\_SUBTITLE:  

`                `break;  

`            `default:  

`                `abort();  

`                `break;  

`            `}  

`            `/\* two pass mode \*/  

`            `if (codec->codec\_id != CODEC\_ID\_H264 &&  

`                    `(codec->flags & (CODEC\_FLAG\_PASS1 | CODEC\_FLAG\_PASS2)))  

`            `{  

`                `char logfilename[1024];  

`                `FILE \*f;  



`                `snprintf(logfilename, sizeof(logfilename), "%s-%d.log",  

`                        `pass\_logfilename\_prefix ? pass\_logfilename\_prefix : DEFAULT\_PASS\_LOGFILENAME\_PREFIX,  

`                        `i);  

`                `if (codec->flags & CODEC\_FLAG\_PASS2){  

`                    `char \*logbuffer;  

`                    `size\_t logbuffer\_size;  

`                    `if (cmdutils\_read\_file(logfilename, &logbuffer, &logbuffer\_size) < 0){  

`                        `av\_log(NULL, AV\_LOG\_FATAL,  

`                                `"Error reading log file '%s' for pass-2 encoding\n",  

`                                `logfilename);  

`                        `exit\_program(1);  

`                    `}  

`                    `codec->stats\_in = logbuffer;  

`                `}  

`                `if (codec->flags & CODEC\_FLAG\_PASS1){  

`                    `f = fopen(logfilename, "wb");  

`                    `if (!f) {  

`                        `av\_log(NULL, AV\_LOG\_FATAL, "Cannot write log file '%s' for pass-1 encoding: %s\n",  

`                                `logfilename, strerror(errno));  

`                        `exit\_program(1);  

`                    `}  

`                    `ost->logfile = f;  

`                `}  

`            `}  

`        `}  

`        `if (codec->codec\_type == AVMEDIA\_TYPE\_VIDEO){  

`            `/\* maximum video buffer size is 6-bytes per pixel, plus DPX header size (1664)\*/  

`            `//计算编码输出缓冲的大小,计算一个最大值  

`            `int size = codec->width \* codec->height;  

`            `bit\_buffer\_size = FFMAX(bit\_buffer\_size, 7 \* size + 10000);  

`        `}  

`    `}  



`    `//分配编码后数据所在的缓冲  

`    `if (!bit\_buffer)  

`        `bit\_buffer = av\_malloc(bit\_buffer\_size);  

`    `if (!bit\_buffer){  

`        `av\_log(NULL, AV\_LOG\_ERROR,  

`                `"Cannot allocate %d bytes output buffer\n",  

`                `bit\_buffer\_size);  

`        `return AVERROR(ENOMEM);  

`    `}  



`    `//轮循所有输出流,打开每个输出流的编码器  

`    `for (i = 0; i < nb\_output\_streams; i++)  

`    `{  

`        `ost = &output\_streams[i];  

`        `if (ost->encoding\_needed){  

`            `//当然,只有在需要编码时才打开编码器  

`            `AVCodec \*codec = ost->enc;  

`            `AVCodecContext \*dec = input\_streams[ost->source\_index].st->codec;  

`            `if (!codec) {  

`                `snprintf(error, sizeof(error),  

`                        `"Encoder (codec %s) not found for output stream #%d:%d",  

`                        `avcodec\_get\_name(ost->st->codec->codec\_id),  

`                        `ost->file\_index, ost->index);  

`                `ret = AVERROR(EINVAL);  

`                `goto dump\_format;  

`            `}  

`            `if (dec->subtitle\_header){  

`                `ost->st->codec->subtitle\_header = av\_malloc(dec->subtitle\_header\_size);  

`                `if (!ost->st->codec->subtitle\_header){  

`                    `ret = AVERROR(ENOMEM);  

`                    `goto dump\_format;  

`                `}  

`                `memcpy(ost->st->codec->subtitle\_header,  

`                        `dec->subtitle\_header,dec->subtitle\_header\_size);  

`                `ost->st->codec->subtitle\_header\_size = dec->subtitle\_header\_size;  

`            `}  

`            `//打开啦  

`            `if (avcodec\_open2(ost->st->codec, codec, &ost->opts) < 0)   {  

`                `snprintf(error, sizeof(error),  

`                        `"Error while opening encoder for output stream #%d:%d - maybe incorrect parameters such as bit\_rate, rate, width or height",  

`                        `ost->file\_index, ost->index);  

`                `ret = AVERROR(EINVAL);  

`                `goto dump\_format;  

`            `}  

`            `assert\_codec\_experimental(ost->st->codec, 1);  

`            `assert\_avoptions(ost->opts);  

`            `if (ost->st->codec->bit\_rate && ost->st->codec->bit\_rate < 1000)  

`                `av\_log(NULL, AV\_LOG\_WARNING,  

`                        `"The bitrate parameter is set too low."  

`                        `" It takes bits/s as argument, not kbits/s\n");  

`            `extra\_size += ost->st->codec->extradata\_size;  



`            `if (ost->st->codec->me\_threshold)  

`                `input\_streams[ost->source\_index].st->codec->debug |= FF\_DEBUG\_MV;  

`        `}  

`    `}  



`    `//初始化所有的输入流(主要做的就是在需要时打开解码器)  

`    `for (i = 0; i < nb\_input\_streams; i++)  

`        `if ((ret = init\_input\_stream(i, output\_streams, nb\_output\_streams,  

`                `error, sizeof(error))) < 0)  

`            `goto dump\_format;  



`    `/\* discard unused programs \*/  

`    `for (i = 0; i < nb\_input\_files; i++){  

`        `InputFile \*ifile = &input\_files[i];  

`        `for (j = 0; j < ifile->ctx->nb\_programs; j++){  

`            `AVProgram \*p = ifile->ctx->programs[j];  

`            `int discard = AVDISCARD\_ALL;  



`            `for (k = 0; k < p->nb\_stream\_indexes; k++){  

`                `if (!input\_streams[ifile->ist\_index + p->stream\_index[k]].discard){  

`                    `discard = AVDISCARD\_DEFAULT;  

`                    `break;  

`                `}  

`            `}  

`            `p->discard = discard;  

`        `}  

`    `}  



`    `//打开所有输出文件，写入媒体文件头  

`    `for (i = 0; i < nb\_output\_files; i++){  

`        `oc = output\_files[i].ctx;  

`        `oc->interrupt\_callback = int\_cb;  

`        `if (avformat\_write\_header(oc, &output\_files[i].opts) < 0){  

`            `snprintf(error, sizeof(error),  

`                    `"Could not write header for output file #%d (incorrect codec parameters ?)",  

`                    `i);  

`            `ret = AVERROR(EINVAL);  

`            `goto dump\_format;  

`        `}  

//        assert\_avoptions(output\_files[i].opts);  

`        `if (strcmp(oc->oformat->name, "rtp")){  

`            `want\_sdp = 0;  

`        `}  

`    `}  



`    `return 0;  

}  
## **8.6 transcode()**
**[cpp]** [view plain](http://blog.csdn.net/niu_gao/article/details/7175421#)[copy](http://blog.csdn.net/niu_gao/article/details/7175421#)

直接从主函数进行分析

int main(int argc, char \*\*argv)  

{  

`    `OptionsContext o = { 0 };  

`    `int64\_t ti;  



`    `//与命令行分析有关的结构的初始化,下面不再罗嗦  

`    `reset\_options(&o, 0);  



`    `//设置日志级别  

`    `av\_log\_set\_flags(AV\_LOG\_SKIP\_REPEATED);  

`    `parse\_loglevel(argc, argv, options);  



`    `if (argc > 1 && !strcmp(argv[1], "-d"))  {  

`        `run\_as\_daemon = 1;  

`        `av\_log\_set\_callback(log\_callback\_null);  

`        `argc--;  

`        `argv++;  

`    `}  



`    `//注册组件们  

`    `avcodec\_register\_all();  

#if CONFIG\_AVDEVICE  

`    `avdevice\_register\_all();  

#endif  

#if CONFIG\_AVFILTER  

`    `avfilter\_register\_all();  

#endif  

`    `av\_register\_all();  

`    `//初始化网络,windows下需要  

`    `avformat\_network\_init();  



`    `show\_banner();  



`    `term\_init();  



`    `//分析命令行输入的参数们  

`    `parse\_options(&o, argc, argv, options, opt\_output\_file);  



`    `//文件的转换就在此函数中发生  

`    `if (transcode(output\_files, nb\_output\_files, input\_files, nb\_input\_files)< 0)  

`        `exit\_program(1);  



`    `exit\_program(0);  

`    `return 0;  

}  

下面是transcode()函数,转换就发生在它里面.不废话,看注释吧,应很详细了

static int transcode(  

`        `OutputFile \*output\_files,//输出文件数组  

`        `int nb\_output\_files,//输出文件的数量  

`        `InputFile \*input\_files,//输入文件数组  

`        `int nb\_input\_files)//输入文件的数量  

{  

`    `int ret, i;  

`    `AVFormatContext \*is, \*os;  

`    `OutputStream \*ost;  

`    `InputStream \*ist;  

`    `uint8\_t \*no\_packet;  

`    `int no\_packet\_count = 0;  

`    `int64\_t timer\_start;  

`    `int key;  



`    `if (!(no\_packet = av\_mallocz(nb\_input\_files)))  

`        `exit\_program(1);  



`    `//设置编码参数,打开所有输出流的编码器,打开所有输入流的解码器,写入所有输出文件的文件头,于是准备好了  

`    `ret = transcode\_init(output\_files, nb\_output\_files, input\_files,nb\_input\_files);  

`    `if (ret < 0)  

`        `goto fail;  



`    `if (!using\_stdin){  

`        `av\_log(NULL, AV\_LOG\_INFO, "Press [q] to stop, [?] for help\n");  

`    `}  



`    `timer\_start = av\_gettime();  



`    `//循环,直到收到系统信号才退出  

`    `for (; received\_sigterm == 0;)  

`    `{  

`        `int file\_index, ist\_index;  

`        `AVPacket pkt;  

`        `int64\_t ipts\_min;  

`        `double opts\_min;  

`        `int64\_t cur\_time = av\_gettime();  



`        `ipts\_min = INT64\_MAX;  

`        `opts\_min = 1e100;  

`        `/\* if 'q' pressed, exits \*/  

`        `if (!using\_stdin)  

`        `{  

`            `//先查看用户按下了什么键,跟据键做出相应的反应  

`            `static int64\_t last\_time;  

`            `if (received\_nb\_signals)  

`                `break;  

`            `/\* read\_key() returns 0 on EOF \*/  

`            `if (cur\_time - last\_time >= 100000 && !run\_as\_daemon){  

`                `key = read\_key();  

`                `last\_time = cur\_time;  

`            `}else{   

`        `}  



`        `/\* select the stream that we must read now by looking at the 

`         `smallest output pts \*/  

`        `//下面这个循环的目的是找一个最小的输出pts(也就是离当前最近的)的输出流  

`        `file\_index = -1;  

`        `for (i = 0; i < nb\_output\_streams; i++){  

`            `OutputFile \*of;  

`            `int64\_t ipts;  

`            `double opts;  

`            `ost = &output\_streams[i];//循环每一个输出流  

`            `of = &output\_files[ost->file\_index];//输出流对应的输出文件  

`            `os = output\_files[ost->file\_index].ctx;//输出流对应的FormatContext  

`            `ist = &input\_streams[ost->source\_index];//输出流对应的输入流  



`            `if (ost->is\_past\_recording\_time || //是否过了录制时间?(可能用户指定了一个录制时间段)  

`                    `no\_packet[ist->file\_index]|| //对应的输入流这个时间内没有数据?  

`                    `(os->pb && avio\_tell(os->pb) >= of->limit\_filesize))//是否超出了录制范围(也是用户指定的)  

`                `continue;//是的,符合上面某一条,那么再看下一个输出流吧  



`            `//判断当前输入流所在的文件是否可以使用(我也不很明白)  

`            `opts = ost->st->pts.val \* av\_q2d(ost->st->time\_base);  

`            `ipts = ist->pts;  

`            `if (!input\_files[ist->file\_index].eof\_reached)   {  

`                `if (ipts < ipts\_min){  

`                    `//每找到一个pts更小的输入流就记录下来,这样循环完所有的输出流时就找到了  

`                    `//pts最小的输入流,及输入文件的序号  

`                    `ipts\_min = ipts;  

`                    `if (input\_sync)  

`                        `file\_index = ist->file\_index;  

`                `}  

`                `if (opts < opts\_min){  

`                    `opts\_min = opts;  

`                    `if (!input\_sync)  

`                        `file\_index = ist->file\_index;  

`                `}  

`            `}  



`            `//难道下面这句话的意思是:如果当前的输出流已接收的帧数,超出用户指定的输出最大帧数时,  

`            `//则当前输出流所属的输出文件对应的所有输出流,都算超过了录像时间?  

`            `if (ost->frame\_number >= ost->max\_frames){  

`                `int j;  

`                `for (j = 0; j < of->ctx->nb\_streams; j++)  

`                    `output\_streams[of->ost\_index + j].is\_past\_recording\_time =   1;  

`                `continue;  

`            `}  

`        `}  

`        `/\* if none, if is finished \*/  

`        `if (file\_index < 0)  {  

`            `//如果没有找到合适的输入文件  

`            `if (no\_packet\_count){  

`                `//如果是因为有的输入文件暂时得不到数据,则还不算是结束  

`                `no\_packet\_count = 0;  

`                `memset(no\_packet, 0, nb\_input\_files);  

`                `usleep(10000);  

`                `continue;  

`            `}  

`            `//全部转换完成了,跳出大循环  

`            `break;  

`        `}  



`        `//从找到的输入文件中读出一帧(可能是音频也可能是视频),并放到fifo队列中  

`        `is = input\_files[file\_index].ctx;  

`        `ret = av\_read\_frame(is, &pkt);  

`        `if (ret == AVERROR(EAGAIN)) {  

`            `//此时发生了暂时没数据的情况  

`            `no\_packet[file\_index] = 1;  

`            `no\_packet\_count++;  

`            `continue;  

`        `}  



`        `//下文判断是否有输入文件到最后了  

`        `if (ret < 0){  

`            `input\_files[file\_index].eof\_reached = 1;  

`            `if (opt\_shortest)  

`                `break;  

`            `else  

`                `continue;  

`        `}  



`        `no\_packet\_count = 0;  

`        `memset(no\_packet, 0, nb\_input\_files);  



`        `if (do\_pkt\_dump){  

`            `av\_pkt\_dump\_log2(NULL, AV\_LOG\_DEBUG, &pkt, do\_hex\_dump,  

`                    `is->streams[pkt.stream\_index]);  

`        `}  

`        `/\* the following test is needed in case new streams appear 

`         `dynamically in stream : we ignore them \*/  

`        `//如果在输入文件中遇到一个忽然冒出的流,那么我们不鸟它  

`        `if (pkt.stream\_index >= input\_files[file\_index].nb\_streams)  

`            `goto discard\_packet;  



`        `//取得当前获得的帧对应的输入流  

`        `ist\_index = input\_files[file\_index].ist\_index + pkt.stream\_index;  

`        `ist = &input\_streams[ist\_index];  

`        `if (ist->discard)  

`            `goto discard\_packet;  



`        `//重新鼓捣一下帧的时间戳  

`        `if (pkt.dts != AV\_NOPTS\_VALUE)  

`            `pkt.dts += av\_rescale\_q(input\_files[ist->file\_index].ts\_offset,  

`                    `AV\_TIME\_BASE\_Q, ist->st->time\_base);  

`        `if (pkt.pts != AV\_NOPTS\_VALUE)  

`            `pkt.pts += av\_rescale\_q(input\_files[ist->file\_index].ts\_offset,  

`                    `AV\_TIME\_BASE\_Q, ist->st->time\_base);  



`        `if (pkt.pts != AV\_NOPTS\_VALUE)  

`            `pkt.pts \*= ist->ts\_scale;  

`        `if (pkt.dts != AV\_NOPTS\_VALUE)  

`            `pkt.dts \*= ist->ts\_scale;  



`        `if (pkt.dts != AV\_NOPTS\_VALUE && ist->next\_pts != AV\_NOPTS\_VALUE  

`                `&& (is->iformat->flags & AVFMT\_TS\_DISCONT))  

`        `{  

`            `int64\_t pkt\_dts = av\_rescale\_q(pkt.dts, ist->st->time\_base,  

`                    `AV\_TIME\_BASE\_Q);  

`            `int64\_t delta = pkt\_dts - ist->next\_pts;  

`            `if ((delta < -1LL \* dts\_delta\_threshold \* AV\_TIME\_BASE  

`                    `|| (delta > 1LL \* dts\_delta\_threshold \* AV\_TIME\_BASE  

`                            `&& ist->st->codec->codec\_type  

`                                    `!= AVMEDIA\_TYPE\_SUBTITLE)  

`                    `|| pkt\_dts + 1 < ist->pts) && !copy\_ts)  

`            `{  

`                `input\_files[ist->file\_index].ts\_offset -= delta;  

`                `av\_log( NULL,   AV\_LOG\_DEBUG,  

`                        `"timestamp discontinuity %"PRId64", new offset= %"PRId64"\n",  

`                        `delta, input\_files[ist->file\_index].ts\_offset);  

`                `pkt.dts -= av\_rescale\_q(delta, AV\_TIME\_BASE\_Q,  ist->st->time\_base);  

`                `if (pkt.pts != AV\_NOPTS\_VALUE)  

`                    `pkt.pts -= av\_rescale\_q(delta, AV\_TIME\_BASE\_Q,  ist->st->time\_base);  

`            `}  

`        `}  



`        `//把这一帧转换并写入到输出文件中  

`        `if (output\_packet(ist, output\_streams, nb\_output\_streams, &pkt) < 0){  

`            `av\_log(NULL, AV\_LOG\_ERROR,  

`                    `"Error while decoding stream #%d:%d\n",  

`                    `ist->file\_index, ist->st->index);  

`            `if (exit\_on\_error)  

`                `exit\_program(1);  

`            `av\_free\_packet(&pkt);  

`            `continue;  

`        `}  



discard\_packet:  

`        `av\_free\_packet(&pkt);  



`        `/\* dump report by using the output first video and audio streams \*/  

`        `print\_report(output\_files, output\_streams, nb\_output\_streams, 0,  

`                `timer\_start, cur\_time);  

`    `}  



`    `//文件处理完了,把缓冲中剩余的数据写到输出文件中  

`    `for (i = 0; i < nb\_input\_streams; i++){  

`        `ist = &input\_streams[i];  

`        `if (ist->decoding\_needed){  

`            `output\_packet(ist, output\_streams, nb\_output\_streams, NULL);  

`        `}  

`    `}  

`    `flush\_encoders(output\_streams, nb\_output\_streams);  



`    `term\_exit();  



`    `//为输出文件写文件尾(有的不需要).  

`    `for (i = 0; i < nb\_output\_files; i++){  

`        `os = output\_files[i].ctx;  

`        `av\_write\_trailer(os);  

`    `}  



`    `/\* dump report by using the first video and audio streams \*/  

`    `print\_report(output\_files, output\_streams, nb\_output\_streams, 1,  

`            `timer\_start, av\_gettime());  



`    `//关闭所有的编码器  

`    `for (i = 0; i < nb\_output\_streams; i++){  

`        `ost = &output\_streams[i];  

`        `if (ost->encoding\_needed){  

`            `av\_freep(&ost->st->codec->stats\_in);  

`            `avcodec\_close(ost->st->codec);  

`        `}  

#if CONFIG\_AVFILTER  

`        `avfilter\_graph\_free(&ost->graph);  

#endif  

`    `}  



`    `//关闭所有的解码器  

`    `for (i = 0; i < nb\_input\_streams; i++){  

`        `ist = &input\_streams[i];  

`        `if (ist->decoding\_needed){  

`            `avcodec\_close(ist->st->codec);  

`        `}  

`    `}  



`    `/\* finished ! \*/  

`    `ret = 0;  



`    `fail: av\_freep(&bit\_buffer);  

`    `av\_freep(&no\_packet);  



`    `if (output\_streams) {  

`        `for (i = 0; i < nb\_output\_streams; i++)  {  

`            `ost = &output\_streams[i];  

`            `if (ost)    {  

`                `if (ost->stream\_copy)  

`                    `av\_freep(&ost->st->codec->extradata);  

`                `if (ost->logfile){  

`                    `fclose(ost->logfile);  

`                    `ost->logfile = NULL;  

`                `}  

`                `av\_fifo\_free(ost->fifo); /\* works even if fifo is not 

`                 `initialized but set to zero \*/  

`                `av\_freep(&ost->st->codec->subtitle\_header);  

`                `av\_free(ost->resample\_frame.data[0]);  

`                `av\_free(ost->forced\_kf\_pts);  

`                `if (ost->video\_resample)  

`                    `sws\_freeContext(ost->img\_resample\_ctx);  

`                `swr\_free(&ost->swr);  

`                `av\_dict\_free(&ost->opts);  

`            `}  

`        `}  

`    `}  

`    `return ret;  

} 
# **第九章 ffmpeg相关工程**
## **9.1 ffdshow**
ffdshow是基于ffmpeg的解码器类库libavcodec的DirectShow Filter。广泛安装在PC上
### [**ffdshow 源代码分析1 ： 整体结构**](http://blog.csdn.net/leixiaohua1020/article/details/12013619)
ffdshow是一个非常强大的DirectShow解码器，封装了ffmpeg，libmpeg2等解码库。它也提供了丰富的加工处理选项，可以锐化画面，调节画面的亮度等等。不止是视频，FFDShow现在同样可以解码音频，AC3、MP3等音频格式都可支持。并且可以外挂winamp 的DSP插件，来改善听觉效果。一个词形容：强大。

因为项目的要求，需要对ffdshow进行二次开发，正好有这个机会，分析研究一下ffdshow的源代码。

ffdshow项目的资源可以从sourceforge下载。包括编译好的程序，以及原代码等，下载地址：<http://sourceforge.net/projects/ffdshow-tryout/>

注意：sourceforge上有两个版本的ffdshow：ffdshow以及ffdshow-tryout。其中前一个版本很早之前已经停止开发了，因此我们需要选择后一个（ffdshow-tryout）。

下载源代码的方法不再赘述，下面直接进入正题。源代码下载后，需要进行编译，推荐使用源代码根目录下的bat脚本一次性完成所有的资源编译。

编译完成后我们就可以打开源代码根目录里的工程了。我自己的开发环境是VC2010，打开后工程如下图所示（解决方案的名字被我修改了= =）：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.143.jpeg)

由图可见，ffdshow由一大堆工程组成，乍一看给人一种杂论无章的感觉，其实大部分工程我们不用去理会，我们重点研究最重要的工程就是那个名字叫“ffdshow”的工程。

下面我介绍几个最重要的文件夹里包含的代码的功能：

audiofilters：音频滤镜都在这里面（例如EQ，调节高低频等）

baseclasses：微软自带directshow的sdk里面就有，主要是微软为了方便DirectShow开发而提供的一些基本的类

codecs：支持的解码器都在这里（例如libavcodec，libmpeg2等）

convert：色彩转换的一些功能（没太用过）

decss：解除版权加密的一些功能（没太用过）

dialog：音频视频滤镜的配置页面

doc：文档，不是程序

ffvfw：VFW相关（目前没太用过）

Header Files：核心代码的头文件

imgfilters：视频滤镜都在这里（显示QP/MV，加LOGO，显示视频信息等）

Resource Files：资源文件

settings：音频视频滤镜的配置信息

Source Files：核心代码的源文件

subtitles：字幕相关的功能

以上用红色标出的，是我们二次开发中最有可能会涉及到的三个部分。掌握了这三个部分，就可以往ffdhow中添加自己写的滤镜（注意：这里说的是视频滤镜，音频的方法是一样的）

黄色背景标出的部分，虽然我们可能不需要做出什么改变，但是为了了解ffdshow的架构，我们需要分析其中的代码。
### [**ffdshow 源代码分析 2： 位图覆盖滤镜（对话框部分Dialog）**](http://blog.csdn.net/leixiaohua1020/article/details/12981725)
本文我们介绍ffdshow的滤镜功能。ffdshow支持很多种滤镜，可以支持多种视频和音频的后期效果。例如OSD滤镜支持在视频的左上角显示视频相关的信息。而可视化滤镜则支持显示视频每一帧的运动矢量以及量化参数。在这里我们介绍一种位图覆盖（Bitmap）滤镜（Filter）。

效果

编译完ffdshow之后，在“项目属性->调试->命令”里面将GraphEdit.exe所在位置设置为调试程序，例如在这里我设置了《终极解码》里面自带GraphEdit.exe，路径为“C:\Program Files\Final Codecs\Codecs\GraphEdit.exe”。这样就可以使用GraphEdit.exe调试ffdshow了。

向GraphEdit.exe里面拖入一个文件“五月天 咸鱼.mp4”，结果如下图所示：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.144.jpeg)

注：有的时候默认的视频解码器可能不是ffdshow，可能是CoreAVC等，可以先删除视频解码器然后添加ffdshow。

点击绿色三角形按钮就可以开始播放视频。

右键点击ffdshow组件，打开属性对话框之后，可以看见右边栏中有很多的滤镜。

勾选“位图覆盖”滤镜，然后选择一张用于覆盖的图片（在这里我选择了一张bmp格式的专辑封面）。

注：可以调整位图所在的水平位置，垂直位置，不透明度，并且可以修改位图叠加模式（在这里用混合）。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.145.jpeg)

添加了该滤镜之后，播放窗口的显示内容为：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.146.jpeg)

可见在右上角显示出了叠加的位图。

源代码分析

1.对话框部分

与位图覆盖（Bitmap）滤镜的对话框有关的类位于dialog目录下的Cbitmap.cpp和Cbitmap.h文件中。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.147.jpeg)

先来看看Cbitmap.h中类的声明：

需要注意的是，里面类的名字居然叫TbitmapPage，而没有和头文件名字一致。=  =

#ifndef \_CBITMAPPAGE\_H\_  

#define \_CBITMAPPAGE\_H\_  



#include "TconfPageDecVideo.h"  

//Bitmap配置页面  

class TbitmapPage : public TconfPageDecVideo  

{  

private:  

`    `void pos2dlg(void), opacity2dlg(void);  

`    `//设置文件路径  

`    `void onFlnm(void);  

protected:  

`    `virtual INT\_PTR msgProc(UINT uMsg, WPARAM wParam, LPARAM lParam);  

public:  

`    `//构造函数  

`    `TbitmapPage(TffdshowPageDec \*Iparent, const TfilterIDFF \*idff);  

`    `//初始化  

`    `virtual void init(void);  

`    `//配置数据传入到对话框界面  

`    `virtual void cfg2dlg(void);  

`    `virtual void translate(void);  

};  



#endif  

再看看Cbitmap.cpp文件吧。关键的代码都已经加上了注释。

/\* 

` `\* Copyright (c) 2004-2006 Milan Cutka 

` `\* 

` `\* This program is free software; you can redistribute it and/or modify 

` `\* it under the terms of the GNU General Public License as published by 

` `\* the Free Software Foundation; either version 2 of the License, or 

` `\* (at your option) any later version. 

` `\* 

` `\* This program is distributed in the hope that it will be useful, 

` `\* but WITHOUT ANY WARRANTY; without even the implied warranty of 

` `\* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the 

` `\* GNU General Public License for more details. 

` `\* 

` `\* You should have received a copy of the GNU General Public License 

` `\* along with this program; if not, write to the Free Software 

` `\* Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA 

` `\*/  

//Bitmap配置页面  

#include "stdafx.h"  

#include "TsubtitlesSettings.h"  

#include "TbitmapSettings.h"  

#include "Cbitmap.h"  

//初始化  

void TbitmapPage::init(void)  

{  

`    `//设置滑动条范围  

`    `edLimitText(IDC\_ED\_BITMAP\_FLNM, MAX\_PATH);  

`    `tbrSetRange(IDC\_TBR\_BITMAP\_POSX, 0, 100, 10);  

`    `tbrSetRange(IDC\_TBR\_BITMAP\_POSY, 0, 100, 10);  

`    `tbrSetRange(IDC\_TBR\_BITMAP\_OPACITY, 0, 256);  

}  

//配置数据传入到对话框界面  

void TbitmapPage::cfg2dlg(void)  

{  

`    `//各种设置  

`    `//EditControl设置  

`    `setDlgItemText(m\_hwnd, IDC\_ED\_BITMAP\_FLNM, cfgGetStr(IDFF\_bitmapFlnm));  

`    `pos2dlg();  

`    `cbxSetCurSel(IDC\_CBX\_BITMAP\_ALIGN, cfgGet(IDFF\_bitmapAlign));  

`    `cbxSetCurSel(IDC\_CBX\_BITMAP\_MODE, cfgGet(IDFF\_bitmapMode));  

`    `opacity2dlg();  

}  

//Bitmap位置信息  

void TbitmapPage::pos2dlg(void)  

{  

`    `char\_t s[260];  

`    `int x;  

`    `//获取  

`    `x = cfgGet(IDFF\_bitmapPosx);  

`    `TsubtitlesSettings::getPosHoriz(x, s, this, IDC\_LBL\_BITMAP\_POSX, countof(s));  

`    `setDlgItemText(m\_hwnd, IDC\_LBL\_BITMAP\_POSX, s);  

`    `//设置  

`    `tbrSet(IDC\_TBR\_BITMAP\_POSX, x);  



`    `x = cfgGet(IDFF\_bitmapPosy);  

`    `TsubtitlesSettings::getPosVert(x, s, this, IDC\_LBL\_BITMAP\_POSY, countof(s));  

`    `setDlgItemText(m\_hwnd, IDC\_LBL\_BITMAP\_POSY, s);  

`    `tbrSet(IDC\_TBR\_BITMAP\_POSY, x);  

}  

void TbitmapPage::opacity2dlg(void)  

{  

`    `int o = cfgGet(IDFF\_bitmapStrength);  

`    `tbrSet(IDC\_TBR\_BITMAP\_OPACITY, o);  

`    `setText(IDC\_LBL\_BITMAP\_OPACITY, \_l("%s %i%%"), \_(IDC\_LBL\_BITMAP\_OPACITY), 100 \* o / 256);  

}  



INT\_PTR TbitmapPage::msgProc(UINT uMsg, WPARAM wParam, LPARAM lParam)  

{  

`    `switch (uMsg) {  

`        `case WM\_COMMAND:  

`            `switch (LOWORD(wParam)) {  

`                `case IDC\_ED\_BITMAP\_FLNM:  

`                    `if (HIWORD(wParam) == EN\_CHANGE && !isSetWindowText) {  

`                        `char\_t flnm[MAX\_PATH];  

`                        `GetDlgItemText(m\_hwnd, IDC\_ED\_BITMAP\_FLNM, flnm, MAX\_PATH);  

`                        `cfgSet(IDFF\_bitmapFlnm, flnm);  

`                    `}  

`                    `return TRUE;  

`            `}  

`            `break;  

`    `}  

`    `return TconfPageDecVideo::msgProc(uMsg, wParam, lParam);  

}  

//设置文件路径  

void TbitmapPage::onFlnm(void)  

{  

`    `char\_t flnm[MAX\_PATH];  

`    `cfgGet(IDFF\_bitmapFlnm, flnm, MAX\_PATH);  

`    `if (dlgGetFile(false, m\_hwnd, \_(-IDD\_BITMAP, \_l("Load image file")), \_l("All supported (\*.jpg,\*.bmp,\*.gif,\*.png)\0\*.bmp;\*.jpg;\*.jpeg;\*.gif;\*.png\0Windows Bitmap (\*.bmp)\0\*.bmp\0JPEG (\*.jpg)\0\*.jpg\0Compuserve Graphics Interchange (\*.gif)\0\*.gif\0Portable Network Graphics (\*.png)\0\*.png"), \_l("bmp"), flnm, \_l("."), 0)) {  

`        `setDlgItemText(m\_hwnd, IDC\_ED\_BITMAP\_FLNM, flnm);  

`        `//设置  

`        `cfgSet(IDFF\_bitmapFlnm, flnm);  

`    `}  

}  



void TbitmapPage::translate(void)  

{  

`    `TconfPageBase::translate();  



`    `cbxTranslate(IDC\_CBX\_BITMAP\_ALIGN, TsubtitlesSettings::alignments);  

`    `cbxTranslate(IDC\_CBX\_BITMAP\_MODE, TbitmapSettings::modes);  

}  

//构造函数  

TbitmapPage::TbitmapPage(TffdshowPageDec \*Iparent, const TfilterIDFF \*idff): TconfPageDecVideo(Iparent, idff)  

{  

`    `//各种绑定  

`    `resInter = IDC\_CHB\_BITMAP;  

`    `static const TbindTrackbar<TbitmapPage> htbr[] = {  

`        `IDC\_TBR\_BITMAP\_POSX, IDFF\_bitmapPosx, &TbitmapPage::pos2dlg,  

`        `IDC\_TBR\_BITMAP\_POSY, IDFF\_bitmapPosy, &TbitmapPage::pos2dlg,  

`        `IDC\_TBR\_BITMAP\_OPACITY, IDFF\_bitmapStrength, &TbitmapPage::opacity2dlg,  

`        `0, 0, NULL  

`    `};  

`    `bindHtracks(htbr);  

`    `static const TbindCombobox<TbitmapPage> cbx[] = {  

`        `IDC\_CBX\_BITMAP\_ALIGN, IDFF\_bitmapAlign, BINDCBX\_SEL, NULL,  

`        `IDC\_CBX\_BITMAP\_MODE, IDFF\_bitmapMode, BINDCBX\_SEL, NULL,  

`        `0  

`    `};  

`    `bindComboboxes(cbx);  

`    `static const TbindButton<TbitmapPage> bt[] = {  

`        `IDC\_BT\_BITMAP\_FLNM, &TbitmapPage::onFlnm,  

`        `0, NULL  

`    `};  

`    `bindButtons(bt);  

}  

看ffdshow源代码的时候，开始会比较费劲。为什么？因为它使用了大量自己写的API函数，以及自己定义的结构体。这些API函数的种类繁多，如果一个一个都看完，估计就精疲力竭了。经过一段时间的学习之后，我发现最方便的方法还是根据函数名字推测其用法。因此我就不深入剖析ffdshow的API函数了。

以上源代码中包含以下API（大致按出现先后次序，可能没有例举全，在这里只是举例子）：

edLimitText();//限制输入字符串长度  

tbrSetRange();//设置滑动条范围  

setDlgItemText();//设置组件名称  

cbxSetCurSel();//设置下拉框当前选项  

cfgGet();//从注册表中读取变量的值  

tbrSet();//设置滑动条的值  

bindHtracks();//绑定注册表变量和滑动条  

bindComboboxes();//绑定注册表变量和下拉框  

bindButtons();//绑定函数和按钮  

从以上函数大致可以看出tbr\*\*\*()基本上都是操作滑动条的，cbx\*\*\*()基本上都是操作下拉框的，函数基本上可以从名称上理解其的意思。bind\*\*\*()就是绑定注册表变量和控件的。注意ffdshow里面有注册表变量这么一个概念。这些变量的值存在系统的注册表里面，不会因为程序结束运行而消失。就目前我的观察来看，绝大部分注册表变量存的是一个整数值。这些注册表变量都以IDFF\_xxx的名称预编译定义在ffdshow\_constants.h头文件中。与MFC控件可以直接与CString，int等变量绑定不同，ffdshow控件只可以和注册表变量绑定。即每次运行的时候都从注册表加载变量的值到界面上。存储的时候把界面上的值存储到注册表中。

注：注册表变量如下所示（截取了一小段）

#define IDFF\_filterBitmap   1650  

#define IDFF\_isBitmap       1651  

#define IDFF\_showBitmap     1652  

#define IDFF\_orderBitmap    1653  

#define IDFF\_fullBitmap     1654  

#define IDFF\_bitmapFlnm     1655  

#define IDFF\_bitmapPosx     1656  

#define IDFF\_bitmapPosy     1657  

#define IDFF\_bitmapPosmode  1658  

#define IDFF\_bitmapAlign    1659  

#define IDFF\_bitmapMode     1660  

#define IDFF\_bitmapStrength 1661  

此外需要注意的是，ffdshow尽管包含了图形化的属性界面，却没有使用MFC类库，因而MFC的很多函数都不能使用，对此我还不甚了解为什么要这样，以后有机会要探究探究。
### [**ffdshow 源代码分析 3： 位图覆盖滤镜（设置部分Settings）**](http://blog.csdn.net/leixiaohua1020/article/details/13004051)
在这里再介绍一下设置部分（Settings），此外还有一个滤镜部分（Filter）。这三个部分就可以组成一个ffdshow的滤镜功能了。

设置部分（Settings）

在ffdshow中滤镜的设置部分（Settings）主要用于存储滤镜运行过程中需要用到的各种变量。一般情况下通过读取注册表变量并赋值给该类当中的变量从而达到操作相应滤镜的功能。

与位图覆盖（Bitmap）滤镜的设置有关的类位于settings->filters->video目录下（隐藏的很深啊）的TbitmapSettings.cpp和TbitmapSettings.h文件中。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.148.jpeg)

先来看看TbitmapSettings.h

该类的名字叫TbitmapSettings，从类的定义我们可以看出，

flnm[]存储了打开的位图的路径

posx，posy存储了位图在屏幕上显示的位置

mode存储了显示的方式

等等，所有跟该滤镜（Filter）相关的数据都存储在该类之中。

该类包含一个TfilterIDFF类型的结构体idffs，用于存储该滤镜的一些属性信息（名称，ID，属性对话框ID等等）

此外，有两个函数至关重要。createFilters()用于创建滤镜（Filter）。 createPages()用于创建滤镜的配置对话框（Dialog）。

#ifndef \_TBITMAPSETTINGS\_H\_  

#define \_TBITMAPSETTINGS\_H\_  

//各个Filter预设值  

#include "TfilterSettings.h"  

#include "Tfont.h"  

//Bitmap的配置信息  

struct TbitmapSettings : TfilterSettingsVideo {  

private:  

`    `static const TfilterIDFF idffs;  

protected:  

`    `virtual const int \*getResets(unsigned int pageId);  

public:  

`    `TbitmapSettings(TintStrColl \*Icoll = NULL, TfilterIDFFs \*filters = NULL);  

`    `//Bitmap文件路径  

`    `char\_t flnm[MAX\_PATH];  

`    `//x,y坐标，以及坐标的模式  

`    `int posx, posy, posmode;  

`    `int align;  

`    `//叠加方式  

`    `enum {  

`        `MODE\_BLEND = 0,  

`        `MODE\_DARKEN = 1,  

`        `MODE\_LIGHTEN = 2,  

`        `MODE\_ADD = 3,  

`        `MODE\_SOFTLIGHT = 4,  

`        `MODE\_EXCLUSION = 5  

`    `};  

`    `int mode;  

`    `static const char\_t \*modes[];  

`    `int strength;  

`    `//创建Filter  

`    `virtual void createFilters(size\_t filtersorder, Tfilters \*filters, TfilterQueue &queue) const;  

`    `//创建属性页面  

`    `virtual void createPages(TffdshowPageDec \*parent) const;  

`    `virtual bool getTip(unsigned int pageId, char\_t \*buf, size\_t buflen);  

};  



#endif  

再来看看TbitmapSettings.cpp

该类包含了TbitmapSettings类中函数方法的具体实现。首先看一下构造函数TbitmapSettings()。从构造函数中可以看出，绑定了类中的变量和注册表变量，使它们形成一一对应的关系。其他的函数就不再细说了，比较简单，理解起来比较容易。

#include "stdafx.h"  

#include "TbitmapSettings.h"  

#include "TimgFilterBitmap.h"  

#include "Cbitmap.h"  

#include "TffdshowPageDec.h"  

#include "TsubtitlesSettings.h"  

//几种叠加方式  

const char\_t\* TbitmapSettings::modes[] = {  

`    `\_l("blend"),  

`    `\_l("darken"),  

`    `\_l("lighten"),  

`    `\_l("add"),  

`    `\_l("softlight"),  

`    `\_l("exclusion"),  

`    `NULL  

};  

//Filter属性  

const TfilterIDFF TbitmapSettings::idffs = {  

`    `/\*name\*/      \_l("Bitmap overlay"),  

`    `/\*id\*/        IDFF\_filterBitmap,  

`    `/\*is\*/        IDFF\_isBitmap,  

`    `/\*order\*/     IDFF\_orderBitmap,  

`    `/\*show\*/      IDFF\_showBitmap,  

`    `/\*full\*/      IDFF\_fullBitmap,  

`    `/\*half\*/      0,  

`    `/\*dlgId\*/     IDD\_BITMAP,  

};  

//构造函数  

TbitmapSettings::TbitmapSettings(TintStrColl \*Icoll, TfilterIDFFs \*filters): TfilterSettingsVideo(sizeof(\*this), Icoll, filters, &idffs)  

{  

`    `half = 0;  

`    `memset(flnm, 0, sizeof(flnm));  

`    `//绑定变量  

`    `static const TintOptionT<TbitmapSettings> iopts[] = {  

`        `IDFF\_isBitmap       , &TbitmapSettings::is        , 0, 0, \_l(""), 1,  

`        `\_l("isBitmap"), 0,  

`        `IDFF\_showBitmap     , &TbitmapSettings::show      , 0, 0, \_l(""), 1,  

`        `\_l("showBitmap"), 1,  

`        `IDFF\_orderBitmap    , &TbitmapSettings::order     , 1, 1, \_l(""), 1,  

`        `\_l("orderBitmap"), 0,  

`        `IDFF\_fullBitmap     , &TbitmapSettings::full      , 0, 0, \_l(""), 1,  

`        `\_l("fullBitmap"), 0,  

`        `IDFF\_bitmapPosx     , &TbitmapSettings::posx      , -4096, 4096, \_l(""), 1,  

`        `\_l("bitmapPosX"), 50,  

`        `IDFF\_bitmapPosy     , &TbitmapSettings::posy      , -4096, 4096, \_l(""), 1,  

`        `\_l("bitmapPosY"), 50,  

`        `IDFF\_bitmapPosmode  , &TbitmapSettings::posmode   , 0, 1, \_l(""), 1,  

`        `\_l("bitmapPosMode"), 0,  

`        `IDFF\_bitmapAlign    , &TbitmapSettings::align     , 0, 3, \_l(""), 1,  

`        `\_l("bitmapAlign"), ALIGN\_CENTER,  

`        `IDFF\_bitmapMode     , &TbitmapSettings::mode      , 0, 5, \_l(""), 1,  

`        `\_l("bitmapMode"), 0,  

`        `IDFF\_bitmapStrength , &TbitmapSettings::strength  , 0, 256, \_l(""), 1,  

`        `\_l("bitmapStrength"), 128,  

`        `0  

`    `};  

`    `addOptions(iopts);  

`    `static const TstrOption sopts[] = {  

`        `IDFF\_bitmapFlnm     , (TstrVal)&TbitmapSettings::flnm  , MAX\_PATH, 0, \_l(""), 1,  

`        `\_l("bitmapFlnm"), \_l(""),  

`        `0  

`    `};  

`    `addOptions(sopts);  



`    `static const TcreateParamList1 listMode(modes);  

`    `setParamList(IDFF\_bitmapMode, &listMode);  

`    `static const TcreateParamList1 listAlign(TsubtitlesSettings::alignments);  

`    `setParamList(IDFF\_bitmapAlign, &listAlign);  

}  

//创建Filter  

void TbitmapSettings::createFilters(size\_t filtersorder, Tfilters \*filters, TfilterQueue &queue) const  

{  

`    `idffOnChange(idffs, filters, queue.temporary);  

`    `if (is && show) {  

`        `queueFilter<TimgFilterBitmap>(filtersorder, filters, queue);  

`    `}  

}  

//创建属性页面  

void TbitmapSettings::createPages(TffdshowPageDec \*parent) const  

{  

`    `parent->addFilterPage<TbitmapPage>(&idffs);  

}  



const int\* TbitmapSettings::getResets(unsigned int pageId)  

{  

`    `static const int idResets[] = {  

`        `IDFF\_bitmapPosx, IDFF\_bitmapPosy, IDFF\_bitmapPosmode, IDFF\_bitmapAlign, IDFF\_bitmapMode, IDFF\_bitmapStrength,  

`        `0  

`    `};  

`    `return idResets;  

}  



bool TbitmapSettings::getTip(unsigned int pageId, char\_t \*tipS, size\_t len)  

{  

`    `if (flnm[0]) {  

`        `tsnprintf\_s(tipS, len, \_TRUNCATE, \_l("%s %s"), modes[mode], flnm);  

`        `tipS[len - 1] = '\0';  

`    `} else {  

`        `tipS[0] = '\0';  

`    `}  

`    `return true;  

}  
### [**ffdshow 源代码分析 4： 位图覆盖滤镜（滤镜部分Filter）**](http://blog.csdn.net/leixiaohua1020/article/details/13006213)
滤镜部分（Filter）

ffdshow的滤镜的滤镜部分（怎么感觉名字有点重复 = =，算了先这么叫吧）的功能主要用于完成具体的图像处理功能。具体到位图覆盖滤镜的话，就是用于把图片覆盖到视频上面，他是ffdshow滤镜的核心。

与位图覆盖（Bitmap）滤镜的滤镜处理有关的类位于imgFilters目录下的TimgFilterBitmap.h和TimgFilterBitmap.cpp文件中。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.149.jpeg)

先来看看TimgFilterBitmap.h

这里要注意一下，该类的名字叫TimgFilterBitmap。它的声明方式确实比较奇怪：DECLARE\_FILTER(TimgFilterBitmap, public, TimgFilter)

可以看出DECLARE\_FILTER是一个宏，具体这个宏的内部代码就先不查看了，否则会感觉很混乱，暂且留下一个小小的谜团。在这里只要知道这是声明了一个滤镜类就可以了。

其实TimgFilterBitmap的核心函数不多，就一个，那就是process()，具体的处理功能都是在这个函数里面实现的。

#ifndef \_TIMGFILTERBITMAP\_H\_  

#define \_TIMGFILTERBITMAP\_H\_  

//叠加一张位图  

#include "TimgFilter.h"  

#include "Tfont.h"  



struct TffPict;  

struct TbitmapSettings;  

//特别的声明方式 = =  

DECLARE\_FILTER(TimgFilterBitmap, public, TimgFilter)  

private:  

//图像  

TffPict \*bitmap;  

//内存  

Tbuffer bitmapbuf;  

char\_t oldflnm[MAX\_PATH];  

typedef void (\*Tblendplane)(const TcspInfo &cspInfo, const unsigned int dx[3], const unsigned int dy[3], unsigned char \*dst[3], const stride\_t dststride[3], const unsigned char \*src[3], const stride\_t srcstride[3], int strength, int invstrength);  

//注意 这个类有一个实例，名字叫w  

class TrenderedSubtitleLineBitmap : public TrenderedSubtitleWordBase  

{  

public:  

`    `TrenderedSubtitleLineBitmap(void): TrenderedSubtitleWordBase(false) {}  

`    `TffPict \*pict;  

`    `const TbitmapSettings \*cfg;  

`    `//叠加  

`    `Tblendplane blend;  

`    `//打印  

`    `virtual void print(int startx, int starty /\* not used \*/, unsigned int dx[3], int dy1[3], unsigned char \*dstLn[3], const stride\_t stride[3], const unsigned char \*bmp[3], const unsigned char \*msk[3], REFERENCE\_TIME rtStart = REFTIME\_INVALID) const;  

} w;  

TrenderedSubtitleLine l;  

//是TrenderedSubtitleLine的一个vector  

TrenderedSubtitleLines ls;  

int oldmode;  

//几种叠加方式  

template<class \_mm> static void blend(const TcspInfo &cspInfo, const unsigned int dx[3], const unsigned int dy[3], unsigned char \*dst[3], const stride\_t dststride[3], const unsigned char \*src[3], const stride\_t srcstride[3], int strength, int invstrength);  

template<class \_mm> static void add(const TcspInfo &cspInfo, const unsigned int dx[3], const unsigned int dy[3], unsigned char \*dst[3], const stride\_t dststride[3], const unsigned char \*src[3], const stride\_t srcstride[3], int strength, int invstrength);  

template<class \_mm> static void darken(const TcspInfo &cspInfo, const unsigned int dx[3], const unsigned int dy[3], unsigned char \*dst[3], const stride\_t dststride[3], const unsigned char \*src[3], const stride\_t srcstride[3], int strength, int invstrength);  

template<class \_mm> static void lighten(const TcspInfo &cspInfo, const unsigned int dx[3], const unsigned int dy[3], unsigned char \*dst[3], const stride\_t dststride[3], const unsigned char \*src[3], const stride\_t srcstride[3], int strength, int invstrength);  

template<class \_mm> static void softlight(const TcspInfo &cspInfo, const unsigned int dx[3], const unsigned int dy[3], unsigned char \*dst[3], const stride\_t dststride[3], const unsigned char \*src[3], const stride\_t srcstride[3], int strength, int invstrength);  

template<class \_mm> static void exclusion(const TcspInfo &cspInfo, const unsigned int dx[3], const unsigned int dy[3], unsigned char \*dst[3], const stride\_t dststride[3], const unsigned char \*src[3], const stride\_t srcstride[3], int strength, int invstrength);  

//获取叠加方式  

template<class \_mm> static Tblendplane getBlend(int mode);  

protected:  

virtual bool is(const TffPictBase &pict, const TfilterSettingsVideo \*cfg);  

virtual uint64\_t getSupportedInputColorspaces(const TfilterSettingsVideo \*cfg) const  

{  

`    `return FF\_CSPS\_MASK\_YUV\_PLANAR;  

}  

public:  

TimgFilterBitmap(IffdshowBase \*Ideci, Tfilters \*Iparent);  

virtual ~TimgFilterBitmap();  

//核心函数（Filter配置信息队列，图像，配置信息）  

virtual HRESULT process(TfilterQueue::iterator it, TffPict &pict, const TfilterSettingsVideo \*cfg0);  

};  



#endif  

再来看看TimgFilterBitmap.cpp

这个文件本身代码量是比较大的，只是其他部分我都还没有仔细分析，确实没那没多时间。。。在这里仅简要分析一下最核心的函数process()。正是这个函数真正实现了滤镜的功能。在这个位图叠加滤镜中，process()实现了位图在视频上面的叠加功能。

//核心函数（Filter配置信息队列，图像，配置信息）  

HRESULT TimgFilterBitmap::process(TfilterQueue::iterator it, TffPict &pict, const TfilterSettingsVideo \*cfg0)  

{  

`    `//都有这一句= =  

`    `if (is(pict, cfg0)) {  

`        `//Bitmap的配置信息  

`        `const TbitmapSettings \*cfg = (const TbitmapSettings\*)cfg0;  

`        `init(pict, cfg->full, cfg->half);  

`        `unsigned char \*dst[4];  

`        `bool cspChanged = getCurNext(FF\_CSPS\_MASK\_YUV\_PLANAR, pict, cfg->full, COPYMODE\_DEF, dst);  

`        `//处理  

`        `if (!bitmap || cspChanged || stricmp(oldflnm, cfg->flnm) != 0) {  

`            `ff\_strncpy(oldflnm, cfg->flnm, countof(oldflnm));  

`            `if (bitmap) {  

`                `delete bitmap;  

`            `}  

`            `//新建一张图  

`            `//通过cfg->flnm路径  

`            `//载入bitmapbuf  

`            `bitmap = new TffPict(csp2, cfg->flnm, bitmapbuf, deci);  

`            `//3个颜色分量？  

`            `for (int i = 0; i < 3; i++) {  

`                `w.dx[i] = bitmap->rectFull.dx >> bitmap->cspInfo.shiftX[i];  

`                `w.dy[i] = bitmap->rectFull.dy >> bitmap->cspInfo.shiftY[i];  

`                `w.bmp[i] = bitmap->data[i];  

`                `w.bmpmskstride[i] = bitmap->stride[i];  

`            `}  

`            `w.dxChar = w.dx[0];  

`            `w.dyChar = w.dy[0];  

`        `}  



`        `if (bitmap->rectFull.dx != 0) {  

`            `if (oldmode != cfg->mode)  

`                `if (Tconfig::cpu\_flags & FF\_CPU\_SSE2) {  

`                    `//获取叠加方式（SSE2）  

`                    `//在cfg的mode里  

`                    `w.blend = getBlend<Tsse2>(oldmode = cfg->mode);  

`                `} else {  

`                    `//获取叠加方式（MMX）  

`                    `w.blend = getBlend<Tmmx>(oldmode = cfg->mode);  

`                `}  

`            `//输出到屏幕上的设置  

`            `TprintPrefs prefs(deci, NULL);  

`            `//各种参数  

`            `prefs.dx = dx2[0];  

`            `prefs.dy = dy2[0];  

`            `prefs.xpos = cfg->posx;  

`            `prefs.ypos = cfg->posy;  

`            `//模式不同的话  

`            `if (cfg->posmode == 1) {  

`                `prefs.xpos \*= -1;  

`                `prefs.ypos \*= -1;  

`            `}  

`            `prefs.align = cfg->align;  

`            `prefs.linespacing = 100;  

`            `prefs.csp = pict.csp;  

`            `w.pict = &pict;  

`            `w.cfg = cfg;  

`            `//打印，需要用到TprintPrefs  

`            `ls.print(prefs, dst, stride2);  

`        `}  

`    `}  

`    `//最后都是这一句？  

`    `return parent->processSample(++it, pict);  

}  
### [**ffdshow 源代码分析 5： 位图覆盖滤镜（总结）**](http://blog.csdn.net/leixiaohua1020/article/details/13660583)
用一张图总结他们之间的关系：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.150.jpeg)

如图中所示，设置（Settings）部分是直接和系统上层关联的，它包含两个接口函数：createPages()和createFilters()。分别用于创建对话框（Dialog）和滤镜（Filter）。其中在TbitmapPage中对话框直接和注册表变量关联。而在TbitmapSettings中注册表变量和系统中的变量关联。TimgFilterBitmap最终读取TbitmapSettings中的变量完成相应的操作。

目前来开TimgFilterBitmap是不会直接读取TbitmapPage类中的值的。
### [**ffdshow 源代码分析 6： 对解码器的dll的封装（libavcodec）**](http://blog.csdn.net/leixiaohua1020/article/details/15493329)
ffdshow封装了多个视音频解码器，比如libmpeg2，libavcodec，xvid等等。其中最重要的是libavcodec，这个是ffmpeg提供的解码器，在ffdshow中起到了“挑大梁”的作用。本文分析ffdshow对解码器的封装方式，就以libavcodec为例。



在ffdshow中，libavcodec的被封装在ffmpeg.dll文件中，通过加载该dll中的函数，就可以使用libavcodec的各种方法。



Ffmpeg对libavcodec的封装类的定义位于codecs->libavcodec->Tlibavcodec.h。实现则位于codecs->libavcodec->Tlibavcodec.cpp。

先来看一看Tlibavcodec.h：

#ifndef \_TLIBAVCODEC\_H\_  

#define \_TLIBAVCODEC\_H\_  

//将FFmpeg的Dll中的方法封装到一个类中，以供使用  

#include "../codecs/ffcodecs.h"  

#include <dxva.h>  

#include "TpostprocSettings.h"  

#include "ffImgfmt.h"  

#include "libavfilter/vf\_yadif.h"  

#include "libavfilter/gradfun.h"  

#include "libswscale/swscale.h"  



struct AVCodecContext;  

struct AVCodec;  

struct AVFrame;  

struct AVPacket;  

struct AVCodecParserContext;  

struct SwsContext;  

struct SwsParams;  

struct PPMode;  

struct AVDictionary;  



struct Tconfig;  

class Tdll;  

struct DSPContext;  

struct TlibavcodecExt;  

//封装FFMPEG  

//里面的函数基本上是FFMPEG的API  

struct Tlibavcodec {  

private:  

`    `int (\*libswscale\_sws\_scale)(struct SwsContext \*context, const uint8\_t\* const srcSlice[], const int srcStride[],  

`                                `int srcSliceY, int srcSliceH, uint8\_t\* const dst[], const int dstStride[]);  

`    `//加载DLL的类  

`    `Tdll \*dll;  

`    `int refcount;  

`    `static int get\_buffer(AVCodecContext \*c, AVFrame \*pic);  

`    `CCritSec csOpenClose;  

public:  

`    `Tlibavcodec(const Tconfig \*config);  

`    `~Tlibavcodec();  

`    `static void avlog(AVCodecContext\*, int, const char\*, va\_list);  

`    `static void avlogMsgBox(AVCodecContext\*, int, const char\*, va\_list);  

`    `void AddRef(void) {  

`        `refcount++;  

`    `}  

`    `void Release(void) {  

`        `if (--refcount < 0) {  

`            `delete this;  

`        `}  

`    `}  

`    `static bool getVersion(const Tconfig \*config, ffstring &vers, ffstring &license);  

`    `static bool check(const Tconfig \*config);  

`    `static int ppCpuCaps(uint64\_t csp);  

`    `static void pp\_mode\_defaults(PPMode &ppMode);  

`    `static int getPPmode(const TpostprocSettings \*cfg, int currentq);  

`    `static void swsInitParams(SwsParams \*params, int resizeMethod);  

`    `static void swsInitParams(SwsParams \*params, int resizeMethod, int flags);  



`    `bool ok;  

`    `AVCodecContext\* avcodec\_alloc\_context(AVCodec \*codec, TlibavcodecExt \*ext = NULL);  



`    `void (\*avcodec\_register\_all)(void);  

`    `AVCodecContext\* (\*avcodec\_alloc\_context0)(AVCodec \*codec);  

`    `AVCodec\* (\*avcodec\_find\_decoder)(AVCodecID codecId);  

`    `AVCodec\* (\*avcodec\_find\_encoder)(AVCodecID id);  

`    `int (\*avcodec\_open0)(AVCodecContext \*avctx, AVCodec \*codec, AVDictionary \*\*options);  

`    `int  avcodec\_open(AVCodecContext \*avctx, AVCodec \*codec);  

`    `AVFrame\* (\*avcodec\_alloc\_frame)(void);  

`    `int (\*avcodec\_decode\_video2)(AVCodecContext \*avctx, AVFrame \*picture,  

`                                 `int \*got\_picture\_ptr,  

`                                 `AVPacket \*avpkt);  

`    `int (\*avcodec\_decode\_audio3)(AVCodecContext \*avctx, int16\_t \*samples,  

`                                 `int \*frame\_size\_ptr,  

`                                 `AVPacket \*avpkt);  

`    `int (\*avcodec\_encode\_video)(AVCodecContext \*avctx, uint8\_t \*buf, int buf\_size, const AVFrame \*pict);  

`    `int (\*avcodec\_encode\_audio)(AVCodecContext \*avctx, uint8\_t \*buf, int buf\_size, const short \*samples);  

`    `void (\*avcodec\_flush\_buffers)(AVCodecContext \*avctx);  

`    `int (\*avcodec\_close0)(AVCodecContext \*avctx);  

`    `int  avcodec\_close(AVCodecContext \*avctx);  



`    `void (\*av\_log\_set\_callback)(void (\*)(AVCodecContext\*, int, const char\*, va\_list));  

`    `void\* (\*av\_log\_get\_callback)(void);  

`    `int (\*av\_log\_get\_level)(void);  

`    `void (\*av\_log\_set\_level)(int);  



`    `void (\*av\_set\_cpu\_flags\_mask)(int mask);  



`    `int (\*avcodec\_default\_get\_buffer)(AVCodecContext \*s, AVFrame \*pic);  

`    `void (\*avcodec\_default\_release\_buffer)(AVCodecContext \*s, AVFrame \*pic);  

`    `int (\*avcodec\_default\_reget\_buffer)(AVCodecContext \*s, AVFrame \*pic);  

`    `const char\* (\*avcodec\_get\_current\_idct)(AVCodecContext \*avctx);  

`    `void (\*avcodec\_get\_encoder\_info)(AVCodecContext \*avctx, int \*xvid\_build, int \*divx\_version, int \*divx\_build, int \*lavc\_build);  



`    `void\* (\*av\_mallocz)(size\_t size);  

`    `void (\*av\_free)(void \*ptr);  



`    `AVCodecParserContext\* (\*av\_parser\_init)(int codec\_id);  

`    `int (\*av\_parser\_parse2)(AVCodecParserContext \*s, AVCodecContext \*avctx, uint8\_t \*\*poutbuf, int \*poutbuf\_size, const uint8\_t \*buf, int buf\_size, int64\_t pts, int64\_t dts, int64\_t pos);  

`    `void (\*av\_parser\_close)(AVCodecParserContext \*s);  



`    `void (\*av\_init\_packet)(AVPacket \*pkt);  

`    `uint8\_t\* (\*av\_packet\_new\_side\_data)(AVPacket \*pkt, enum AVPacketSideDataType type, int size);  



`    `int (\*avcodec\_h264\_search\_recovery\_point)(AVCodecContext \*avctx,  

`            `const uint8\_t \*buf, int buf\_size, int \*recovery\_frame\_cnt);  



`    `static const char\_t \*idctNames[], \*errorRecognitions[], \*errorConcealments[];  

`    `struct Tdia\_size {  

`        `int size;  

`        `const char\_t \*descr;  

`    `};  

`    `static const Tdia\_size dia\_sizes[];  



`    `//libswscale imports  

`    `SwsContext\* (\*sws\_getCachedContext)(struct SwsContext \*context, int srcW, int srcH, enum PixelFormat srcFormat,  

`                                        `int dstW, int dstH, enum PixelFormat dstFormat, int flags,  

`                                        `SwsFilter \*srcFilter, SwsFilter \*dstFilter, const double \*param, SwsParams \*ffdshow\_params);  



`    `void (\*sws\_freeContext)(SwsContext \*c);  

`    `SwsFilter\* (\*sws\_getDefaultFilter)(float lumaGBlur, float chromaGBlur,  

`                                       `float lumaSharpen, float chromaSharpen,  

`                                       `float chromaHShift, float chromaVShift,  

`                                       `int verbose);  

`    `void (\*sws\_freeFilter)(SwsFilter \*filter);  

`    `int sws\_scale(struct SwsContext \*context, const uint8\_t\* const srcSlice[], const stride\_t srcStride[],  

`                  `int srcSliceY, int srcSliceH, uint8\_t\* const dst[], const stride\_t dstStride[]);  

`    `SwsVector \*(\*sws\_getConstVec)(double c, int length);  

`    `SwsVector \*(\*sws\_getGaussianVec)(double variance, double quality);  

`    `void (\*sws\_normalizeVec)(SwsVector \*a, double height);  

`    `void (\*sws\_freeVec)(SwsVector \*a);  

`    `int (\*sws\_setColorspaceDetails)(struct SwsContext \*c, const int inv\_table[4],  

`                                    `int srcRange, const int table[4], int dstRange,  

`                                    `int brightness, int contrast, int saturation);  

`    `const int\* (\*sws\_getCoefficients)(int colorspace);  



`    `int (\*GetCPUCount)(void);  



`    `//libpostproc imports  

`    `void (\*pp\_postprocess)(const uint8\_t \* src[3], const stride\_t srcStride[3],  

`                           `uint8\_t \* dst[3], const stride\_t dstStride[3],  

`                           `int horizontalSize, int verticalSize,  

`                           `const /\*QP\_STORE\_T\*/int8\_t \*QP\_store,  int QP\_stride,  

`                           `/\*pp\_mode\*/void \*mode, /\*pp\_context\*/void \*ppContext, int pict\_type);  

`    `/\*pp\_context\*/  

`    `void \*(\*pp\_get\_context)(int width, int height, int flags);  

`    `void (\*pp\_free\_context)(/\*pp\_context\*/void \*ppContext);  

`    `void (\*ff\_simple\_idct\_mmx)(int16\_t \*block);  



`    `// DXVA imports  

`    `int (\*av\_h264\_decode\_frame)(struct AVCodecContext\* avctx, uint8\_t \*buf, int buf\_size);  

`    `int (\*av\_vc1\_decode\_frame)(struct AVCodecContext\* avctx, uint8\_t \*buf, int buf\_size);  



`    `// === H264 functions  

`    `int (\*FFH264CheckCompatibility)(int nWidth, int nHeight, struct AVCodecContext\* pAVCtx, BYTE\* pBuffer, UINT nSize, int nPCIVendor, int nPCIDevice, LARGE\_INTEGER VideoDriverVersion);  

`    `int (\*FFH264DecodeBuffer)(struct AVCodecContext\* pAVCtx, BYTE\* pBuffer, UINT nSize, int\* pFramePOC, int\* pOutPOC, REFERENCE\_TIME\* pOutrtStart);  

`    `HRESULT(\*FFH264BuildPicParams)(DXVA\_PicParams\_H264\* pDXVAPicParams, DXVA\_Qmatrix\_H264\* pDXVAScalingMatrix, int\* nFieldType, int\* nSliceType, struct AVCodecContext\* pAVCtx, int nPCIVendor);  



`    `void (\*FFH264SetCurrentPicture)(int nIndex, DXVA\_PicParams\_H264\* pDXVAPicParams, struct AVCodecContext\* pAVCtx);  

`    `void (\*FFH264UpdateRefFramesList)(DXVA\_PicParams\_H264\* pDXVAPicParams, struct AVCodecContext\* pAVCtx);  

`    `BOOL (\*FFH264IsRefFrameInUse)(int nFrameNum, struct AVCodecContext\* pAVCtx);  

`    `void (\*FF264UpdateRefFrameSliceLong)(DXVA\_PicParams\_H264\* pDXVAPicParams, DXVA\_Slice\_H264\_Long\* pSlice, struct AVCodecContext\* pAVCtx);  

`    `void (\*FFH264SetDxvaSliceLong)(struct AVCodecContext\* pAVCtx, void\* pSliceLong);  



`    `// === VC1 functions  

`    `HRESULT(\*FFVC1UpdatePictureParam)(DXVA\_PictureParameters\* pPicParams, struct AVCodecContext\* pAVCtx, int\* nFieldType, int\* nSliceType, BYTE\* pBuffer, UINT nSize, UINT\* nFrameSize, BOOL b\_SecondField, BOOL\* b\_repeat\_pict);  

`    `int (\*FFIsSkipped)(struct AVCodecContext\* pAVCtx);  



`    `// === Common functions  

`    `char\*    (\*GetFFMpegPictureType)(int nType);  

`    `unsigned long(\*FFGetMBNumber)(struct AVCodecContext\* pAVCtx);  



`    `// yadif  

`    `void (\*yadif\_init)(YADIFContext \*yadctx);  

`    `void (\*yadif\_uninit)(YADIFContext \*yadctx);  

`    `void (\*yadif\_filter)(YADIFContext \*yadctx, uint8\_t \*dst[3], stride\_t dst\_stride[3], int width, int height, int parity, int tff);  



`    `// gradfun  

`    `int (\*gradfunInit)(GradFunContext \*ctx, const char \*args, void \*opaque);  

`    `void (\*gradfunFilter)(GradFunContext \*ctx, uint8\_t \*dst, uint8\_t \*src, int width, int height, int dst\_linesize, int src\_linesize, int r);  

};  



#endif  

从Tlibavcodec定义可以看出，里面包含了大量的ffmpeg中的API，占据了很大的篇幅。通过调用这些API，就可以使用livavcodec的各种功能。

在Tlibavcodec的定义中，有一个变量：Tdll \*dll，通过该变量，就可以加载ffmpeg.dll中的方法。

先来看一下Tdll的定义：

` `#ifndef \_TDLL\_H\_  

#define \_TDLL\_H\_  



#include "Tconfig.h"  

//操作Dll的类  

class Tdll  

{  

public:  

`    `bool ok;  

`    `Tdll(const char\_t \*dllName1, const Tconfig \*config, bool explicitFullPath = false) {  

`        `char\_t name[MAX\_PATH], ext[MAX\_PATH];  

`        `\_splitpath\_s(dllName1, NULL, 0, NULL, 0, name, countof(name), ext, countof(ext));  

`        `if (config && !explicitFullPath) {  

`            `char\_t dllName2[MAX\_PATH]; //installdir+filename+ext  

`            `\_makepath\_s(dllName2, countof(dllName2), NULL, config->pth, name, ext);  

`            `hdll = LoadLibrary(dllName2);  

`        `} else {  

`            `hdll = NULL;  

`        `}  

`        `if (!hdll) {  

`            `hdll = LoadLibrary(dllName1);  

`            `if (!hdll && !explicitFullPath) {  

`                `if (config) {  

`                    `char\_t dllName3[MAX\_PATH]; //ffdshow.ax\_path+filename+ext  

`                    `\_makepath\_s(dllName3, countof(dllName3), NULL, config->epth, name, ext);  

`                    `hdll = LoadLibrary(dllName3);  

`                `}  

`                `if (!hdll) {  

`                    `char\_t dllName0[MAX\_PATH]; //only filename+ext - let Windows find it  

`                    `\_makepath\_s(dllName0, countof(dllName0), NULL, NULL, name, ext);  

`                    `hdll = LoadLibrary(dllName0);  

`                `}  

`            `}  

`        `}  

`        `ok = (hdll != NULL);  

`    `}  

`    `~Tdll() {  

`        `if (hdll) {  

`            `FreeLibrary(hdll);  

`        `}  

`    `}  

`    `HMODULE hdll;  

`    `//封装一下直接加载Dll的GetProcAddress  

`    `template<class T> \_\_forceinline void loadFunction(T &fnc, const char \*name) {  

`        `fnc = hdll ? (T)GetProcAddress(hdll, name) : NULL;  

`        `ok &= (fnc != NULL);  

`    `}  

`    `template<class T> \_\_forceinline void loadFunctionByIndex(T &fnc, uint16\_t id) {  

`        `uint32\_t id32 = uint32\_t(id);  

`        `fnc = hdll ?  

`              `(T) GetProcAddress(hdll, (LPCSTR)id32) :  

`              `NULL;  

`        `ok &= (fnc != NULL);  

`    `}  

`    `//检查Dll的状态是否正常  

`    `static bool check(const char\_t \*dllName1, const Tconfig \*config) {  

`        `char\_t name[MAX\_PATH], ext[MAX\_PATH];  

`        `\_splitpath\_s(dllName1, NULL, 0, NULL, 0, name, countof(name), ext, countof(ext));  

`        `if (config) {  

`            `char\_t dllName2[MAX\_PATH]; //installdir+filename+ext  

`            `\_makepath\_s(dllName2, countof(dllName2), NULL, config->pth, name, ext);  

`            `if (fileexists(dllName2)) {  

`                `return true;  

`            `}  

`        `}  

`        `if (fileexists(dllName1)) {  

`            `return true;  

`        `}  

`        `if (config) {  

`            `char\_t dllName3[MAX\_PATH]; //ffdshow.ax\_path+filename+ext  

`            `\_makepath\_s(dllName3, MAX\_PATH, NULL, config->epth, name, ext);  

`            `if (fileexists(dllName3)) {  

`                `return true;  

`            `}  

`        `}  

`        `char\_t dllName0[MAX\_PATH]; //only filename+ext - let Windows find it  

`        `\_makepath\_s(dllName0, countof(dllName0), NULL, NULL, name, ext);  

`        `char\_t dir0[MAX\_PATH], \*dir0flnm;  

`        `if (SearchPath(NULL, dllName0, NULL, MAX\_PATH, dir0, &dir0flnm)) {  

`            `return true;  

`        `}  

`        `return false;  

`    `}  

};  



#endif  

从Tdll的定义可以看出，该类的loadFunction()函数封装了系统使用Dll功能的函数GetProcAddress()。

该类的构造函数Tdll()封装了系统加载Dll的函数LoadLibrary()。

此外该类还提供了check()用于检查Dll。

对于Tdll的分析先告一段落，现在我们回到Tlibavcodec，来看看它是如何加载libavcodec的函数的。查看一下Tlibavcodec的类的实现，位于codecs->libavcodec->Tlibavcodec.cpp。

该类的实现代码比较长，因此只能选择重要的函数查看一下。首先来看一下构造函数：

//===================================== Tlibavcodec ====================================  

//FFMPEG封装类的构造函数  

Tlibavcodec::Tlibavcodec(const Tconfig \*config): refcount(0)  

{  

`    `//加载FFMPEG的Dll  

`    `dll = new Tdll(\_l("ffmpeg.dll"), config);  

`    `//加载各个函数  

`    `dll->loadFunction(avcodec\_register\_all, "avcodec\_register\_all");  

`    `dll->loadFunction(avcodec\_find\_decoder, "avcodec\_find\_decoder");  

`    `dll->loadFunction(avcodec\_open0, "avcodec\_open2");  

`    `dll->loadFunction(avcodec\_alloc\_context0, "avcodec\_alloc\_context3");  

`    `dll->loadFunction(avcodec\_alloc\_frame, "avcodec\_alloc\_frame");  

`    `dll->loadFunction(avcodec\_decode\_video2, "avcodec\_decode\_video2");  

`    `dll->loadFunction(avcodec\_flush\_buffers, "avcodec\_flush\_buffers");  

`    `dll->loadFunction(avcodec\_close0, "avcodec\_close");  

`    `dll->loadFunction(av\_log\_set\_callback, "av\_log\_set\_callback");  

`    `dll->loadFunction(av\_log\_get\_callback, "av\_log\_get\_callback");  

`    `dll->loadFunction(av\_log\_get\_level, "av\_log\_get\_level");  

`    `dll->loadFunction(av\_log\_set\_level, "av\_log\_set\_level");  

`    `dll->loadFunction(av\_set\_cpu\_flags\_mask, "av\_set\_cpu\_flags\_mask");  

`    `dll->loadFunction(av\_mallocz, "av\_mallocz");  

`    `dll->loadFunction(av\_free, "av\_free");  

`    `dll->loadFunction(avcodec\_default\_get\_buffer, "avcodec\_default\_get\_buffer");  

`    `dll->loadFunction(avcodec\_default\_release\_buffer, "avcodec\_default\_release\_buffer");  

`    `dll->loadFunction(avcodec\_default\_reget\_buffer, "avcodec\_default\_reget\_buffer");  

`    `dll->loadFunction(avcodec\_get\_current\_idct, "avcodec\_get\_current\_idct");  

`    `dll->loadFunction(avcodec\_get\_encoder\_info, "avcodec\_get\_encoder\_info");  

`    `dll->loadFunction(av\_init\_packet, "av\_init\_packet");  

`    `dll->loadFunction(av\_packet\_new\_side\_data, "av\_packet\_new\_side\_data");  

`    `dll->loadFunction(avcodec\_h264\_search\_recovery\_point, "avcodec\_h264\_search\_recovery\_point");  



`    `dll->loadFunction(avcodec\_decode\_audio3, "avcodec\_decode\_audio3");  



`    `dll->loadFunction(avcodec\_find\_encoder, "avcodec\_find\_encoder");  

`    `dll->loadFunction(avcodec\_encode\_video, "avcodec\_encode\_video");  

`    `dll->loadFunction(avcodec\_encode\_audio, "avcodec\_encode\_audio");  



`    `dll->loadFunction(av\_parser\_init, "av\_parser\_init");  

`    `dll->loadFunction(av\_parser\_parse2, "av\_parser\_parse2");  

`    `dll->loadFunction(av\_parser\_close, "av\_parser\_close");  



`    `//libswscale methods  

`    `dll->loadFunction(sws\_getCachedContext, "sws\_getCachedContext");  

`    `dll->loadFunction(sws\_freeContext, "sws\_freeContext");  

`    `dll->loadFunction(sws\_getDefaultFilter, "sws\_getDefaultFilter");  

`    `dll->loadFunction(sws\_freeFilter, "sws\_freeFilter");  

`    `dll->loadFunction(libswscale\_sws\_scale, "sws\_scale");  



`    `dll->loadFunction(GetCPUCount, "GetCPUCount");  

`    `dll->loadFunction(sws\_getConstVec, "sws\_getConstVec");  

`    `dll->loadFunction(sws\_getGaussianVec, "sws\_getGaussianVec");  

`    `dll->loadFunction(sws\_normalizeVec, "sws\_normalizeVec");  

`    `dll->loadFunction(sws\_freeVec, "sws\_freeVec");  

`    `dll->loadFunction(sws\_setColorspaceDetails, "sws\_setColorspaceDetails");  

`    `dll->loadFunction(sws\_getCoefficients, "sws\_getCoefficients");  



`    `//libpostproc methods  

`    `dll->loadFunction(pp\_postprocess, "pp\_postprocess");  

`    `dll->loadFunction(pp\_get\_context, "pp\_get\_context");  

`    `dll->loadFunction(pp\_free\_context, "pp\_free\_context");  

`    `dll->loadFunction(ff\_simple\_idct\_mmx, "ff\_simple\_idct\_mmx");  



`    `//DXVA methods  

`    `dll->loadFunction(av\_h264\_decode\_frame, "av\_h264\_decode\_frame");  

`    `dll->loadFunction(av\_vc1\_decode\_frame, "av\_vc1\_decode\_frame");  



`    `dll->loadFunction(FFH264CheckCompatibility, "FFH264CheckCompatibility");  

`    `dll->loadFunction(FFH264DecodeBuffer, "FFH264DecodeBuffer");  

`    `dll->loadFunction(FFH264BuildPicParams, "FFH264BuildPicParams");  

`    `dll->loadFunction(FFH264SetCurrentPicture, "FFH264SetCurrentPicture");  

`    `dll->loadFunction(FFH264UpdateRefFramesList, "FFH264UpdateRefFramesList");  

`    `dll->loadFunction(FFH264IsRefFrameInUse, "FFH264IsRefFrameInUse");  

`    `dll->loadFunction(FF264UpdateRefFrameSliceLong, "FF264UpdateRefFrameSliceLong");  

`    `dll->loadFunction(FFH264SetDxvaSliceLong, "FFH264SetDxvaSliceLong");  



`    `dll->loadFunction(FFVC1UpdatePictureParam, "FFVC1UpdatePictureParam");  

`    `dll->loadFunction(FFIsSkipped, "FFIsSkipped");  



`    `dll->loadFunction(GetFFMpegPictureType, "GetFFMpegPictureType");  

`    `dll->loadFunction(FFGetMBNumber, "FFGetMBNumber");  



`    `//yadif methods  

`    `dll->loadFunction(yadif\_init, "yadif\_init");  

`    `dll->loadFunction(yadif\_uninit, "yadif\_uninit");  

`    `dll->loadFunction(yadif\_filter, "yadif\_filter");  



`    `//gradfun  

`    `dll->loadFunction(gradfunInit, "gradfunInit");  

`    `dll->loadFunction(gradfunFilter, "gradfunFilter");  



`    `ok = dll->ok;  

`    `//加载完毕后，进行注册  

`    `if (ok) {  

`        `avcodec\_register\_all();  

`        `av\_log\_set\_callback(avlog);  

`    `}  

}  

该构造函数尽管篇幅比较长，但是还是比较好理解的，主要完成了3步：

\1.      创建一个Tdll类的对象，加载“ffmpeg.dll”。

\2.      使用loadFunction()加载各种函数。

\3.      最后调用avcodec\_register\_all()注册各种解码器。



Tlibavcodec的析构函数则比较简单：

Tlibavcodec::~Tlibavcodec()  

{  

`    `delete dll;  

}  

检查Dll的函数也比较简单：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/15493329#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/15493329#)![](https://code.csdn.net/assets/CODE\_ico.png)![](https://code.csdn.net/assets/ico\_fork.svg)

bool Tlibavcodec::check(const Tconfig \*config)  

{  

`    `return Tdll::check(\_l("ffmpeg.dll"), config);  

}  

此外，可能是出于某些功能的考虑，ffdshow还自己写了几个函数，但是限于篇幅不能一一介绍，在这里只介绍一个：

获取libavcodec版本：

bool Tlibavcodec::getVersion(const Tconfig \*config, ffstring &vers, ffstring &license)  

{  

`    `Tdll \*dl = new Tdll(\_l("ffmpeg.dll"), config);  



`    `void (\*av\_getVersion)(char \*\*version, char \*\*build, char \*\*datetime, const char\* \*license);  

`    `dl->loadFunction(av\_getVersion, "getVersion");  

`    `bool res;  

`    `if (av\_getVersion) {  

`        `res = true;  

`        `char \*version, \*build, \*datetime;  

`        `const char \*lic;  

`        `av\_getVersion(&version, &build, &datetime, &lic);  

`        `vers = (const char\_t\*)text<char\_t>(version) + ffstring(\_l(" (")) + (const char\_t\*)text<char\_t>(datetime) + \_l(")");  

`        `license = text<char\_t>(lic);  

`    `} else {  

`        `res = false;  

`        `vers.clear();  

`        `license.clear();  

`    `}  

`    `delete dl;  

`    `return res;  

}  

[ffdshow 源代码分析 7： libavcodec视频解码器类（TvideoCodecLibavcodec）](http://blog.csdn.net/leixiaohua1020/article/details/15493521)

在这里我们进一步介绍一下其libavcodec解码器类。注意前一篇文章介绍的类Tlibavcodec仅仅是对libavcodec所在的“ffmpeg.dll”的函数进行封装的类。但Tlibavcodec并不是一个解码器类，其没有继承任何类，还不能为ffdshow所用。本文介绍的TvideoCodecLibavcodec才是libavcodec解码器类，其继承了TvideoCodecDec。



先来看一看TvideoCodecLibavcodec的定义吧，位于codecs-> TvideoCodecLibavcodec.h中。

#ifndef \_TVIDEOCODECLIBAVCODEC\_H\_  

#define \_TVIDEOCODECLIBAVCODEC\_H\_  



#include "TvideoCodec.h"  

#include "ffmpeg/Tlibavcodec.h"  

#include "ffmpeg/libavcodec/avcodec.h"  



#define MAX\_THREADS 8 // FIXME: This is defined in mpegvideo.h.  



struct Textradata;  

class TccDecoder;  

//libavcodec解码器（视频）  

struct TlibavcodecExt {  

private:  

`    `static int get\_buffer(AVCodecContext \*s, AVFrame \*pic);  

`    `int (\*default\_get\_buffer)(AVCodecContext \*s, AVFrame \*pic);  

`    `static void release\_buffer(AVCodecContext \*s, AVFrame \*pic);  

`    `void (\*default\_release\_buffer)(AVCodecContext \*s, AVFrame \*pic);  

`    `static int reget\_buffer(AVCodecContext \*s, AVFrame \*pic);  

`    `int (\*default\_reget\_buffer)(AVCodecContext \*s, AVFrame \*pic);  

`    `static void handle\_user\_data0(AVCodecContext \*c, const uint8\_t \*buf, int buf\_len);  

public:  

`    `virtual ~TlibavcodecExt() {}  

`    `void connectTo(AVCodecContext \*ctx, Tlibavcodec \*libavcodec);  

`    `virtual void onGetBuffer(AVFrame \*pic) {}  

`    `virtual void onRegetBuffer(AVFrame \*pic) {}  

`    `virtual void onReleaseBuffer(AVFrame \*pic) {}  

`    `virtual void handle\_user\_data(const uint8\_t \*buf, int buf\_len) {}  

};  

//libavcodec解码，不算是Filter？  

class TvideoCodecLibavcodec : public TvideoCodecDec, public TvideoCodecEnc, public TlibavcodecExt  

{  

`    `friend class TDXVADecoderVC1;  

`    `friend class TDXVADecoderH264;  

protected:  

`    `//各种信息（源自AVCodecContext中）  

`    `Tlibavcodec \*libavcodec;  

`    `void create(void);  

`    `AVCodec \*avcodec;  

`    `mutable char\_t codecName[100];  

`    `AVCodecContext \*avctx;  

`    `uint32\_t palette[AVPALETTE\_COUNT];  

`    `int palette\_size;  

`    `AVFrame \*frame;  

`    `FOURCC fcc;  

`    `FILE \*statsfile;  

`    `int cfgcomode;  

`    `int psnr;  

`    `bool isAdaptive;  

`    `int threadcount;  

`    `bool dont\_use\_rtStop\_from\_upper\_stream; // and reordering of timpestams is justified.  

`    `bool theorart;  

`    `bool codecinited, ownmatrices;  

`    `REFERENCE\_TIME rtStart, rtStop, avgTimePerFrame, segmentTimeStart;  

`    `REFERENCE\_TIME prior\_in\_rtStart, prior\_in\_rtStop;  

`    `REFERENCE\_TIME prior\_out\_rtStart, prior\_out\_rtStop;  



`    `struct {  

`        `REFERENCE\_TIME rtStart, rtStop;  

`        `unsigned int srcSize;  

`    `} b[MAX\_THREADS + 1];  

`    `int inPosB;  



`    `Textradata \*extradata;  

`    `bool sendextradata;  

`    `unsigned int mb\_width, mb\_height, mb\_count;  

`    `static void line(unsigned char \*dst, unsigned int \_x0, unsigned int \_y0, unsigned int \_x1, unsigned int \_y1, stride\_t strideY);  

`    `static void draw\_arrow(uint8\_t \*buf, int sx, int sy, int ex, int ey, stride\_t stride, int mulx, int muly, int dstdx, int dstdy);  

`    `unsigned char \*ffbuf;  

`    `unsigned int ffbuflen;  

`    `bool wasKey;  

`    `virtual void handle\_user\_data(const uint8\_t \*buf, int buf\_len);  

`    `TccDecoder \*ccDecoder;  

`    `bool autoSkipingLoopFilter;  

`    `enum AVDiscard initialSkipLoopFilter;  

`    `int got\_picture;  

`    `bool firstSeek; // firstSeek means start of palyback.  

`    `bool mpeg2\_in\_doubt;  

`    `bool mpeg2\_new\_sequence;  

`    `bool bReorderBFrame;  

`    `//时长（AVCodecContext中）  

`    `REFERENCE\_TIME getDuration();  

`    `int isReallyMPEG2(const unsigned char \*src, size\_t srcLen);  

protected:  

`    `virtual LRESULT beginCompress(int cfgcomode, uint64\_t csp, const Trect &r);  

`    `virtual bool beginDecompress(TffPictBase &pict, FOURCC infcc, const CMediaType &mt, int sourceFlags);  

`    `virtual HRESULT flushDec(void);  

`    `AVCodecParserContext \*parser;  

public:  

`    `TvideoCodecLibavcodec(IffdshowBase \*Ideci, IdecVideoSink \*IsinkD);  

`    `TvideoCodecLibavcodec(IffdshowBase \*Ideci, IencVideoSink \*IsinkE);  

`    `virtual ~TvideoCodecLibavcodec();  

`    `virtual int getType(void) const {  

`        `return IDFF\_MOVIE\_LAVC;  

`    `}  

`    `virtual const char\_t\* getName(void) const;  

`    `virtual int caps(void) const {  

`        `return CAPS::VIS\_MV | CAPS::VIS\_QUANTS;  

`    `}  



`    `virtual void end(void);  



`    `virtual void getCompressColorspaces(Tcsps &csps, unsigned int outDx, unsigned int outDy);  

`    `virtual bool supExtradata(void);  

`    `//获得ExtraData（AVCodecContext中）  

`    `virtual bool getExtradata(const void\* \*ptr, size\_t \*len);  

`    `virtual HRESULT compress(const TffPict &pict, TencFrameParams ¶ms);  

`    `virtual HRESULT flushEnc(const TffPict &pict, TencFrameParams ¶ms) {  

`        `return compress(pict, params);  

`    `}  



`    `virtual HRESULT decompress(const unsigned char \*src, size\_t srcLen, IMediaSample \*pIn);  

`    `virtual void onGetBuffer(AVFrame \*pic);  

`    `virtual bool onSeek(REFERENCE\_TIME segmentStart);  

`    `virtual bool onDiscontinuity(void);  

`    `//画出运动矢量（AVCodecContext中）  

`    `virtual bool drawMV(unsigned char \*dst, unsigned int dx, stride\_t stride, unsigned int dy) const;  

`    `//编码器信息（AVCodecContext中）  

`    `virtual void getEncoderInfo(char\_t \*buf, size\_t buflen) const;  

`    `virtual const char\* get\_current\_idct(void);  

`    `virtual HRESULT BeginFlush();  

`    `bool isReorderBFrame() {  

`        `return bReorderBFrame;  

`    `};  

`    `virtual void reorderBFrames(REFERENCE\_TIME& rtStart, REFERENCE\_TIME& rtStop);  



`    `class Th264RandomAccess  

`    `{  

`        `friend class TvideoCodecLibavcodec;  

`    `private:  

`        `TvideoCodecLibavcodec\* parent;  

`        `int recovery\_mode;  // 0:OK, 1:searching 2: found, 3:waiting for frame\_num decoded, 4:waiting for POC outputed  

`        `int recovery\_frame\_cnt;  

`        `int recovery\_poc;  

`        `int thread\_delay;  



`    `public:  

`        `Th264RandomAccess(TvideoCodecLibavcodec\* Iparent);  

`        `int search(uint8\_t\* buf, int buf\_size);  

`        `void onSeek(void);  

`        `void judgeUsability(int \*got\_picture\_ptr);  

`    `} h264RandomAccess;  

};  



#endif  

这里有一个类TlibavcodecExt，我觉得应该是扩展了Tlibavcodec的一些功能，在这里我们先不管它，直接看看TvideoCodecLibavcodec都包含了什么变量：

Tlibavcodec \*libavcodec：该类封装了libavcodec的各种函数，在前一篇文章中已经做过介绍，在此不再重复叙述了。可以认为该变量是TvideoCodecLibavcodec类的灵魂，所有libavcodec中的函数都是通过该类调用的。

AVCodec \*avcodec：FFMPEG中的结构体，解码器

AVCodecContext \*avctx：FFMPEG中的结构体，解码器上下文

AVFrame \*frame FFMPEG中的结构体，视频帧

mutable char\_t codecName[100]：解码器名称

FOURCC fcc：FourCC

Textradata \*extradata：附加数据

…

再来看一下TvideoCodecLibavcodec都包含什么方法：

create()：创建解码器的时候调用

getDuration()：获得时长

getExtradata()：获得附加数据

drawMV()：画运动矢量

getEncoderInfo()：获得编码器信息

此外还包括一些有关解码的方法【这个是最关键的】：

beginDecompress()：解码初始化

decompress()：解码

下面我们来详细看看这些函数的实现吧：

先来看一下TvideoCodecLibavcodec的构造函数：

//libavcodec解码器（视频）  

//内容大部分都很熟悉，因为是FFmpeg的API  

TvideoCodecLibavcodec::TvideoCodecLibavcodec(IffdshowBase \*Ideci, IdecVideoSink \*IsinkD):  

`    `Tcodec(Ideci), TcodecDec(Ideci, IsinkD),  

`    `TvideoCodec(Ideci),  

`    `TvideoCodecDec(Ideci, IsinkD),  

`    `TvideoCodecEnc(Ideci, NULL),  

`    `h264RandomAccess(this),  

`    `bReorderBFrame(true)  

{  

`    `create();  

}  

可见构造函数调用了Create()，我们再来看看Create()：

void TvideoCodecLibavcodec::create(void)  

{  

`    `ownmatrices = false;  

`    `deci->getLibavcodec(&libavcodec);  

`    `ok = libavcodec ? libavcodec->ok : false;  

`    `avctx = NULL;  

`    `avcodec = NULL;  

`    `frame = NULL;  

`    `quantBytes = 1;  

`    `statsfile = NULL;  

`    `threadcount = 0;  

`    `codecinited = false;  

`    `extradata = NULL;  

`    `theorart = false;  

`    `ffbuf = NULL;  

`    `ffbuflen = 0;  

`    `codecName[0] = '\0';  

`    `ccDecoder = NULL;  

`    `autoSkipingLoopFilter = false;  

`    `inPosB = 1;  

`    `firstSeek = true;  

`    `mpeg2\_new\_sequence = true;  

`    `parser = NULL;  

}  

从Create()函数我们可以看出，其完成了各种变量的初始化工作。其中有一行代码：

deci->getLibavcodec(&libavcodec);  

完成了Tlibavcodec\*libavcodec的初始化工作。

再来看几个函数。

getDuration()，用于从AVCodecContext中获取时长：

REFERENCE\_TIME TvideoCodecLibavcodec::getDuration()  

{  

`    `REFERENCE\_TIME duration = REF\_SECOND\_MULT / 100;  

`    `if (avctx && avctx->time\_base.num && avctx->time\_base.den) {  

`        `duration = REF\_SECOND\_MULT \* avctx->time\_base.num / avctx->time\_base.den;  

`        `if (codecId == AV\_CODEC\_ID\_H264) {  

`            `duration \*= 2;  

`        `}  

`    `}  

`    `if (duration == 0) {  

`        `return REF\_SECOND\_MULT / 100;  

`    `}  

`    `return duration;  

}  

getExtradata()用于从AVCodecContext中获取附加信息：

bool TvideoCodecLibavcodec::getExtradata(const void\* \*ptr, size\_t \*len)  

{  

`    `if (!avctx || !len) {  

`        `return false;  

`    `}  

`    `\*len = avctx->extradata\_size;  

`    `if (ptr) {  

`        `\*ptr = avctx->extradata;  

`    `}  

`    `return true;  

}  

drawMV()用于从AVFrame中获取运动矢量信息，并画出来（这个函数用于一个名为“可视化”的滤镜里面，用于显示视频的运动矢量信息）。

//画出运动矢量  

bool TvideoCodecLibavcodec::drawMV(unsigned char \*dst, unsigned int dstdx, stride\_t stride, unsigned int dstdy) const  

{  

`    `if (!frame->motion\_val || !frame->mb\_type || !frame->motion\_val[0]) {  

`        `return false;  

`    `}  



#define IS\_8X8(a)  ((a)&MB\_TYPE\_8x8)  

#define IS\_16X8(a) ((a)&MB\_TYPE\_16x8)  

#define IS\_8X16(a) ((a)&MB\_TYPE\_8x16)  

#define IS\_INTERLACED(a) ((a)&MB\_TYPE\_INTERLACED)  

#define USES\_LIST(a, list) ((a) & ((MB\_TYPE\_P0L0|MB\_TYPE\_P1L0)<<(2\*(list))))  



`    `const int shift = 1 + ((frame->play\_flags & CODEC\_FLAG\_QPEL) ? 1 : 0);  

`    `const int mv\_sample\_log2 = 4 - frame->motion\_subsample\_log2;  

`    `const int mv\_stride = (frame->mb\_width << mv\_sample\_log2) + (avctx->codec\_id == AV\_CODEC\_ID\_H264 ? 0 : 1);  

`    `int direction = 0;  



`    `int mulx = (dstdx << 12) / avctx->width;  

`    `int muly = (dstdy << 12) / avctx->height;  

`    `//提取两个方向上的运动矢量信息（根据不同的宏块划分，可以分成几种情况）  

`    `//在AVCodecContext的motion\_val中  

`    `for (int mb\_y = 0; mb\_y < frame->mb\_height; mb\_y++)  

`        `for (int mb\_x = 0; mb\_x < frame->mb\_width; mb\_x++) {  

`            `const int mb\_index = mb\_x + mb\_y \* frame->mb\_stride;  

`            `if (!USES\_LIST(frame->mb\_type[mb\_index], direction)) {  

`                `continue;  

`            `}  

`            `…此处代码太长，略  

`        `}  

#undef IS\_8X8  

#undef IS\_16X8  

#undef IS\_8X16  

#undef IS\_INTERLACED  

#undef USES\_LIST  

`    `return true;  

}  

下面来看几个很重要的函数，这几个函数继承自TvideoCodecDec类。

beginDecompress()用于解码器的初始化。注：这个函数的代码太长了，因此只选择一点关键的代码。

//----------------------------- decompression -----------------------------  

bool TvideoCodecLibavcodec::beginDecompress(TffPictBase &pict, FOURCC fcc, const CMediaType &mt, int sourceFlags)  

{  

`    `palette\_size = 0;  

`    `prior\_out\_rtStart = REFTIME\_INVALID;  

`    `prior\_out\_rtStop = 0;  

`    `rtStart = rtStop = REFTIME\_INVALID;  

`    `prior\_in\_rtStart = prior\_in\_rtStop = REFTIME\_INVALID;  

`    `mpeg2\_in\_doubt = codecId == AV\_CODEC\_ID\_MPEG2VIDEO;  



`    `int using\_dxva = 0;  



`    `int numthreads = deci->getParam2(IDFF\_numLAVCdecThreads);  

`    `int thread\_type = 0;  

`    `if (numthreads > 1 && sup\_threads\_dec\_frame(codecId)) {  

`        `thread\_type = FF\_THREAD\_FRAME;  

`    `} else if (numthreads > 1 && sup\_threads\_dec\_slice(codecId)) {  

`        `thread\_type = FF\_THREAD\_SLICE;  

`    `}  



`    `if (numthreads > 1 && thread\_type != 0) {  

`        `threadcount = numthreads;  

`    `} else {  

`        `threadcount = 1;  

`    `}  



`    `if (codecId == CODEC\_ID\_H264\_DXVA) {  

`        `codecId = AV\_CODEC\_ID\_H264;  

`        `using\_dxva = 1;  

`    `} else if (codecId == CODEC\_ID\_VC1\_DXVA) {  

`        `codecId = AV\_CODEC\_ID\_VC1;  

`        `using\_dxva = 1;  

`    `}  



`    `avcodec = libavcodec->avcodec\_find\_decoder(codecId);  

`    `if (!avcodec) {  

`        `return false;  

`    `}  

`    `avctx = libavcodec->avcodec\_alloc\_context(avcodec, this);  

`    `avctx->thread\_type = thread\_type;  

`    `avctx->thread\_count = threadcount;  

`    `avctx->h264\_using\_dxva = using\_dxva;  

`    `if (codecId == AV\_CODEC\_ID\_H264) {  

`        `// If we do not set this, first B-frames before the IDR pictures are dropped.  

`        `avctx->has\_b\_frames = 1;  

`    `}  



`    `frame = libavcodec->avcodec\_alloc\_frame();  

`    `avctx->width = pict.rectFull.dx;  

`    `avctx->height = pict.rectFull.dy;  

`    `intra\_matrix = avctx->intra\_matrix = (uint16\_t\*)calloc(sizeof(uint16\_t), 64);  

`    `inter\_matrix = avctx->inter\_matrix = (uint16\_t\*)calloc(sizeof(uint16\_t), 64);  

`    `ownmatrices = true;  





`    `// Fix for new Haali custom media type and fourcc. ffmpeg does not understand it, we have to change it to FOURCC\_AVC1  

`    `if (fcc == FOURCC\_CCV1) {  

`        `fcc = FOURCC\_AVC1;  

`    `}  



`    `avctx->codec\_tag = fcc;  

`    `avctx->workaround\_bugs = deci->getParam2(IDFF\_workaroundBugs);  

#if 0  

`    `avctx->error\_concealment = FF\_EC\_GUESS\_MVS | FF\_EC\_DEBLOCK;  

`    `avctx->err\_recognition   = AV\_EF\_CRCCHECK | AV\_EF\_BITSTREAM | AV\_EF\_BUFFER | AV\_EF\_COMPLIANT | AV\_EF\_AGGRESSIVE;  

#endif  

`    `if (codecId == AV\_CODEC\_ID\_MJPEG) {  

`        `avctx->flags |= CODEC\_FLAG\_TRUNCATED;  

`    `}  

`    `if (mpeg12\_codec(codecId) && deci->getParam2(IDFF\_fastMpeg2)) {  

`        `avctx->flags2 = CODEC\_FLAG2\_FAST;  

`    `}  

`    `if (codecId == AV\_CODEC\_ID\_H264)  

`        `if (int skip = deci->getParam2(IDFF\_fastH264)) {  

`            `avctx->skip\_loop\_filter = skip & 2 ? AVDISCARD\_ALL : AVDISCARD\_NONREF;  

`        `}  

`    `initialSkipLoopFilter = avctx->skip\_loop\_filter;  



`    `avctx->debug\_mv = !using\_dxva; //(deci->getParam2(IDFF\_isVis) & deci->getParam2(IDFF\_visMV));  



`    `avctx->idct\_algo = limit(deci->getParam2(IDFF\_idct), 0, 6);  

`    `if (extradata) {  

`        `delete extradata;  

`    `}  

extradata = new Textradata(mt, FF\_INPUT\_BUFFER\_PADDING\_SIZE);  

此处代码太长，略…  

}  

从代码中可以看出这个函数的流程是：

1.avcodec\_find\_decoder();

2.avcodec\_alloc\_context();

3.avcodec\_alloc\_frame();

4.avcodec\_open();

主要做了libavcodec初始化工作。

begin decompress()用于解码器的初始化。 注：这个函数的代码太长了，因此只选择一点关键的代码。

HRESULT TvideoCodecLibavcodec::decompress(const unsigned char \*src, size\_t srcLen0, IMediaSample \*pIn)  

{  

`    `代码太长，略…  

`    `AVPacket avpkt;  

`    `libavcodec->av\_init\_packet(&avpkt);  

`    `if (palette\_size) {  

`        `uint32\_t \*pal = (uint32\_t \*)libavcodec->av\_packet\_new\_side\_data(&avpkt, AV\_PKT\_DATA\_PALETTE, AVPALETTE\_SIZE);  

`        `for (int i = 0; i < palette\_size / 4; i++) {  

`            `pal[i] = 0xFF << 24 | AV\_RL32(palette + i);  

`        `}  

`    `}  



`    `while (!src || size > 0) {  

`        `int used\_bytes;  



`        `avctx->reordered\_opaque = rtStart;  

`        `avctx->reordered\_opaque2 = rtStop;  

`        `avctx->reordered\_opaque3 = size;  



`        `if (sendextradata && extradata->data && extradata->size > 0) {  

`            `avpkt.data = (uint8\_t \*)extradata->data;  

`            `avpkt.size = (int)extradata->size;  

`            `used\_bytes = libavcodec->avcodec\_decode\_video2(avctx, frame, &got\_picture, &avpkt);  

`            `sendextradata = false;  

`            `if (used\_bytes > 0) {  

`                `used\_bytes = 0;  

`            `}  

`            `if (mpeg12\_codec(codecId)) {  

`                `avctx->extradata = NULL;  

`                `avctx->extradata\_size = 0;  

`            `}  

`        `} else {  

`            `unsigned int neededsize = size + FF\_INPUT\_BUFFER\_PADDING\_SIZE;  



`            `if (ffbuflen < neededsize) {  

`                `ffbuf = (unsigned char\*)realloc(ffbuf, ffbuflen = neededsize);  

`            `}  



`            `if (src) {  

`                `memcpy(ffbuf, src, size);  

`                `memset(ffbuf + size, 0, FF\_INPUT\_BUFFER\_PADDING\_SIZE);  

`            `}  

`            `if (parser) {  

`                `uint8\_t \*outBuf = NULL;  

`                `int out\_size = 0;  

`                `used\_bytes = libavcodec->av\_parser\_parse2(parser, avctx, &outBuf, &out\_size, src ? ffbuf : NULL, size, AV\_NOPTS\_VALUE, AV\_NOPTS\_VALUE, 0);  

`                `if (prior\_in\_rtStart == REFTIME\_INVALID) {  

`                    `prior\_in\_rtStart = rtStart;  

`                    `prior\_in\_rtStop = rtStop;  

`                `}  

`                `if (out\_size > 0 || !src) {  

`                    `mpeg2\_in\_doubt = false;  

`                    `avpkt.data = out\_size > 0 ? outBuf : NULL;  

`                    `avpkt.size = out\_size;  

`                    `if (out\_size > used\_bytes) {  

`                        `avctx->reordered\_opaque = prior\_in\_rtStart;  

`                        `avctx->reordered\_opaque2 = prior\_in\_rtStop;  

`                    `} else {  

`                        `avctx->reordered\_opaque = rtStart;  

`                        `avctx->reordered\_opaque2 = rtStop;  

`                    `}  

`                    `prior\_in\_rtStart = rtStart;  

`                    `prior\_in\_rtStop = rtStop;  

`                    `avctx->reordered\_opaque3 = out\_size;  

`                    `if (h264RandomAccess.search(avpkt.data, avpkt.size)) {  

`                        `libavcodec->avcodec\_decode\_video2(avctx, frame, &got\_picture, &avpkt);  

`                        `h264RandomAccess.judgeUsability(&got\_picture);  

`                    `} else {  

`                        `got\_picture = 0;  

`                    `}  

`                `} else {  

`                    `got\_picture = 0;  

`                `}  

`            `} else {  

`                `avpkt.data = src ? ffbuf : NULL;  

`                `avpkt.size = size;  

`                `if (codecId == AV\_CODEC\_ID\_H264) {  

`                    `if (h264RandomAccess.search(avpkt.data, avpkt.size)) {  

`                        `used\_bytes = libavcodec->avcodec\_decode\_video2(avctx, frame, &got\_picture, &avpkt);  

`                        `if (used\_bytes < 0) {  

`                            `return S\_OK;  

`                        `}  

`                        `h264RandomAccess.judgeUsability(&got\_picture);  

`                    `} else {  

`                        `got\_picture = 0;  

`                        `return S\_OK;  

`                    `}  

`                `} else {  

`                    `used\_bytes = libavcodec->avcodec\_decode\_video2(avctx, frame, &got\_picture, &avpkt);  

`                `}  

`            `}  

`        `}  

`    `代码太长，略…  

}  

从代码中可以看出这个函数的流程是：

1.AVPacket avpkt;

2.av\_init\_packet();

3.avcodec\_decode\_video2();

和ffmpeg的解码流程相差不大。
### [**ffdshow 源代码分析 8： 视频解码器类（TvideoCodecDec）**](http://blog.csdn.net/leixiaohua1020/article/details/15493743)
其中libavcodec的解码器类TvideoCodecLibavcodec通过调用Tlibavcodec中的方法实现了libavcodec的dll中方法的调用；而它继承了TvideoCodecDec，本文正是要分析它继承的这个类。



TvideoCodecDec是所有视频解码器共有的父类。可以看一下它的继承关系：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.151.jpeg)

可见，除了TvideoCodecLibavcodec继承了TvideoCodecDec之外，还有好几个类继承了TvideoCodecDec，比如说：TvideoCodecLibmpeg2，TvideoCodecXviD4等等…。突然来了兴趣，我们可以看一下其他的解码器类的定义是什么样的。

TvideoCodecLibmpeg2定义如下：

#ifndef \_TVIDEOCODECLIBMPEG2\_H\_  

#define \_TVIDEOCODECLIBMPEG2\_H\_  



#include "TvideoCodec.h"  

#include "libmpeg2/include/mpeg2.h"  



class Tdll;  

struct Textradata;  

class TccDecoder;  

//libmpeg2解码器  

class TvideoCodecLibmpeg2 : public TvideoCodecDec  

{  

private:  

`    `Tdll \*dll;  

`    `uint32\_t (\*mpeg2\_set\_accel)(uint32\_t accel);  

`    `mpeg2dec\_t\* (\*mpeg2\_init)(void);  

`    `const mpeg2\_info\_t\* (\*mpeg2\_info)(mpeg2dec\_t \*mpeg2dec);  

`    `mpeg2\_state\_t (\*mpeg2\_parse)(mpeg2dec\_t \*mpeg2dec);  

`    `void (\*mpeg2\_buffer)(mpeg2dec\_t \*mpeg2dec, const uint8\_t \*start, const uint8\_t \*end);  

`    `void (\*mpeg2\_close)(mpeg2dec\_t \*mpeg2dec);  

`    `void (\*mpeg2\_reset)(mpeg2dec\_t \*mpeg2dec, int full\_reset);  

`    `void (\*mpeg2\_set\_rtStart)(mpeg2dec\_t \*mpeg2dec, int64\_t rtStart);  

`    `int (\*mpeg2\_guess\_aspect)(const mpeg2\_sequence\_t \* sequence, unsigned int \* pixel\_width, unsigned int \* pixel\_height);  



`    `mpeg2dec\_t \*mpeg2dec;  

`    `const mpeg2\_info\_t \*info;  

`    `bool wait4Iframe;  

`    `int sequenceFlag;  

`    `REFERENCE\_TIME avgTimePerFrame;  

`    `TffPict oldpict;  

`    `Textradata \*extradata;  

`    `TccDecoder \*ccDecoder;  

`    `Tbuffer \*buffer;  

`    `uint32\_t oldflags;  

`    `bool m\_fFilm;  

`    `int SetDeinterlaceMethod(void);  



`    `void init(void);  

`    `HRESULT decompressI(const unsigned char \*src, size\_t srcLen, IMediaSample \*pIn);  



protected:  

`    `virtual bool beginDecompress(TffPictBase &pict, FOURCC infcc, const CMediaType &mt, int sourceFlags);  



public:  

`    `TvideoCodecLibmpeg2(IffdshowBase \*Ideci, IdecVideoSink \*Isink);  

`    `virtual ~TvideoCodecLibmpeg2();  



`    `static const char\_t \*dllname;  

`    `virtual int getType(void) const {  

`        `return IDFF\_MOVIE\_LIBMPEG2;  

`    `}  

`    `virtual int caps(void) const {  

`        `return CAPS::VIS\_QUANTS;  

`    `}  



`    `virtual void end(void);  

`    `virtual HRESULT decompress(const unsigned char \*src, size\_t srcLen, IMediaSample \*pIn);  

`    `virtual bool onSeek(REFERENCE\_TIME segmentStart);  

`    `virtual HRESULT BeginFlush();  

};  



#endif  

TvideoCodecXviD4定义如下：

#ifndef \_TVIDEOCODECXVID4\_H\_  

#define \_TVIDEOCODECXVID4\_H\_  



#include "TvideoCodec.h"  



class Tdll;  

struct Textradata;  

//xvid解码器  

class TvideoCodecXviD4 : public TvideoCodecDec  

{  

private:  

`    `void create(void);  

`    `Tdll \*dll;  

public:  

`    `TvideoCodecXviD4(IffdshowBase \*Ideci, IdecVideoSink \*IsinkD);  

`    `virtual ~TvideoCodecXviD4();  

`    `int (\*xvid\_global)(void \*handle, int opt, void \*param1, void \*param2);  

`    `int (\*xvid\_decore)(void \*handle, int opt, void \*param1, void \*param2);  

`    `int (\*xvid\_plugin\_single)(void \*handle, int opt, void \*param1, void \*param2);  

`    `int (\*xvid\_plugin\_lumimasking)(void \*handle, int opt, void \*param1, void \*param2);  

`    `static const char\_t \*dllname;  

private:  

`    `void \*enchandle, \*dechandle;  

`    `int psnr;  

`    `TffPict pict;  

`    `Tbuffer pictbuf;  

`    `static int me\_hq(int rd3), me\_(int me3);  

`    `Textradata \*extradata;  

`    `REFERENCE\_TIME rtStart, rtStop;  

protected:  

`    `virtual bool beginDecompress(TffPictBase &pict, FOURCC infcc, const CMediaType &mt, int sourceFlags);  

`    `virtual HRESULT flushDec(void);  

public:  

`    `virtual int getType(void) const {  

`        `return IDFF\_MOVIE\_XVID4;  

`    `}  

`    `virtual int caps(void) const {  

`        `return CAPS::VIS\_QUANTS;  

`    `}  



`    `virtual HRESULT decompress(const unsigned char \*src, size\_t srcLen, IMediaSample \*pIn);  

};  



#endif  

从以上这2种解码器类的定义，我们可以看出一些规律，比如说：

\1.  都有Tdll \*dll这个变量，用于加载视频解码器的dll

\2.  都有beginDecompress()函数，用于初始化解码器

\3.  都有decompress()函数，用于解码



好了，闲话不说，回归正题，来看一下这些解码器共有的父类：TvideoCodecDec

//具体 视频 解码器的父类，存一些公共信息  

class TvideoCodecDec : virtual public TvideoCodec, virtual public TcodecDec  

{  

protected:  

`    `bool isdvdproc;  

`    `comptrQ<IffdshowDecVideo> deciV;  

`    `IdecVideoSink \*sinkD;  

`    `TvideoCodecDec(IffdshowBase \*Ideci, IdecVideoSink \*Isink);  

`    `Rational guessMPEG2sar(const Trect &r, const Rational &sar2, const Rational &containerSar);  



`    `class TtelecineManager  

`    `{  

`    `private:  

`        `TvideoCodecDec\* parent;  

`        `int segment\_count;  

`        `int pos\_in\_group;  

`        `struct {  

`            `int fieldtype;  

`            `int repeat\_pict;  

`            `REFERENCE\_TIME rtStart;  

`        `} group[2]; // store information about 2 recent frames.  

`        `REFERENCE\_TIME group\_rtStart;  

`        `bool film;  

`        `int cfg\_softTelecine;  

`    `public:  

`        `TtelecineManager(TvideoCodecDec\* Iparent);  

`        `void get\_timestamps(TffPict &pict);  

`        `void get\_fieldtype(TffPict &pict);  

`        `void new\_frame(int top\_field\_first, int repeat\_pict, const REFERENCE\_TIME &rtStart, const REFERENCE\_TIME &rtStop);  

`        `void onSeek(void);  

`    `} telecineManager;  



public:  

`    `static TvideoCodecDec\* initDec(IffdshowBase \*deci, IdecVideoSink \*Isink, AVCodecID codecId, FOURCC fcc, const CMediaType &mt);  



`    `virtual ~TvideoCodecDec();  



`    `virtual int caps(void) const {  

`        `return CAPS::NONE;  

`    `}  

`    `virtual bool testMediaType(FOURCC fcc, const CMediaType &mt) {  

`        `return true;  

`    `}  

`    `virtual void forceOutputColorspace(const BITMAPINFOHEADER \*hdr, int \*ilace, TcspInfos &forcedCsps) {  

`        `\*ilace = 0; //cspInfos of forced output colorspace, empty when entering function  

`    `}  

`    `enum {SOURCE\_REORDER = 1};  

`    `virtual bool beginDecompress(TffPictBase &pict, FOURCC infcc, const CMediaType &mt, int sourceFlags) = 0;  

`    `virtual HRESULT decompress(const unsigned char \*src, size\_t srcLen, IMediaSample \*pIn) = 0;  

`    `virtual bool onDiscontinuity(void) {  

`        `return false;  

`    `}  

`    `virtual HRESULT onEndOfStream(void) {  

`        `return S\_OK;  

`    `}  



`    `unsigned int quantsDx, quantsStride, quantsDy, quantBytes, quantType;  

`    `//QP表  

`    `void \*quants;  

`    `uint16\_t \*intra\_matrix, \*inter\_matrix;  

`    `//计算平均QP  

`    `float calcMeanQuant(void);  

`    `//画运动矢量  

`    `virtual bool drawMV(unsigned char \*dst, unsigned int dx, stride\_t stride, unsigned int dy) const {  

`        `return false;  

`    `}  

`    `virtual const char\* get\_current\_idct(void) {  

`        `return NULL;  

`    `}  

`    `virtual int useDXVA(void) {  

`        `return 0;  

`    `};  



`    `virtual void setOutputPin(IPin \* /\*pPin\*/) {}  

};  

TvideoCodecDec这个类中，还定义了一个类TtelecineManager。这种在类里面再定义一个类的方式还是不太多见的。TtelecineManager这个类的作用还没有研究，先不管它。

可以看出，TvideoCodecDec类的定义并不复杂，最主要的变量有如下几个，这几个变量都是子类中会用到的：

comptrQ<IffdshowDecVideo>deciV：重要性不言而喻，回头介绍

IdecVideoSink \*sinkD：重要性不言而喻，回头介绍

void \*quants：QP表（为什么要存在这里还没搞清）

TvideoCodecDec类定义了几个函数：

initDec()：初始化解码器（重要）

calcMeanQuant()：计算平均QP（为什么要在这里计算还没搞清）

TvideoCodecDec类还定义了一些纯虚函数，作为接口，这些函数的实现都在TvideoCodecDec的子类中完成【这几个函数是最重要的】：

beginDecompress();

decompress();

TvideoCodecDec类中最重要的函数只有一个，就是initDec()，作用主要是初始化解码器。其他的很多函数大多只是定义了一个名称，并没有实现，因为都是打算在具体各种解码器类中再进行实现的。

看一下initDec()的代码：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/15493743#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/15493743#)![](https://code.csdn.net/assets/CODE\_ico.png)![](https://code.csdn.net/assets/ico\_fork.svg)

TvideoCodecDec\* TvideoCodecDec::initDec(IffdshowBase \*deci, IdecVideoSink \*sink, AVCodecID codecId, FOURCC fcc, const CMediaType &mt)  

{  

`    `// DXVA mode is a preset setting  

`    `switch (codecId) {  

`        `case AV\_CODEC\_ID\_H264:  

`            `if (deci->getParam2(IDFF\_filterMode) & IDFF\_FILTERMODE\_VIDEODXVA) {  

`                `if (deci->getParam2(IDFF\_dec\_DXVA\_H264)) {  

`                    `codecId = CODEC\_ID\_H264\_DXVA;  

`                `} else {  

`                    `return NULL;  

`                `}  

`            `}  

`            `break;  

`        `case AV\_CODEC\_ID\_VC1:  

`        `case CODEC\_ID\_WMV9\_LIB:  

`            `if (deci->getParam2(IDFF\_filterMode) & IDFF\_FILTERMODE\_VIDEODXVA) {  

`                `if (deci->getParam2(IDFF\_dec\_DXVA\_VC1)) {  

`                    `codecId = CODEC\_ID\_VC1\_DXVA;  

`                `} else {  

`                    `return NULL;  

`                `}  

`            `}  

`            `break;  

`        `default:  

`            `break;  

`    `}  



`    `TvideoCodecDec \*movie = NULL;  



`    `if (is\_quicksync\_codec(codecId)) {  

`        `movie = new TvideoCodecQuickSync(deci, sink, codecId);  

`    `} else if (lavc\_codec(codecId)) {  

`        `movie = new TvideoCodecLibavcodec(deci, sink);  

`    `} else if (raw\_codec(codecId)) {  

`        `movie = new TvideoCodecUncompressed(deci, sink);  

`    `} else if (wmv9\_codec(codecId)) {  

`        `movie = new TvideoCodecWmv9(deci, sink);  

`    `} else if (codecId == CODEC\_ID\_XVID4) {  

`        `movie = new TvideoCodecXviD4(deci, sink);  

`    `} else if (codecId == CODEC\_ID\_LIBMPEG2) {  

`        `movie = new TvideoCodecLibmpeg2(deci, sink);  

`    `} else if (codecId == CODEC\_ID\_AVISYNTH) {  

`        `movie = new TvideoCodecAvisynth(deci, sink);  

`    `} else if (codecId == CODEC\_ID\_H264\_DXVA || codecId == CODEC\_ID\_VC1\_DXVA) {  

`        `movie = new TvideoCodecLibavcodecDxva(deci, sink, codecId);  

`    `} else {  

`        `return NULL;  

`    `}  

`    `if (!movie) {  

`        `return NULL;  

`    `}  

`    `if (movie->ok && movie->testMediaType(fcc, mt)) {  

`        `movie->codecId = codecId;  

`        `return movie;  

`    `} else if (is\_quicksync\_codec(codecId)) {  

`        `// QuickSync decoder init failed, revert to internal decoder.  

`        `switch (codecId) {  

`            `case CODEC\_ID\_H264\_QUICK\_SYNC:  

`                `codecId = AV\_CODEC\_ID\_H264;  

`                `break;  

`            `case CODEC\_ID\_MPEG2\_QUICK\_SYNC:  

`                `codecId = CODEC\_ID\_LIBMPEG2;  

`                `break;  

`            `case CODEC\_ID\_VC1\_QUICK\_SYNC:  

`                `codecId = CODEC\_ID\_WMV9\_LIB;  

`                `break;  

`            `default:  

`                `ASSERT(FALSE); // this shouldn't happen!  

`        `}  



`        `delete movie;  



`        `// Call this function again with the new codecId.  

`        `return initDec(deci, sink, codecId, fcc, mt);  

`    `} else {  

`        `delete movie;  

`        `return NULL;  

`    `}  

}  

这个函数的功能还是比较好理解的，根据CodecID的不同，创建不同的解码器（从TvideoCodecLibavcodec，TvideoCodecXviD4，TvideoCodecLibmpeg2这些里面选择）。

虽然不知道用途是什么，但是我们可以顺便看一下计算平均QP的函数，就是把quants1指向的QP表里面的数据求了一个平均值：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/15493743#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/15493743#)![](https://code.csdn.net/assets/CODE\_ico.png)![](https://code.csdn.net/assets/ico\_fork.svg)

//计算平均QP  

float TvideoCodecDec::calcMeanQuant(void)  

{  

`    `if (!quants || !quantsDx || !quantsDy) {  

`        `return 0;  

`    `}  

`    `unsigned int sum = 0, num = quantsDx \* quantsDy;  

`    `unsigned char \*quants1 = (unsigned char\*)quants;  

`    `for (unsigned int y = 0; y < quantsDy; y++)  

`        `for (unsigned int x = 0; x < quantsDx; x++) {  

`            `sum += quants1[(y \* quantsStride + x) \* quantBytes];  

`        `}  

`    `return float(sum) / num;  

} 
### [**ffdshow 源代码分析 9： 编解码器有关类的总结**](http://blog.csdn.net/leixiaohua1020/article/details/15493961)
本文再做最后一点的分析。在ffdshow中有如下继承关系：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.152.jpeg)

前文已经分析过TvideoCodecLibavcodec，TvideoCodecDec，在这里我们看一下他们的父类：TvideoCodec，TcodecDec，以及前两个类的父类Tcodec。

其实本文介绍的这3个类充当了接口的作用，TvideoCodecDec继承TvideoCodec，TcodecDec，以及这两个类继承Tcodec，都使用了virtual的方式。



先来看看TvideoCodec。注意这个类强调的是【视频】：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/15493961#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/15493961#)![](https://code.csdn.net/assets/CODE\_ico.png)![](https://code.csdn.net/assets/ico\_fork.svg)

//编解码器的父类  

class TvideoCodec : virtual public Tcodec  

{  

public:  

`    `TvideoCodec(IffdshowBase \*Ideci);  

`    `virtual ~TvideoCodec();  

`    `bool ok;  

`    `int connectedSplitter;  

`    `bool isInterlacedRawVideo;  

`    `Rational containerSar;  



`    `struct CAPS {  

`        `enum {  

`            `NONE = 0,  

`            `VIS\_MV = 1,  

`            `VIS\_QUANTS = 2  

`        `};  

`    `};  



`    `virtual void end(void) {}  

};  

可以看出TvideoCodec定义非常的简单，只包含了视频编解码器会用到的一些变量。注意，是编解码器，不仅仅是解码器。

再来看看TcodecDec。注意这个类强调的是【解码】：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/15493961#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/15493961#)![](https://code.csdn.net/assets/CODE\_ico.png)![](https://code.csdn.net/assets/ico\_fork.svg)

//实现了解码器的祖父类  

class TcodecDec : virtual public Tcodec  

{  

private:  

`    `IdecSink \*sink;  

protected:  

`    `comptrQ<IffdshowDec> deciD;  

`    `TcodecDec(IffdshowBase \*Ideci, IdecSink \*Isink);  

`    `virtual ~TcodecDec();  

`    `virtual HRESULT flushDec(void) {  

`        `return S\_OK;  

`    `}  

public:  

`    `virtual HRESULT flush(void);  

};  

可以看出TcodecDec定义非常简单，只包含了解码器需要的一些变量，注意不限于视频解码器，还包含音频解码器。有两个变量比较重要：

IdecSink \*sink;

comptrQ<IffdshowDec> deciD;

最后来看一下Tcodec。这个类不再继承任何类：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/15493961#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/15493961#)![](https://code.csdn.net/assets/CODE\_ico.png)![](https://code.csdn.net/assets/ico\_fork.svg)

//编解码器的祖父类，都是虚函数  

class Tcodec  

{  

protected:  

`    `const Tconfig \*config;  

`    `comptr<IffdshowBase> deci;  

`    `Tcodec(IffdshowBase \*Ideci);  

`    `virtual ~Tcodec();  

public:  

`    `AVCodecID codecId;  

`    `virtual int getType(void) const = 0;  

`    `virtual const char\_t\* getName(void) const {  

`        `return getMovieSourceName(getType());  

`    `}  

`    `virtual void getEncoderInfo(char\_t \*buf, size\_t buflen) const {  

`        `ff\_strncpy(buf, \_l("unknown"), buflen);  

`        `buf[buflen - 1] = '\0';  

`    `}  

`    `static const char\_t\* getMovieSourceName(int source);  



`    `virtual HRESULT flush() {  

`        `return S\_OK;  

`    `}  

`    `virtual HRESULT BeginFlush() {  

`        `return S\_OK;  

`    `}  

`    `virtual HRESULT EndFlush() {  

`        `return S\_OK;  

`    `}  

`    `virtual bool onSeek(REFERENCE\_TIME segmentStart) {  

`        `return false;  

`    `}  

};  

可以看出，该类定义了一些编解码器会用到的公共函数。有几个变量还是比较重要的：

const Tconfig \*config;

comptr<IffdshowBase> deci;

Tcodec(IffdshowBase \*Ideci);

AVCodecID codecId

自此，我们可以总结出ffdshow编解码器这部分继承关系如下（图太大了，截成两张）：

从TcodecDec继承下来的如下图所示。包含视频解码器以及音频解码器。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.153.jpeg)

从TvideoCodec继承下来的如下图所示。包含了解码器类和编码器类。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.154.jpeg)

总算大体上完成了，关于ffdshow解码器封装的内容就先告一段落吧。
## **9.2 LAV filters**
LAV Filter是基于ffmpeg的解码器类库libavcodec，以及解封装器类库libavformat的DirectShow Filter。广泛安装在PC上。
### [**LAV Filter 源代码分析 1： 总体结构**](http://blog.csdn.net/leixiaohua1020/article/details/12711379)
LAV Filter 是一款视频分离和解码软件，他的分离器封装了FFMPEG中的libavformat，解码器则封装了FFMPEG中的libavcodec。它支持十分广泛的视音频格式。

源代码位于GitHub或Google Code：

<https://github.com/Nevcairiel/LAVFilters>

<http://code.google.com/p/lavfilters/>

本文分析了LAV Filter源代码的总体架构。

使用git获取LAV filter源代码之后，使用VC 2010 打开源代码，发现代码目录结构如图所示：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.155.jpeg)

整个解决方案由8个工程组成，介绍一下我目前所知的几个工程：

baseclasses：DirectShow基类，在DirectShow的SDK中也有，是微软为了简化DirectShow开发而提供的。

Demuxers：解封装的基类，LAVSplitter需要调用其中的方法完成解封装操作。

LAVAudio：音频解码Filter。封装了libavcodec。

LAVSplitter：解封装Filter。封装了libavformat。

LAVVideo：视频解码Filter。封装了libavcodec。

libbluray：蓝光的支持。

以上标为咖啡色字体的是要重点分析的，也是最重要的工程。
### [**LAV Filter 源代码分析 2： LAV Splitter**](http://blog.csdn.net/leixiaohua1020/article/details/12711723)
LAV Filter 中最著名的就是 LAV Splitter，支持Matroska /WebM，MPEG-TS/PS，MP4/MOV，FLV，OGM / OGG，AVI等其他格式，广泛存在于各种视频播放器（暴风影音这类的）之中。

本文分析一下它的源代码。在分析之前，先看看它是什么样的。

使用GraphEdit随便打开一个视频文件，就可以看见LAV Filter：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.156.jpeg)

可以右键点击这个Filter看一下它的属性页面，如图所示：

属性设置页面：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.157.jpeg)

支持输入格式：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.158.jpeg)

下面我们在 VC 2010 中看一下它的源代码：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.159.jpeg)

从何看起呢？就先从directshow的注册函数看起吧，位于dllmain.cpp之中。部分代码的含义已经用注释标注上了。从代码可以看出，和普通的DirectShow Filter没什么区别。

dllmain.cpp

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)

/\* 

` `\*      Copyright (C) 2010-2013 Hendrik Leppkes 

` `\*      http://www.1f0.de 

` `\* 

` `\*  This program is free software; you can redistribute it and/or modify 

` `\*  it under the terms of the GNU General Public License as published by 

` `\*  the Free Software Foundation; either version 2 of the License, or 

` `\*  (at your option) any later version. 

` `\* 

` `\*  This program is distributed in the hope that it will be useful, 

` `\*  but WITHOUT ANY WARRANTY; without even the implied warranty of 

` `\*  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the 

` `\*  GNU General Public License for more details. 

` `\* 

` `\*  You should have received a copy of the GNU General Public License along 

` `\*  with this program; if not, write to the Free Software Foundation, Inc., 

` `\*  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. 

` `\*/  



// Based on the SampleParser Template by GDCL  

// --------------------------------------------------------------------------------  

// Copyright (c) GDCL 2004. All Rights Reserved.   

// You are free to re-use this as the basis for your own filter development,  

// provided you retain this copyright notice in the source.  

// http://www.gdcl.co.uk  

// --------------------------------------------------------------------------------  

//各种定义。。。  

#include "stdafx.h"  



// Initialize the GUIDs  

#include <InitGuid.h>  



#include <qnetwork.h>  

#include "LAVSplitter.h"  

#include "moreuuids.h"  



#include "registry.h"  

#include "IGraphRebuildDelegate.h"  



// The GUID we use to register the splitter media types  

DEFINE\_GUID(MEDIATYPE\_LAVSplitter,  

`  `0x9c53931c, 0x7d5a, 0x4a75, 0xb2, 0x6f, 0x4e, 0x51, 0x65, 0x4d, 0xb2, 0xc0);  



// --- COM factory table and registration code --------------  

//注册时候的信息  

const AMOVIESETUP\_MEDIATYPE   

`  `sudMediaTypes[] = {  

`    `{ &MEDIATYPE\_Stream, &MEDIASUBTYPE\_NULL },  

};  

//注册时候的信息（PIN）  

const AMOVIESETUP\_PIN sudOutputPins[] =   

{  

`  `{  

`    `L"Output",            // pin name  

`      `FALSE,              // is rendered?      

`      `TRUE,               // is output?  

`      `FALSE,              // zero instances allowed?  

`      `TRUE,               // many instances allowed?  

`      `&CLSID\_NULL,        // connects to filter (for bridge pins)  

`      `NULL,               // connects to pin (for bridge pins)  

`      `0,                  // count of registered media types  

`      `NULL                // list of registered media types  

`  `},  

`  `{  

`    `L"Input",             // pin name  

`      `FALSE,              // is rendered?      

`      `FALSE,              // is output?  

`      `FALSE,              // zero instances allowed?  

`      `FALSE,              // many instances allowed?  

`      `&CLSID\_NULL,        // connects to filter (for bridge pins)  

`      `NULL,               // connects to pin (for bridge pins)  

`      `1,                  // count of registered media types  

`      `&sudMediaTypes[0]   // list of registered media types  

`  `}  

};  

//注册时候的信息（名称等）  

//CLAVSplitter  

const AMOVIESETUP\_FILTER sudFilterReg =  

{  

`  `&\_\_uuidof(CLAVSplitter),        // filter clsid  

`  `L"LAV Splitter",                // filter name  

`  `MERIT\_PREFERRED + 4,            // merit  

`  `2,                              // count of registered pins  

`  `sudOutputPins,                  // list of pins to register  

`  `CLSID\_LegacyAmFilterCategory  

};  

//注册时候的信息（名称等）  

//CLAVSplitterSource  

const AMOVIESETUP\_FILTER sudFilterRegSource =  

{  

`  `&\_\_uuidof(CLAVSplitterSource),  // filter clsid  

`  `L"LAV Splitter Source",         // filter name  

`  `MERIT\_PREFERRED + 4,            // merit  

`  `1,                              // count of registered pins  

`  `sudOutputPins,                  // list of pins to register  

`  `CLSID\_LegacyAmFilterCategory  

};  



// --- COM factory table and registration code --------------  



// DirectShow base class COM factory requires this table,   

// declaring all the COM objects in this DLL  

// 注意g\_Templates名称是固定的  

CFactoryTemplate g\_Templates[] = {  

`  `// one entry for each CoCreate-able object  

`  `{  

`    `sudFilterReg.strName,  

`      `sudFilterReg.clsID,  

`      `CreateInstance<CLAVSplitter>,  

`      `CLAVSplitter::StaticInit,  

`      `&sudFilterReg  

`  `},  

`  `{  

`    `sudFilterRegSource.strName,  

`      `sudFilterRegSource.clsID,  

`      `CreateInstance<CLAVSplitterSource>,  

`      `NULL,  

`      `&sudFilterRegSource  

`  `},  

`  `// This entry is for the property page.  

`  `// 属性页  

`  `{   

`      `L"LAV Splitter Properties",  

`      `&CLSID\_LAVSplitterSettingsProp,  

`      `CreateInstance<CLAVSplitterSettingsProp>,  

`      `NULL, NULL  

`  `},  

`  `{  

`      `L"LAV Splitter Input Formats",  

`      `&CLSID\_LAVSplitterFormatsProp,  

`      `CreateInstance<CLAVSplitterFormatsProp>,  

`      `NULL, NULL  

`  `}  

};  

int g\_cTemplates = sizeof(g\_Templates) / sizeof(g\_Templates[0]);  



// self-registration entrypoint  

STDAPI DllRegisterServer()  

{  

`  `std::list<LPCWSTR> chkbytes;  



`  `// BluRay  

`  `chkbytes.clear();  

`  `chkbytes.push\_back(L"0,4,,494E4458"); // INDX (index.bdmv)  

`  `chkbytes.push\_back(L"0,4,,4D4F424A"); // MOBJ (MovieObject.bdmv)  

`  `chkbytes.push\_back(L"0,4,,4D504C53"); // MPLS  

`  `RegisterSourceFilter(\_\_uuidof(CLAVSplitterSource),  

`    `MEDIASUBTYPE\_LAVBluRay, chkbytes, NULL);  



`  `// base classes will handle registration using the factory template table  

`  `return AMovieDllRegisterServer2(true);  

}  



STDAPI DllUnregisterServer()  

{  

`  `UnRegisterSourceFilter(MEDIASUBTYPE\_LAVBluRay);  



`  `// base classes will handle de-registration using the factory template table  

`  `return AMovieDllRegisterServer2(false);  

}  



// if we declare the correct C runtime entrypoint and then forward it to the DShow base  

// classes we will be sure that both the C/C++ runtimes and the base classes are initialized  

// correctly  

extern "C" BOOL WINAPI DllEntryPoint(HINSTANCE, ULONG, LPVOID);  

BOOL WINAPI DllMain(HANDLE hDllHandle, DWORD dwReason, LPVOID lpReserved)  

{  

`  `return DllEntryPoint(reinterpret\_cast<HINSTANCE>(hDllHandle), dwReason, lpReserved);  

}  



void CALLBACK OpenConfiguration(HWND hwnd, HINSTANCE hinst, LPSTR lpszCmdLine, int nCmdShow)  

{  

`  `HRESULT hr = S\_OK;  

`  `CUnknown \*pInstance = CreateInstance<CLAVSplitter>(NULL, &hr);  

`  `IBaseFilter \*pFilter = NULL;  

`  `pInstance->NonDelegatingQueryInterface(IID\_IBaseFilter, (void \*\*)&pFilter);  

`  `if (pFilter) {  

`    `pFilter->AddRef();  

`    `CBaseDSPropPage::ShowPropPageDialog(pFilter);  

`  `}  

`  `delete pInstance;  

}  

接下来就要进入正题了，看一看核心的分离器（解封装器）的类CLAVSplitter的定义文件LAVSplitter.h。乍一看这个类确实了得，居然继承了那么多的父类，实在是碉堡了。先不管那么多，看看里面都有什么函数吧。主要的函数上面都加了注释。注意还有一个类CLAVSplitterSource继承了CLAVSplitter。

LAVSplitter.h

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)

/\* 

` `\*      Copyright (C) 2010-2013 Hendrik Leppkes 

` `\*      http://www.1f0.de 

` `\* 

` `\*  This program is free software; you can redistribute it and/or modify 

` `\*  it under the terms of the GNU General Public License as published by 

` `\*  the Free Software Foundation; either version 2 of the License, or 

` `\*  (at your option) any later version. 

` `\* 

` `\*  This program is distributed in the hope that it will be useful, 

` `\*  but WITHOUT ANY WARRANTY; without even the implied warranty of 

` `\*  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the 

` `\*  GNU General Public License for more details. 

` `\* 

` `\*  You should have received a copy of the GNU General Public License along 

` `\*  with this program; if not, write to the Free Software Foundation, Inc., 

` `\*  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. 

` `\* 

` `\*  Initial design and concept by Gabest and the MPC-HC Team, copyright under GPLv2 

` `\*  Contributions by Ti-BEN from the XBMC DSPlayer Project, also under GPLv2 

` `\*/  



#pragma once  



#include <string>  

#include <list>  

#include <set>  

#include <vector>  

#include <map>  

#include "PacketQueue.h"  



#include "BaseDemuxer.h"  



#include "LAVSplitterSettingsInternal.h"  

#include "SettingsProp.h"  

#include "IBufferInfo.h"  



#include "ISpecifyPropertyPages2.h"  



#include "LAVSplitterTrayIcon.h"  



#define LAVF\_REGISTRY\_KEY L"Software\\LAV\\Splitter"  

#define LAVF\_REGISTRY\_KEY\_FORMATS LAVF\_REGISTRY\_KEY L"\\Formats"  

#define LAVF\_LOG\_FILE     L"LAVSplitter.txt"  



#define MAX\_PTS\_SHIFT 50000000i64  



class CLAVOutputPin;  

class CLAVInputPin;  



#ifdef  \_MSC\_VER  

#pragma warning(disable: 4355)  

#endif  

//核心解复用（分离器）  

//暴漏的接口在ILAVFSettings中  

[uuid("171252A0-8820-4AFE-9DF8-5C92B2D66B04")]  

class CLAVSplitter   

`  `: public CBaseFilter  

`  `, public CCritSec  

`  `, protected CAMThread  

`  `, public IFileSourceFilter  

`  `, public IMediaSeeking  

`  `, public IAMStreamSelect  

`  `, public IAMOpenProgress  

`  `, public ILAVFSettingsInternal  

`  `, public ISpecifyPropertyPages2  

`  `, public IObjectWithSite  

`  `, public IBufferInfo  

{  

public:  

`  `CLAVSplitter(LPUNKNOWN pUnk, HRESULT\* phr);  

`  `virtual ~CLAVSplitter();  



`  `static void CALLBACK StaticInit(BOOL bLoading, const CLSID \*clsid);  



`  `// IUnknown  

`  `//  

`  `DECLARE\_IUNKNOWN;  

`  `//暴露接口，使外部程序可以QueryInterface，关键！  

`  `//翻译（“没有代表的方式查询接口”）  

`  `STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void\*\* ppv);  



`  `// CBaseFilter methods  

`  `//输入是一个，输出就不一定了！  

`  `int GetPinCount();  

`  `CBasePin \*GetPin(int n);  

`  `STDMETHODIMP GetClassID(CLSID\* pClsID);  



`  `STDMETHODIMP Stop();  

`  `STDMETHODIMP Pause();  

`  `STDMETHODIMP Run(REFERENCE\_TIME tStart);  



`  `STDMETHODIMP JoinFilterGraph(IFilterGraph \* pGraph, LPCWSTR pName);  



`  `// IFileSourceFilter  

`  `// 源Filter的接口方法  

`  `STDMETHODIMP Load(LPCOLESTR pszFileName, const AM\_MEDIA\_TYPE \* pmt);  

`  `STDMETHODIMP GetCurFile(LPOLESTR \*ppszFileName, AM\_MEDIA\_TYPE \*pmt);  



`  `// IMediaSeeking  

`  `STDMETHODIMP GetCapabilities(DWORD\* pCapabilities);  

`  `STDMETHODIMP CheckCapabilities(DWORD\* pCapabilities);  

`  `STDMETHODIMP IsFormatSupported(const GUID\* pFormat);  

`  `STDMETHODIMP QueryPreferredFormat(GUID\* pFormat);  

`  `STDMETHODIMP GetTimeFormat(GUID\* pFormat);  

`  `STDMETHODIMP IsUsingTimeFormat(const GUID\* pFormat);  

`  `STDMETHODIMP SetTimeFormat(const GUID\* pFormat);  

`  `STDMETHODIMP GetDuration(LONGLONG\* pDuration);  

`  `STDMETHODIMP GetStopPosition(LONGLONG\* pStop);  

`  `STDMETHODIMP GetCurrentPosition(LONGLONG\* pCurrent);  

`  `STDMETHODIMP ConvertTimeFormat(LONGLONG\* pTarget, const GUID\* pTargetFormat, LONGLONG Source, const GUID\* pSourceFormat);  

`  `STDMETHODIMP SetPositions(LONGLONG\* pCurrent, DWORD dwCurrentFlags, LONGLONG\* pStop, DWORD dwStopFlags);  

`  `STDMETHODIMP GetPositions(LONGLONG\* pCurrent, LONGLONG\* pStop);  

`  `STDMETHODIMP GetAvailable(LONGLONG\* pEarliest, LONGLONG\* pLatest);  

`  `STDMETHODIMP SetRate(double dRate);  

`  `STDMETHODIMP GetRate(double\* pdRate);  

`  `STDMETHODIMP GetPreroll(LONGLONG\* pllPreroll);  



`  `// IAMStreamSelect  

`  `STDMETHODIMP Count(DWORD \*pcStreams);  

`  `STDMETHODIMP Enable(long lIndex, DWORD dwFlags);  

`  `STDMETHODIMP Info(long lIndex, AM\_MEDIA\_TYPE \*\*ppmt, DWORD \*pdwFlags, LCID \*plcid, DWORD \*pdwGroup, WCHAR \*\*ppszName, IUnknown \*\*ppObject, IUnknown \*\*ppUnk);  



`  `// IAMOpenProgress  

`  `STDMETHODIMP QueryProgress(LONGLONG \*pllTotal, LONGLONG \*pllCurrent);  

`  `STDMETHODIMP AbortOperation();  



`  `// ISpecifyPropertyPages2  

`  `STDMETHODIMP GetPages(CAUUID \*pPages);  

`  `STDMETHODIMP CreatePage(const GUID& guid, IPropertyPage\*\* ppPage);  



`  `// IObjectWithSite  

`  `STDMETHODIMP SetSite(IUnknown \*pUnkSite);  

`  `STDMETHODIMP GetSite(REFIID riid, void \*\*ppvSite);  



`  `// IBufferInfo  

`  `STDMETHODIMP\_(int) GetCount();  

`  `STDMETHODIMP GetStatus(int i, int& samples, int& size);  

`  `STDMETHODIMP\_(DWORD) GetPriority();  



`  `// ILAVFSettings  

`  `STDMETHODIMP SetRuntimeConfig(BOOL bRuntimeConfig);  

`  `STDMETHODIMP GetPreferredLanguages(LPWSTR \*ppLanguages);  

`  `STDMETHODIMP SetPreferredLanguages(LPCWSTR pLanguages);  

`  `STDMETHODIMP GetPreferredSubtitleLanguages(LPWSTR \*ppLanguages);  

`  `STDMETHODIMP SetPreferredSubtitleLanguages(LPCWSTR pLanguages);  

`  `STDMETHODIMP\_(LAVSubtitleMode) GetSubtitleMode();  

`  `STDMETHODIMP SetSubtitleMode(LAVSubtitleMode mode);  

`  `STDMETHODIMP\_(BOOL) GetSubtitleMatchingLanguage();  

`  `STDMETHODIMP SetSubtitleMatchingLanguage(BOOL dwMode);  

`  `STDMETHODIMP\_(BOOL) GetPGSForcedStream();  

`  `STDMETHODIMP SetPGSForcedStream(BOOL bFlag);  

`  `STDMETHODIMP\_(BOOL) GetPGSOnlyForced();  

`  `STDMETHODIMP SetPGSOnlyForced(BOOL bForced);  

`  `STDMETHODIMP\_(int) GetVC1TimestampMode();  

`  `STDMETHODIMP SetVC1TimestampMode(int iMode);  

`  `STDMETHODIMP SetSubstreamsEnabled(BOOL bSubStreams);  

`  `STDMETHODIMP\_(BOOL) GetSubstreamsEnabled();  

`  `STDMETHODIMP SetVideoParsingEnabled(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetVideoParsingEnabled();  

`  `STDMETHODIMP SetFixBrokenHDPVR(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetFixBrokenHDPVR();  

`  `STDMETHODIMP\_(HRESULT) SetFormatEnabled(LPCSTR strFormat, BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) IsFormatEnabled(LPCSTR strFormat);  

`  `STDMETHODIMP SetStreamSwitchRemoveAudio(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetStreamSwitchRemoveAudio();  

`  `STDMETHODIMP GetAdvancedSubtitleConfig(LPWSTR \*ppAdvancedConfig);  

`  `STDMETHODIMP SetAdvancedSubtitleConfig(LPCWSTR pAdvancedConfig);  

`  `STDMETHODIMP SetUseAudioForHearingVisuallyImpaired(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetUseAudioForHearingVisuallyImpaired();  

`  `STDMETHODIMP SetMaxQueueMemSize(DWORD dwMaxSize);  

`  `STDMETHODIMP\_(DWORD) GetMaxQueueMemSize();  

`  `STDMETHODIMP SetTrayIcon(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetTrayIcon();  

`  `STDMETHODIMP SetPreferHighQualityAudioStreams(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetPreferHighQualityAudioStreams();  

`  `STDMETHODIMP SetLoadMatroskaExternalSegments(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetLoadMatroskaExternalSegments();  

`  `STDMETHODIMP GetFormats(LPSTR\*\* formats, UINT\* nFormats);  

`  `STDMETHODIMP SetNetworkStreamAnalysisDuration(DWORD dwDuration);  

`  `STDMETHODIMP\_(DWORD) GetNetworkStreamAnalysisDuration();  



`  `// ILAVSplitterSettingsInternal  

`  `STDMETHODIMP\_(LPCSTR) GetInputFormat() { if (m\_pDemuxer) return m\_pDemuxer->GetContainerFormat(); return NULL; }  

`  `STDMETHODIMP\_(std::set<FormatInfo>&) GetInputFormats();  

`  `STDMETHODIMP\_(BOOL) IsVC1CorrectionRequired();  

`  `STDMETHODIMP\_(CMediaType \*) GetOutputMediatype(int stream);  

`  `STDMETHODIMP\_(IFilterGraph \*) GetFilterGraph() { if (m\_pGraph) { m\_pGraph->AddRef(); return m\_pGraph; } return NULL; }  



`  `STDMETHODIMP\_(DWORD) GetStreamFlags(DWORD dwStream) { if (m\_pDemuxer) return m\_pDemuxer->GetStreamFlags(dwStream); return 0; }  

`  `STDMETHODIMP\_(int) GetPixelFormat(DWORD dwStream) { if (m\_pDemuxer) return m\_pDemuxer->GetPixelFormat(dwStream); return AV\_PIX\_FMT\_NONE; }  

`  `STDMETHODIMP\_(int) GetHasBFrames(DWORD dwStream){ if (m\_pDemuxer) return m\_pDemuxer->GetHasBFrames(dwStream); return -1; }  



`  `// Settings helper  

`  `std::list<std::string> GetPreferredAudioLanguageList();  

`  `std::list<CSubtitleSelector> GetSubtitleSelectors();  



`  `bool IsAnyPinDrying();  

`  `void SetFakeASFReader(BOOL bFlag) { m\_bFakeASFReader = bFlag; }  

protected:  

`  `// CAMThread  

`  `enum {CMD\_EXIT, CMD\_SEEK};  

`  `DWORD ThreadProc();  



`  `HRESULT DemuxSeek(REFERENCE\_TIME rtStart);  

`  `HRESULT DemuxNextPacket();  

`  `HRESULT DeliverPacket(Packet \*pPacket);  



`  `void DeliverBeginFlush();  

`  `void DeliverEndFlush();  



`  `STDMETHODIMP Close();  

`  `STDMETHODIMP DeleteOutputs();  

`  `//初始化解复用器  

`  `STDMETHODIMP InitDemuxer();  



`  `friend class CLAVOutputPin;  

`  `STDMETHODIMP SetPositionsInternal(void \*caller, LONGLONG\* pCurrent, DWORD dwCurrentFlags, LONGLONG\* pStop, DWORD dwStopFlags);  



public:  

`  `CLAVOutputPin \*GetOutputPin(DWORD streamId, BOOL bActiveOnly = FALSE);  

`  `STDMETHODIMP RenameOutputPin(DWORD TrackNumSrc, DWORD TrackNumDst, std::vector<CMediaType> pmts);  

`  `STDMETHODIMP UpdateForcedSubtitleMediaType();  



`  `STDMETHODIMP CompleteInputConnection();  

`  `STDMETHODIMP BreakInputConnection();  



protected:  

`    `//相关的参数设置  

`  `STDMETHODIMP LoadDefaults();  

`  `STDMETHODIMP ReadSettings(HKEY rootKey);  

`  `STDMETHODIMP LoadSettings();  

`  `STDMETHODIMP SaveSettings();  

`  `//创建图标  

`  `STDMETHODIMP CreateTrayIcon();  



protected:  

`  `CLAVInputPin \*m\_pInput;  



private:  

`  `CCritSec m\_csPins;  

`  `//用vector存储输出PIN（解复用的时候是不确定的）  

`  `std::vector<CLAVOutputPin \*> m\_pPins;  

`  `//活动的  

`  `std::vector<CLAVOutputPin \*> m\_pActivePins;  

`  `//不用的  

`  `std::vector<CLAVOutputPin \*> m\_pRetiredPins;  

`  `std::set<DWORD> m\_bDiscontinuitySent;  



`  `std::wstring m\_fileName;  

`  `std::wstring m\_processName;  

`  `//有很多纯虚函数的基本解复用类  

`  `//注意：绝大部分信息都是从这获得的  

`  `//这里的信息是由其派生类从FFMPEG中获取到的  

`  `CBaseDemuxer \*m\_pDemuxer;  



`  `BOOL m\_bPlaybackStarted;  

`  `BOOL m\_bFakeASFReader;  



`  `// Times  

`  `REFERENCE\_TIME m\_rtStart, m\_rtStop, m\_rtCurrent, m\_rtNewStart, m\_rtNewStop;  

`  `REFERENCE\_TIME m\_rtOffset;  

`  `double m\_dRate;  

`  `BOOL m\_bStopValid;  



`  `// Seeking  

`  `REFERENCE\_TIME m\_rtLastStart, m\_rtLastStop;  

`  `std::set<void \*> m\_LastSeekers;  



`  `// flushing  

`  `bool m\_fFlushing;  

`  `CAMEvent m\_eEndFlush;  



`  `std::set<FormatInfo> m\_InputFormats;  



`  `// Settings  

`  `//设置  

`  `struct Settings {  

`    `BOOL TrayIcon;  

`    `std::wstring prefAudioLangs;  

`    `std::wstring prefSubLangs;  

`    `std::wstring subtitleAdvanced;  

`    `LAVSubtitleMode subtitleMode;  

`    `BOOL PGSForcedStream;  

`    `BOOL PGSOnlyForced;  

`    `int vc1Mode;  

`    `BOOL substreams;  



`    `BOOL MatroskaExternalSegments;  



`    `BOOL StreamSwitchRemoveAudio;  

`    `BOOL ImpairedAudio;  

`    `BOOL PreferHighQualityAudio;  

`    `DWORD QueueMaxSize;  

`    `DWORD NetworkAnalysisDuration;  



`    `std::map<std::string, BOOL> formats;  

`  `} m\_settings;  



`  `BOOL m\_bRuntimeConfig;  



`  `IUnknown \*m\_pSite;  



`  `CBaseTrayIcon \*m\_pTrayIcon;  

};  



[uuid("B98D13E7-55DB-4385-A33D-09FD1BA26338")]  

class CLAVSplitterSource : public CLAVSplitter  

{  

public:  

`  `// construct only via class factory  

`  `CLAVSplitterSource(LPUNKNOWN pUnk, HRESULT\* phr);  

`  `virtual ~CLAVSplitterSource();  



`  `// IUnknown  

`  `DECLARE\_IUNKNOWN;  

`  `//暴露接口，使外部程序可以QueryInterface，关键！  

`  `//翻译（“没有代表的方式查询接口”）  

`  `STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void\*\* ppv);  

};  

先来看一下查询接口的函数NonDelegatingQueryInterface()吧

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)

//暴露接口，使外部程序可以QueryInterface，关键！  

STDMETHODIMP CLAVSplitter::NonDelegatingQueryInterface(REFIID riid, void\*\* ppv)  

{  

`  `CheckPointer(ppv, E\_POINTER);  



`  `\*ppv = NULL;  



`  `if (m\_pDemuxer && (riid == \_\_uuidof(IKeyFrameInfo) || riid == \_\_uuidof(ITrackInfo) || riid == IID\_IAMExtendedSeeking || riid == IID\_IAMMediaContent)) {  

`    `return m\_pDemuxer->QueryInterface(riid, ppv);  

`  `}  

`  `//写法好特别啊，意思是一样的  

`  `return  

`    `QI(IMediaSeeking)  

`    `QI(IAMStreamSelect)  

`    `QI(ISpecifyPropertyPages)  

`    `QI(ISpecifyPropertyPages2)  

`    `QI2(ILAVFSettings)  

`    `QI2(ILAVFSettingsInternal)  

`    `QI(IObjectWithSite)  

`    `QI(IBufferInfo)  

`    `\_\_super::NonDelegatingQueryInterface(riid, ppv);  

}  

这个NonDelegatingQueryInterface()的写法确实够特别的，不过其作用还是一样的：根据不同的REFIID，获得不同的接口指针。在这里就不多说了。

再看一下Load()函数

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)

// IFileSourceFilter  

// 打开  

STDMETHODIMP CLAVSplitter::Load(LPCOLESTR pszFileName, const AM\_MEDIA\_TYPE \* pmt)  

{  

`  `CheckPointer(pszFileName, E\_POINTER);  



`  `m\_bPlaybackStarted = FALSE;  



`  `m\_fileName = std::wstring(pszFileName);  



`  `HRESULT hr = S\_OK;  

`  `SAFE\_DELETE(m\_pDemuxer);  

`  `LPWSTR extension = PathFindExtensionW(pszFileName);  



`  `DbgLog((LOG\_TRACE, 10, L"::Load(): Opening file '%s' (extension: %s)", pszFileName, extension));  



`  `// BDMV uses the BD demuxer, everything else LAVF  

`  `if (\_wcsicmp(extension, L".bdmv") == 0 || \_wcsicmp(extension, L".mpls") == 0) {  

`    `m\_pDemuxer = new CBDDemuxer(this, this);  

`  `} else {  

`    `m\_pDemuxer = new CLAVFDemuxer(this, this);  

`  `}  

`  `//打开  

`  `if(FAILED(hr = m\_pDemuxer->Open(pszFileName))) {  

`    `SAFE\_DELETE(m\_pDemuxer);  

`    `return hr;  

`  `}  

`  `m\_pDemuxer->AddRef();  



`  `return InitDemuxer();  

}  

在这里我们要注意CLAVSplitter的一个变量：m\_pDemuxer。这是一个指向 CBaseDemuxer的指针。因此在这里CLAVSplitter实际上调用了 CBaseDemuxer中的方法。

从代码中的逻辑我们可以看出：

1.寻找文件后缀

2.当文件后缀是：".bdmv"或者".mpls"的时候，m\_pDemuxer指向一个CBDDemuxer（我推测这代表目标文件是蓝光文件什么的），其他情况下m\_pDemuxer指向一个CLAVFDemuxer。

3.然后m\_pDemuxer会调用Open()方法。

4.最后会调用一个InitDemuxer()方法。

在这里我们应该看看m\_pDemuxer->Open()这个方法里面有什么。我们先考虑m\_pDemuxer指向CLAVFDemuxer的情况。

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)

// Demuxer Functions  

// 打开（就是一个封装）  

STDMETHODIMP CLAVFDemuxer::Open(LPCOLESTR pszFileName)  

{  

`  `return OpenInputStream(NULL, pszFileName, NULL, TRUE);  

}  

发现是一层封装，于是果断决定层层深入。

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)

//实际的打开,使用FFMPEG  

STDMETHODIMP CLAVFDemuxer::OpenInputStream(AVIOContext \*byteContext, LPCOLESTR pszFileName, const char \*format, BOOL bForce)  

{  

`  `CAutoLock lock(m\_pLock);  

`  `HRESULT hr = S\_OK;  



`  `int ret; // return code from avformat functions  



`  `// Convert the filename from wchar to char for avformat  

`  `char fileName[4100] = {0};  

`  `if (pszFileName) {  

`    `ret = WideCharToMultiByte(CP\_UTF8, 0, pszFileName, -1, fileName, 4096, NULL, NULL);  

`  `}  



`  `if (\_strnicmp("mms:", fileName, 4) == 0) {  

`    `memmove(fileName+1, fileName, strlen(fileName));  

`    `memcpy(fileName, "mmsh", 4);  

`  `}  



`  `AVIOInterruptCB cb = {avio\_interrupt\_cb, this};  



trynoformat:  

`  `// Create the avformat\_context  

`  `// FFMPEG中的函数  

`  `m\_avFormat = avformat\_alloc\_context();  

`  `m\_avFormat->pb = byteContext;  

`  `m\_avFormat->interrupt\_callback = cb;  



`  `if (m\_avFormat->pb)  

`    `m\_avFormat->flags |= AVFMT\_FLAG\_CUSTOM\_IO;  



`  `LPWSTR extension = pszFileName ? PathFindExtensionW(pszFileName) : NULL;  



`  `AVInputFormat \*inputFormat = NULL;  

`  `//如果指定了格式  

`  `if (format) {  

`      `//查查有木有  

`    `inputFormat = av\_find\_input\_format(format);  

`  `} else if (pszFileName) {  

`    `LPWSTR extension = PathFindExtensionW(pszFileName);  

`    `for (int i = 0; i < countof(wszImageExtensions); i++) {  

`      `if (\_wcsicmp(extension, wszImageExtensions[i]) == 0) {  

`        `if (byteContext) {  

`          `inputFormat = av\_find\_input\_format("image2pipe");  

`        `} else {  

`          `inputFormat = av\_find\_input\_format("image2");  

`        `}  

`        `break;  

`      `}  

`    `}  

`    `for (int i = 0; i < countof(wszBlockedExtensions); i++) {  

`      `if (\_wcsicmp(extension, wszBlockedExtensions[i]) == 0) {  

`        `goto done;  

`      `}  

`    `}  

`  `}  



`  `// Disable loading of external mkv segments, if required  

`  `if (!m\_pSettings->GetLoadMatroskaExternalSegments())  

`    `m\_avFormat->flags |= AVFMT\_FLAG\_NOEXTERNAL;  



`  `m\_timeOpening = time(NULL);  

`  `//实际的打开  

`  `ret = avformat\_open\_input(&m\_avFormat, fileName, inputFormat, NULL);  

`  `//出错了  

`  `if (ret < 0) {  

`    `DbgLog((LOG\_ERROR, 0, TEXT("::OpenInputStream(): avformat\_open\_input failed (%d)"), ret));  

`    `if (format) {  

`      `DbgLog((LOG\_ERROR, 0, TEXT(" -> trying again without specific format")));  

`      `format = NULL;  

`      `//实际的关闭  

`      `avformat\_close\_input(&m\_avFormat);  

`      `goto trynoformat;  

`    `}  

`    `goto done;  

`  `}  

`  `DbgLog((LOG\_TRACE, 10, TEXT("::OpenInputStream(): avformat\_open\_input opened file of type '%S' (took %I64d seconds)"), m\_avFormat->iformat->name, time(NULL) - m\_timeOpening));  

`  `m\_timeOpening = 0;  

`  `//初始化AVFormat  

`  `CHECK\_HR(hr = InitAVFormat(pszFileName, bForce));  



`  `return S\_OK;  

done:  

`  `CleanupAVFormat();  

`  `return E\_FAIL;  

}  

看到这个函数，立马感受到了一种“拨云见日”的感觉。看到了很多FFMPEG的API函数。最重要的依据当属avformat\_open\_input()了，通过这个函数，打开了实际的文件。如果出现错误，则调用avformat\_close\_input()进行清理。

最后，还调用了InitAVFormat()函数：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/12711723#)

//初始化AVFormat  

STDMETHODIMP CLAVFDemuxer::InitAVFormat(LPCOLESTR pszFileName, BOOL bForce)  

{  

`  `HRESULT hr = S\_OK;  

`  `const char \*format = NULL;  

`  `//获取InputFormat信息（，短名称，长名称）  

`  `lavf\_get\_iformat\_infos(m\_avFormat->iformat, &format, NULL);  

`  `if (!bForce && (!format || !m\_pSettings->IsFormatEnabled(format))) {  

`    `DbgLog((LOG\_TRACE, 20, L"::InitAVFormat() - format of type '%S' disabled, failing", format ? format : m\_avFormat->iformat->name));  

`    `return E\_FAIL;  

`  `}  



`  `m\_pszInputFormat = format ? format : m\_avFormat->iformat->name;  



`  `m\_bVC1SeenTimestamp = FALSE;  



`  `LPWSTR extension = pszFileName ? PathFindExtensionW(pszFileName) : NULL;  



`  `m\_bMatroska = (\_strnicmp(m\_pszInputFormat, "matroska", 8) == 0);  

`  `m\_bOgg = (\_strnicmp(m\_pszInputFormat, "ogg", 3) == 0);  

`  `m\_bAVI = (\_strnicmp(m\_pszInputFormat, "avi", 3) == 0);  

`  `m\_bMPEGTS = (\_strnicmp(m\_pszInputFormat, "mpegts", 6) == 0);  

`  `m\_bMPEGPS = (\_stricmp(m\_pszInputFormat, "mpeg") == 0);  

`  `m\_bRM = (\_stricmp(m\_pszInputFormat, "rm") == 0);  

`  `m\_bPMP = (\_stricmp(m\_pszInputFormat, "pmp") == 0);  

`  `m\_bMP4 = (\_stricmp(m\_pszInputFormat, "mp4") == 0);  



`  `m\_bTSDiscont = m\_avFormat->iformat->flags & AVFMT\_TS\_DISCONT;  



`  `WCHAR szProt[24] = L"file";  

`  `if (pszFileName) {  

`    `DWORD dwNumChars = 24;  

`    `hr = UrlGetPart(pszFileName, szProt, &dwNumChars, URL\_PART\_SCHEME, 0);  

`    `if (SUCCEEDED(hr) && dwNumChars && (\_wcsicmp(szProt, L"file") != 0)) {  

`      `m\_avFormat->flags |= AVFMT\_FLAG\_NETWORK;  

`      `DbgLog((LOG\_TRACE, 10, TEXT("::InitAVFormat(): detected network protocol: %s"), szProt));  

`    `}  

`  `}  



`  `// TODO: make both durations below configurable  

`  `// decrease analyze duration for network streams  

`  `if (m\_avFormat->flags & AVFMT\_FLAG\_NETWORK || (m\_avFormat->flags & AVFMT\_FLAG\_CUSTOM\_IO && !m\_avFormat->pb->seekable)) {  

`    `// require at least 0.2 seconds  

`    `m\_avFormat->max\_analyze\_duration = max(m\_pSettings->GetNetworkStreamAnalysisDuration() \* 1000, 200000);  

`  `} else {  

`    `// And increase it for mpeg-ts/ps files  

`    `if (m\_bMPEGTS || m\_bMPEGPS)  

`      `m\_avFormat->max\_analyze\_duration = 10000000;  

`  `}  



`  `av\_opt\_set\_int(m\_avFormat, "correct\_ts\_overflow", !m\_pBluRay, 0);  



`  `if (m\_bMatroska)  

`    `m\_avFormat->flags |= AVFMT\_FLAG\_KEEP\_SIDE\_DATA;  



`  `m\_timeOpening = time(NULL);  

`  `//获取媒体流信息  

`  `int ret = avformat\_find\_stream\_info(m\_avFormat, NULL);  

`  `if (ret < 0) {  

`    `DbgLog((LOG\_ERROR, 0, TEXT("::InitAVFormat(): av\_find\_stream\_info failed (%d)"), ret));  

`    `goto done;  

`  `}  

`  `DbgLog((LOG\_TRACE, 10, TEXT("::InitAVFormat(): avformat\_find\_stream\_info finished, took %I64d seconds"), time(NULL) - m\_timeOpening));  

`  `m\_timeOpening = 0;  



`  `// Check if this is a m2ts in a BD structure, and if it is, read some extra stream properties out of the CLPI files  

`  `if (m\_pBluRay) {  

`    `m\_pBluRay->ProcessClipLanguages();  

`  `} else if (pszFileName && m\_bMPEGTS) {  

`    `CheckBDM2TSCPLI(pszFileName);  

`  `}  



`  `SAFE\_CO\_FREE(m\_stOrigParser);  

`  `m\_stOrigParser = (enum AVStreamParseType \*)CoTaskMemAlloc(m\_avFormat->nb\_streams \* sizeof(enum AVStreamParseType));  

`  `if (!m\_stOrigParser)  

`    `return E\_OUTOFMEMORY;  



`  `for(unsigned int idx = 0; idx < m\_avFormat->nb\_streams; ++idx) {  

`    `AVStream \*st = m\_avFormat->streams[idx];  



`    `// Disable full stream parsing for these formats  

`    `if (st->need\_parsing == AVSTREAM\_PARSE\_FULL) {  

`      `if (st->codec->codec\_id == AV\_CODEC\_ID\_DVB\_SUBTITLE) {  

`        `st->need\_parsing = AVSTREAM\_PARSE\_NONE;  

`      `}  

`    `}  



`    `if (m\_bOgg && st->codec->codec\_id == AV\_CODEC\_ID\_H264) {  

`      `st->need\_parsing = AVSTREAM\_PARSE\_FULL;  

`    `}  



`    `// Create the parsers with the appropriate flags  

`    `init\_parser(m\_avFormat, st);  

`    `UpdateParserFlags(st);  



#ifdef DEBUG  

`    `AVProgram \*streamProg = av\_find\_program\_from\_stream(m\_avFormat, NULL, idx);  

`    `DbgLog((LOG\_TRACE, 30, L"Stream %d (pid %d) - program: %d, codec: %S; parsing: %S;", idx, st->id, streamProg ? streamProg->pmt\_pid : -1, avcodec\_get\_name(st->codec->codec\_id), lavf\_get\_parsing\_string(st->need\_parsing)));  

#endif  

`    `m\_stOrigParser[idx] = st->need\_parsing;  



`    `if ((st->codec->codec\_id == AV\_CODEC\_ID\_DTS && st->codec->codec\_tag == 0xA2)  

`     `|| (st->codec->codec\_id == AV\_CODEC\_ID\_EAC3 && st->codec->codec\_tag == 0xA1))  

`      `st->disposition |= LAVF\_DISPOSITION\_SECONDARY\_AUDIO;  



`    `UpdateSubStreams();  



`    `if (st->codec->codec\_type == AVMEDIA\_TYPE\_ATTACHMENT && (st->codec->codec\_id == AV\_CODEC\_ID\_TTF || st->codec->codec\_id == AV\_CODEC\_ID\_OTF)) {  

`      `if (!m\_pFontInstaller) {  

`        `m\_pFontInstaller = new CFontInstaller();  

`      `}  

`      `m\_pFontInstaller->InstallFont(st->codec->extradata, st->codec->extradata\_size);  

`    `}  

`  `}  



`  `CHECK\_HR(hr = CreateStreams());  



`  `return S\_OK;  

done:  

`  `//关闭输入  

`  `CleanupAVFormat();  

`  `return E\_FAIL;  

}  

该函数通过avformat\_find\_stream\_info()等获取到流信息，这里就不多说了。
### [**LAV Filter 源代码分析 3： LAV Video （1）**](http://blog.csdn.net/leixiaohua1020/article/details/13022201)
LAV Video 是使用很广泛的DirectShow Filter。它封装了FFMPEG中的libavcodec，支持十分广泛的视频格式的解码。在这里对其源代码进行详细的分析。

LAV Video 工程代码的结构如下图所示

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.160.jpeg)

直接看LAV Video最主要的类CLAVVideo吧，它的定义位于LAVVideo.h中。

LAVVideo.h

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)

/\* 雷霄骅 

` `\* 中国传媒大学/数字电视技术 

` `\* leixiaohua1020@126.com 

` `\* 

` `\*/  

/\* 

` `\*      Copyright (C) 2010-2013 Hendrik Leppkes 

` `\*      http://www.1f0.de 

` `\* 

` `\*  This program is free software; you can redistribute it and/or modify 

` `\*  it under the terms of the GNU General Public License as published by 

` `\*  the Free Software Foundation; either version 2 of the License, or 

` `\*  (at your option) any later version. 

` `\* 

` `\*  This program is distributed in the hope that it will be useful, 

` `\*  but WITHOUT ANY WARRANTY; without even the implied warranty of 

` `\*  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the 

` `\*  GNU General Public License for more details. 

` `\* 

` `\*  You should have received a copy of the GNU General Public License along 

` `\*  with this program; if not, write to the Free Software Foundation, Inc., 

` `\*  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. 

` `\*/  



#pragma once  



#include "decoders/ILAVDecoder.h"  

#include "DecodeThread.h"  

#include "ILAVPinInfo.h"  



#include "LAVPixFmtConverter.h"  

#include "LAVVideoSettings.h"  

#include "H264RandomAccess.h"  

#include "FloatingAverage.h"  



#include "ISpecifyPropertyPages2.h"  

#include "SynchronizedQueue.h"  



#include "subtitles/LAVSubtitleConsumer.h"  

#include "subtitles/LAVVideoSubtitleInputPin.h"  



#include "BaseTrayIcon.h"  



#define LAVC\_VIDEO\_REGISTRY\_KEY L"Software\\LAV\\Video"  

#define LAVC\_VIDEO\_REGISTRY\_KEY\_FORMATS L"Software\\LAV\\Video\\Formats"  

#define LAVC\_VIDEO\_REGISTRY\_KEY\_OUTPUT L"Software\\LAV\\Video\\Output"  

#define LAVC\_VIDEO\_REGISTRY\_KEY\_HWACCEL L"Software\\LAV\\Video\\HWAccel"  



#define LAVC\_VIDEO\_LOG\_FILE     L"LAVVideo.txt"  



#define DEBUG\_FRAME\_TIMINGS 0  

#define DEBUG\_PIXELCONV\_TIMINGS 0  



#define LAV\_MT\_FILTER\_QUEUE\_SIZE 4  



typedef struct {  

`  `REFERENCE\_TIME rtStart;  

`  `REFERENCE\_TIME rtStop;  

} TimingCache;  

//解码核心类  

//Transform Filter  

[uuid("EE30215D-164F-4A92-A4EB-9D4C13390F9F")]  

class CLAVVideo : public CTransformFilter, public ISpecifyPropertyPages2, public ILAVVideoSettings, public ILAVVideoStatus, public ILAVVideoCallback  

{  

public:  

`  `CLAVVideo(LPUNKNOWN pUnk, HRESULT\* phr);  

`  `~CLAVVideo();  



`  `static void CALLBACK StaticInit(BOOL bLoading, const CLSID \*clsid);  



`  `// IUnknown  

`  `// 查找接口必须实现  

`  `DECLARE\_IUNKNOWN;  

`  `STDMETHODIMP NonDelegatingQueryInterface(REFIID riid, void\*\* ppv);  



`  `// ISpecifyPropertyPages2  

`  `// 属性页  

`  `// 获取或者创建  

`  `STDMETHODIMP GetPages(CAUUID \*pPages);  

`  `STDMETHODIMP CreatePage(const GUID& guid, IPropertyPage\*\* ppPage);  



`  `// ILAVVideoSettings  



`  `STDMETHODIMP SetRuntimeConfig(BOOL bRuntimeConfig);  

`  `STDMETHODIMP SetFormatConfiguration(LAVVideoCodec vCodec, BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetFormatConfiguration(LAVVideoCodec vCodec);  

`  `STDMETHODIMP SetNumThreads(DWORD dwNum);  

`  `STDMETHODIMP\_(DWORD) GetNumThreads();  

`  `STDMETHODIMP SetStreamAR(DWORD bStreamAR);  

`  `STDMETHODIMP\_(DWORD) GetStreamAR();  

`  `STDMETHODIMP SetPixelFormat(LAVOutPixFmts pixFmt, BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetPixelFormat(LAVOutPixFmts pixFmt);  

`  `STDMETHODIMP SetRGBOutputRange(DWORD dwRange);  

`  `STDMETHODIMP\_(DWORD) GetRGBOutputRange();  



`  `STDMETHODIMP SetDeintFieldOrder(LAVDeintFieldOrder fieldOrder);  

`  `STDMETHODIMP\_(LAVDeintFieldOrder) GetDeintFieldOrder();  

`  `STDMETHODIMP SetDeintForce(BOOL bForce);  

`  `STDMETHODIMP\_(BOOL) GetDeintForce();  

`  `STDMETHODIMP SetDeintAggressive(BOOL bAggressive);  

`  `STDMETHODIMP\_(BOOL) GetDeintAggressive();  



`  `STDMETHODIMP\_(DWORD) CheckHWAccelSupport(LAVHWAccel hwAccel);  

`  `STDMETHODIMP SetHWAccel(LAVHWAccel hwAccel);  

`  `STDMETHODIMP\_(LAVHWAccel) GetHWAccel();  

`  `STDMETHODIMP SetHWAccelCodec(LAVVideoHWCodec hwAccelCodec, BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetHWAccelCodec(LAVVideoHWCodec hwAccelCodec);  

`  `STDMETHODIMP SetHWAccelDeintMode(LAVHWDeintModes deintMode);  

`  `STDMETHODIMP\_(LAVHWDeintModes) GetHWAccelDeintMode();  

`  `STDMETHODIMP SetHWAccelDeintOutput(LAVDeintOutput deintOutput);  

`  `STDMETHODIMP\_(LAVDeintOutput) GetHWAccelDeintOutput();  

`  `STDMETHODIMP SetHWAccelDeintHQ(BOOL bHQ);  

`  `STDMETHODIMP\_(BOOL) GetHWAccelDeintHQ();  

`  `STDMETHODIMP SetSWDeintMode(LAVSWDeintModes deintMode);  

`  `STDMETHODIMP\_(LAVSWDeintModes) GetSWDeintMode();  

`  `STDMETHODIMP SetSWDeintOutput(LAVDeintOutput deintOutput);  

`  `STDMETHODIMP\_(LAVDeintOutput) GetSWDeintOutput();  



`  `STDMETHODIMP SetDeintTreatAsProgressive(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetDeintTreatAsProgressive();  



`  `STDMETHODIMP SetDitherMode(LAVDitherMode ditherMode);  

`  `STDMETHODIMP\_(LAVDitherMode) GetDitherMode();  



`  `STDMETHODIMP SetUseMSWMV9Decoder(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetUseMSWMV9Decoder();  



`  `STDMETHODIMP SetDVDVideoSupport(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetDVDVideoSupport();  



`  `STDMETHODIMP SetHWAccelResolutionFlags(DWORD dwResFlags);  

`  `STDMETHODIMP\_(DWORD) GetHWAccelResolutionFlags();  



`  `STDMETHODIMP SetTrayIcon(BOOL bEnabled);  

`  `STDMETHODIMP\_(BOOL) GetTrayIcon();  



`  `STDMETHODIMP SetDeinterlacingMode(LAVDeintMode deintMode);  

`  `STDMETHODIMP\_(LAVDeintMode) GetDeinterlacingMode();  



`  `// ILAVVideoStatus  

`  `STDMETHODIMP\_(const WCHAR \*) GetActiveDecoderName() { return m\_Decoder.GetDecoderName(); }  



`  `// CTransformFilter  

`  `// 核心的  

`  `HRESULT CheckInputType(const CMediaType\* mtIn);  

`  `HRESULT CheckTransform(const CMediaType\* mtIn, const CMediaType\* mtOut);  

`  `HRESULT DecideBufferSize(IMemAllocator \* pAllocator, ALLOCATOR\_PROPERTIES \*pprop);  

`  `HRESULT GetMediaType(int iPosition, CMediaType \*pMediaType);  



`  `HRESULT SetMediaType(PIN\_DIRECTION dir, const CMediaType \*pmt);  

`  `HRESULT EndOfStream();  

`  `HRESULT BeginFlush();  

`  `HRESULT EndFlush();  

`  `HRESULT NewSegment(REFERENCE\_TIME tStart, REFERENCE\_TIME tStop, double dRate);  

`  `//处理的核心  

`  `//核心一般才有IMediaSample  

`  `HRESULT Receive(IMediaSample \*pIn);  



`  `HRESULT CheckConnect(PIN\_DIRECTION dir, IPin \*pPin);  

`  `HRESULT BreakConnect(PIN\_DIRECTION dir);  

`  `HRESULT CompleteConnect(PIN\_DIRECTION dir, IPin \*pReceivePin);  



`  `int GetPinCount();  

`  `CBasePin\* GetPin(int n);  



`  `STDMETHODIMP JoinFilterGraph(IFilterGraph \* pGraph, LPCWSTR pName);  



`  `// ILAVVideoCallback  

`  `STDMETHODIMP AllocateFrame(LAVFrame \*\*ppFrame);  

`  `STDMETHODIMP ReleaseFrame(LAVFrame \*\*ppFrame);  

`  `STDMETHODIMP Deliver(LAVFrame \*pFrame);  

`  `STDMETHODIMP\_(LPWSTR) GetFileExtension();  

`  `STDMETHODIMP\_(BOOL) FilterInGraph(PIN\_DIRECTION dir, const GUID &clsid) { if (dir == PINDIR\_INPUT) return FilterInGraphSafe(m\_pInput, clsid); else return FilterInGraphSafe(m\_pOutput, clsid); }  

`  `STDMETHODIMP\_(DWORD) GetDecodeFlags() { return m\_dwDecodeFlags; }  

`  `STDMETHODIMP\_(CMediaType&) GetInputMediaType() { return m\_pInput->CurrentMediaType(); }  

`  `STDMETHODIMP GetLAVPinInfo(LAVPinInfo &info) { if (m\_LAVPinInfoValid) { info = m\_LAVPinInfo; return S\_OK; } return E\_FAIL; }  

`  `STDMETHODIMP\_(CBasePin\*) GetOutputPin() { return m\_pOutput; }  

`  `STDMETHODIMP\_(CMediaType&) GetOutputMediaType() { return m\_pOutput->CurrentMediaType(); }  

`  `STDMETHODIMP DVDStripPacket(BYTE\*& p, long& len) { static\_cast<CDeCSSTransformInputPin\*>(m\_pInput)->StripPacket(p, len); return S\_OK; }  

`  `STDMETHODIMP\_(LAVFrame\*) GetFlushFrame();  

`  `STDMETHODIMP ReleaseAllDXVAResources() { ReleaseLastSequenceFrame(); return S\_OK; }  



public:  

`  `// Pin Configuration  

`  `const static AMOVIESETUP\_MEDIATYPE    sudPinTypesIn[];  

`  `const static int                      sudPinTypesInCount;  

`  `const static AMOVIESETUP\_MEDIATYPE    sudPinTypesOut[];  

`  `const static int                      sudPinTypesOutCount;  



private:  

`  `HRESULT LoadDefaults();  

`  `HRESULT ReadSettings(HKEY rootKey);  

`  `HRESULT LoadSettings();  

`  `HRESULT SaveSettings();  



`  `HRESULT CreateTrayIcon();  



`  `HRESULT CreateDecoder(const CMediaType \*pmt);  



`  `HRESULT GetDeliveryBuffer(IMediaSample\*\* ppOut, int width, int height, AVRational ar, DXVA2\_ExtendedFormat dxvaExtFormat, REFERENCE\_TIME avgFrameDuration);  

`  `HRESULT ReconnectOutput(int width, int height, AVRational ar, DXVA2\_ExtendedFormat dxvaExtFlags, REFERENCE\_TIME avgFrameDuration, BOOL bDXVA = FALSE);  



`  `HRESULT SetFrameFlags(IMediaSample\* pMS, LAVFrame \*pFrame);  



`  `HRESULT NegotiatePixelFormat(CMediaType &mt, int width, int height);  

`  `BOOL IsInterlaced();  





`  `HRESULT Filter(LAVFrame \*pFrame);  

`  `HRESULT DeliverToRenderer(LAVFrame \*pFrame);  



`  `HRESULT PerformFlush();  

`  `HRESULT ReleaseLastSequenceFrame();  



`  `HRESULT GetD3DBuffer(LAVFrame \*pFrame);  

`  `HRESULT RedrawStillImage();  

`  `HRESULT SetInDVDMenu(bool menu) { m\_bInDVDMenu = menu; return S\_OK; }  



`  `enum {CNTRL\_EXIT, CNTRL\_REDRAW};  

`  `HRESULT ControlCmd(DWORD cmd) {  

`    `return m\_ControlThread->CallWorker(cmd);  

`  `}  



private:  

`  `friend class CVideoOutputPin;  

`  `friend class CDecodeThread;  

`  `friend class CLAVControlThread;  

`  `friend class CLAVSubtitleProvider;  

`  `friend class CLAVSubtitleConsumer;  

`  `//解码线程  

`  `CDecodeThread        m\_Decoder;  

`  `CAMThread            \*m\_ControlThread;  



`  `REFERENCE\_TIME       m\_rtPrevStart;  

`  `REFERENCE\_TIME       m\_rtPrevStop;  



`  `BOOL                 m\_bForceInputAR;  

`  `BOOL                 m\_bSendMediaType;  

`  `BOOL                 m\_bFlushing;  



`  `HRESULT              m\_hrDeliver;  



`  `CLAVPixFmtConverter  m\_PixFmtConverter;  

`  `std::wstring         m\_strExtension;  



`  `DWORD                m\_bDXVAExtFormatSupport;  

`  `DWORD                m\_bMadVR;  

`  `DWORD                m\_bOverlayMixer;  

`  `DWORD                m\_dwDecodeFlags;  



`  `BOOL                 m\_bInDVDMenu;  



`  `AVFilterGraph        \*m\_pFilterGraph;  

`  `AVFilterContext      \*m\_pFilterBufferSrc;  

`  `AVFilterContext      \*m\_pFilterBufferSink;  



`  `LAVPixelFormat       m\_filterPixFmt;  

`  `int                  m\_filterWidth;  

`  `int                  m\_filterHeight;  

`  `LAVFrame             m\_FilterPrevFrame;  



`  `BOOL                 m\_LAVPinInfoValid;  

`  `LAVPinInfo           m\_LAVPinInfo;  



`  `CLAVVideoSubtitleInputPin \*m\_pSubtitleInput;  

`  `CLAVSubtitleConsumer \*m\_SubtitleConsumer;  



`  `LAVFrame             \*m\_pLastSequenceFrame;  



`  `AM\_SimpleRateChange  m\_DVDRate;  



`  `BOOL                 m\_bRuntimeConfig;  

`  `struct VideoSettings {  

`    `BOOL TrayIcon;  

`    `DWORD StreamAR;  

`    `DWORD NumThreads;  

`    `BOOL bFormats[Codec\_VideoNB];  

`    `BOOL bMSWMV9DMO;  

`    `BOOL bPixFmts[LAVOutPixFmt\_NB];  

`    `DWORD RGBRange;  

`    `DWORD HWAccel;  

`    `BOOL bHWFormats[HWCodec\_NB];  

`    `DWORD HWAccelResFlags;  

`    `DWORD HWDeintMode;  

`    `DWORD HWDeintOutput;  

`    `BOOL HWDeintHQ;  

`    `DWORD DeintFieldOrder;  

`    `LAVDeintMode DeintMode;  

`    `DWORD SWDeintMode;  

`    `DWORD SWDeintOutput;  

`    `DWORD DitherMode;  

`    `BOOL bDVDVideo;  

`  `} m\_settings;  



`  `CBaseTrayIcon \*m\_pTrayIcon;  



#ifdef DEBUG  

`  `FloatingAverage<double> m\_pixFmtTimingAvg;  

#endif  

};  

可见该类继承了CTransformFilter，其的功能真的是非常丰富的。在这里肯定无法对其进行一一分析，只能选择其中重点的函数进行一下分析。

该类中包含了解码线程类：CDecodeThread        m\_Decoder;，这里封装了解码功能。

同时该类中包含了函数Receive(IMediaSample \*pIn);，是发挥解码功能的函数，其中pIn是输入的解码前的视频压缩编码数据。

下面来看看Receive()函数：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)

//处理的核心  

//核心一般才有IMediaSample  

HRESULT CLAVVideo::Receive(IMediaSample \*pIn)  

{  

`  `CAutoLock cAutoLock(&m\_csReceive);  

`  `HRESULT        hr = S\_OK;  



`  `AM\_SAMPLE2\_PROPERTIES const \*pProps = m\_pInput->SampleProps();  

`  `if(pProps->dwStreamId != AM\_STREAM\_MEDIA) {  

`    `return m\_pOutput->Deliver(pIn);  

`  `}  



`  `AM\_MEDIA\_TYPE \*pmt = NULL;  

`  `//获取媒体类型等等  

`  `if (SUCCEEDED(pIn->GetMediaType(&pmt)) && pmt) {  

`    `CMediaType mt = \*pmt;  

`    `DeleteMediaType(pmt);  

`    `if (mt != m\_pInput->CurrentMediaType() || !(m\_dwDecodeFlags & LAV\_VIDEO\_DEC\_FLAG\_DVD)) {  

`      `DbgLog((LOG\_TRACE, 10, L"::Receive(): Input sample contained media type, dynamic format change..."));  

`      `m\_Decoder.EndOfStream();  

`      `hr = m\_pInput->SetMediaType(&mt);  

`      `if (FAILED(hr)) {  

`        `DbgLog((LOG\_ERROR, 10, L"::Receive(): Setting new media type failed..."));  

`        `return hr;  

`      `}  

`    `}  

`  `}  



`  `m\_hrDeliver = S\_OK;  



`  `// Skip over empty packets  

`  `if (pIn->GetActualDataLength() == 0) {  

`    `return S\_OK;  

`  `}  

`  `//解码  

`  `hr = m\_Decoder.Decode(pIn);  

`  `if (FAILED(hr))  

`    `return hr;  



`  `if (FAILED(m\_hrDeliver))  

`    `return m\_hrDeliver;  



`  `return S\_OK;  

}  

由代码我们可以看出，实际发挥出解码功能的函数是hr = m\_Decoder.Decode(pIn);。

下面我们来看看CDecodeThread类的Decode()方法：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)

//解码线程的解码函数  

STDMETHODIMP CDecodeThread::Decode(IMediaSample \*pSample)  

{  

`  `CAutoLock decoderLock(this);  



`  `if (!CAMThread::ThreadExists())  

`    `return E\_UNEXPECTED;  



`  `// Wait until the queue is empty  

`  `while(HasSample())  

`    `Sleep(1);  



`  `// Re-init the decoder, if requested  

`  `// Doing this inside the worker thread alone causes problems  

`  `// when switching from non-sync to sync, so ensure we're in sync.  

`  `if (m\_bDecoderNeedsReInit) {  

`    `CAMThread::CallWorker(CMD\_REINIT);  

`    `while (!m\_evEOSDone.Check()) {  

`      `m\_evSample.Wait();  

`      `ProcessOutput();  

`    `}  

`  `}  



`  `m\_evDeliver.Reset();  

`  `m\_evSample.Reset();  

`  `m\_evDecodeDone.Reset();  



`  `pSample->AddRef();  



`  `// Send data to worker thread, and wake it (if it was waiting)  

`  `PutSample(pSample);  



`  `// If we don't have thread safe buffers, we need to synchronize  

`  `// with the worker thread and deliver them when they are available  

`  `// and then let it know that we did so  

`  `if (m\_bSyncToProcess) {  

`    `while (!m\_evDecodeDone.Check()) {  

`      `m\_evSample.Wait();  

`      `ProcessOutput();  

`    `}  

`  `}  



`  `ProcessOutput();  



`  `return S\_OK;  

}  

这个方法乍一看感觉很抽象，好像没看见直接调用任何解码的函数。如果LAVVideo的封装的ffmpeg的libavcodec的话，应该是最终调用avcodec\_decode\_video2()才对啊。。。先来看看CDecodeThread这个类的定义吧！

DecodeThread.h

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)

/\* 雷霄骅 

` `\* 中国传媒大学/数字电视技术 

` `\* leixiaohua1020@126.com 

` `\* 

` `\*/  

/\* 

` `\*      Copyright (C) 2010-2013 Hendrik Leppkes 

` `\*      http://www.1f0.de 

` `\* 

` `\*  This program is free software; you can redistribute it and/or modify 

` `\*  it under the terms of the GNU General Public License as published by 

` `\*  the Free Software Foundation; either version 2 of the License, or 

` `\*  (at your option) any later version. 

` `\* 

` `\*  This program is distributed in the hope that it will be useful, 

` `\*  but WITHOUT ANY WARRANTY; without even the implied warranty of 

` `\*  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the 

` `\*  GNU General Public License for more details. 

` `\* 

` `\*  You should have received a copy of the GNU General Public License along 

` `\*  with this program; if not, write to the Free Software Foundation, Inc., 

` `\*  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. 

` `\*/  



#pragma once  



#include "decoders/ILAVDecoder.h"  

#include "SynchronizedQueue.h"  



class CLAVVideo;  



class CDecodeThread : public ILAVVideoCallback, protected CAMThread, protected CCritSec  

{  

public:  

`  `CDecodeThread(CLAVVideo \*pLAVVideo);  

`  `~CDecodeThread();  



`  `// Parts of ILAVDecoder  

`  `STDMETHODIMP\_(const WCHAR\*) GetDecoderName() { return m\_pDecoder ? m\_pDecoder->GetDecoderName() : NULL; }  

`  `STDMETHODIMP\_(long) GetBufferCount() { return m\_pDecoder ? m\_pDecoder->GetBufferCount() : 4; }  

`  `STDMETHODIMP\_(BOOL) IsInterlaced() { return m\_pDecoder ? m\_pDecoder->IsInterlaced() : TRUE; }  

`  `STDMETHODIMP GetPixelFormat(LAVPixelFormat \*pPix, int \*pBpp) { ASSERT(m\_pDecoder); return m\_pDecoder->GetPixelFormat(pPix, pBpp); }  

`  `STDMETHODIMP\_(REFERENCE\_TIME) GetFrameDuration() { ASSERT(m\_pDecoder); return m\_pDecoder->GetFrameDuration(); }  

`  `STDMETHODIMP HasThreadSafeBuffers() { return m\_pDecoder ? m\_pDecoder->HasThreadSafeBuffers() : S\_FALSE; }  





`  `STDMETHODIMP CreateDecoder(const CMediaType \*pmt, AVCodecID codec);  

`  `STDMETHODIMP Close();  

`  `//解码线程的解码函数  

`  `STDMETHODIMP Decode(IMediaSample \*pSample);  

`  `STDMETHODIMP Flush();  

`  `STDMETHODIMP EndOfStream();  



`  `STDMETHODIMP InitAllocator(IMemAllocator \*\*ppAlloc);  

`  `STDMETHODIMP PostConnect(IPin \*pPin);  



`  `STDMETHODIMP\_(BOOL) IsHWDecoderActive() { return m\_bHWDecoder; }  



`  `// ILAVVideoCallback  

`  `STDMETHODIMP AllocateFrame(LAVFrame \*\*ppFrame);  

`  `STDMETHODIMP ReleaseFrame(LAVFrame \*\*ppFrame);  

`  `STDMETHODIMP Deliver(LAVFrame \*pFrame);  

`  `STDMETHODIMP\_(LPWSTR) GetFileExtension();  

`  `STDMETHODIMP\_(BOOL) FilterInGraph(PIN\_DIRECTION dir, const GUID &clsid);  

`  `STDMETHODIMP\_(DWORD) GetDecodeFlags();  

`  `STDMETHODIMP\_(CMediaType&) GetInputMediaType();  

`  `STDMETHODIMP GetLAVPinInfo(LAVPinInfo &info);  

`  `STDMETHODIMP\_(CBasePin\*) GetOutputPin();  

`  `STDMETHODIMP\_(CMediaType&) GetOutputMediaType();  

`  `STDMETHODIMP DVDStripPacket(BYTE\*& p, long& len);  

`  `STDMETHODIMP\_(LAVFrame\*) GetFlushFrame();  

`  `STDMETHODIMP ReleaseAllDXVAResources();  



protected:  

`    `//包含了对进程的各种操作，重要  

`  `DWORD ThreadProc();  



private:  

`  `STDMETHODIMP CreateDecoderInternal(const CMediaType \*pmt, AVCodecID codec);  

`  `STDMETHODIMP PostConnectInternal(IPin \*pPin);  



`  `STDMETHODIMP DecodeInternal(IMediaSample \*pSample);  

`  `STDMETHODIMP ClearQueues();  

`  `STDMETHODIMP ProcessOutput();  



`  `bool HasSample();  

`  `void PutSample(IMediaSample \*pSample);  

`  `IMediaSample\* GetSample();  

`  `void ReleaseSample();  



`  `bool CheckForEndOfSequence(IMediaSample \*pSample);  



private:  

//各种对进程进行的操作  

`  `enum {CMD\_CREATE\_DECODER, CMD\_CLOSE\_DECODER, CMD\_FLUSH, CMD\_EOS, CMD\_EXIT, CMD\_INIT\_ALLOCATOR, CMD\_POST\_CONNECT, CMD\_REINIT};  

`  `//注意DecodeThread像是一个处于中间位置的东西  

`  `//连接了Filter核心类CLAVVideo和解码器的接口ILAVDecoder  

`  `CLAVVideo    \*m\_pLAVVideo;  

`  `ILAVDecoder  \*m\_pDecoder;  



`  `AVCodecID    m\_Codec;  



`  `BOOL         m\_bHWDecoder;  

`  `BOOL         m\_bHWDecoderFailed;  



`  `BOOL         m\_bSyncToProcess;  

`  `BOOL         m\_bDecoderNeedsReInit;  

`  `CAMEvent     m\_evInput;  

`  `CAMEvent     m\_evDeliver;  

`  `CAMEvent     m\_evSample;  

`  `CAMEvent     m\_evDecodeDone;  

`  `CAMEvent     m\_evEOSDone;  



`  `CCritSec     m\_ThreadCritSec;  

`  `struct {  

`    `const CMediaType \*pmt;  

`    `AVCodecID codec;  

`    `IMemAllocator \*\*allocator;  

`    `IPin \*pin;  

`  `} m\_ThreadCallContext;  

`  `CSynchronizedQueue<LAVFrame \*> m\_Output;  



`  `CCritSec     m\_SampleCritSec;  

`  `IMediaSample \*m\_NextSample;  



`  `IMediaSample \*m\_TempSample[2];  

`  `IMediaSample \*m\_FailedSample;  



`  `std::wstring m\_processName;  

};  

从名字上我们可以判断，这个类用于管理解码的线程。在这里我们关注该类里面的两个指针变量：  CLAVVideo    \*m\_pLAVVideo;

`  `ILAVDecoder  \*m\_pDecoder;

其中第一个指针变量就是这个工程中最核心的类CLAVVideo，而第二个指针变量则是解码器的接口。通过这个接口就可以调用具体解码器的相应方法了。（注：在源代码中发现，解码器不光包含libavcodec，也可以是wmv9等等，换句话说，是可以扩展其他种类的解码器的。不过就目前的情况来看，lavvideo似乎不如ffdshow支持的解码器种类多）

该类里面还有一个函数：

ThreadProc()

该函数中包含了对线程的各种操作，其中包含调用了ILAVDecoder接口的各种方法：

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/13022201#)

//包含了对进程的各种操作  

DWORD CDecodeThread::ThreadProc()  

{  

`  `HRESULT hr;  

`  `DWORD cmd;  



`  `BOOL bEOS = FALSE;  

`  `BOOL bReinit = FALSE;  



`  `SetThreadName(-1, "LAVVideo Decode Thread");  



`  `HANDLE hWaitEvents[2] = { GetRequestHandle(), m\_evInput };  

`  `//不停转圈，永不休止  

`  `while(1) {  

`    `if (!bEOS && !bReinit) {  

`      `// Wait for either an input sample, or an request  

`      `WaitForMultipleObjects(2, hWaitEvents, FALSE, INFINITE);  

`    `}  

`    `//根据操作命令的不同  

`    `if (CheckRequest(&cmd)) {  

`      `switch (cmd) {  

`          `//创建解码器  

`      `case CMD\_CREATE\_DECODER:  

`        `{  

`          `CAutoLock lock(&m\_ThreadCritSec);  

`          `//创建  

`          `hr = CreateDecoderInternal(m\_ThreadCallContext.pmt, m\_ThreadCallContext.codec);  

`          `Reply(hr);  



`          `m\_ThreadCallContext.pmt = NULL;  

`        `}  

`        `break;  

`      `case CMD\_CLOSE\_DECODER:  

`        `{  

`            `//关闭  

`          `ClearQueues();  

`          `SAFE\_DELETE(m\_pDecoder);  

`          `Reply(S\_OK);  

`        `}  

`        `break;  

`      `case CMD\_FLUSH:  

`        `{  

`            `//清楚  

`          `ClearQueues();  

`          `m\_pDecoder->Flush();  

`          `Reply(S\_OK);  

`        `}  

`        `break;  

`      `case CMD\_EOS:  

`        `{  

`          `bEOS = TRUE;  

`          `m\_evEOSDone.Reset();  

`          `Reply(S\_OK);  

`        `}  

`        `break;  

`      `case CMD\_EXIT:  

`        `{  

`            `//退出  

`          `Reply(S\_OK);  

`          `return 0;  

`        `}  

`        `break;  

`      `case CMD\_INIT\_ALLOCATOR:  

`        `{  

`          `CAutoLock lock(&m\_ThreadCritSec);  

`          `hr = m\_pDecoder->InitAllocator(m\_ThreadCallContext.allocator);  

`          `Reply(hr);  



`          `m\_ThreadCallContext.allocator = NULL;  

`        `}  

`        `break;  

`      `case CMD\_POST\_CONNECT:  

`        `{  

`          `CAutoLock lock(&m\_ThreadCritSec);  

`          `hr = PostConnectInternal(m\_ThreadCallContext.pin);  

`          `Reply(hr);  



`          `m\_ThreadCallContext.pin = NULL;  

`        `}  

`        `break;  

`      `case CMD\_REINIT:  

`        `{  

`            `//重启  

`          `CMediaType &mt = m\_pLAVVideo->GetInputMediaType();  

`          `CreateDecoderInternal(&mt, m\_Codec);  

`          `m\_TempSample[1] = m\_NextSample;  

`          `m\_NextSample = m\_FailedSample;  

`          `m\_FailedSample = NULL;  

`          `bReinit = TRUE;  

`          `m\_evEOSDone.Reset();  

`          `Reply(S\_OK);  

`          `m\_bDecoderNeedsReInit = FALSE;  

`        `}  

`        `break;  

`      `default:  

`        `ASSERT(0);  

`      `}  

`    `}  



`    `if (m\_bDecoderNeedsReInit) {  

`      `m\_evInput.Reset();  

`      `continue;  

`    `}  



`    `if (bReinit && !m\_NextSample) {  

`      `if (m\_TempSample[0]) {  

`        `m\_NextSample = m\_TempSample[0];  

`        `m\_TempSample[0] = NULL;  

`      `} else if (m\_TempSample[1]) {  

`        `m\_NextSample = m\_TempSample[1];  

`        `m\_TempSample[1] = NULL;  

`      `} else {  

`        `bReinit = FALSE;  

`        `m\_evEOSDone.Set();  

`        `m\_evSample.Set();  

`        `continue;  

`      `}  

`    `}  

`    `//获得一份数据  

`    `IMediaSample \*pSample = GetSample();  

`    `if (!pSample) {  

`      `// Process the EOS now that the sample queue is empty  

`      `if (bEOS) {  

`        `bEOS = FALSE;  

`        `m\_pDecoder->EndOfStream();  

`        `m\_evEOSDone.Set();  

`        `m\_evSample.Set();  

`      `}  

`      `continue;  

`    `}  

`    `//解码  

`    `DecodeInternal(pSample);  



`    `// Release the sample  

`    `//释放  

`    `SafeRelease(&pSample);  



`    `// Indicates we're done decoding this sample  

`    `m\_evDecodeDone.Set();  



`    `// Set the Sample Event to unblock any waiting threads  

`    `m\_evSample.Set();  

`  `}  



`  `return 0;  

}  

先分析到这里了，至于ILAVDecoder接口方面的东西下篇文章再写。
### [**LAV Filter 源代码分析 4： LAV Video （2）**](http://blog.csdn.net/leixiaohua1020/article/details/13272409)
文章中提到LAVVideo主要通过CDecodeThread这个类进行解码线程的管理，其中有一个关键的管理函数：ThreadProc()，包含了对解码线程的各种操作。函数如下所示：

//包含了对进程的各种操作  

DWORD CDecodeThread::ThreadProc()  

{  

`  `HRESULT hr;  

`  `DWORD cmd;  



`  `BOOL bEOS = FALSE;  

`  `BOOL bReinit = FALSE;  



`  `SetThreadName(-1, "LAVVideo Decode Thread");  



`  `HANDLE hWaitEvents[2] = { GetRequestHandle(), m\_evInput };  

`  `//不停转圈，永不休止  

`  `while(1) {  

`    `if (!bEOS && !bReinit) {  

`      `// Wait for either an input sample, or an request  

`      `WaitForMultipleObjects(2, hWaitEvents, FALSE, INFINITE);  

`    `}  

`    `//根据操作命令的不同  

`    `if (CheckRequest(&cmd)) {  

`      `switch (cmd) {  

`          `//创建解码器  

`      `case CMD\_CREATE\_DECODER:  

`        `{  

`          `CAutoLock lock(&m\_ThreadCritSec);  

`          `//创建  

`          `hr = CreateDecoderInternal(m\_ThreadCallContext.pmt, m\_ThreadCallContext.codec);  

`          `Reply(hr);  



`          `m\_ThreadCallContext.pmt = NULL;  

`        `}  

`        `break;  

`      `case CMD\_CLOSE\_DECODER:  

`        `{  

`            `//关闭  

`          `ClearQueues();  

`          `SAFE\_DELETE(m\_pDecoder);  

`          `Reply(S\_OK);  

`        `}  

`        `break;  

`      `case CMD\_FLUSH:  

`        `{  

`            `//清楚  

`          `ClearQueues();  

`          `m\_pDecoder->Flush();  

`          `Reply(S\_OK);  

`        `}  

`        `break;  

`      `case CMD\_EOS:  

`        `{  

`          `bEOS = TRUE;  

`          `m\_evEOSDone.Reset();  

`          `Reply(S\_OK);  

`        `}  

`        `break;  

`      `case CMD\_EXIT:  

`        `{  

`            `//退出  

`          `Reply(S\_OK);  

`          `return 0;  

`        `}  

`        `break;  

`      `case CMD\_INIT\_ALLOCATOR:  

`        `{  

`          `CAutoLock lock(&m\_ThreadCritSec);  

`          `hr = m\_pDecoder->InitAllocator(m\_ThreadCallContext.allocator);  

`          `Reply(hr);  



`          `m\_ThreadCallContext.allocator = NULL;  

`        `}  

`        `break;  

`      `case CMD\_POST\_CONNECT:  

`        `{  

`          `CAutoLock lock(&m\_ThreadCritSec);  

`          `hr = PostConnectInternal(m\_ThreadCallContext.pin);  

`          `Reply(hr);  



`          `m\_ThreadCallContext.pin = NULL;  

`        `}  

`        `break;  

`      `case CMD\_REINIT:  

`        `{  

`            `//重启  

`          `CMediaType &mt = m\_pLAVVideo->GetInputMediaType();  

`          `CreateDecoderInternal(&mt, m\_Codec);  

`          `m\_TempSample[1] = m\_NextSample;  

`          `m\_NextSample = m\_FailedSample;  

`          `m\_FailedSample = NULL;  

`          `bReinit = TRUE;  

`          `m\_evEOSDone.Reset();  

`          `Reply(S\_OK);  

`          `m\_bDecoderNeedsReInit = FALSE;  

`        `}  

`        `break;  

`      `default:  

`        `ASSERT(0);  

`      `}  

`    `}  



`    `if (m\_bDecoderNeedsReInit) {  

`      `m\_evInput.Reset();  

`      `continue;  

`    `}  



`    `if (bReinit && !m\_NextSample) {  

`      `if (m\_TempSample[0]) {  

`        `m\_NextSample = m\_TempSample[0];  

`        `m\_TempSample[0] = NULL;  

`      `} else if (m\_TempSample[1]) {  

`        `m\_NextSample = m\_TempSample[1];  

`        `m\_TempSample[1] = NULL;  

`      `} else {  

`        `bReinit = FALSE;  

`        `m\_evEOSDone.Set();  

`        `m\_evSample.Set();  

`        `continue;  

`      `}  

`    `}  

`    `//获得一份数据  

`    `IMediaSample \*pSample = GetSample();  

`    `if (!pSample) {  

`      `// Process the EOS now that the sample queue is empty  

`      `if (bEOS) {  

`        `bEOS = FALSE;  

`        `m\_pDecoder->EndOfStream();  

`        `m\_evEOSDone.Set();  

`        `m\_evSample.Set();  

`      `}  

`      `continue;  

`    `}  

`    `//解码  

`    `DecodeInternal(pSample);  



`    `// Release the sample  

`    `//释放  

`    `SafeRelease(&pSample);  



`    `// Indicates we're done decoding this sample  

`    `m\_evDecodeDone.Set();  



`    `// Set the Sample Event to unblock any waiting threads  

`    `m\_evSample.Set();  

`  `}  



`  `return 0;  

}  

该函数中，DecodeInternal(pSample)为实际上真正具有解码功能的函数，来看看它的源代码吧：

STDMETHODIMP CDecodeThread::DecodeInternal(IMediaSample \*pSample)  

{  

`  `HRESULT hr = S\_OK;  



`  `if (!m\_pDecoder)  

`    `return E\_UNEXPECTED;  

`  `//调用接口进行解码  

`  `hr = m\_pDecoder->Decode(pSample);  



`  `// If a hardware decoder indicates a hard failure, we switch back to software  

`  `// This is used to indicate incompatible media  

`  `if (FAILED(hr) && m\_bHWDecoder) {  

`    `DbgLog((LOG\_TRACE, 10, L"::Receive(): Hardware decoder indicates failure, switching back to software"));  

`    `m\_bHWDecoderFailed = TRUE;  



`    `// Store the failed sample for re-try in a moment  

`    `m\_FailedSample = pSample;  

`    `m\_FailedSample->AddRef();  



`    `// Schedule a re-init when the main thread goes there the next time  

`    `m\_bDecoderNeedsReInit = TRUE;  



`    `// Make room in the sample buffer, to ensure the main thread can get in  

`    `m\_TempSample[0] = GetSample();  

`  `}  



`  `return S\_OK;  

}  

该函数比较简短，从源代码中可以看出，调用了m\_pDecoder的Decode()方法。其中m\_pDecoder为ILAVDecoder类型的指针，而ILAVDecoder是一个接口，并不包含实际的方法，如下所示。注意，从程序注释中可以看出，每一个解码器都需要实现该接口规定的函数。

//接口  

interface ILAVDecoder  

{  

`  `/\*\* 

`   `\* Virtual destructor 

`   `\*/  

`  `virtual ~ILAVDecoder(void) {};  



`  `/\*\* 

`   `\* Initialize interfaces with the LAV Video core 

`   `\* This function should also be used to create all interfaces with external DLLs 

`   `\* 

`   `\* @param pSettings reference to the settings interface 

`   `\* @param pCallback reference to the callback interface 

`   `\* @return S\_OK on success, error code if this decoder is lacking an external support dll 

`   `\*/  

`  `STDMETHOD(InitInterfaces)(ILAVVideoSettings \*pSettings, ILAVVideoCallback \*pCallback) PURE;  



`  `/\*\* 

`   `\* Check if the decoder is functional 

`   `\*/  

`  `STDMETHOD(Check)() PURE;  



`  `/\*\* 

`   `\* Initialize the codec to decode a stream specified by codec and pmt. 

`   `\* 

`   `\* @param codec Codec Id 

`   `\* @param pmt DirectShow Media Type 

`   `\* @return S\_OK on success, an error code otherwise 

`   `\*/  

`  `STDMETHOD(InitDecoder)(AVCodecID codec, const CMediaType \*pmt) PURE;  



`  `/\*\* 

`   `\* Decode a frame. 

`   `\* 

`   `\* @param pSample Media Sample to decode 

`   `\* @return S\_OK if decoding was successfull, S\_FALSE if no frame could be extracted, an error code if the decoder is not compatible with the bitstream 

`   `\* 

`   `\* Note: When returning an actual error code, the filter will switch to the fallback software decoder! This should only be used for catastrophic failures, 

`   `\* like trying to decode a unsupported format on a hardware decoder. 

`   `\*/  

`  `STDMETHOD(Decode)(IMediaSample \*pSample) PURE;  



`  `/\*\* 

`   `\* Flush the decoder after a seek. 

`   `\* The decoder should discard any remaining data. 

`   `\* 

`   `\* @return unused 

`   `\*/  

`  `STDMETHOD(Flush)() PURE;  



`  `/\*\* 

`   `\* End of Stream 

`   `\* The decoder is asked to output any buffered frames for immediate delivery 

`   `\* 

`   `\* @return unused 

`   `\*/  

`  `STDMETHOD(EndOfStream)() PURE;  



`  `/\*\* 

`   `\* Query the decoder for the current pixel format 

`   `\* Mostly used by the media type creation logic before playback starts 

`   `\* 

`   `\* @return the pixel format used in the decoding process 

`   `\*/  

`  `STDMETHOD(GetPixelFormat)(LAVPixelFormat \*pPix, int \*pBpp) PURE;  



`  `/\*\* 

`   `\* Get the frame duration. 

`   `\* 

`   `\* This function is not mandatory, and if you cannot provide any specific duration, return 0. 

`   `\*/  

`  `STDMETHOD\_(REFERENCE\_TIME, GetFrameDuration)() PURE;  



`  `/\*\* 

`   `\* Query whether the format can potentially be interlaced. 

`   `\* This function should return false if the format can 100% not be interlaced, and true if it can be interlaced (but also progressive). 

`   `\*/  

`  `STDMETHOD\_(BOOL, IsInterlaced)() PURE;  



`  `/\*\* 

`   `\* Allows the decoder to handle an allocator. 

`   `\* Used by DXVA2 decoding 

`   `\*/  

`  `STDMETHOD(InitAllocator)(IMemAllocator \*\*ppAlloc) PURE;  



`  `/\*\* 

`   `\* Function called after connection is established, with the pin as argument 

`   `\*/  

`  `STDMETHOD(PostConnect)(IPin \*pPin) PURE;  



`  `/\*\* 

`   `\* Get the number of sample buffers optimal for this decoder 

`   `\*/  

`  `STDMETHOD\_(long, GetBufferCount)() PURE;  



`  `/\*\* 

`   `\* Get the name of the decoder 

`   `\*/  

`  `STDMETHOD\_(const WCHAR\*, GetDecoderName)() PURE;  



`  `/\*\* 

`   `\* Get whether the decoder outputs thread-safe buffers 

`   `\*/  

`  `STDMETHOD(HasThreadSafeBuffers)() PURE;  



`  `/\*\* 

`   `\* Get whether the decoder should sync to the main thread 

`   `\*/  

`  `STDMETHOD(SyncToProcessThread)() PURE;  

};  

下面来看看封装libavcodec库的类吧，该类的定义位于decoders文件夹下，名为avcodec.h，如图所示：![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.161.jpeg)

该类名字叫CDecAvcodec，其继承了CDecBase。而CDecBase继承了ILAVDecoder。

/\* 

` `\*      Copyright (C) 2010-2013 Hendrik Leppkes 

` `\*      http://www.1f0.de 

` `\* 

` `\*  This program is free software; you can redistribute it and/or modify 

` `\*  it under the terms of the GNU General Public License as published by 

` `\*  the Free Software Foundation; either version 2 of the License, or 

` `\*  (at your option) any later version. 

` `\* 

` `\*  This program is distributed in the hope that it will be useful, 

` `\*  but WITHOUT ANY WARRANTY; without even the implied warranty of 

` `\*  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the 

` `\*  GNU General Public License for more details. 

` `\* 

` `\*  You should have received a copy of the GNU General Public License along 

` `\*  with this program; if not, write to the Free Software Foundation, Inc., 

` `\*  51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA. 

` `\*/  



#pragma once  



#include "DecBase.h"  

#include "H264RandomAccess.h"  



#include <map>  



#define AVCODEC\_MAX\_THREADS 16  



typedef struct {  

`  `REFERENCE\_TIME rtStart;  

`  `REFERENCE\_TIME rtStop;  

} TimingCache;  

//解码器（AVCODEC）（其实还有WMV9，CUVID等）  

class CDecAvcodec : public CDecBase  

{  

public:  

`  `CDecAvcodec(void);  

`  `virtual ~CDecAvcodec(void);  



`  `// ILAVDecoder  

`  `STDMETHODIMP InitDecoder(AVCodecID codec, const CMediaType \*pmt);  

`  `//解码  

`  `STDMETHODIMP Decode(const BYTE \*buffer, int buflen, REFERENCE\_TIME rtStart, REFERENCE\_TIME rtStop, BOOL bSyncPoint, BOOL bDiscontinuity);  

`  `STDMETHODIMP Flush();  

`  `STDMETHODIMP EndOfStream();  

`  `STDMETHODIMP GetPixelFormat(LAVPixelFormat \*pPix, int \*pBpp);  

`  `STDMETHODIMP\_(REFERENCE\_TIME) GetFrameDuration();  

`  `STDMETHODIMP\_(BOOL) IsInterlaced();  

`  `STDMETHODIMP\_(const WCHAR\*) GetDecoderName() { return L"avcodec"; }  

`  `STDMETHODIMP HasThreadSafeBuffers() { return S\_OK; }  

`  `STDMETHODIMP SyncToProcessThread() { return m\_pAVCtx && m\_pAVCtx->thread\_count > 1 ? S\_OK : S\_FALSE; }  



`  `// CDecBase  

`  `STDMETHODIMP Init();  



protected:  

`  `virtual HRESULT AdditionaDecoderInit() { return S\_FALSE; }  

`  `virtual HRESULT PostDecode() { return S\_FALSE; }  

`  `virtual HRESULT HandleDXVA2Frame(LAVFrame \*pFrame) { return S\_FALSE; }  

`  `//销毁解码器，各种Free  

`  `STDMETHODIMP DestroyDecoder();  



private:  

`  `STDMETHODIMP ConvertPixFmt(AVFrame \*pFrame, LAVFrame \*pOutFrame);  



protected:  

`  `AVCodecContext       \*m\_pAVCtx;  

`  `AVFrame              \*m\_pFrame;  

`  `AVCodecID            m\_nCodecId;  

`  `BOOL                 m\_bDXVA;  



private:  

`  `AVCodec              \*m\_pAVCodec;  

`  `AVCodecParserContext \*m\_pParser;  



`  `BYTE                 \*m\_pFFBuffer;  

`  `BYTE                 \*m\_pFFBuffer2;  

`  `int                  m\_nFFBufferSize;  

`  `int                  m\_nFFBufferSize2;  



`  `SwsContext           \*m\_pSwsContext;  



`  `CH264RandomAccess    m\_h264RandomAccess;  



`  `BOOL                 m\_bNoBufferConsumption;  

`  `BOOL                 m\_bHasPalette;  



`  `// Timing settings  

`  `BOOL                 m\_bFFReordering;  

`  `BOOL                 m\_bCalculateStopTime;  

`  `BOOL                 m\_bRVDropBFrameTimings;  

`  `BOOL                 m\_bInputPadded;  



`  `BOOL                 m\_bBFrameDelay;  

`  `TimingCache          m\_tcBFrameDelay[2];  

`  `int                  m\_nBFramePos;  



`  `TimingCache          m\_tcThreadBuffer[AVCODEC\_MAX\_THREADS];  

`  `int                  m\_CurrentThread;  



`  `REFERENCE\_TIME       m\_rtStartCache;  

`  `BOOL                 m\_bResumeAtKeyFrame;  

`  `BOOL                 m\_bWaitingForKeyFrame;  

`  `int                  m\_iInterlaced;  

};  

从CDecAvcodec类的定义可以看出，包含了各种功能的函数。首先我们看看初始化函数Init()

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/13272409#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/13272409#)

// ILAVDecoder  

STDMETHODIMP CDecAvcodec::Init()  

{  

#ifdef DEBUG  

`  `DbgSetModuleLevel (LOG\_CUSTOM1, DWORD\_MAX); // FFMPEG messages use custom1  

`  `av\_log\_set\_callback(lavf\_log\_callback);  

#else  

`  `av\_log\_set\_callback(NULL);  

#endif  

`  `//注册  

`  `avcodec\_register\_all();  

`  `return S\_OK;  

}  

可见其调用了ffmpeg的API函数avcodec\_register\_all()进行了解码器的注册。

我们再来看看其解码函数Decode()：

//解码  

STDMETHODIMP CDecAvcodec::Decode(const BYTE \*buffer, int buflen, REFERENCE\_TIME rtStartIn, REFERENCE\_TIME rtStopIn, BOOL bSyncPoint, BOOL bDiscontinuity)  

{  

`  `int     got\_picture = 0;  

`  `int     used\_bytes  = 0;  

`  `BOOL    bParserFrame = FALSE;  

`  `BOOL    bFlush = (buffer == NULL);  

`  `BOOL    bEndOfSequence = FALSE;  

`  `//初始化Packet  

`  `AVPacket avpkt;  

`  `av\_init\_packet(&avpkt);  



`  `if (m\_pAVCtx->active\_thread\_type & FF\_THREAD\_FRAME) {  

`    `if (!m\_bFFReordering) {  

`      `m\_tcThreadBuffer[m\_CurrentThread].rtStart = rtStartIn;  

`      `m\_tcThreadBuffer[m\_CurrentThread].rtStop  = rtStopIn;  

`    `}  



`    `m\_CurrentThread = (m\_CurrentThread + 1) % m\_pAVCtx->thread\_count;  

`  `} else if (m\_bBFrameDelay) {  

`    `m\_tcBFrameDelay[m\_nBFramePos].rtStart = rtStartIn;  

`    `m\_tcBFrameDelay[m\_nBFramePos].rtStop = rtStopIn;  

`    `m\_nBFramePos = !m\_nBFramePos;  

`  `}  



`  `uint8\_t \*pDataBuffer = NULL;  

`  `if (!bFlush && buflen > 0) {  

`    `if (!m\_bInputPadded && (!(m\_pAVCtx->active\_thread\_type & FF\_THREAD\_FRAME) || m\_pParser)) {  

`      `// Copy bitstream into temporary buffer to ensure overread protection  

`      `// Verify buffer size  

`      `if (buflen > m\_nFFBufferSize) {  

`        `m\_nFFBufferSize = buflen;  

`        `m\_pFFBuffer = (BYTE \*)av\_realloc\_f(m\_pFFBuffer, m\_nFFBufferSize + FF\_INPUT\_BUFFER\_PADDING\_SIZE, 1);  

`        `if (!m\_pFFBuffer) {  

`          `m\_nFFBufferSize = 0;  

`          `return E\_OUTOFMEMORY;  

`        `}  

`      `}  



`      `memcpy(m\_pFFBuffer, buffer, buflen);  

`      `memset(m\_pFFBuffer+buflen, 0, FF\_INPUT\_BUFFER\_PADDING\_SIZE);  

`      `pDataBuffer = m\_pFFBuffer;  

`    `} else {  

`      `pDataBuffer = (uint8\_t \*)buffer;  

`    `}  



`    `if (m\_nCodecId == AV\_CODEC\_ID\_H264) {  

`      `BOOL bRecovered = m\_h264RandomAccess.searchRecoveryPoint(pDataBuffer, buflen);  

`      `if (!bRecovered) {  

`        `return S\_OK;  

`      `}  

`    `} else if (m\_nCodecId == AV\_CODEC\_ID\_VP8 && m\_bWaitingForKeyFrame) {  

`      `if (!(pDataBuffer[0] & 1)) {  

`        `DbgLog((LOG\_TRACE, 10, L"::Decode(): Found VP8 key-frame, resuming decoding"));  

`        `m\_bWaitingForKeyFrame = FALSE;  

`      `} else {  

`        `return S\_OK;  

`      `}  

`    `}  

`  `}  



`  `while (buflen > 0 || bFlush) {  

`    `REFERENCE\_TIME rtStart = rtStartIn, rtStop = rtStopIn;  



`    `if (!bFlush) {  

`        `//设置AVPacket中的数据  

`      `avpkt.data = pDataBuffer;  

`      `avpkt.size = buflen;  

`      `avpkt.pts = rtStartIn;  

`      `if (rtStartIn != AV\_NOPTS\_VALUE && rtStopIn != AV\_NOPTS\_VALUE)  

`        `avpkt.duration = (int)(rtStopIn - rtStartIn);  

`      `else  

`        `avpkt.duration = 0;  

`      `avpkt.flags = AV\_PKT\_FLAG\_KEY;  



`      `if (m\_bHasPalette) {  

`        `m\_bHasPalette = FALSE;  

`        `uint32\_t \*pal = (uint32\_t \*)av\_packet\_new\_side\_data(&avpkt, AV\_PKT\_DATA\_PALETTE, AVPALETTE\_SIZE);  

`        `int pal\_size = FFMIN((1 << m\_pAVCtx->bits\_per\_coded\_sample) << 2, m\_pAVCtx->extradata\_size);  

`        `uint8\_t \*pal\_src = m\_pAVCtx->extradata + m\_pAVCtx->extradata\_size - pal\_size;  



`        `for (int i = 0; i < pal\_size/4; i++)  

`          `pal[i] = 0xFF<<24 | AV\_RL32(pal\_src+4\*i);  

`      `}  

`    `} else {  

`      `avpkt.data = NULL;  

`      `avpkt.size = 0;  

`    `}  



`    `// Parse the data if a parser is present  

`    `// This is mandatory for MPEG-1/2  

`    `// 不一定需要  

`    `if (m\_pParser) {  

`      `BYTE \*pOut = NULL;  

`      `int pOut\_size = 0;  



`      `used\_bytes = av\_parser\_parse2(m\_pParser, m\_pAVCtx, &pOut, &pOut\_size, avpkt.data, avpkt.size, AV\_NOPTS\_VALUE, AV\_NOPTS\_VALUE, 0);  



`      `if (used\_bytes == 0 && pOut\_size == 0 && !bFlush) {  

`        `DbgLog((LOG\_TRACE, 50, L"::Decode() - could not process buffer, starving?"));  

`        `break;  

`      `}  



`      `// Update start time cache  

`      `// If more data was read then output, update the cache (incomplete frame)  

`      `// If output is bigger, a frame was completed, update the actual rtStart with the cached value, and then overwrite the cache  

`      `if (used\_bytes > pOut\_size) {  

`        `if (rtStartIn != AV\_NOPTS\_VALUE)  

`          `m\_rtStartCache = rtStartIn;  

`      `} else if (used\_bytes == pOut\_size || ((used\_bytes + 9) == pOut\_size)) {  

`        `// Why +9 above?  

`        `// Well, apparently there are some broken MKV muxers that like to mux the MPEG-2 PICTURE\_START\_CODE block (which is 9 bytes) in the package with the previous frame  

`        `// This would cause the frame timestamps to be delayed by one frame exactly, and cause timestamp reordering to go wrong.  

`        `// So instead of failing on those samples, lets just assume that 9 bytes are that case exactly.  

`        `m\_rtStartCache = rtStartIn = AV\_NOPTS\_VALUE;  

`      `} else if (pOut\_size > used\_bytes) {  

`        `rtStart = m\_rtStartCache;  

`        `m\_rtStartCache = rtStartIn;  

`        `// The value was used once, don't use it for multiple frames, that ends up in weird timings  

`        `rtStartIn = AV\_NOPTS\_VALUE;  

`      `}  



`       `bParserFrame = (pOut\_size > 0);  



`      `if (pOut\_size > 0 || bFlush) {  



`        `if (pOut && pOut\_size > 0) {  

`          `if (pOut\_size > m\_nFFBufferSize2) {  

`            `m\_nFFBufferSize2    = pOut\_size;  

`            `m\_pFFBuffer2 = (BYTE \*)av\_realloc\_f(m\_pFFBuffer2, m\_nFFBufferSize2 + FF\_INPUT\_BUFFER\_PADDING\_SIZE, 1);  

`            `if (!m\_pFFBuffer2) {  

`              `m\_nFFBufferSize2 = 0;  

`              `return E\_OUTOFMEMORY;  

`            `}  

`          `}  

`          `memcpy(m\_pFFBuffer2, pOut, pOut\_size);  

`          `memset(m\_pFFBuffer2+pOut\_size, 0, FF\_INPUT\_BUFFER\_PADDING\_SIZE);  



`          `avpkt.data = m\_pFFBuffer2;  

`          `avpkt.size = pOut\_size;  

`          `avpkt.pts = rtStart;  

`          `avpkt.duration = 0;  



`          `const uint8\_t \*eosmarker = CheckForEndOfSequence(m\_nCodecId, avpkt.data, avpkt.size, &m\_MpegParserState);  

`          `if (eosmarker) {  

`            `bEndOfSequence = TRUE;  

`          `}  

`        `} else {  

`          `avpkt.data = NULL;  

`          `avpkt.size = 0;  

`        `}  

`        `//真正的解码  

`        `int ret2 = avcodec\_decode\_video2 (m\_pAVCtx, m\_pFrame, &got\_picture, &avpkt);  

`        `if (ret2 < 0) {  

`          `DbgLog((LOG\_TRACE, 50, L"::Decode() - decoding failed despite successfull parsing"));  

`          `got\_picture = 0;  

`        `}  

`      `} else {  

`        `got\_picture = 0;  

`      `}  

`    `} else {  

`      `used\_bytes = avcodec\_decode\_video2 (m\_pAVCtx, m\_pFrame, &got\_picture, &avpkt);  

`    `}  



`    `if (FAILED(PostDecode())) {  

`      `av\_frame\_unref(m\_pFrame);  

`      `return E\_FAIL;  

`    `}  



`    `// Decoding of this frame failed ... oh well!  

`    `if (used\_bytes < 0) {  

`      `av\_frame\_unref(m\_pFrame);  

`      `return S\_OK;  

`    `}  



`    `// When Frame Threading, we won't know how much data has been consumed, so it by default eats everything.  

`    `// In addition, if no data got consumed, and no picture was extracted, the frame probably isn't all that useufl.  

`    `// The MJPEB decoder is somewhat buggy and doesn't let us know how much data was consumed really...  

`    `if ((!m\_pParser && (m\_pAVCtx->active\_thread\_type & FF\_THREAD\_FRAME || (!got\_picture && used\_bytes == 0))) || m\_bNoBufferConsumption || bFlush) {  

`      `buflen = 0;  

`    `} else {  

`      `buflen -= used\_bytes;  

`      `pDataBuffer += used\_bytes;  

`    `}  



`    `// Judge frame usability  

`    `// This determines if a frame is artifact free and can be delivered  

`    `// For H264 this does some wicked magic hidden away in the H264RandomAccess class  

`    `// MPEG-2 and VC-1 just wait for a keyframe..  

`    `if (m\_nCodecId == AV\_CODEC\_ID\_H264 && (bParserFrame || !m\_pParser || got\_picture)) {  

`      `m\_h264RandomAccess.judgeFrameUsability(m\_pFrame, &got\_picture);  

`    `} else if (m\_bResumeAtKeyFrame) {  

`      `if (m\_bWaitingForKeyFrame && got\_picture) {  

`        `if (m\_pFrame->key\_frame) {  

`          `DbgLog((LOG\_TRACE, 50, L"::Decode() - Found Key-Frame, resuming decoding at %I64d", m\_pFrame->pkt\_pts));  

`          `m\_bWaitingForKeyFrame = FALSE;  

`        `} else {  

`          `got\_picture = 0;  

`        `}  

`      `}  

`    `}  



`    `// Handle B-frame delay for frame threading codecs  

`    `if ((m\_pAVCtx->active\_thread\_type & FF\_THREAD\_FRAME) && m\_bBFrameDelay) {  

`      `m\_tcBFrameDelay[m\_nBFramePos] = m\_tcThreadBuffer[m\_CurrentThread];  

`      `m\_nBFramePos = !m\_nBFramePos;  

`    `}  



`    `if (!got\_picture || !m\_pFrame->data[0]) {  

`      `if (!avpkt.size)  

`        `bFlush = FALSE; // End flushing, no more frames  

`      `av\_frame\_unref(m\_pFrame);  

`      `continue;  

`    `}  



`    `///////////////////////////////////////////////////////////////////////////////////////////////  

`    `// Determine the proper timestamps for the frame, based on different possible flags.  

`    `///////////////////////////////////////////////////////////////////////////////////////////////  

`    `if (m\_bFFReordering) {  

`      `rtStart = m\_pFrame->pkt\_pts;  

`      `if (m\_pFrame->pkt\_duration)  

`        `rtStop = m\_pFrame->pkt\_pts + m\_pFrame->pkt\_duration;  

`      `else  

`        `rtStop = AV\_NOPTS\_VALUE;  

`    `} else if (m\_bBFrameDelay && m\_pAVCtx->has\_b\_frames) {  

`      `rtStart = m\_tcBFrameDelay[m\_nBFramePos].rtStart;  

`      `rtStop  = m\_tcBFrameDelay[m\_nBFramePos].rtStop;  

`    `} else if (m\_pAVCtx->active\_thread\_type & FF\_THREAD\_FRAME) {  

`      `unsigned index = m\_CurrentThread;  

`      `rtStart = m\_tcThreadBuffer[index].rtStart;  

`      `rtStop  = m\_tcThreadBuffer[index].rtStop;  

`    `}  



`    `if (m\_bRVDropBFrameTimings && m\_pFrame->pict\_type == AV\_PICTURE\_TYPE\_B) {  

`      `rtStart = AV\_NOPTS\_VALUE;  

`    `}  



`    `if (m\_bCalculateStopTime)  

`      `rtStop = AV\_NOPTS\_VALUE;  



`    `///////////////////////////////////////////////////////////////////////////////////////////////  

`    `// All required values collected, deliver the frame  

`    `///////////////////////////////////////////////////////////////////////////////////////////////  

`    `LAVFrame \*pOutFrame = NULL;  

`    `AllocateFrame(&pOutFrame);  



`    `AVRational display\_aspect\_ratio;  

`    `int64\_t num = (int64\_t)m\_pFrame->sample\_aspect\_ratio.num \* m\_pFrame->width;  

`    `int64\_t den = (int64\_t)m\_pFrame->sample\_aspect\_ratio.den \* m\_pFrame->height;  

`    `av\_reduce(&display\_aspect\_ratio.num, &display\_aspect\_ratio.den, num, den, 1 << 30);  



`    `pOutFrame->width        = m\_pFrame->width;  

`    `pOutFrame->height       = m\_pFrame->height;  

`    `pOutFrame->aspect\_ratio = display\_aspect\_ratio;  

`    `pOutFrame->repeat       = m\_pFrame->repeat\_pict;  

`    `pOutFrame->key\_frame    = m\_pFrame->key\_frame;  

`    `pOutFrame->frame\_type   = av\_get\_picture\_type\_char(m\_pFrame->pict\_type);  

`    `pOutFrame->ext\_format   = GetDXVA2ExtendedFlags(m\_pAVCtx, m\_pFrame);  



`    `if (m\_pFrame->interlaced\_frame || (!m\_pAVCtx->progressive\_sequence && (m\_nCodecId == AV\_CODEC\_ID\_H264 || m\_nCodecId == AV\_CODEC\_ID\_MPEG2VIDEO)))  

`      `m\_iInterlaced = 1;  

`    `else if (m\_pAVCtx->progressive\_sequence)  

`      `m\_iInterlaced = 0;  



`    `pOutFrame->interlaced   = (m\_pFrame->interlaced\_frame || (m\_iInterlaced == 1 && m\_pSettings->GetDeinterlacingMode() == DeintMode\_Aggressive) || m\_pSettings->GetDeinterlacingMode() == DeintMode\_Force) && !(m\_pSettings->GetDeinterlacingMode() == DeintMode\_Disable);  



`    `LAVDeintFieldOrder fo   = m\_pSettings->GetDeintFieldOrder();  

`    `pOutFrame->tff          = (fo == DeintFieldOrder\_Auto) ? m\_pFrame->top\_field\_first : (fo == DeintFieldOrder\_TopFieldFirst);  



`    `pOutFrame->rtStart      = rtStart;  

`    `pOutFrame->rtStop       = rtStop;  



`    `PixelFormatMapping map  = getPixFmtMapping((AVPixelFormat)m\_pFrame->format);  

`    `pOutFrame->format       = map.lavpixfmt;  

`    `pOutFrame->bpp          = map.bpp;  



`    `if (m\_nCodecId == AV\_CODEC\_ID\_MPEG2VIDEO || m\_nCodecId == AV\_CODEC\_ID\_MPEG1VIDEO)  

`      `pOutFrame->avgFrameDuration = GetFrameDuration();  



`    `if (map.conversion) {  

`      `ConvertPixFmt(m\_pFrame, pOutFrame);  

`    `} else {  

`      `for (int i = 0; i < 4; i++) {  

`        `pOutFrame->data[i]   = m\_pFrame->data[i];  

`        `pOutFrame->stride[i] = m\_pFrame->linesize[i];  

`      `}  



`      `pOutFrame->priv\_data = av\_frame\_alloc();  

`      `av\_frame\_ref((AVFrame \*)pOutFrame->priv\_data, m\_pFrame);  

`      `pOutFrame->destruct  = lav\_avframe\_free;  

`    `}  



`    `if (bEndOfSequence)  

`      `pOutFrame->flags |= LAV\_FRAME\_FLAG\_END\_OF\_SEQUENCE;  



`    `if (pOutFrame->format == LAVPixFmt\_DXVA2) {  

`      `pOutFrame->data[0] = m\_pFrame->data[4];  

`      `HandleDXVA2Frame(pOutFrame);  

`    `} else {  

`      `Deliver(pOutFrame);  

`    `}  



`    `if (bEndOfSequence) {  

`      `bEndOfSequence = FALSE;  

`      `if (pOutFrame->format == LAVPixFmt\_DXVA2) {  

`        `HandleDXVA2Frame(m\_pCallback->GetFlushFrame());  

`      `} else {  

`        `Deliver(m\_pCallback->GetFlushFrame());  

`      `}  

`    `}  



`    `if (bFlush) {  

`      `m\_CurrentThread = (m\_CurrentThread + 1) % m\_pAVCtx->thread\_count;  

`    `}  

`    `av\_frame\_unref(m\_pFrame);  

`  `}  



`  `return S\_OK;  

}  

终于，我们从这个函数中看到了很多的ffmpeg的API，结构体，以及变量。比如解码视频的函数avcodec\_decode\_video2()。

解码器初始化函数：InitDecoder()

//创建解码器  

STDMETHODIMP CDecAvcodec::InitDecoder(AVCodecID codec, const CMediaType \*pmt)  

{  

`    `//要是有，先销毁  

`  `DestroyDecoder();  

`  `DbgLog((LOG\_TRACE, 10, L"Initializing ffmpeg for codec %S", avcodec\_get\_name(codec)));  



`  `BITMAPINFOHEADER \*pBMI = NULL;  

`  `videoFormatTypeHandler((const BYTE \*)pmt->Format(), pmt->FormatType(), &pBMI);  

`  `//查找解码器  

`  `m\_pAVCodec = avcodec\_find\_decoder(codec);  

`  `CheckPointer(m\_pAVCodec, VFW\_E\_UNSUPPORTED\_VIDEO);  

`  `//初始化上下文环境  

`  `m\_pAVCtx = avcodec\_alloc\_context3(m\_pAVCodec);  

`  `CheckPointer(m\_pAVCtx, E\_POINTER);  



`  `if(codec == AV\_CODEC\_ID\_MPEG1VIDEO || codec == AV\_CODEC\_ID\_MPEG2VIDEO || pmt->subtype == FOURCCMap(MKTAG('H','2','6','4')) || pmt->subtype == FOURCCMap(MKTAG('h','2','6','4'))) {  

`    `m\_pParser = av\_parser\_init(codec);  

`  `}  



`  `DWORD dwDecFlags = m\_pCallback->GetDecodeFlags();  



`  `LONG biRealWidth = pBMI->biWidth, biRealHeight = pBMI->biHeight;  

`  `if (pmt->formattype == FORMAT\_VideoInfo || pmt->formattype == FORMAT\_MPEGVideo) {  

`    `VIDEOINFOHEADER \*vih = (VIDEOINFOHEADER \*)pmt->Format();  

`    `if (vih->rcTarget.right != 0 && vih->rcTarget.bottom != 0) {  

`      `biRealWidth  = vih->rcTarget.right;  

`      `biRealHeight = vih->rcTarget.bottom;  

`    `}  

`  `} else if (pmt->formattype == FORMAT\_VideoInfo2 || pmt->formattype == FORMAT\_MPEG2Video) {  

`    `VIDEOINFOHEADER2 \*vih2 = (VIDEOINFOHEADER2 \*)pmt->Format();  

`    `if (vih2->rcTarget.right != 0 && vih2->rcTarget.bottom != 0) {  

`      `biRealWidth  = vih2->rcTarget.right;  

`      `biRealHeight = vih2->rcTarget.bottom;  

`    `}  

`  `}  

`  `//各种赋值  

`  `m\_pAVCtx->codec\_id              = codec;  

`  `m\_pAVCtx->codec\_tag             = pBMI->biCompression;  

`  `m\_pAVCtx->coded\_width           = pBMI->biWidth;  

`  `m\_pAVCtx->coded\_height          = abs(pBMI->biHeight);  

`  `m\_pAVCtx->bits\_per\_coded\_sample = pBMI->biBitCount;  

`  `m\_pAVCtx->error\_concealment     = FF\_EC\_GUESS\_MVS | FF\_EC\_DEBLOCK;  

`  `m\_pAVCtx->err\_recognition       = AV\_EF\_CAREFUL;  

`  `m\_pAVCtx->workaround\_bugs       = FF\_BUG\_AUTODETECT;  

`  `m\_pAVCtx->refcounted\_frames     = 1;  



`  `if (codec == AV\_CODEC\_ID\_H264)  

`    `m\_pAVCtx->flags2             |= CODEC\_FLAG2\_SHOW\_ALL;  



`  `// Setup threading  

`  `int thread\_type = getThreadFlags(codec);  

`  `if (thread\_type) {  

`    `// Thread Count. 0 = auto detect  

`    `int thread\_count = m\_pSettings->GetNumThreads();  

`    `if (thread\_count == 0) {  

`      `thread\_count = av\_cpu\_count() \* 3 / 2;  

`    `}  



`    `m\_pAVCtx->thread\_count = max(1, min(thread\_count, AVCODEC\_MAX\_THREADS));  

`    `m\_pAVCtx->thread\_type = thread\_type;  

`  `} else {  

`    `m\_pAVCtx->thread\_count = 1;  

`  `}  



`  `if (dwDecFlags & LAV\_VIDEO\_DEC\_FLAG\_NO\_MT) {  

`    `m\_pAVCtx->thread\_count = 1;  

`  `}  

`  `//初始化AVFrame  

`  `m\_pFrame = av\_frame\_alloc();  

`  `CheckPointer(m\_pFrame, E\_POINTER);  



`  `m\_h264RandomAccess.SetAVCNALSize(0);  



`  `// Process Extradata  

`  `//处理ExtraData  

`  `BYTE \*extra = NULL;  

`  `size\_t extralen = 0;  

`  `getExtraData(\*pmt, NULL, &extralen);  



`  `BOOL bH264avc = FALSE;  

`  `if (extralen > 0) {  

`    `DbgLog((LOG\_TRACE, 10, L"-> Processing extradata of %d bytes", extralen));  

`    `// Reconstruct AVC1 extradata format  

`    `if (pmt->formattype == FORMAT\_MPEG2Video && (m\_pAVCtx->codec\_tag == MAKEFOURCC('a','v','c','1') || m\_pAVCtx->codec\_tag == MAKEFOURCC('A','V','C','1') || m\_pAVCtx->codec\_tag == MAKEFOURCC('C','C','V','1'))) {  

`      `MPEG2VIDEOINFO \*mp2vi = (MPEG2VIDEOINFO \*)pmt->Format();  

`      `extralen += 7;  

`      `extra = (uint8\_t \*)av\_mallocz(extralen + FF\_INPUT\_BUFFER\_PADDING\_SIZE);  

`      `extra[0] = 1;  

`      `extra[1] = (BYTE)mp2vi->dwProfile;  

`      `extra[2] = 0;  

`      `extra[3] = (BYTE)mp2vi->dwLevel;  

`      `extra[4] = (BYTE)(mp2vi->dwFlags ? mp2vi->dwFlags : 4) - 1;  



`      `// Actually copy the metadata into our new buffer  

`      `size\_t actual\_len;  

`      `getExtraData(\*pmt, extra+6, &actual\_len);  



`      `// Count the number of SPS/PPS in them and set the length  

`      `// We'll put them all into one block and add a second block with 0 elements afterwards  

`      `// The parsing logic does not care what type they are, it just expects 2 blocks.  

`      `BYTE \*p = extra+6, \*end = extra+6+actual\_len;  

`      `BOOL bSPS = FALSE, bPPS = FALSE;  

`      `int count = 0;  

`      `while (p+1 < end) {  

`        `unsigned len = (((unsigned)p[0] << 8) | p[1]) + 2;  

`        `if (p + len > end) {  

`          `break;  

`        `}  

`        `if ((p[2] & 0x1F) == 7)  

`          `bSPS = TRUE;  

`        `if ((p[2] & 0x1F) == 8)  

`          `bPPS = TRUE;  

`        `count++;  

`        `p += len;  

`      `}  

`      `extra[5] = count;  

`      `extra[extralen-1] = 0;  



`      `bH264avc = TRUE;  

`      `m\_h264RandomAccess.SetAVCNALSize(mp2vi->dwFlags);  

`    `} else if (pmt->subtype == MEDIASUBTYPE\_LAV\_RAWVIDEO) {  

`      `if (extralen < sizeof(m\_pAVCtx->pix\_fmt)) {  

`        `DbgLog((LOG\_TRACE, 10, L"-> LAV RAW Video extradata is missing.."));  

`      `} else {  

`        `extra = (uint8\_t \*)av\_mallocz(extralen + FF\_INPUT\_BUFFER\_PADDING\_SIZE);  

`        `getExtraData(\*pmt, extra, NULL);  

`        `m\_pAVCtx->pix\_fmt = \*(AVPixelFormat \*)extra;  

`        `extralen -= sizeof(AVPixelFormat);  

`        `memmove(extra, extra+sizeof(AVPixelFormat), extralen);  

`      `}  

`    `} else {  

`      `// Just copy extradata for other formats  

`      `extra = (uint8\_t \*)av\_mallocz(extralen + FF\_INPUT\_BUFFER\_PADDING\_SIZE);  

`      `getExtraData(\*pmt, extra, NULL);  

`    `}  

`    `// Hack to discard invalid MP4 metadata with AnnexB style video  

`    `if (codec == AV\_CODEC\_ID\_H264 && !bH264avc && extra[0] == 1) {  

`      `av\_freep(&extra);  

`      `extralen = 0;  

`    `}  

`    `m\_pAVCtx->extradata = extra;  

`    `m\_pAVCtx->extradata\_size = (int)extralen;  

`  `} else {  

`    `if (codec == AV\_CODEC\_ID\_VP6 || codec == AV\_CODEC\_ID\_VP6A || codec == AV\_CODEC\_ID\_VP6F) {  

`      `int cropH = pBMI->biWidth - biRealWidth;  

`      `int cropV = pBMI->biHeight - biRealHeight;  

`      `if (cropH >= 0 && cropH <= 0x0f && cropV >= 0 && cropV <= 0x0f) {  

`        `m\_pAVCtx->extradata = (uint8\_t \*)av\_mallocz(1 + FF\_INPUT\_BUFFER\_PADDING\_SIZE);  

`        `m\_pAVCtx->extradata\_size = 1;  

`        `m\_pAVCtx->extradata[0] = (cropH << 4) | cropV;  

`      `}  

`    `}  

`  `}  



`  `m\_h264RandomAccess.flush(m\_pAVCtx->thread\_count);  

`  `m\_CurrentThread = 0;  

`  `m\_rtStartCache = AV\_NOPTS\_VALUE;  



`  `LAVPinInfo lavPinInfo = {0};  

`  `BOOL bLAVInfoValid = SUCCEEDED(m\_pCallback->GetLAVPinInfo(lavPinInfo));  



`  `m\_bInputPadded = dwDecFlags & LAV\_VIDEO\_DEC\_FLAG\_LAVSPLITTER;  



`  `// Setup codec-specific timing logic  

`  `BOOL bVC1IsPTS = (codec == AV\_CODEC\_ID\_VC1 && !(dwDecFlags & LAV\_VIDEO\_DEC\_FLAG\_VC1\_DTS));  



`  `// Use ffmpegs logic to reorder timestamps  

`  `// This is required for H264 content (except AVI), and generally all codecs that use frame threading  

`  `// VC-1 is also a special case. Its required for splitters that deliver PTS timestamps (see bVC1IsPTS above)  

`  `m\_bFFReordering        =  ( codec == AV\_CODEC\_ID\_H264 && !(dwDecFlags & LAV\_VIDEO\_DEC\_FLAG\_H264\_AVI))  

`                           `|| codec == AV\_CODEC\_ID\_VP8  

`                           `|| codec == AV\_CODEC\_ID\_VP3  

`                           `|| codec == AV\_CODEC\_ID\_THEORA  

`                           `|| codec == AV\_CODEC\_ID\_HUFFYUV  

`                           `|| codec == AV\_CODEC\_ID\_FFVHUFF  

`                           `|| codec == AV\_CODEC\_ID\_MPEG2VIDEO  

`                           `|| codec == AV\_CODEC\_ID\_MPEG1VIDEO  

`                           `|| codec == AV\_CODEC\_ID\_DIRAC  

`                           `|| codec == AV\_CODEC\_ID\_UTVIDEO  

`                           `|| codec == AV\_CODEC\_ID\_DNXHD  

`                           `|| codec == AV\_CODEC\_ID\_JPEG2000  

`                           `|| (codec == AV\_CODEC\_ID\_MPEG4 && pmt->formattype == FORMAT\_MPEG2Video)  

`                           `|| bVC1IsPTS;  



`  `// Stop time is unreliable, drop it and calculate it  

`  `m\_bCalculateStopTime   = (codec == AV\_CODEC\_ID\_H264 || codec == AV\_CODEC\_ID\_DIRAC || (codec == AV\_CODEC\_ID\_MPEG4 && pmt->formattype == FORMAT\_MPEG2Video) || bVC1IsPTS);  



`  `// Real Video content has some odd timestamps  

`  `// LAV Splitter does them allright with RV30/RV40, everything else screws them up  

`  `m\_bRVDropBFrameTimings = (codec == AV\_CODEC\_ID\_RV10 || codec == AV\_CODEC\_ID\_RV20 || ((codec == AV\_CODEC\_ID\_RV30 || codec == AV\_CODEC\_ID\_RV40) && (!(dwDecFlags & LAV\_VIDEO\_DEC\_FLAG\_LAVSPLITTER) || (bLAVInfoValid && (lavPinInfo.flags & LAV\_STREAM\_FLAG\_RV34\_MKV)))));  



`  `// Enable B-Frame delay handling  

`  `m\_bBFrameDelay = !m\_bFFReordering && !m\_bRVDropBFrameTimings;  



`  `m\_bWaitingForKeyFrame = TRUE;  

`  `m\_bResumeAtKeyFrame =    codec == AV\_CODEC\_ID\_MPEG2VIDEO  

`                        `|| codec == AV\_CODEC\_ID\_VC1  

`                        `|| codec == AV\_CODEC\_ID\_RV30  

`                        `|| codec == AV\_CODEC\_ID\_RV40  

`                        `|| codec == AV\_CODEC\_ID\_VP3  

`                        `|| codec == AV\_CODEC\_ID\_THEORA  

`                        `|| codec == AV\_CODEC\_ID\_MPEG4;  



`  `m\_bNoBufferConsumption =    codec == AV\_CODEC\_ID\_MJPEGB  

`                           `|| codec == AV\_CODEC\_ID\_LOCO  

`                           `|| codec == AV\_CODEC\_ID\_JPEG2000;  



`  `m\_bHasPalette = m\_pAVCtx->bits\_per\_coded\_sample <= 8 && m\_pAVCtx->extradata\_size && !(dwDecFlags & LAV\_VIDEO\_DEC\_FLAG\_LAVSPLITTER)  

`                  `&&  (codec == AV\_CODEC\_ID\_MSVIDEO1  

`                    `|| codec == AV\_CODEC\_ID\_MSRLE  

`                    `|| codec == AV\_CODEC\_ID\_CINEPAK  

`                    `|| codec == AV\_CODEC\_ID\_8BPS  

`                    `|| codec == AV\_CODEC\_ID\_QPEG  

`                    `|| codec == AV\_CODEC\_ID\_QTRLE  

`                    `|| codec == AV\_CODEC\_ID\_TSCC);  



`  `if (FAILED(AdditionaDecoderInit())) {  

`    `return E\_FAIL;  

`  `}  



`  `if (bLAVInfoValid) {  

`    `// Setting has\_b\_frames to a proper value will ensure smoother decoding of H264  

`    `if (lavPinInfo.has\_b\_frames >= 0) {  

`      `DbgLog((LOG\_TRACE, 10, L"-> Setting has\_b\_frames to %d", lavPinInfo.has\_b\_frames));  

`      `m\_pAVCtx->has\_b\_frames = lavPinInfo.has\_b\_frames;  

`    `}  

`  `}  



`  `// Open the decoder  

`  `//打开解码器  

`  `int ret = avcodec\_open2(m\_pAVCtx, m\_pAVCodec, NULL);  

`  `if (ret >= 0) {  

`    `DbgLog((LOG\_TRACE, 10, L"-> ffmpeg codec opened successfully (ret: %d)", ret));  

`    `m\_nCodecId = codec;  

`  `} else {  

`    `DbgLog((LOG\_TRACE, 10, L"-> ffmpeg codec failed to open (ret: %d)", ret));  

`    `DestroyDecoder();  

`    `return VFW\_E\_UNSUPPORTED\_VIDEO;  

`  `}  



`  `m\_iInterlaced = 0;  

`  `for (int i = 0; i < countof(ff\_interlace\_capable); i++) {  

`    `if (codec == ff\_interlace\_capable[i]) {  

`      `m\_iInterlaced = -1;  

`      `break;  

`    `}  

`  `}  



`  `// Detect chroma and interlaced  

`  `if (m\_pAVCtx->extradata && m\_pAVCtx->extradata\_size) {  

`    `if (codec == AV\_CODEC\_ID\_MPEG2VIDEO) {  

`      `CMPEG2HeaderParser mpeg2Parser(extra, extralen);  

`      `if (mpeg2Parser.hdr.valid) {  

`        `if (mpeg2Parser.hdr.chroma < 2) {  

`          `m\_pAVCtx->pix\_fmt = AV\_PIX\_FMT\_YUV420P;  

`        `} else if (mpeg2Parser.hdr.chroma == 2) {  

`          `m\_pAVCtx->pix\_fmt = AV\_PIX\_FMT\_YUV422P;  

`        `}  

`        `m\_iInterlaced = mpeg2Parser.hdr.interlaced;  

`      `}  

`    `} else if (codec == AV\_CODEC\_ID\_H264) {  

`      `CH264SequenceParser h264parser;  

`      `if (bH264avc)  

`        `h264parser.ParseNALs(extra+6, extralen-6, 2);  

`      `else  

`        `h264parser.ParseNALs(extra, extralen, 0);  

`      `if (h264parser.sps.valid)  

`        `m\_iInterlaced = h264parser.sps.interlaced;  

`    `} else if (codec == AV\_CODEC\_ID\_VC1) {  

`      `CVC1HeaderParser vc1parser(extra, extralen);  

`      `if (vc1parser.hdr.valid)  

`        `m\_iInterlaced = (vc1parser.hdr.interlaced ? -1 : 0);  

`    `}  

`  `}  



`  `if (codec == AV\_CODEC\_ID\_DNXHD)  

`    `m\_pAVCtx->pix\_fmt = AV\_PIX\_FMT\_YUV422P10;  

`  `else if (codec == AV\_CODEC\_ID\_FRAPS)  

`    `m\_pAVCtx->pix\_fmt = AV\_PIX\_FMT\_BGR24;  



`  `if (bLAVInfoValid && codec != AV\_CODEC\_ID\_FRAPS && m\_pAVCtx->pix\_fmt != AV\_PIX\_FMT\_DXVA2\_VLD)  

`    `m\_pAVCtx->pix\_fmt = lavPinInfo.pix\_fmt;  



`  `DbgLog((LOG\_TRACE, 10, L"AVCodec init successfull. interlaced: %d", m\_iInterlaced));  



`  `return S\_OK;  

}  

解码器销毁函数：DestroyDecoder()

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/13272409#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/13272409#)

//销毁解码器，各种Free  

STDMETHODIMP CDecAvcodec::DestroyDecoder()  

{  

`  `DbgLog((LOG\_TRACE, 10, L"Shutting down ffmpeg..."));  

`  `m\_pAVCodec    = NULL;  



`  `if (m\_pParser) {  

`    `av\_parser\_close(m\_pParser);  

`    `m\_pParser = NULL;  

`  `}  



`  `if (m\_pAVCtx) {  

`    `avcodec\_close(m\_pAVCtx);  

`    `av\_freep(&m\_pAVCtx->extradata);  

`    `av\_freep(&m\_pAVCtx);  

`  `}  

`  `av\_frame\_free(&m\_pFrame);  



`  `av\_freep(&m\_pFFBuffer);  

`  `m\_nFFBufferSize = 0;  



`  `av\_freep(&m\_pFFBuffer2);  

`  `m\_nFFBufferSize2 = 0;  



`  `if (m\_pSwsContext) {  

`    `sws\_freeContext(m\_pSwsContext);  

`    `m\_pSwsContext = NULL;  

`  `}  



`  `m\_nCodecId = AV\_CODEC\_ID\_NONE;  



`  `return S\_OK;  

}  
## **9.3 MPlayer**
### **9.3.1 Mplayer支持的格式**
MPlayer是一个LINUX下的视频播放器，它支持相当多的媒体格式，无论在音频播放还是在视频播放方面，可以说它支持的格式是相当全面的。

视频格式支持：MPEG、AVI、ASF 与WMV、QuickTime 与 OGG/OGM、SDP、PVA、GIF。

音频格式支持：MP3、WAV、OGG/OGM 文件(Vorbis)、WMA 与 ASF、MP4、CD音频、XMMS。
### **9.3.2 Mplayer 中头文件的功能分析**
config.h // 各种本地配置宏定义头  

version.h // 版本定义头 #define VERSION "1.0pre7try2-3.4.2"  

mp\_msg.h // 消息处理头  

help\_mp.h // 根据配置自动生成的帮助头 #include "help/help\_mpen.h"  

cfg-mplayer-def.h // Mplayer 运行时的选项缺省值头文件 char\*  

default\_config =  

sub\_reader.h // 拥有格式自动发现功能的字幕(subtitle)阅读器  

libvo/video\_out.h // 该文件包含 libvo 视频输出的公共函数、变量  

libvo/font\_load.h // 有关字体装载的例程  

libao2/audio\_out.h // 音频输出驱动程序相关结构定义和全局数据  

libmpcodecs/dec\_audio.h // 音频解码  

libmpcodecs/dec\_video.h // 视频解码  

libmpdemux/matroska.h // 多路解复用，媒体容器格式 matroska 处理头  

libmpdemux/stream.h // 流处理  

libmpdemux/demuxer.h // 多路解复用头文件  

libmpdemux/stheader.h // 媒体流头处理  

get\_path.c // 路径获取头文件  

spudec.h // SPU 子画面单元头，DVD 字幕流  

edl.h // 剪辑控制清单  

m\_option.h // 选项类型处理头  

m\_config.h // 配置处理头文件  
### **9.3.3 MPlayer.main 主流程简要说明**
int main() {  

\1) 变量声明，电影信息 movie info:  

\2) 初始化，消息系统……  

play\_next\_file:  

3)播放文件 filename 的循环 goto play\_next\_file 开始  

main:  

\4) 主处理 main  

\5) 播放真正主循环 2010 ~3541 while (!eof)  

while (!eof) {  

5.1) 播放音频 PLAY AUDIO 2017 ~ 2064 decode\_audio(sh\_audio, ...);  

5.2) 播放视频 PLAY VIDEO, 2068 ~ 2300 decode\_video(sh\_video, ...);  

5.3) 处理暂停 PAUSE  

5.4) 处理 EDL  

5.5) 键盘事件处理, 搜索2400~3216 while (!brk\_cmd &&  

(cmd=mp\_input\_get\_cmd(0,0,0))!=NULL)  

5.6) 时间寻道(秒) if (seek\_to\_sec)  

5.7) 寻道 3243 ~ 3306, if (rel\_seek\_secs || abs\_seek\_pos)  

5.8) 处理 GUI  

5.9) 变更 Update OSD  

5.10) 找到字幕 find sub  

5.11) 处理 X11 窗口  

5.12) DVD 字幕 sub:  

}  

goto\_next\_file:  

\6) 播放结束，转到下个文件 goto\_next\_file:  

}  
### **9.3.4 Mplayer源码分析**
从Mplayer.c的main开始处理参数

mconfig = m\_config\_new();  

m\_config\_register\_options(mconfig,mplayer\_opts);  

// TODO : add something to let modules register their options  

mp\_input\_register\_options(mconfig);  

parse\_cfgfiles(mconfig);  

初始化mpctx结构体，mpctx应该是mplayer context的意思，顾名思义是一个统筹全局的变量。

[cpp] [view plain](http://blog.csdn.net/leixiaohua1020/article/details/11885509#)[copy](http://blog.csdn.net/leixiaohua1020/article/details/11885509#)

static MPContext \*mpctx = &mpctx\_s;  

// Not all functions in mplayer.c take the context as an argument yet  

static MPContext mpctx\_s = {  

.osd\_function = OSD\_PLAY,  

.begin\_skip = MP\_NOPTS\_VALUE,  

.play\_tree\_step = 1,  

.global\_sub\_pos = -1,  

.set\_of\_sub\_pos = -1,  

.file\_format = DEMUXER\_TYPE\_UNKNOWN,  

.loop\_times = -1,  

#ifdef HAS\_DVBIN\_SUPPORT  

.last\_dvb\_step = 1,  

#endif  

};  

原型

//真正统筹全局的结构  

typedef struct MPContext {  

`    `int osd\_show\_percentage;  

`    `int osd\_function;  

`    `const ao\_functions\_t \*audio\_out;  

`    `play\_tree\_t \*playtree;  

`    `play\_tree\_iter\_t \*playtree\_iter;  

`    `int eof;  

`    `int play\_tree\_step;  

`    `int loop\_times;  



`    `stream\_t \*stream;  

`    `demuxer\_t \*demuxer;  

`    `sh\_audio\_t \*sh\_audio;  

`    `sh\_video\_t \*sh\_video;  

`    `demux\_stream\_t \*d\_audio;  

`    `demux\_stream\_t \*d\_video;  

`    `demux\_stream\_t \*d\_sub;  

`    `mixer\_t mixer;  

`    `const vo\_functions\_t \*video\_out;  

`    `// Frames buffered in the vo ready to flip. Currently always 0 or 1.  

`    `// This is really a vo variable but currently there's no suitable vo  

`    `// struct.  

`    `int num\_buffered\_frames;  



`    `// used to retry decoding after startup/seeking to compensate for codec delay  

`    `int startup\_decode\_retry;  

`    `// how long until we need to display the "current" frame  

`    `float time\_frame;  



`    `// AV sync: the next frame should be shown when the audio out has this  

`    `// much (in seconds) buffered data left. Increased when more data is  

`    `// written to the ao, decreased when moving to the next frame.  

`    `// In the audio-only case used as a timer since the last seek  

`    `// by the audio CPU usage meter.  

`    `double delay;  



`    `float begin\_skip; ///< start time of the current skip while on edlout mode  

`    `// audio is muted if either EDL or user activates mute  

`    `short edl\_muted; ///< Stores whether EDL is currently in muted mode.  

`    `short user\_muted; ///< Stores whether user wanted muted mode.  



`    `int global\_sub\_size; // this encompasses all subtitle sources  

`    `int global\_sub\_pos; // this encompasses all subtitle sources  

`    `int set\_of\_sub\_pos;  

`    `int set\_of\_sub\_size;  

`    `int sub\_counts[SUB\_SOURCES];  

#ifdef CONFIG\_ASS  

`    `// set\_of\_ass\_tracks[i] contains subtitles from set\_of\_subtitles[i]  

`    `// parsed by libass or NULL if format unsupported  

`    `ASS\_Track\* set\_of\_ass\_tracks[MAX\_SUBTITLE\_FILES];  

#endif  

`    `sub\_data\* set\_of\_subtitles[MAX\_SUBTITLE\_FILES];  



`    `int file\_format;  



#ifdef CONFIG\_DVBIN  

`    `int last\_dvb\_step;  

`    `int dvbin\_reopen;  

#endif  



`    `int was\_paused;  



#ifdef CONFIG\_DVDNAV  

`    `struct mp\_image \*nav\_smpi;   ///< last decoded dvdnav video image  

`    `unsigned char \*nav\_buffer;   ///< last read dvdnav video frame  

`    `unsigned char \*nav\_start;    ///< pointer to last read video buffer  

`    `int            nav\_in\_size;  ///< last read size  

#endif  

} MPContext;  

一些GUI相关的操作

打开字幕流

打开音视频流

mpctx->stream=open\_stream(filename,0,&mpctx->file\_format);  

fileformat 文件还是TV 流DEMUXER\_TYPE\_PLAYLIST 或DEMUXER\_TYPE\_UNKNOWN  

DEMUXER\_TYPE\_TV  

current\_module记录状态vobsub open\_stream handle\_playlist dumpstream  

stream\_reset(mpctx->stream);  

stream\_seek(mpctx->stream,mpctx->stream->start\_pos);  

f=fopen(stream\_dump\_name,”wb”); dump文件流  

stream->type==STREAMTYPE\_DVD  

//============ Open DEMUXERS — DETECT file type ======================

Demux。分离视频流和音频流

mpctx->demuxer=demux\_open(mpctx->stream,mpctx-  

\>file\_format,audio\_id,video\_id,dvdsub\_id,filename);  

Demux过程  

demux\_open  

get\_demuxer\_type\_from\_name  

……  

mpctx->d\_audio=mpctx->demuxer->audio;  

mpctx->d\_video=mpctx->demuxer->video;  

mpctx->d\_sub=mpctx->demuxer->sub;  

mpctx->sh\_audio=mpctx->d\_audio->sh;  

mpctx->sh\_video=mpctx->d\_video->sh;  

分离了之后就开始分别Play audio和video

这里只关心play video

/\*======================== PLAY VIDEO ============================\*/  

vo\_pts=mpctx->sh\_video->timer\*90000.0;  

vo\_fps=mpctx->sh\_video->fps;  

if (!mpctx->num\_buffered\_frames) {  

double frame\_time = update\_video(&blit\_frame);  

mp\_dbg(MSGT\_AVSYNC,MSGL\_DBG2,”\*\*\* ftime=%5.3f \*\*\*\n”,frame\_time);  

if (mpctx->sh\_video->vf\_inited < 0) {  

mp\_msg(MSGT\_CPLAYER,MSGL\_FATAL, MSGTR\_NotInitializeVOPorVO);  

mpctx->eof = 1; goto goto\_next\_file;  

}  

if (frame\_time < 0)  

mpctx->eof = 1;  

else {  

// might return with !eof && !blit\_frame if !correct\_pts  

mpctx->num\_buffered\_frames += blit\_frame;  

time\_frame += frame\_time / playback\_speed; // for nosound  

}  

}  

关键的函数是update\_video根据pts是否正确调整一下同步并在必要的时候丢帧处理。最终调用decode\_video开始解码（包括generate\_video\_frame里）。mpi = mpvdec->decode(sh\_video, start, in\_size, drop\_frame);mpvdec是在main里通过reinit\_video\_chain的一系列调用动态选定的解码程序。其实就一结构体。它的原型是

typedef struct vd\_functions\_s  

{  

vd\_info\_t \*info;  

int (\*init)(sh\_video\_t \*sh);  

void (\*uninit)(sh\_video\_t \*sh);  

int (\*control)(sh\_video\_t \*sh,int cmd,void\* arg, …);  

mp\_image\_t\* (\*decode)(sh\_video\_t \*sh,void\* data,int len,int flags);  

} vd\_functions\_t;  

这是所有解码器必须实现的接口。

int (\*init)(sh\_video\_t \*sh);是一个名为init的指针，指向一个接受sh\_video\_t \*类型参数，并返回int类型值的函数地址。那些vd\_开头的文件都是解码相关的。随便打开一个vd文件以上几个函数和info变量肯定都包含了。mpi被mplayer用来存储解码后的图像。在mp\_image.h里定义。

typedef struct mp\_image\_s {  

unsigned short flags;  

unsigned char type;  

unsigned char bpp; // bits/pixel. NOT depth! for RGB it will be n\*8  

unsigned int imgfmt;  

int width,height; // stored dimensions  

int x,y,w,h; // visible dimensions  

unsigned char\* planes[MP\_MAX\_PLANES];  

int stride[MP\_MAX\_PLANES];  

char \* qscale;  

int qstride;  

int pict\_type; // 0->unknown, 1->I, 2->P, 3->B  

int fields;  

int qscale\_type; // 0->mpeg1/4/h263, 1->mpeg2  

int num\_planes;  

/\* these are only used by planar formats Y,U(Cb),V(Cr) \*/  

int chroma\_width;  

int chroma\_height;  

int chroma\_x\_shift; // horizontal  

int chroma\_y\_shift; // vertical  

/\* for private use by filter or vo driver (to store buffer id or dmpi) \*/  

void\* priv;  

} mp\_image\_t;  

图像在解码以后会输出到显示器，mplayer本来就是一个视频播放器么。但也有可能作为输入提供给编码器进行二次编码，MP附带的mencoder.exe就是专门用来编码的。在这之前可以定义filter对图像进行处理，以实现各种效果。所有以vf\_开头的文件，都是这样的filter。图像的显示是通过vo，即video out来实现的。解码器只负责把解码完成的帧传给vo，怎样显示就不用管了。这也是平台相关性最大的部分，单独分出来的好处是不言而喻的，像在Windows下有通过direcx实现的vo，Linux下有输出到X的vo。vo\_\*文件是各种不同的vo实现，只是他们不都是以显示为目的，像vo\_md5sum.c只是计算一下图像的md5值。在解码完成以后，即得到mpi以后，filter\_video被调用，其结果是整个filter链上的所有filter都被调用了一遍，包括最后的VO，在vo的put\_image里把图像输出到显示器。这个时候需要考虑的是图像存储的方法即用哪种色彩空间。

附上两张MPlayer结构图：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.162.jpeg)

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.163.jpeg)

MPLayer源代码下载地址：<http://download.csdn.net/detail/leixiaohua1020/6374337>
# **第十章 开发实例**
# 第十一章 mp4文件封装协议分析
## **11.1  概述** 
MP4文件格式中，所有的内容存在一个称为movie的容器中。一个movie可以由多个trak组成。每个trak就是一个随时间变化的媒体序列，例如，视频帧序列。trak里的每个时间单位是一个sample，它可以是一帧视频，或者音频。sample按照时间顺序排列。注意，一帧音频可以分解成多个音频sample，所以音频一般用sample作为单位，而不用帧。MP4文件格式的定义里面，用sample这个单词表示一个时间帧或者数据单元。每个trak会有一个或者多个sample descriptions。track里面的每个sample通过引用关联到一个sample description。这个sample descriptions定义了怎样解码这个sample，例如使用的压缩算法。 

与其他的多媒体文件格式不同的是，MP4文件格式经常使用几个不同的概念，理解其不同是理解这个文件格式的关键。 

这个文件的物理格式没有限定媒体本身的格式。例如，许多文件格式将媒体数据分成帧，头部或者其他数据紧紧跟随每一帧视频。而MP4文件格式不是如此。 

文件的物理格式和媒体数据的排列都不受媒体的时间顺序的限制。视频帧不需要在文件按时间顺序排列。这就意味着如果文件中真的存在这样的一些帧，那么就有一些文件结构来描述媒体的排列和对应的时间信息。 

MP4文件中所有的数据都封装在一些box中（以前叫atom）。所有的metadata(媒体描述元数据)，包括定义媒体的排列和时间信息的数据都包含在这样的一些结构box中。MP4文件格式定义了这些这些box的格式。Metadata对媒体数据（例如，视频帧）引用说明。媒体数据可以包含在同一个的一个或多个box里，也可以在其他文件中，metadata允许使用URLs来引用其他的文件，而媒体数据在这些引用文件中的排列关系全部在第一个主文件中的metadata描述。其他的文件不一定是MP4文件格式，例如，可能就没有一个box。 

有很多种类的trak，其中有三个最重要，video track包含了视频sample；audio trak包含了audio sample；hint trak稍有不同，它描述了一个流媒体服务器如何把文件中的媒体数据组成符合流媒体协议的数据包。 如果文件只是本地播放，可以忽略hint track，他们只与流媒体有关系。 
## **11.2  mp4的物理结构**
Box定义了如何在sample table中找到媒体数据的排列。这包括data reference(数据引用), the sample size table, the sample to chunk table, and the chunk offset table. 这些表就可以找到trak中每个sample在文件中的位置和大小。 为了节约空间，这些表都很紧凑。另外，interleave不是sample by sample，而是把单个trak的几个samples组合到一起，然后另外几个sample又进行新的组合。一个trak的连续几个sample组成的单元就被称为chunk。每个chunk在文件中有一个偏移量，这个偏移量是从文件开头算起的，在这个chunk内，sample是连续存储的。 

这样，如果一个chunk包含两个sample，第二个sample的位置就是chunk的偏移量加上第一个sample的大小。chunk offset table说明了每个chunk的偏移量，sample to chunk table说明了sample序号和chunk序号的映射关系。 

注意chunk之间可能会有死区，没有任何媒体数据引用到这部分区域，但是chunk内部不会有这样的死区。
## **11.3  数据的组织结构**
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.164.png)
## **11.4  mp4的时间结构**
文件中的时间可以理解为一些结构。电影以及每个trak都有一个timescale。它定义了一个时间轴来说明每秒钟有多少个ticks。合理的选择这个数目，就可以实现准确的计时。一般来说，对于audio track，就是audio的sampling rate。对于video track，情况稍微复杂，需要合理选择。例如，如果一个media TimeScale是30000，media sample durations是1001，就准确的定义了NTSC video的时间格式（虽然不准确，但一般就是29.97）。

每个trak的全部duration定义在文件头部，这就是对track的总结，每个sample有一个规定的duration。一个sample的准确描述时间，也就是他的时间戳(time-stamp)就是以前的sample的duration之和。 

关键词：

\1.	**trak**  表示一些sample的集合，对于媒体数据来说，track表示一个视频或音频序列。

\2.	**sample**  video sample即为一帧视频，或一组连续视频帧，audio sample即为一段连续的压缩音频，它们统称sample。

\3.	**chunk** 一个trak的几个sample组成的单元。

**4.  box**  box由header和body组成，其中header统一指明box的大小和类型，body根据类型有不同的意义和格式。 标准的box开头的4个字节（32位）为box size，该大小包括box header和box body整个box的大小，这样我们就可以在文件中定位各个box。size后面紧跟的32位为box type，一般是4个字符，如“ftyp”、“moov”等，这些box type都是已经预定义好的，分别表示固定的意义。

下图为一个典型的MP4文件的结构树：

![[转载]mp4文件格式解析（一）](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.165.jpeg "[转载]mp4文件格式解析（一）")
## **11.5  文件结构分析**
### **11.5.1  File Type Box（ftyp）**
`    `该box有且只有1个，并且只能被包含在文件层，而不能被其他box包含。该box应该被放在文件的最开始，指示该MP4文件应用的相关信息。

“ftyp” body依次包括1个32位的major brand（4个字符），1个32位的minor version（整数）和1个以32位（4个字符）为单位元素的数组compatible brands。这些都是用来指示文件应用级别的信息。

该box的字节实例如下：

![[转载]mp4文件格式解析（一）](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.166.jpeg "[转载]mp4文件格式解析（一）")
### **11.5.2  Movie Box（moov）**
该box包含了文件媒体的metadata信息，“moov”是一个container box，具体内容信息由子box诠释。同File Type Box一样，该box有且只有一个，且只被包含在文件层。一般情况下，“moov”会紧随“ftyp”出现。

一般情况下，“moov”中会包含1个“mvhd”和若干个“trak”。其中“mvhd”为header box，一般作为“moov”的第一个子box出现。
#### **11.5.1.1  Movie Header Box（mvhd）** 
mvhd定义了整个movie的特性，例如time scale和duration，它的atom类型是'mvhd'。具体字段的表结构如下：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|box size|4|box size|
|box type|4|box类型|
|version|1|box版本，0或1，一般为0。（以下字节数均按version=0）|
|flags|3| |
|creation time|4|创建时间（相对于UTC时间1904-01-01零点的秒数）|
|modification time|4|修改时间|
|time scale|4|时间缩放因子|
|duration|4|该视频的时长(整体标记)|
|rate|4|推荐播放速率，高16位和低16位分别为小数点整数部分和小数部分，即[16.16] 格式，该值为1.0（0x00010000）表示正常前向播放|
|volume|2|与rate类似，[8.8] 格式，1.0（0x0100）表示最大音量|
|reserved|10|保留位|
|matrix|36|视频变换矩阵|
|pre-defined|24| |
|next track id|4|下一个track使用的id号|

“mvhd”的字节实例如下图，各字段已经用颜色区分开：

![[转载]mp4文件格式解析（一）](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.167.jpeg "[转载]mp4文件格式解析（一）")
#### **11.5.1.2  Track Box（trak）**
` 	`主数据存储结构，一部movie可以包含一个或多个tracks，它们之间相互独立，各自有各自的时间和空间信息。每个track atom 都有与之关联的media atom。 

trak atoms 的atom类型是'trak'. trak atom要求必须有一个trak header atom ('tkhd') 和一个media atom ('mdia')。其他的track clipping atom ('clip')，track matte atom ('matt')，edit atom ('edts')，track reference atom ('tref')，track load settings atom ('load')，a track input map atom ('imap')以及user data atom ('udta')都是可选的。 具体表结构如下：

**1. Track Header Box（tkhd）**

trak的头信息，具体表结构如下：

|**字段**|**长度（单位：byte）**|**意义**|
| :-: | :-: | :-: |
|box size|4|box大小|
|box type|4|box类型|
|version|1|box版本，0或1，一般为0。（以下字节数均按version=0）|
|flags|3|<p>按位或操作结果值，预定义如下：</p><p>0x000001 track\_enabled，否则该track不被播放；</p><p>0x000002 track\_in\_movie，表示该track在播放中被引用；</p><p>0x000004 track\_in\_preview，表示该track在预览时被引用。</p><p>一般该值为7，如果一个媒体所有track均未设置track\_in\_movie和track\_in\_preview，将被理解为所有track均设置了这两项。</p><p></p><p></p>|
|creation time|4|<p>创建时间（相对于UTC时间1904-01-01零点的秒数）</p><p></p><p></p>|
|modification time|4|<p>修改时间</p><p></p><p></p>|
|track id|4|<p>id号，不能重复且不能为0</p><p></p><p></p>|
|reserved|4|<p>保留位</p><p></p><p></p>|
|duration|4|<p>trak的时间长度</p><p></p><p></p>|
|reserved|8|<p>保留位</p><p></p><p></p>|
|layer|2|<p>视频层，默认为0(跳过)</p><p></p><p></p>|
|alternate group|2|<p>trak分组信息，默认为0表示该trak未与其他trak有群组关系</p><p></p><p></p>|
|volume|2|<p>[8.8] 格式，如果为音频trak，1.0（0x0100）表示最大音量；否则为0</p><p></p><p></p>|
|reserved|2|<p>保留位</p><p></p><p></p>|
|matrix|36|<p>视频变换矩阵</p><p></p><p></p>|
|width|4|<p>宽</p><p></p><p></p>|
|height|4|<p>高</p><p></p><p></p>|
“tkhd”的字节实例如下图，各字段已经用颜色区分开：

![mp4文件格式解析（二）](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.168.jpeg "mp4文件格式解析（二）")

**2. Media Box（mdia）**

“mdia”也是个container box，其子box的结构和种类还是比较复杂的。树结构图如下：

![mp4文件格式解析（二）](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.169.jpeg "mp4文件格式解析（二）")

` 	`总体来说，“mdia”定义了trak媒体类型以及sample数据，描述sample信息。一般“mdia”包含一个“mdhd”，一个“hdlr”和一个“minf”，其中“mdhd”为media header box，“hdlr” 为handler reference box，“minf”为media information box。

**1**. **Media Header Box（mdhd）**

Media header atom 定义了媒体的特性，例如time scale和duration。它的类型是'mdhd'。

具体表结构如下：

|**字段**|**长度（单位：byte）**|**意义**|
| :-: | :-: | :-: |
|box size|4|box大小|
|box type|4|box类型|
|version|1|box版本，0或1，一般为0。（以下字节数均按version=0）|
|flags|3| |
|creation time|4|创建时间（相对于UTC时间1904-01-01零点的秒数）|
|modification time|4|修改时间|
|time scale|4|时间缩放因子|
|duration|4|track的时间长度|
|language|2|媒体语言码。最高位为0，后面15位为3个字符（见ISO 639-2/T标准中定义）|
|pre-defined|2| |
**2. Handler Reference Box（hdlr）**

Handler reference atom 定义了描述此媒体数据的media handler component，类型是'hdlr'。在过去，handler reference atom也可以用来数据引用，现在废弃。一个media atom内的handler atom解释了媒体流的播放过程。例如，一个视频handler处理一个video track。 具体表结构如下：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|尺寸|4|这个atom的字节数|
|类型|4|hdlr|
|版本|1|这个atom的版本|
|标志|3|这里为0|
|Component type|4|<p>handler的类型。当前只有两种类型：</p><p>'mhlr'：media handlers</p><p>'dhlr'：data handlers**(废弃)**</p><p></p><p></p>|
|Component subtype|4|<p>media handler or data handler的类型。</p><p>如果component type是mhlr，这个字段定义了数据的类型，可以用来判断该trak的类型，例如，'vide'是video数据，'soun'是sound数据</p><p>如果component type是dhlr，这个字段定义了数据引用的类型(**废弃**)</p><p></p><p></p>|
|Component manufacturer|4|<p>保留字段，缺省为0</p><p></p><p></p>|
|Component flags|4|<p>保留字段，缺省为0</p><p></p><p></p>|
|Component flags mask|4|<p>保留字段，缺省为0</p><p></p><p></p>|
|Component name|可变|<p>这个component的名字，也就是生成此media的media handler。该字段的长度可以为0</p><p></p><p></p>|
**3. Media Information Atoms - MINF** 

“minf”存储了解释trak媒体数据的handler-specific信息，media handler用这些信息将媒体时间映射到媒体数据并进行处理。“minf”中的信息格式和内容与媒体类型以及解释媒体数据的media handler密切相关，其他media handler不知道如何解释这些信息。“minf”是一个container box，其实际内容由子box说明。

一般情况下，“minf”包含一个header box，一个“dinf”和一个“stbl”，其中，header box根据track type（即media handler type）分为“vmhd”、“smhd”，“dinf”为data information box，“stbl”为sample table box。

**3.1 Media Information Header Box（vmhd、smhd）（拆包时可直接跳过）**

**Video Media Header Box（vmhd）** 

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|box size|4|box大小|
|box type|4|box类型|
|version|1|box版本，0或1，一般为0。|
|flags|3| |
|graphics mode|4|**跳过**|
|opcolor|2×3|｛red，green，blue｝|
**Sound Media Header Box（smhd）** 

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|box size|4|box大小|
|box type|4|box类型|
|version|1|box版本，0或1，一般为0。（以下字节数均按version=0）|
|flags|3| |
|balance|2|立体声平衡(**跳过**)|
|reserved|2| |
**3.2  Data Information Box（dinf）**

“dinf”解释如何定位媒体信息，是一个container box。“dinf”一般包含一个“dref”，即data reference box；“dref”下会包含若干个“url”或“urn”，这些box组成一个表，用来定位trak数据。简单的说，trak可以被分成若干段，每一段都可以根据“url”或“urn”指向的地址来获取数据，sample描述中会用这些片段的序号将这些片段组成一个完整的trak。一般情况下，当数据被完全包含在文件中时，“url”或“urn”中的定位字符串是空的。

**“dref”的字节结构如下表：**

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|box size|4|box大小|
|box type|4|box类型|
|version|1|box版本，0或1，一般为0。（以下字节数均按version=0）|
|flags|3| |
|entry count|4|“url”或“urn”表的元素个数,每个data reference就像atom的格式一样，包含以下的数据成员|
|“url”或“urn”列表|不定|“url”或“urn”列表|
**entry的结构如下表：**

|box size|4|box大小|
| :- | :- | :- |
|box type|4|见下表|
|version|1|这个data reference的版本|
|flags|3|<p>目前只有一个标志：</p><p>Self reference</p><p>This flag indicates that the media’s data is in the same file as the movie atom. On the Macintosh, and other file systems with multifork files, set this flag to 1 even if the data resides in a different fork from the movie atom. This flag’s value is 0x0001.</p><p></p><p></p>|
|数据|可变|<p>data reference信息</p><p></p><p></p>|

**data reference具体结构如下：**

|**类型**|**描述**|
| :-: | :-: |
|alis|Data reference是一个Macintosh alias。一个alias包含文件信息，例如全路径名。|
|rsrc|Data reference是一个Macintosh alias。Alias末尾是文件使用的资源类型（32bit整数）和ID（16bit带符号的整数）|
|url |一个C类型的字符串，表示一个URL。字符串后可以有其他的数据。|
**3.3 Sample Table Box（stbl）（重要）**

“stbl”包含了关于trak中sample所有时间和位置的信息，以及sample的编解码等信息。利用这个表，可以解释sample的时序、类型、大小以及在各自存储容器中的位置。“stbl”是一个container box，其子box包括：sample description box（stsd）、time to sample box（stts）、sample size box（stsz或stz2）、sample to chunk box（stsc）、chunk offset box（stco或co64）、composition time to sample box（ctts）、sync sample box（stss）等。

**3.3.1 Sample Description Atoms - STSD** 

“stsd”必不可少，且至少包含一个条目，该box包含了data reference box进行sample数据检索的信息。没有“stsd”就无法计算media sample的存储位置。“stsd”包含了编码的信息，其存储的信息随媒体类型不同而不同。

在认识stsd之前我们首先需要了解一个数据结构SampleEntry和它的子类AudioSampleEntry,VisualSampleEntry,HintSampleEntry(不作分析)，具体关系如下：

![sample\_e](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.170.png "sampleentry")

SampleEntry 是一个继成box的抽象的数据结构模型，具体如下表：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|box size|4|box大小|
|box type|4|box类型(根据该值查找视频格式id表获得编码器类型，如"avc1"通过查表标记为H264\_ID类型)(重要)|
|resved|6|保留字段,(跳过)|
|drefid|2|无用(跳过)|
VisualSampleEntry(类型为"avc1")继承于SampleEntry ，具体结构如下表：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|SampleEntry |16|SampleEntry |
|resved|16|保留字段(**跳过**)|
|width|2|宽度|
|height|2|高度|
|hrsl|4|水平分辨率|
|vtsl|4|垂直分辨率|
|reserved |4|一直为0|
|frame\_count|2|每个采样里面的贞数,一般是1|
|compressorname |4|字符串，对齐到32位，(无用跳过)|
|depth |2|视频的色深 0x18 表示24位色|

AudioSampleEntry(类型为"mp4a")继承于SampleEntry ,具体结构如下表：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|SampleEntry |16|SampleEntry |
|resved|16|保留字段(**跳过**)|
|channelcount |2|声道数1或者2|
|samplesize |2|采样位宽 一般为8bit 或16bit|
|reserved |4|保留字段(跳过)|
|samplerate|4|采样率|
|esds扩展(重要)||如果audio type为AAC,需要读取esds扩展，否则音频无法解码。|
|version + flags|4|version + flags|
|tag|1|决定的后续的解析|
|descr length|4|**跳过**|
|Id+priority|2或2+1|<p>如果tag='0x03'为2个字节(**跳过**)</p><p>其他值为2+1个字节(**跳过**)</p><p></p><p></p>|
|tag|1|<p>决定的后续的解析，如果解析正确该值为"0x04"</p><p></p><p></p>|
|descr length|4|<p>**跳过**</p><p></p><p></p>|
|audio type id|1|<p>如果解析正确为'0x40',为CODEC\_ID\_AAC类型</p><p></p><p></p>|
|resved|1+3+4+4|<p>**跳过**</p><p></p><p></p>|
|tag|1|<p>如果解析正确为'0x05'</p><p></p><p></p>|
|descr length|4|<p>Descr data的长度</p><p></p><p></p>|
|Descr data|n|<p>0-3位为采样率查表index</p><p>4-7位为声道的数目</p><p>具体其他信息关系到sbr的一些参数，具体请参看官方文档</p><p></p><p></p>|

其他的实体格式如AMRSampleEntry AMRWPSampleEntry H263SampleEntry等分析同上。

对于"stsd"的表结构如下：


|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|box size|4|box大小|
|box type|4|该类型为"stsd"|
|version|1|box版本，0或1，一般为0|
|flags|3||
|entry count|4|entry的个数|
|entry |n|具体参考上表|
**3.3.2 Time-to-Sample Atoms - STTS**

Time-to-sample atoms存储了media sample的duration 信息，提供了时间对具体data sample的映射方法，通过这个atom，你可以找到任何时间的sample，类型是'stts'。

这个atom可以包含一个压缩的表来映射时间和sample序号，用其他的表来提供每个sample的长度和指针。表中每个条目提供了在同一个时间偏移量里面连续的sample序号， 以及samples的偏移量。递增这些偏移量，就可以建立一个完整的time-to-sample表，计算公式如下

DT(n+1) = DT(n) + STTS(n)

其中STTS(n)是没有压缩的STTS第n项信息，DT是第n个sample的显示时间。Sample的排列是按照时间戳的顺序，这样偏移量永远是非负的。DT一般以0开始，如果不为0，edit list atom 设定初始的DT值。DT计算公式如下

DT(i) = SUM (for j=0 to i-1 of delta(j))

所有偏移量的和就是trak中media的时间的长度。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.171.png)

|` `**字段**|**长度（单位：byte）**|**描述**|
| - | :-: | :-: |
|尺寸|4|这个atom的字节数|
|类型|4|stts|
|版本|1|这个atom的版本|
|标志|3|这里为0|
|条目数目|4|time-to-sample的数目|
|time-to-sample| |Media中每个sample的duration。包含如下结构|
|Sample count|4|有相同duration的连续sample的数目|
|Sample duration|4|每个sample的duration|
如果多个sample有相同的duration，可以只用一项描述所有这些samples，数量字段说明sample的个数。例如，如果一个视频媒体的帧率保持不变，整个表可以只有一项，数量就是全部的帧数。

**3.3.3 Sync Sample Atoms - STSS**

sync sample atom确定media中的关键帧。对于压缩的媒体，关键帧是一系列压缩序列的开始帧，它的解压缩是不依赖于以前的帧。后续帧的解压缩依赖于这个关键帧。

sync sample atom可以非常紧凑的标记媒体内的随机存取点。它包含一个sample序号表，表内的每一项严格按照sample的序号排列，说明了媒体中的哪一个sample是关键帧。如果此表不存在，说明每一个sample都是一个关键帧，是一个随机存取点。

Sync sample atoms 的类型是'stss'。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.172.png)

具体表结构如下：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|尺寸|4|这个atom的字节数|
|类型|4|stss|
|版本|1|这个atom的版本|
|标志|3|这里为0|
|条目数目|4|sync sample的数目|
|sync sample| |sync sample表的结构|
|Sample序号|4|是关键帧的sample序号|

**3.3.4 Sample-to-Chunk Atoms - STSC**

当添加samples到media时，用chunks组织这些sample，这样可以方便优化数据获取。一个trunk包含一个或多个sample，chunk的长度可以不同，chunk内的sample的长度也可以不同。sample-to-chunk atom存储sample与chunk的映射关系。

Sample-to-chunk atoms的类型是'stsc'。它也有一个表来映射sample和trunk之间的关系，查看这张表，就可以找到包含指定sample的trunk，从而找到这个sample。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.173.png)

具体表结构如下：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|尺寸|4|这个atom的字节数|
|类型|4|stsc|
|版本|1|这个atom的版本|
|标志|3|这里为0|
|条目数目|4|sample-to-chunk的数目|
|sample-to-chunk| |sample-to-chunk表的结构|
|First chunk|4|这个table使用的第一个chunk序号|
|Samples per chunk|4|当前trunk内的sample数目|
|Sample description ID|4|与这些sample关联的sample description的序号|
**3.3.5 Sample Size Atoms - STSZ**

sample size atoms定义了每个sample的大小，它的类型是'stsz'，包含了媒体中全部sample的数目和一张给出每个sample大小的表。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.174.png)

具体的表的结构如下：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|尺寸|4|这个atom的字节数|
|类型|4|stsz|
|版本|1|这个atom的版本|
|标志|3|这里为0|
|Sample size|4|全部sample的数目。如果所有的sample有相同的长度，这个字段就是这个值。否则，这个字段的值就是0。那些长度存在sample size表中|
|条目数目|4|sample size的数目|
|sample size|` `4|sample size表的结构。这个表根据sample number索引，第一项就是第一个sample，第二项就是第二个sample|
**3.3.5 Chunk Offset Atoms - STCO**

Chunk offset atoms 定义了每个trunk在媒体流中的位置，它的类型是'stco'。位置有两种可能，32位的和64位的，后者对非常大的电影很有用。在一个表中只会有一种可能，这个位置是在整个文件中的，而不是在任何atom中的，这样做就可以直接在文件中找到媒体数据，而不用解释atom。需要注意的是一旦前面的atom有了任何改变，这张表都要重新建立，因为位置信息已经改变了。

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.175.png)

具体表结构如下：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|尺寸|4|这个atom的字节数|
|类型|4|"stco"或"co64"|
|版本|1|这个atom的版本|
|标志|3|这里为0|
|条目数目|4|chunk offset的数目|
|chunk offset| |字节偏移量从文件开始到当前chunk。这个表根据chunk number索引，第一项就是第一个chunk，第二项就是第二个chunk|
|大小|n|<p>每个sample的大小,如果类型="scto" 大小为4个字节，如果类型="co64"，大小为8个字节</p><p></p><p></p>|

**3.3.6 Composition Time to Sample Box- CTTS**

Composition Time to Sample Box 提供了在dts(解码时间戳)与pts(显示时间戳)的时间的偏移量，它的类型是'ctts'。因为需要纠正时间的帧的pts一定比dts要大，所以每一个项的值一定是正值。具体可以通过pts(n)=dts(n)+ctts(n)进行简单计算。

具体的表结构如下：

|**字段**|**长度（单位：byte）**|**描述**|
| :-: | :-: | :-: |
|尺寸|4|这个atom的字节数|
|类型|4|"ctts"|
|版本|1|这个atom的版本|
|标志|3|这里为0|
|条目数目|4|ctts的数目|
|Sample count|4 |有相同的Sample\_offset的连续sample的数目|
|Sample\_offset|4|dts与pts的时间的残差|
# **第十二章** flv 文件格式分析
## **12.1  概述**
` 	`FLV视频格式是Adobe公司设计开发的一种流媒体的封装格式，总体上看，FLV包括文件头（Flv Header）和文件体（Flv Body）两部分，其中文件体由一系列的Tag及Tag Size对组成。Tag又可以分成三类:audio,video,script，分别代表音频流，视频流，脚本流（关键字或者文件信息之类）。
## **12.2  文件总体结构**
![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.176.jpeg)

其中，Previous Tag Size紧跟在每个Tag之后，占4个字节表示一个UI32类型的数值，表示前面一个Tag的大小。需要注意的是，Previous Tag Size #0的值总是为0。Tag类型包括视频、音频和Script，且每个Tag只能包含一种类型的数据。

具体的工具分析如下：

![](/images/2020/ffmpeg/Aspose.Words.a0ce5ffc-99a8-4e85-b952-e75d3ea7f9c4.177.jpeg "0{YA]KF}OB]KP08[@\_9G78Q")  
## **12.3  文件结构分析**
### **12.3.1  flv文件头的结构**
`    `在ffmpeg进行格式识别的时候，是以头部的前3个字节进行探测，识别到'F' 'L' 'V'即可认定该格式为flv格式。

|**FLV 头部**|**长度(byte)**|**描述**|
| :-: | :-: | :-: |
|文件类型|3|'F' (0x46) 'L' (0x4C) 'V' (0x56)|
|版本|1|版本，目前为1（0x01）|
|流信息|1|<p>1. UB[7]~UB[3]，前5位保留，必须为0。</p><p>2. UB[2] 表示是否存在音频Tag。</p><p>3. UB[1] 该位保留，必须为0。</p><p>4. UB[0] 表示是否存在视频。</p><p></p><p></p>|
|header长度|4|<p>整个文件头的长度，一般是9（3+1+1+4）。个人感觉该字段多余，可以去掉。</p><p></p><p></p>|
由于第一个标识长度的4字节签名无tag，但为了格式上的统一，所以可以划为头部。
### **12.3.2  body主体结构**
`  `Tag包括Tag Header和Tag Data两部分。不同类型的Tag的Header结构是相同的，但是Data结构各不相同。

当前版本的Tag Header结构占用11个字节。

12.3.2.1 Tag Header结构

`   `基于现在版本的Tag Header结构固定占用11个字节，具体描述见下表：

|**字段**|**长度（byte）**|**描述**|
| :-: | :-: | :-: |
|tag type|1|Tag的类型，值：audio=（0x08）、video=（0x09）和script data=（0x12），其他类型值被保留,一般可以直接忽略掉。|
|data size|3|表示该Tag 真实Data部分的大小。|
|timestamp|3|表示该Tag的时间戳（单位为ms），第一个Tag的时间戳总是0。|
|timestampExtended|1|当时间戳24位数值不够时，该字节作为最高位将时间戳扩展为32位值。左移24位与Timestamp值进行或操作|
|streamID|3|表示stream id，总是0|
12.3.2.2 Tag Data结构

` 	`音视频Tag用开始的第1个字节包含视频数据的参数信息，根据Tag Header中的Tag Type类型值为8(音频),值为9(视频),该头部表示的意义会不同，具体结构如下：

1  **音频类型结构如下**

|**字段**|**长度(单位:bit)**|**描述**|
| :-: | :-: | :-: |
|audio format|4|<p>0 -- 未压缩　　</p><p>1 -- ADPCM 　　</p><p>2 -- MP3 　　</p><p>5 -- Nellymoser 8kHz momo 　　</p><p>6 -- Nellymoser 　　</p><p>7 --G.711 A-law logarithmic PCM</p><p>8 --G.711 mu-law logarithmic PCM</p><p>9 -- reserved</p><p>10 --AAC(需要后面附加1个字节，具体见下文)</p><p>11 --Speex</p><p>14--MP3 8-kHz</p><p>15 --Device -specific sound</p><p>Formats 7, 8, 14, and 15 为保留字段，ffmpeg拆包直接跳过</p><p></p><p></p>|
|samplerate|2|<p>0 -- 5.5kHz 　　</p><p>1 -- 11kHz 　　</p><p>2 -- 22kHz 　　</p><p>3 -- 44kHz 　</p><p>没有8kHz的采样率，音频8KHz，一般为人声通话的amr格式所采用，所以该字段和Audio format字段都没有提及。</p><p></p><p></p>|
|sample length|1|<p>即每一帧所占用的位宽。</p><p>0 -- 8Bit 　　</p><p>1 -- 16Bit </p><p></p><p></p>|
|channel type|1|<p>0 --Momo(单声道) 　　</p><p>1 -- Stereo(立体声)</p><p></p><p></p>|
AAC需要注意：

如果SoundFormat是10 (AAC)，TagDataHeader后紧随着一个1个字节的数据AACPacketType，这个字段来表示AACAUDIODATA的类型：0 = AAC sequence header，1 = AAC raw。在flv中一般情况下，带有该AACPacketType 的Tag只会在第一个audio Tag中出现一次，因为aac格式的音频需要在每帧AAC ES流前边添加7个字节ADST头(相当于帧头)，就是AAC的纯ES流要打包成ADST格式的AAC文件，解码器才能正常播放.特别对于RTSP,RTP等实时传输流，ADST必须存在，否则传输过来的流不知道该怎么播放。

1  **视频类型结构如下**

|**字段**|**长度（单位:bit）**|**描述**|
| :-: | :-: | :-: |
|video format|4|<p>1 -- keyframe 　　</p><p>2 -- inner frame 　　</p><p>3 -- disposable inner frame (H.263 only) </p><p></p><p></p>|
|<p>codec id</p><p></p>|4|<p>1 = JPEG（废弃）</p><p>2 -- Seronson H.263 　　</p><p>3 -- Screen video 　　</p><p>4 -- On2 VP6 　</p><p>5 -- On2 VP6 without channel 　　</p><p>6 -- Screen video version 2 　</p><p>7 -- AVC(h264)</p><p></p><p></p>|
大小为：Tag Header中的Data size - Tag Data Header,根据大小读取数据即可。

12.3.2.3  script Tag结构如下

如果TAG包中的TagType==18时，就表示这个TAG是SCRIPT Tag。该类型Tag又通常被称为Metadata Tag，会放一些关于FLV视频和音频的参数信息，如duration、width、height等。通常该类型Tag会跟在File Header后面作为第一个Tag出现，而且只有一个。

一般来说，该Tag Data结构包含两个AMF包。AMF（Action Message Format）是Adobe设计的一种通用数据封装格式，在Adobe的很多产品中应用，简单来说，AMF不区分根节点与子节点，将不同类型的数据用统一的格式来描述。第一个AMF包封装字符串类型数据，即：“02” type+string length+“onMetaData”。第二个AMF包封装一个数组类型，这个数组中包含了音视频信息项的名称和值。

AMF具体表定义和结构如下：

|**字段**|**长度(单位:byte)**|**描述**|
| :-: | :-: | :-: |
|data type|1|数据的类型|
|data|n|<p>If Type = 0, DOUBLE(8个字节)</p><p>If Type = 1, BOOL(1个字节)</p><p>If Type = 2, 后续:2字节(表征字符串长度)+字符串数据</p><p>If Type = 3, 遵从Object  memeber表结构，可以看做array的一个数据项。</p><p>If Type = 8, 遵从MixedArray结构表。</p><p>If Type = 10,遵从normal array表。</p><p>If Type = 11,日期类型</p><p></p><p></p>|
Type='0x08' MixedArray内部结构定义：

|**字段**|**长度(单位:byte)**|**描述**|
| :-: | :-: | :-: |
|object number|4|数组中包括的对象数目。|
|object memeber|n|数据成员具体见下表。|
|end flag|3|数组的结束标志总为'0x09'。|
MixedArray Object memeber具体结构如下（采用key-value结构）：

|**字段**|**长度(单位:byte)**|**描述**|
| :-: | :-: | :-: |
|key length|2|对象的名称长度。|
|stringData|n|对象名称，长度由StringLength指出。|
|object type|1|遵从AMF定义，可以为数组。|
|data|n|遵从AMF定义。|
Type='0x0a' normal array表结构：

|**字段**|**长度(单位:byte)**|**描述**|
| :-: | :-: | :-: |
|object number|4|数组中包括的对象数目。|
|object member|n|遵从AMF表结构。|
|end flag|3|数组的结束标志总为'0x09'。|
在script tag中常用的字段的键表如下：

|**字段**|**类型**|**描述**|
| :-: | :-: | :-: |
|hasKeyFrames|bool|无|
|hasVideo|bool|无|
|hasAudio|bool|无|
|hasMetaData|bool|无|
|canSeekToEnd|bool|无|
|duration|Number|单位为秒|
|datasize|Number|实际的音视频数据的总的大小|
|videosize|Number|实际的视频数据的大小|
|audiosize|Number|实际的音频数据的大小|
|width|Number|视频的原始的宽度|
|height|Number|视频的原始的高度|
|framerate|Number|视频的帧率|
|videodatarate|Number|数值\*1024为比特率|
|audiosamplerate|Number|音频采样率|
|audiosmplesize|Number|音频每个sample的位宽|
|filesize|Number|整体文件的大小|
|lastkeyframestamp|Number|最后关键帧的时间戳|
|lastkeyframelocation|Number|最后关键帧的在文件中的偏移量|
**附加关键帧索引(Keyframes)**

`   `Adobe的官方文档中并没有keyframes头，但是由于flv的每一个tag没有同步头，所以在进行seek时只能不断的通过往下读取数据来进行判断，这在网络流媒体播放时是不能忍受的(优酷的flv都带有keyframes)所以在script tag中加入了该关键帧的索引表，以进行快速的seek等操作。包含着2个内容 'filepositions' and 'times'分别指的是关键帧的文件位置和关键帧的PTS.通过keyframes可以建立起自己的Index，然后再seek和快进快退的操作中，快速有效的跳转到你想要找的关键帧的位置进行处理。

具体结构如下：

keyframes             

`   `- filepositions(在文件中的offset)  value(普通数组，遵从amf协议)

`   `-times(关键帧的时间)  value(普通数组，遵从amf协议)。
# **附录A：常见问题**
## **1 [ffmpeg 从内存中读取数据**](http://blog.csdn.net/leixiaohua1020/article/details/12980423)**
ffmpeg一般情况下支持打开一个本地文件，例如“C:\test.avi”

或者是一个流媒体协议的URL，例如“rtmp://222.31.64.208/vod/test.flv”

其打开文件的函数是avformat\_open\_input()，直接将文件路径或者流媒体URL的字符串传递给该函数就可以了。

但其是否支持从内存中读取数据呢？这个问题困扰了我很长时间。当时在做项目的时候，通过Winpcap抓取网络上的RTP包，打算直接送给ffmpeg进行解码。一直没能找到合适的方法。因为抓取的数据包是存在内存中的，所以无法传递给avformat\_open\_input()函数其路径（根本没有路径= =）。当然也可以将抓取的数据报存成文件，然后用ffmpeg打开这个文件，但是这样的话，程序的就太难控制了。

后来经过分析ffmpeg的源代码，发现其竟然是可以从内存中读取数据的，代码很简单，如下所示：

AVFormatContext \*ic = NULL;  

ic = avformat\_alloc\_context();  

unsigned char \* iobuffer=(unsigned char \*)av\_malloc(32768);  

AVIOContext \*avio =avio\_alloc\_context(iobuffer, 32768,0,buffer,fill\_iobuffer,NULL,NULL);  

ic->pb=avio;  

err = avformat\_open\_input(&ic, is->filename, is->iformat, &format\_opts);  

关键要在avformat\_open\_input()之前初始化一个AVIOContext，而且将原本的AVFormatContext的指针pb（AVIOContext类型）指向这个自行初始化AVIOContext。当自行指定了AVIOContext之后，avformat\_open\_input()里面的URL参数就不起作用了。示例代码开辟了一块空间iobuffer作为AVIOContext的缓存。

此外buffer就是期望读取数据的内存，fill\_iobuffer则是读取buffer数据至iobuffer的回调函数。fill\_iobuffer()形式（参数，返回值）是固定的，是一个回调函数，如下所示（只是个例子，具体怎么读取数据可以自行设计）。

//把数据从buffer向iobuf传-------------------------  

//AVIOContext使用的回调函数！  

//注意：返回值是读取的字节数  

//手动初始化AVIOContext只需要两个东西：内容来源的buffer，和读取这个Buffer到FFmpeg中的函数  

int fill\_iobuffer(void \* buffer,uint8\_t \*iobuf, int bufsize){  

`    `int i;  

`    `for(i=0;i<bufsize;i++){  

`    `iobuf[i]=mediabuf\_get();  

`    `}  

`    `return i;  

}  
## **2 [MFC中使用SDL播放音频没有声音的解决方法**](http://blog.csdn.net/leixiaohua1020/article/details/15029951)**
此处所说的音频是指的纯音频，不包含视频的那种。

在控制台中使用SDL播放音频，一般情况下不会有问题。

但是在MFC中使用SDL播放音频的时候，会出现没有声音的情况。经过长时间探索，没有找到特别好的解决方案，但是有一种方式可以让声音播放出来：那就是让SDL显示图像（视频）时候的那个对话框弹出来，声音就会出现了。

具体的方法可以加载一张图片（比如说BMP），下图所示代码片段为加载BMP图片的代码。

SDL\_Surface \*screen = SDL\_SetVideoMode(640, 480, 8, SDL\_SWSURFACE);  

SDL\_Surface \*image;  

/\* Load the BMP file into a surface \*/  

image = SDL\_LoadBMP("background.bmp");  

if (image == NULL) {  

`    `return 0;  

}  

/\* 

\* Palettized screen modes will have a default palette (a standard 

\* 8\*8\*4 colour cube), but if the image is palettized as well we can 

\* use that palette for a nicer colour matching 

\*/  

if (image->format->palette && screen->format->palette) {  

`    `SDL\_SetColors(screen, image->format->palette->colors, 0,  

`        `image->format->palette->ncolors);  

}  

/\* Blit onto the screen surface \*/  

if(SDL\_BlitSurface(image, NULL, screen, NULL) < 0)  

`    `fprintf(stderr, "BlitSurface error: %s\n", SDL\_GetError());  

SDL\_UpdateRect(screen, 0, 0, image->w, image->h);  

不明白这是为什么，但是程序就可以出声了。
# **附录B：经典代码示例**
**output\_example.c事例代码**

#include <stdlib.h>

#include <stdio.h>

#include <string.h>

#include <math.h>

#ifndef M\_PI

#define M\_PI 3.14159265358979323846

#endif

#include "libavformat/avformat.h"

#include "libswscale/swscale.h"

#undef exit

/\* 5 seconds stream duration \*/

#define STREAM\_DURATION   5.0

#define STREAM\_FRAME\_RATE 25 /\* 25 images/s \*/

#define STREAM\_NB\_FRAMES  ((int)(STREAM\_DURATION \* STREAM\_FRAME\_RATE))

#define STREAM\_PIX\_FMT PIX\_FMT\_YUV420P /\* default pix\_fmt \*/

static int sws\_flags = SWS\_BICUBIC;

/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/

/\* audio output \*/

float t, tincr, tincr2;

int16\_t \*samples;

uint8\_t \*audio\_outbuf;

int audio\_outbuf\_size;

int audio\_input\_frame\_size;

/\*

` `\* add an audio output stream

` `\*/

static AVStream \*add\_audio\_stream(AVFormatContext \*oc, int codec\_id)

{

`    `AVCodecContext \*c;

`    `AVStream \*st;

`    `st = av\_new\_stream(oc, 1);

`    `if (!st) {

`        `fprintf(stderr, "Could not alloc stream\n");

`        `exit(1);

`    `}

`    `c = st->codec;

`    `c->codec\_id = codec\_id;

`    `c->codec\_type = CODEC\_TYPE\_AUDIO;

`    `/\* put sample parameters \*/

`    `c->bit\_rate = 64000;

`    `c->sample\_rate = 44100;

`    `c->channels = 2;

`    `return st;

}

static void open\_audio(AVFormatContext \*oc, AVStream \*st)

{

`    `AVCodecContext \*c;

`    `AVCodec \*codec;

`    `c = st->codec;

`    `/\* find the audio encoder \*/

`    `codec = avcodec\_find\_encoder(c->codec\_id);

`    `if (!codec) {

`        `fprintf(stderr, "codec not found\n");

`        `exit(1);

`    `}

`    `/\* open it \*/

`    `if (avcodec\_open(c, codec) < 0) {

`        `fprintf(stderr, "could not open codec\n");

`        `exit(1);

`    `}

`    `/\* init signal generator \*/

`    `t = 0;

`    `tincr = 2 \* M\_PI \* 110.0 / c->sample\_rate;

`    `/\* increment frequency by 110 Hz per second \*/

`    `tincr2 = 2 \* M\_PI \* 110.0 / c->sample\_rate / c->sample\_rate;

`    `audio\_outbuf\_size = 10000;

`    `audio\_outbuf = av\_malloc(audio\_outbuf\_size);

`    `/\* ugly hack for PCM codecs (will be removed ASAP with new PCM

`       `support to compute the input frame size in samples \*/

`    `if (c->frame\_size <= 1) {

`        `audio\_input\_frame\_size = audio\_outbuf\_size / c->channels;

`        `switch(st->codec->codec\_id) {

`        `case CODEC\_ID\_PCM\_S16LE:

`        `case CODEC\_ID\_PCM\_S16BE:

`        `case CODEC\_ID\_PCM\_U16LE:

`        `case CODEC\_ID\_PCM\_U16BE:

`            `audio\_input\_frame\_size >>= 1;

`            `break;

`        `default:

`            `break;

`        `}

`    `} else {

`        `audio\_input\_frame\_size = c->frame\_size;

`    `}

`    `samples = av\_malloc(audio\_input\_frame\_size \* 2 \* c->channels);

}

/\* prepare a 16 bit dummy audio frame of 'frame\_size' samples and

`   `'nb\_channels' channels \*/

static void get\_audio\_frame(int16\_t \*samples, int frame\_size, int nb\_channels)

{

`    `int j, i, v;

`    `int16\_t \*q;

`    `q = samples;

`    `for(j=0;j<frame\_size;j++) {

`        `v = (int)(sin(t) \* 10000);

`        `for(i = 0; i < nb\_channels; i++)

`            `\*q++ = v;

`        `t += tincr;

`        `tincr += tincr2;

`    `}

}

static void write\_audio\_frame(AVFormatContext \*oc, AVStream \*st)

{

`    `AVCodecContext \*c;

`    `AVPacket pkt;

`    `av\_init\_packet(&pkt);

`    `c = st->codec;

`    `get\_audio\_frame(samples, audio\_input\_frame\_size, c->channels);

`    `pkt.size= avcodec\_encode\_audio(c, audio\_outbuf, audio\_outbuf\_size, samples);

`    `pkt.pts= av\_rescale\_q(c->coded\_frame->pts, c->time\_base, st->time\_base);

`    `pkt.flags |= PKT\_FLAG\_KEY;

`    `pkt.stream\_index= st->index;

`    `pkt.data= audio\_outbuf;

`    `/\* write the compressed frame in the media file \*/

`    `if (av\_write\_frame(oc, &pkt) != 0) {

`        `fprintf(stderr, "Error while writing audio frame\n");

`        `exit(1);

`    `}

}

static void close\_audio(AVFormatContext \*oc, AVStream \*st)

{

`    `avcodec\_close(st->codec);

`    `av\_free(samples);

`    `av\_free(audio\_outbuf);

}

/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/

/\* video output \*/

AVFrame \*picture, \*tmp\_picture;

uint8\_t \*video\_outbuf;

int frame\_count, video\_outbuf\_size;

/\* add a video output stream \*/

static AVStream \*add\_video\_stream(AVFormatContext \*oc, int codec\_id)

{

`    `AVCodecContext \*c;

`    `AVStream \*st;

`    `st = av\_new\_stream(oc, 0);

`    `if (!st) {

`        `fprintf(stderr, "Could not alloc stream\n");

`        `exit(1);

`    `}

`    `c = st->codec;

`    `c->codec\_id = codec\_id;

`    `c->codec\_type = CODEC\_TYPE\_VIDEO;

`    `/\* put sample parameters \*/

`    `c->bit\_rate = 400000;

`    `/\* resolution must be a multiple of two \*/

`    `c->width = 352;

`    `c->height = 288;

`    `/\* time base: this is the fundamental unit of time (in seconds) in terms

`       `of which frame timestamps are represented. for fixed-fps content,

`       `timebase should be 1/framerate and timestamp increments should be

`       `identically 1. \*/

`    `c->time\_base.den = STREAM\_FRAME\_RATE;

`    `c->time\_base.num = 1;

`    `c->gop\_size = 12; /\* emit one intra frame every twelve frames at most \*/

`    `c->pix\_fmt = STREAM\_PIX\_FMT;

`    `if (c->codec\_id == CODEC\_ID\_MPEG2VIDEO) {

`        `/\* just for testing, we also add B frames \*/

`        `c->max\_b\_frames = 2;

`    `}

`    `if (c->codec\_id == CODEC\_ID\_MPEG1VIDEO){

`        `/\* Needed to avoid using macroblocks in which some coeffs overflow.

`           `This does not happen with normal video, it just happens here as

`           `the motion of the chroma plane does not match the luma plane. \*/

`        `c->mb\_decision=2;

`    `}

`    `// some formats want stream headers to be separate

`    `if(!strcmp(oc->oformat->name, "mp4") || !strcmp(oc->oformat->name, "mov") || !strcmp(oc->oformat->name, "3gp"))

`        `c->flags |= CODEC\_FLAG\_GLOBAL\_HEADER;

`    `return st;

}

static AVFrame \*alloc\_picture(int pix\_fmt, int width, int height)

{

`    `AVFrame \*picture;

`    `uint8\_t \*picture\_buf;

`    `int size;

`    `picture = avcodec\_alloc\_frame();

`    `if (!picture)

`        `return NULL;

`    `size = avpicture\_get\_size(pix\_fmt, width, height);

`    `picture\_buf = av\_malloc(size);

`    `if (!picture\_buf) {

`        `av\_free(picture);

`        `return NULL;

`    `}

`    `avpicture\_fill((AVPicture \*)picture, picture\_buf,

`                   `pix\_fmt, width, height);

`    `return picture;

}

static void open\_video(AVFormatContext \*oc, AVStream \*st)

{

`    `AVCodec \*codec;

`    `AVCodecContext \*c;

`    `c = st->codec;

`    `/\* find the video encoder \*/

`    `codec = avcodec\_find\_encoder(c->codec\_id);

`    `if (!codec) {

`        `fprintf(stderr, "codec not found\n");

`        `exit(1);

`    `}

`    `/\* open the codec \*/

`    `if (avcodec\_open(c, codec) < 0) {

`        `fprintf(stderr, "could not open codec\n");

`        `exit(1);

`    `}

`    `video\_outbuf = NULL;

`    `if (!(oc->oformat->flags & AVFMT\_RAWPICTURE)) {

`        `/\* allocate output buffer \*/

`        `/\* XXX: API change will be done \*/

`        `/\* buffers passed into lav\* can be allocated any way you prefer,

`           `as long as they're aligned enough for the architecture, and

`           `they're freed appropriately (such as using av\_free for buffers

`           `allocated with av\_malloc) \*/

`        `video\_outbuf\_size = 200000;

`        `video\_outbuf = av\_malloc(video\_outbuf\_size);

`    `}

`    `/\* allocate the encoded raw picture \*/

`    `picture = alloc\_picture(c->pix\_fmt, c->width, c->height);

`    `if (!picture) {

`        `fprintf(stderr, "Could not allocate picture\n");

`        `exit(1);

`    `}

`    `/\* if the output format is not YUV420P, then a temporary YUV420P

`       `picture is needed too. It is then converted to the required

`       `output format \*/

`    `tmp\_picture = NULL;

`    `if (c->pix\_fmt != PIX\_FMT\_YUV420P) {

`        `tmp\_picture = alloc\_picture(PIX\_FMT\_YUV420P, c->width, c->height);

`        `if (!tmp\_picture) {

`            `fprintf(stderr, "Could not allocate temporary picture\n");

`            `exit(1);

`        `}

`    `}

}

/\* prepare a dummy image \*/

static void fill\_yuv\_image(AVFrame \*pict, int frame\_index, int width, int height)

{

`    `int x, y, i;

`    `i = frame\_index;

`    `/\* Y \*/

`    `for(y=0;y<height;y++) {

`        `for(x=0;x<width;x++) {

`            `pict->data[0][y \* pict->linesize[0] + x] = x + y + i \* 3;

`        `}

`    `}

`    `/\* Cb and Cr \*/

`    `for(y=0;y<height/2;y++) {

`        `for(x=0;x<width/2;x++) {

`            `pict->data[1][y \* pict->linesize[1] + x] = 128 + y + i \* 2;

`            `pict->data[2][y \* pict->linesize[2] + x] = 64 + x + i \* 5;

`        `}

`    `}

}

static void write\_video\_frame(AVFormatContext \*oc, AVStream \*st)

{

`    `int out\_size, ret;

`    `AVCodecContext \*c;

`    `static struct SwsContext \*img\_convert\_ctx;

`    `c = st->codec;

`    `if (frame\_count >= STREAM\_NB\_FRAMES) {

`        `/\* no more frame to compress. The codec has a latency of a few

`           `frames if using B frames, so we get the last frames by

`           `passing the same picture again \*/

`    `} else {

`        `if (c->pix\_fmt != PIX\_FMT\_YUV420P) {

`            `/\* as we only generate a YUV420P picture, we must convert it

`               `to the codec pixel format if needed \*/

`            `if (img\_convert\_ctx == NULL) {

`                `img\_convert\_ctx = sws\_getContext(c->width, c->height,

`                                                 `PIX\_FMT\_YUV420P,

`                                                 `c->width, c->height,

`                                                 `c->pix\_fmt,

`                                                 `sws\_flags, NULL, NULL, NULL);

`                `if (img\_convert\_ctx == NULL) {

`                    `fprintf(stderr, "Cannot initialize the conversion context\n");

`                    `exit(1);

`                `}

`            `}

`            `fill\_yuv\_image(tmp\_picture, frame\_count, c->width, c->height);

`            `sws\_scale(img\_convert\_ctx, tmp\_picture->data, tmp\_picture->linesize,

`                      `0, c->height, picture->data, picture->linesize);

`        `} else {

`            `fill\_yuv\_image(picture, frame\_count, c->width, c->height);

`        `}

`    `}

`    `if (oc->oformat->flags & AVFMT\_RAWPICTURE) {

`        `/\* raw video case. The API will change slightly in the near

`           `futur for that \*/

`        `AVPacket pkt;

`        `av\_init\_packet(&pkt);

`        `pkt.flags |= PKT\_FLAG\_KEY;

`        `pkt.stream\_index= st->index;

`        `pkt.data= (uint8\_t \*)picture;

`        `pkt.size= sizeof(AVPicture);

`        `ret = av\_write\_frame(oc, &pkt);

`    `} else {

`        `/\* encode the image \*/

`        `out\_size = avcodec\_encode\_video(c, video\_outbuf, video\_outbuf\_size, picture);

`        `/\* if zero size, it means the image was buffered \*/

`        `if (out\_size > 0) {

`            `AVPacket pkt;

`            `av\_init\_packet(&pkt);

`            `pkt.pts= av\_rescale\_q(c->coded\_frame->pts, c->time\_base, st->time\_base);

`            `if(c->coded\_frame->key\_frame)

`                `pkt.flags |= PKT\_FLAG\_KEY;

`            `pkt.stream\_index= st->index;

`            `pkt.data= video\_outbuf;

`            `pkt.size= out\_size;

`            `/\* write the compressed frame in the media file \*/

`            `ret = av\_write\_frame(oc, &pkt);

`        `} else {

`            `ret = 0;

`        `}

`    `}

`    `if (ret != 0) {

`        `fprintf(stderr, "Error while writing video frame\n");

`        `exit(1);

`    `}

`    `frame\_count++;

}

static void close\_video(AVFormatContext \*oc, AVStream \*st)

{

`    `avcodec\_close(st->codec);

`    `av\_free(picture->data[0]);

`    `av\_free(picture);

`    `if (tmp\_picture) {

`        `av\_free(tmp\_picture->data[0]);

`        `av\_free(tmp\_picture);

`    `}

`    `av\_free(video\_outbuf);

}

/\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*/

/\* media file output \*/

int main(int argc, char \*\*argv)

{

`    `const char \*filename;

`    `AVOutputFormat \*fmt;

`    `AVFormatContext \*oc;

`    `AVStream \*audio\_st, \*video\_st;

`    `double audio\_pts, video\_pts;

`    `int i;

`    `/\* initialize libavcodec, and register all codecs and formats \*/

`    `av\_register\_all();

`    `if (argc != 2) {

`        `printf("usage: %s output\_file\n"

`               `"API example program to output a media file with libavformat.\n"

`               `"The output format is automatically guessed according to the file extension.\n"

`               `"Raw images can also be output by using '%%d' in the filename\n"

`               `"\n", argv[0]);

`        `exit(1);

`    `}

`    `filename = argv[1];

`    `/\* auto detect the output format from the name. default is

`       `mpeg. \*/

`    `fmt = guess\_format(NULL, filename, NULL);

`    `if (!fmt) {

`        `printf("Could not deduce output format from file extension: using MPEG.\n");

`        `fmt = guess\_format("mpeg", NULL, NULL);

`    `}

`    `if (!fmt) {

`        `fprintf(stderr, "Could not find suitable output format\n");

`        `exit(1);

`    `}

`    `/\* allocate the output media context \*/

`    `oc = av\_alloc\_format\_context();

`    `if (!oc) {

`        `fprintf(stderr, "Memory error\n");

`        `exit(1);

`    `}

`    `oc->oformat = fmt;

`    `snprintf(oc->filename, sizeof(oc->filename), "%s", filename);

`    `/\* add the audio and video streams using the default format codecs

`       `and initialize the codecs \*/

`    `video\_st = NULL;

`    `audio\_st = NULL;

`    `if (fmt->video\_codec != CODEC\_ID\_NONE) {

`        `video\_st = add\_video\_stream(oc, fmt->video\_codec);

`    `}

`    `if (fmt->audio\_codec != CODEC\_ID\_NONE) {

`        `audio\_st = add\_audio\_stream(oc, fmt->audio\_codec);

`    `}

`    `/\* set the output parameters (must be done even if no

`       `parameters). \*/

`    `if (av\_set\_parameters(oc, NULL) < 0) {

`        `fprintf(stderr, "Invalid output format parameters\n");

`        `exit(1);

`    `}

`    `dump\_format(oc, 0, filename, 1);

`    `/\* now that all the parameters are set, we can open the audio and

`       `video codecs and allocate the necessary encode buffers \*/

`    `if (video\_st)

`        `open\_video(oc, video\_st);

`    `if (audio\_st)

`        `open\_audio(oc, audio\_st);

`    `/\* open the output file, if needed \*/

`    `if (!(fmt->flags & AVFMT\_NOFILE)) {

`        `if (url\_fopen(&oc->pb, filename, URL\_WRONLY) < 0) {

`            `fprintf(stderr, "Could not open '%s'\n", filename);

`            `exit(1);

`        `}

`    `}

`    `/\* write the stream header, if any \*/

`    `av\_write\_header(oc);

`    `for(;;) {

`        `/\* compute current audio and video time \*/

`        `if (audio\_st)

`            `audio\_pts = (double)audio\_st->pts.val \* audio\_st->time\_base.num / audio\_st->time\_base.den;

`        `else

`            `audio\_pts = 0.0;

`        `if (video\_st)

`            `video\_pts = (double)video\_st->pts.val \* video\_st->time\_base.num / video\_st->time\_base.den;

`        `else

`            `video\_pts = 0.0;

`        `if ((!audio\_st || audio\_pts >= STREAM\_DURATION) &&

`            `(!video\_st || video\_pts >= STREAM\_DURATION))

`            `break;

`        `/\* write interleaved audio and video frames \*/

`        `if (!video\_st || (video\_st && audio\_st && audio\_pts < video\_pts)) {

`            `write\_audio\_frame(oc, audio\_st);

`        `} else {

`            `write\_video\_frame(oc, video\_st);

`        `}

`    `}

`    `/\* close each codec \*/

`    `if (video\_st)

`        `close\_video(oc, video\_st);

`    `if (audio\_st)

`        `close\_audio(oc, audio\_st);

`    `/\* write the trailer, if any \*/

`    `av\_write\_trailer(oc);

`    `/\* free the streams \*/

`    `for(i = 0; i < oc->nb\_streams; i++) {

`        `av\_freep(&oc->streams[i]->codec);

`        `av\_freep(&oc->streams[i]);

`    `}

`    `if (!(fmt->flags & AVFMT\_NOFILE)) {

`        `/\* close the output file \*/

`        `url\_fclose(&oc->pb);

`    `}

`    `/\* free the stream \*/

`    `av\_free(oc);

`    `return 0;

}
# **附录c：ffmpeg参数中文详细解释**
**a) 通用选项**

-L license

-h 帮助

-fromats 显示可用的格式，编解码的，协议的...

-f fmt 强迫采用格式fmt

-I filename 输入文件

-y 覆盖输出文件

-t duration 设置纪录时间 hh:mm:ss[.xxx]格式的记录时间也支持

-ss position 搜索到指定的时间 [-]hh:mm:ss[.xxx]的格式也支持

-title string 设置标题

-author string 设置作者

-copyright string 设置版权

-comment string 设置评论

-target type 设置目标文件类型(vcd,svcd,dvd) 所有的格式选项（比特率，编解码以及缓冲区大小）自动设置，只需要输入如下的就可以了：ffmpeg -i myfile.avi -target vcd /tmp/vcd.mpg

-hq 激活高质量设置

-itsoffset offset 设置以秒为基准的时间偏移，该选项影响所有后面的输入文件。该偏移被加到输入文件的时戳，定义一个正偏移意味着相应的流被延迟了 offset秒。 [-]hh:mm:ss[.xxx]的格式也支持

**b) 视频选项**

-b bitrate 设置比特率，缺省200kb/s

-r fps 设置帧频 缺省25

-s size 设置帧大小 格式为WXH 缺省160X128.下面的简写也可以直接使用：

Sqcif 128X96 qcif 176X144 cif 252X288 4cif 704X576

-aspect aspect 设置横纵比 4:3 16:9 或 1.3333 1.7777

-croptop size 设置顶部切除带大小 像素单位

-cropbottom size –cropleft size –cropright size

-padtop size 设置顶部补齐的大小 像素单位

-padbottom size –padleft size –padright size –padcolor color 设置补齐条颜色(hex,6个16进制的数，红:绿:兰排列，比如 000000代表黑色)

-vn 不做视频记录

-bt tolerance 设置视频码率容忍度kbit/s

-maxrate bitrate设置最大视频码率容忍度

-minrate bitreate 设置最小视频码率容忍度

-bufsize size 设置码率控制缓冲区大小

-vcodec codec 强制使用codec编解码方式。如果用copy表示原始编解码数据必须被拷贝。

-sameq 使用同样视频质量作为源（VBR）

-pass n 选择处理遍数（1或者2）。两遍编码非常有用。第一遍生成统计信息，第二遍生成精确的请求的码率

-passlogfile file 选择两遍的纪录文件名为file

**c)高级视频选项**

-g gop\_size 设置图像组大小

-intra 仅适用帧内编码

-qscale q 使用固定的视频量化标度(VBR)

-qmin q 最小视频量化标度(VBR)

-qmax q 最大视频量化标度(VBR)

-qdiff q 量化标度间最大偏差 (VBR)

-qblur blur 视频量化标度柔化(VBR)

-qcomp compression 视频量化标度压缩(VBR)

-rc\_init\_cplx complexity 一遍编码的初始复杂度

-b\_qfactor factor 在p和b帧间的qp因子

-i\_qfactor factor 在p和i帧间的qp因子

-b\_qoffset offset 在p和b帧间的qp偏差

-i\_qoffset offset 在p和i帧间的qp偏差

-rc\_eq equation 设置码率控制方程 默认tex^qComp

-rc\_override override 特定间隔下的速率控制重载

-me method 设置运动估计的方法 可用方法有 zero phods log x1 epzs(缺省) full

-dct\_algo algo 设置dct的算法 可用的有 0 FF\_DCT\_AUTO 缺省的DCT 1 FF\_DCT\_FASTINT 2 FF\_DCT\_INT 3 FF\_DCT\_MMX 4 FF\_DCT\_MLIB 5 FF\_DCT\_ALTIVEC

-idct\_algo algo 设置idct算法。可用的有 0 FF\_IDCT\_AUTO 缺省的IDCT 1 FF\_IDCT\_INT 2 FF\_IDCT\_SIMPLE 3 FF\_IDCT\_SIMPLEMMX 4 FF\_IDCT\_LIBMPEG2MMX 5 FF\_IDCT\_PS2 6 FF\_IDCT\_MLIB 7 FF\_IDCT\_ARM 8 FF\_IDCT\_ALTIVEC 9 FF\_IDCT\_SH4 10 FF\_IDCT\_SIMPLEARM

-er n 设置错误残留为n 1 FF\_ER\_CAREFULL 缺省 2 FF\_ER\_COMPLIANT 3 FF\_ER\_AGGRESSIVE 4 FF\_ER\_VERY\_AGGRESSIVE

-ec bit\_mask 设置错误掩蔽为bit\_mask,该值为如下值的位掩码 1 FF\_EC\_GUESS\_MVS (default=enabled) 2 FF\_EC\_DEBLOCK (default=enabled)

-bf frames 使用frames B 帧，支持mpeg1,mpeg2,mpeg4

-mbd mode 宏块决策 0 FF\_MB\_DECISION\_SIMPLE 使用mb\_cmp 1 FF\_MB\_DECISION\_BITS 2 FF\_MB\_DECISION\_RD

-4mv 使用4个运动矢量 仅用于mpeg4

-part 使用数据划分 仅用于mpeg4

-bug param 绕过没有被自动监测到编码器的问题

-strict strictness 跟标准的严格性

-aic 使能高级帧内编码 h263+

-umv 使能无限运动矢量 h263+

-deinterlace 不采用交织方法

-interlace 强迫交织法编码仅对mpeg2和mpeg4有效。当你的输入是交织的并且你想要保持交织以最小图像损失的时候采用该选项。可选的方法是不交织，但是损失更大

-psnr 计算压缩帧的psnr

-vstats 输出视频编码统计到vstats\_hhmmss.log

-vhook module 插入视频处理模块 module 包括了模块名和参数，用空格分开

**D)音频选项**

-ab bitrate 设置音频码率

-ar freq 设置音频采样率

-ac channels 设置通道 缺省为1

-an 不使能音频纪录

-acodec codec 使用codec编解码

**E)音频/视频捕获选项**

-vd device 设置视频捕获设备。比如/dev/video0

-vc channel 设置视频捕获通道 DV1394专用

-tvstd standard 设置电视标准 NTSC PAL(SECAM)

-dv1394 设置DV1394捕获

-av device 设置音频设备 比如/dev/dsp

**F)高级选项**

-map file:stream 设置输入流映射

-debug 打印特定调试信息

-benchmark 为基准测试加入时间

-hex 倾倒每一个输入包

-bitexact 仅使用位精确算法 用于编解码测试

-ps size 设置包大小，以bits为单位

-re 以本地帧频读数据，主要用于模拟捕获设备

-loop 循环输入流（只工作于图像流，用于ffserver测试）
# **附录D：[ffplay的快捷键以及选项**](http://blog.csdn.net/leixiaohua1020/article/details/15186441)**
ffplay是ffmpeg工程中提供的播放器，功能相当的强大，凡是ffmpeg支持的视音频格式它基本上都支持。甚至连VLC不支持的一些流媒体都可以播放（比如说RTMP），但是它的缺点是其不是图形化界面的，必须通过键盘来操作。因此本文介绍一下它的快捷键以及选项。

快捷键

` `播放视音频文件的时候，可以通过下列按键控制视音频的播放

|按键|作用|
| - | - |
|q, ESC|退出|
|F|全屏|
|p,空格|暂停|
|w|显示音频波形|
|s|逐帧显示|
|左/右方向键|向后/前10s|
|上/下方向键|向后/前1min|
|page down/page up|向后/前10min|
|鼠标点击屏幕|跳转到指定位置（根据鼠标位置相对屏幕的宽度计算）|
选项

在播放视频前，可以预设一些参数。

一般播放视频的时候，使用命令：

#ffplay "abc.flv"  

如果我们希望能在播放完成后自动退出，则可以使用命令：

ffplay -autoexit "abc.flv";  

所有的命令如下列表所示：

|名称|有参数|作用|
| - | - | - |
|x|Y|强制屏幕宽度|
|y|Y|强制屏幕高度|
|s|Y|强制屏幕大小|
|fs|N|全屏|
|an|N|关闭音频|
|vn|N|关闭视频|
|ast|Y|设置想播放的音频流（需要指定流ID）|
|vst|Y|设置想播放的视频流（需要指定流ID）|
|sst|Y|设置想播放的字幕流（需要指定流ID）|
|ss|Y|从指定位置开始播放，单位是秒|
|t|Y|播放指定时长的视频|
|nodisp|N|无显示屏幕|
|f|Y|强制封装格式|
|pix\_fmt|Y|指定像素格式|
|stats|N|显示统计信息|
|idct|Y|IDCT算法|
|ec|Y|错误隐藏方法|
|sync|Y|视音频同步方式（type=audio/video/ext）|
|autoexit|N|播放完成自动退出|
|exitonkeydown|N|按下按键退出|
|exitonmousedown|N|按下鼠标退出|
|loop|Y|指定循环次数|
|framedrop|N|CPU不够的时候丢帧|
|window\_title|Y|显示窗口的标题|
|rdftspeed|Y|Rdft速度|
|showmode|Y|显示方式(0 = video, 1 = waves, 2 = RDFT)|
|codec|Y|强制解码器|
# **附录E： ffmpeg处理rtmp流媒体**
1、将文件当做直播送至live

ffmpeg -re -i localFile.mp4 -c copy -f flv rtmp://server/live/streamName  

2、将直播媒体保存至本地文件

ffmpeg -i rtmp://server/live/streamName -c copy dump.flv  

3、将其中一个直播流，视频改用h264压缩，音频不变，送至另外一个直播服务流

ffmpeg -i rtmp://server/live/originalStream -c:a copy -c:v libx264 -vpre slow -f flv rtmp://server/live/h264Stream  

4、将其中一个直播流，视频改用h264压缩，音频改用faac压缩，送至另外一个直播服务流

ffmpeg -i rtmp://server/live/originalStream -c:a libfaac -ar 44100 -ab 48k -c:v libx264 -vpre slow -vpre baseline -f flv rtmp://server/live/h264Stream  

5、将其中一个直播流，视频不变，音频改用faac压缩，送至另外一个直播服务流

ffmpeg -i rtmp://server/live/originalStream -acodec libfaac -ar 44100 -ab 48k -vcodec copy -f flv rtmp://server/live/h264\_AAC\_Stream  

6、将一个高清流，复制为几个不同视频清晰度的流重新发布，其中音频不变

ffmpeg -re -i rtmp://server/live/high\_FMLE\_stream -acodec copy -vcodec x264lib -s 640×360 -b 500k -vpre medium -vpre baseline rtmp://server/live/baseline\_500k -acodec copy -vcodec x264lib -s 480×272 -b 300k -vpre medium -vpre baseline rtmp://server/live/baseline\_300k -acodec copy -vcodec x264lib -s 320×200 -b 150k -vpre medium -vpre baseline rtmp://server/live/baseline\_150k -acodec libfaac -vn -ab 48k rtmp://server/live/audio\_only\_AAC\_48k  

7、功能一样，只是采用-x264opts选项

ffmpeg -re -i rtmp://server/live/high\_FMLE\_stream -c:a copy -c:v x264lib -s 640×360 -x264opts bitrate=500:profile=baseline:preset=slow rtmp://server/live/baseline\_500k -c:a copy -c:v x264lib -s 480×272 -x264opts bitrate=300:profile=baseline:preset=slow rtmp://server/live/baseline\_300k -c:a copy -c:v x264lib -s 320×200 -x264opts bitrate=150:profile=baseline:preset=slow rtmp://server/live/baseline\_150k -c:a libfaac -vn -b:a 48k rtmp://server/live/audio\_only\_AAC\_48k  

8、将当前摄像头及音频通过DSSHOW采集，视频h264、音频faac压缩后发布

ffmpeg -r 25 -f dshow -s 640×480 -i video=”video source name”:audio=”audio source name” -vcodec libx264 -b 600k -vpre slow -acodec libfaac -ab 128k rtmp://server/application/stream\_name  

9、将一个JPG图片经过h264压缩循环输出为mp4视频

ffmpeg.exe -i INPUT.jpg -an -vcodec libx264 -coder 1 -flags +loop -cmp +chroma -subq 10 -qcomp 0.6 -qmin 10 -qmax 51 -qdiff 4 -flags2 +dct8x8 -trellis 2 -partitions +parti8x8+parti4x4 -crf 24 -threads 0 -r 25 -g 25 -y OUTPUT.mp4  

10、将普通流视频改用h264压缩，音频不变，送至高清流服务(新版本FMS live=1)

ffmpeg -i rtmp://server/live/originalStream -c:a copy -c:v libx264 -vpre slow -f flv “rtmp://server/live/h264Stream live=1″  

